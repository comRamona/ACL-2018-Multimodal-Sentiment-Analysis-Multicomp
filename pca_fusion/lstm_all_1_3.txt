/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 00:20:31.799323: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.7091 - acc: 0.4375
 128/1283 [=>............................] - ETA: 7s - loss: 0.7143 - acc: 0.4219 
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7132 - acc: 0.4479
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7087 - acc: 0.4492
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7049 - acc: 0.4688
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7043 - acc: 0.4792
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7011 - acc: 0.5067
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6993 - acc: 0.5117
 576/1283 [============>.................] - ETA: 1s - loss: 0.6975 - acc: 0.5208
 640/1283 [=============>................] - ETA: 1s - loss: 0.6956 - acc: 0.5266
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6959 - acc: 0.5156
 768/1283 [================>.............] - ETA: 0s - loss: 0.6946 - acc: 0.5221
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6904 - acc: 0.5301
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6900 - acc: 0.5333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6888 - acc: 0.5400
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6872 - acc: 0.5460
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6871 - acc: 0.5451
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6859 - acc: 0.5477
1280/1283 [============================>.] - ETA: 0s - loss: 0.6846 - acc: 0.5523
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6847 - acc: 0.5526 - val_loss: 0.6577 - val_acc: 0.6550

Epoch 00001: val_acc improved from -inf to 0.65502, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6345 - acc: 0.6719
 128/1283 [=>............................] - ETA: 1s - loss: 0.6319 - acc: 0.6797
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6252 - acc: 0.6979
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6311 - acc: 0.6953
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6357 - acc: 0.6719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6285 - acc: 0.6953
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6283 - acc: 0.6987
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6277 - acc: 0.6973
 576/1283 [============>.................] - ETA: 0s - loss: 0.6272 - acc: 0.7014
 640/1283 [=============>................] - ETA: 0s - loss: 0.6271 - acc: 0.6969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6247 - acc: 0.7003
 768/1283 [================>.............] - ETA: 0s - loss: 0.6228 - acc: 0.7070
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6209 - acc: 0.7103
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6204 - acc: 0.7098
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6182 - acc: 0.7135
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6165 - acc: 0.7148
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6143 - acc: 0.7215
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6128 - acc: 0.7240
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6122 - acc: 0.7237
1280/1283 [============================>.] - ETA: 0s - loss: 0.6109 - acc: 0.7227
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6107 - acc: 0.7233 - val_loss: 0.6261 - val_acc: 0.6638

Epoch 00002: val_acc improved from 0.65502 to 0.66376, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5387 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.5521 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5581 - acc: 0.7708
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5517 - acc: 0.7875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5533 - acc: 0.7839
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5518 - acc: 0.7879
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5413 - acc: 0.7988
 576/1283 [============>.................] - ETA: 0s - loss: 0.5396 - acc: 0.7934
 640/1283 [=============>................] - ETA: 0s - loss: 0.5409 - acc: 0.7891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5385 - acc: 0.7926
 768/1283 [================>.............] - ETA: 0s - loss: 0.5371 - acc: 0.7917
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5339 - acc: 0.7933
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5334 - acc: 0.7935
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5321 - acc: 0.7937
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5300 - acc: 0.7979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5273 - acc: 0.7987
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5262 - acc: 0.8012
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5206 - acc: 0.8067
1280/1283 [============================>.] - ETA: 0s - loss: 0.5197 - acc: 0.8063
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5192 - acc: 0.8067 - val_loss: 0.5785 - val_acc: 0.7205

Epoch 00003: val_acc improved from 0.66376 to 0.72052, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4638 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4690 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4410 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4435 - acc: 0.8398
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4468 - acc: 0.8375
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4529 - acc: 0.8255
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4396 - acc: 0.8348
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4441 - acc: 0.8281
 576/1283 [============>.................] - ETA: 0s - loss: 0.4312 - acc: 0.8420
 640/1283 [=============>................] - ETA: 0s - loss: 0.4258 - acc: 0.8438
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4231 - acc: 0.8452
 768/1283 [================>.............] - ETA: 0s - loss: 0.4222 - acc: 0.8438
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4275 - acc: 0.8389
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4272 - acc: 0.8404
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4243 - acc: 0.8396
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4213 - acc: 0.8398
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4215 - acc: 0.8382
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4204 - acc: 0.8377
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4200 - acc: 0.8372
1280/1283 [============================>.] - ETA: 0s - loss: 0.4182 - acc: 0.8359
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4195 - acc: 0.8348 - val_loss: 0.5723 - val_acc: 0.6943

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3376 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.3490 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3396 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3380 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3380 - acc: 0.8969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3301 - acc: 0.8984
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3289 - acc: 0.8973
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3247 - acc: 0.8965
 576/1283 [============>.................] - ETA: 0s - loss: 0.3337 - acc: 0.8889
 640/1283 [=============>................] - ETA: 0s - loss: 0.3333 - acc: 0.8922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3314 - acc: 0.8920
 768/1283 [================>.............] - ETA: 0s - loss: 0.3291 - acc: 0.8919
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3282 - acc: 0.8930
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3321 - acc: 0.8884
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3336 - acc: 0.8865
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3388 - acc: 0.8828
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3380 - acc: 0.8833
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3380 - acc: 0.8828
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3372 - acc: 0.8799
1280/1283 [============================>.] - ETA: 0s - loss: 0.3367 - acc: 0.8781
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3364 - acc: 0.8784 - val_loss: 0.5636 - val_acc: 0.7293

Epoch 00005: val_acc improved from 0.72052 to 0.72926, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2633 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.2535 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2718 - acc: 0.8854
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2648 - acc: 0.8945
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2798 - acc: 0.8844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2904 - acc: 0.8802
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2848 - acc: 0.8817
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2861 - acc: 0.8789
 576/1283 [============>.................] - ETA: 0s - loss: 0.2817 - acc: 0.8854
 640/1283 [=============>................] - ETA: 0s - loss: 0.2839 - acc: 0.8859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2836 - acc: 0.8864
 768/1283 [================>.............] - ETA: 0s - loss: 0.2805 - acc: 0.8893
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2764 - acc: 0.8930
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2774 - acc: 0.8906
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2799 - acc: 0.8896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2762 - acc: 0.8916
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2734 - acc: 0.8943
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2717 - acc: 0.8950
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2669 - acc: 0.8997
1280/1283 [============================>.] - ETA: 0s - loss: 0.2662 - acc: 0.9000
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2677 - acc: 0.8995 - val_loss: 0.5803 - val_acc: 0.7293

Epoch 00006: val_acc improved from 0.72926 to 0.72926, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1917 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1873 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1996 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1935 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1903 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2040 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2084 - acc: 0.9397
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2090 - acc: 0.9355
 576/1283 [============>.................] - ETA: 1s - loss: 0.2039 - acc: 0.9392
 640/1283 [=============>................] - ETA: 0s - loss: 0.2010 - acc: 0.9406
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1996 - acc: 0.9403
 768/1283 [================>.............] - ETA: 0s - loss: 0.1986 - acc: 0.9414
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1952 - acc: 0.9435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1966 - acc: 0.9420
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1942 - acc: 0.9448
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1922 - acc: 0.9473
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1924 - acc: 0.9467
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1929 - acc: 0.9462
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1907 - acc: 0.9474
1280/1283 [============================>.] - ETA: 0s - loss: 0.1892 - acc: 0.9484
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1892 - acc: 0.9486 - val_loss: 0.6514 - val_acc: 0.6943

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1707 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1663 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1729 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1660 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1594 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1498 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1422 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1352 - acc: 0.9688
 576/1283 [============>.................] - ETA: 1s - loss: 0.1322 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.1365 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1368 - acc: 0.9631
 768/1283 [================>.............] - ETA: 0s - loss: 0.1380 - acc: 0.9609
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1410 - acc: 0.9615
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1380 - acc: 0.9643
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1352 - acc: 0.9656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1354 - acc: 0.9668
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1357 - acc: 0.9660
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1361 - acc: 0.9670
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1378 - acc: 0.9663
1280/1283 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9656
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1383 - acc: 0.9657 - val_loss: 0.6964 - val_acc: 0.7074

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1170 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1325 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1095 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0966 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1081 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1086 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1101 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1070 - acc: 0.9766
 576/1283 [============>.................] - ETA: 1s - loss: 0.1018 - acc: 0.9792
 640/1283 [=============>................] - ETA: 0s - loss: 0.1019 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0989 - acc: 0.9773
 768/1283 [================>.............] - ETA: 0s - loss: 0.1016 - acc: 0.9753
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1026 - acc: 0.9748
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1002 - acc: 0.9766
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1043 - acc: 0.9740
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1016 - acc: 0.9756
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1004 - acc: 0.9770
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1021 - acc: 0.9740
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1011 - acc: 0.9753
1280/1283 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9734
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1043 - acc: 0.9735 - val_loss: 0.7629 - val_acc: 0.6943

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0780 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0757 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0784 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0804 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0847 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0828 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0795 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0764 - acc: 0.9883
 576/1283 [============>.................] - ETA: 0s - loss: 0.0736 - acc: 0.9896
 640/1283 [=============>................] - ETA: 0s - loss: 0.0748 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0722 - acc: 0.9886
 768/1283 [================>.............] - ETA: 0s - loss: 0.0723 - acc: 0.9870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0779 - acc: 0.9820
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0787 - acc: 0.9833
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0784 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0753 - acc: 0.9854
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0763 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0759 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0737 - acc: 0.9852
1280/1283 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9852
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0723 - acc: 0.9852 - val_loss: 0.7676 - val_acc: 0.7293

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0501 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0435 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0438 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0399 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0358 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0370 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0367 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0368 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0393 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0421 - acc: 0.9906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0417 - acc: 0.9915
 768/1283 [================>.............] - ETA: 0s - loss: 0.0401 - acc: 0.9922
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0395 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0390 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0391 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0399 - acc: 0.9922
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0396 - acc: 0.9926
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0405 - acc: 0.9922
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0401 - acc: 0.9926
1280/1283 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9930
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0423 - acc: 0.9922 - val_loss: 0.8258 - val_acc: 0.7293

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0442 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0360 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0417 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0459 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0474 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0478 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0506 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0467 - acc: 0.9902
 576/1283 [============>.................] - ETA: 0s - loss: 0.0471 - acc: 0.9896
 640/1283 [=============>................] - ETA: 0s - loss: 0.0456 - acc: 0.9906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0480 - acc: 0.9901
 768/1283 [================>.............] - ETA: 0s - loss: 0.0466 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0453 - acc: 0.9916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0453 - acc: 0.9922
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0440 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0433 - acc: 0.9922
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0434 - acc: 0.9926
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0450 - acc: 0.9922
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0453 - acc: 0.9926
1280/1283 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9914
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0470 - acc: 0.9914 - val_loss: 0.9113 - val_acc: 0.7162

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0645 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0437 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0379 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0467 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0442 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0476 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0437 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0429 - acc: 0.9902
 576/1283 [============>.................] - ETA: 0s - loss: 0.0439 - acc: 0.9896
 640/1283 [=============>................] - ETA: 0s - loss: 0.0449 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0424 - acc: 0.9886
 768/1283 [================>.............] - ETA: 0s - loss: 0.0410 - acc: 0.9896
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0406 - acc: 0.9892
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0415 - acc: 0.9888
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0409 - acc: 0.9896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0399 - acc: 0.9902
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0387 - acc: 0.9908
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0380 - acc: 0.9913
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0367 - acc: 0.9918
1280/1283 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9922
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0363 - acc: 0.9922 - val_loss: 0.9039 - val_acc: 0.7031

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0234 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0187 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0157 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0157 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0157 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0186 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0193 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0189 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0210 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0205 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0216 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0211 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0201 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0202 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0195 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0199 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0208 - acc: 0.9982
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0212 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9977
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0208 - acc: 0.9977 - val_loss: 0.9667 - val_acc: 0.7031

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0089 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0140 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0151 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0142 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0144 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0140 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0142 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0141 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0159 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0156 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0152 - acc: 0.9987
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0148 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0148 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0144 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0143 - acc: 0.9991
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0143 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9992
1280/1283 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9992
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0142 - acc: 0.9992 - val_loss: 1.0096 - val_acc: 0.7074

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0155 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0133 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0123 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0123 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0124 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0115 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0115 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0107 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0110 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0112 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0116 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0114 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 1.0000
1283/1283 [==============================] - 1s 889us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 1.0538 - val_acc: 0.7074

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=25
nodes=100
mode=all
PCA audio=10
PCA visual=25
PCA text=110
accuracy=0.6895043731778425
best_valid_accuracy=0.6793002915451894
