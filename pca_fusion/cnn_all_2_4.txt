/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 01:41:48.645470: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.7730 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 1s - loss: 0.8356 - acc: 0.4896
 384/1283 [=======>......................] - ETA: 0s - loss: 0.7784 - acc: 0.5260
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7525 - acc: 0.5430
 640/1283 [=============>................] - ETA: 0s - loss: 0.7344 - acc: 0.5531
 768/1283 [================>.............] - ETA: 0s - loss: 0.7372 - acc: 0.5495
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7347 - acc: 0.5558
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7290 - acc: 0.5449
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7207 - acc: 0.5452
1283/1283 [==============================] - 1s 693us/step - loss: 0.7204 - acc: 0.5448 - val_loss: 0.7010 - val_acc: 0.5590

Epoch 00001: val_acc improved from -inf to 0.55895, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5565 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5603 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5387 - acc: 0.7156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5224 - acc: 0.7388
 640/1283 [=============>................] - ETA: 0s - loss: 0.5281 - acc: 0.7312
 768/1283 [================>.............] - ETA: 0s - loss: 0.5210 - acc: 0.7370
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5237 - acc: 0.7299
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5129 - acc: 0.7480
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5034 - acc: 0.7604
1280/1283 [============================>.] - ETA: 0s - loss: 0.4984 - acc: 0.7664
1283/1283 [==============================] - 1s 495us/step - loss: 0.4984 - acc: 0.7662 - val_loss: 0.6723 - val_acc: 0.6114

Epoch 00002: val_acc improved from 0.55895 to 0.61135, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3286 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3187 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3353 - acc: 0.8938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3293 - acc: 0.8951
 576/1283 [============>.................] - ETA: 0s - loss: 0.3252 - acc: 0.8837
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3227 - acc: 0.8835
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3219 - acc: 0.8858
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3179 - acc: 0.8865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3144 - acc: 0.8888
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3102 - acc: 0.8873
1283/1283 [==============================] - 1s 511us/step - loss: 0.3077 - acc: 0.8893 - val_loss: 0.7104 - val_acc: 0.6245

Epoch 00003: val_acc improved from 0.61135 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1775 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1670 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1702 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1766 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.1705 - acc: 0.9601
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1674 - acc: 0.9560
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1607 - acc: 0.9603
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1592 - acc: 0.9594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1581 - acc: 0.9586
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1545 - acc: 0.9605
1283/1283 [==============================] - 1s 566us/step - loss: 0.1530 - acc: 0.9595 - val_loss: 0.8149 - val_acc: 0.6419

Epoch 00004: val_acc improved from 0.62445 to 0.64192, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0751 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0780 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0770 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0722 - acc: 0.9888
 576/1283 [============>.................] - ETA: 0s - loss: 0.0664 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0649 - acc: 0.9915
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0656 - acc: 0.9904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0644 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0626 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0620 - acc: 0.9901
1283/1283 [==============================] - 1s 587us/step - loss: 0.0601 - acc: 0.9906 - val_loss: 0.9678 - val_acc: 0.6157

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0252 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0278 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0284 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0259 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0249 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0248 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0247 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0246 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0249 - acc: 1.0000
1283/1283 [==============================] - 1s 507us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.9922 - val_acc: 0.6332

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0129 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0170 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0133 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0134 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0124 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0126 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0118 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0114 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 1.0000
1283/1283 [==============================] - 1s 475us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1674 - val_acc: 0.6638

Epoch 00007: val_acc improved from 0.64192 to 0.66376, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0050 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0057 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0057 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0053 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0051 - acc: 1.0000
1283/1283 [==============================] - 0s 331us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 1.2016 - val_acc: 0.6463

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0042 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0040 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0038 - acc: 1.0000
1283/1283 [==============================] - 0s 304us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.2607 - val_acc: 0.6332

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0029 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0044 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0039 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0037 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 1.0000
1283/1283 [==============================] - 0s 289us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.3562 - val_acc: 0.6376

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0021 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0020 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0019 - acc: 1.0000
1283/1283 [==============================] - 0s 314us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.3783 - val_acc: 0.6332

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 8.4104e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0026 - acc: 1.0000    
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0017 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0016 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1283/1283 [==============================] - 0s 308us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.4032 - val_acc: 0.6376

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 7.8812e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 8.9435e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 9.3504e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0011 - acc: 1.0000    
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0011 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0010 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 1.0000
1283/1283 [==============================] - 0s 285us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.4154 - val_acc: 0.6463

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 4.5301e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0012 - acc: 1.0000    
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0014 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0012 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0011 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 9.8988e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 1.0000    
1283/1283 [==============================] - 0s 300us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.4202 - val_acc: 0.6463

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 5.9940e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 8.9076e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0018 - acc: 1.0000    
 640/1283 [=============>................] - ETA: 0s - loss: 0.0015 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1283/1283 [==============================] - 0s 303us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.5060 - val_acc: 0.6507

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 6.7042e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0038 - acc: 1.0000    
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0024 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0026 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0026 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 1.0000
1283/1283 [==============================] - 0s 299us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.6823 - val_acc: 0.6332

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0045 - acc: 0.9986
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0044 - acc: 0.9989
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0045 - acc: 0.9991
1283/1283 [==============================] - 0s 289us/step - loss: 0.0043 - acc: 0.9992 - val_loss: 1.6965 - val_acc: 0.6550

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
nodes=100
mode=all
PCA audio=20
PCA visual=15
PCA text=130
accuracy=0.6705539358600583
best_valid_accuracy=0.6472303206997084
