/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 02:07:08.247600: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 14s - loss: 0.9055 - acc: 0.4531
 128/1283 [=>............................] - ETA: 7s - loss: 1.0282 - acc: 0.5391 
 192/1283 [===>..........................] - ETA: 5s - loss: 1.1616 - acc: 0.5365
 256/1283 [====>.........................] - ETA: 4s - loss: 1.0816 - acc: 0.5352
 320/1283 [======>.......................] - ETA: 3s - loss: 1.0339 - acc: 0.5156
 384/1283 [=======>......................] - ETA: 3s - loss: 0.9999 - acc: 0.5156
 448/1283 [=========>....................] - ETA: 2s - loss: 0.9690 - acc: 0.5045
 512/1283 [==========>...................] - ETA: 2s - loss: 0.9416 - acc: 0.5059
 576/1283 [============>.................] - ETA: 1s - loss: 0.9204 - acc: 0.5069
 640/1283 [=============>................] - ETA: 1s - loss: 0.9001 - acc: 0.5188
 704/1283 [===============>..............] - ETA: 1s - loss: 0.8795 - acc: 0.5256
 768/1283 [================>.............] - ETA: 1s - loss: 0.8711 - acc: 0.5247
 832/1283 [==================>...........] - ETA: 1s - loss: 0.8542 - acc: 0.5312
 896/1283 [===================>..........] - ETA: 0s - loss: 0.8448 - acc: 0.5346
 960/1283 [=====================>........] - ETA: 0s - loss: 0.8354 - acc: 0.5375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.8307 - acc: 0.5312
1088/1283 [========================>.....] - ETA: 0s - loss: 0.8234 - acc: 0.5303
1152/1283 [=========================>....] - ETA: 0s - loss: 0.8199 - acc: 0.5260
1216/1283 [===========================>..] - ETA: 0s - loss: 0.8133 - acc: 0.5296
1280/1283 [============================>.] - ETA: 0s - loss: 0.8019 - acc: 0.5398
1283/1283 [==============================] - 3s 2ms/step - loss: 0.8020 - acc: 0.5386 - val_loss: 0.7060 - val_acc: 0.5721

Epoch 00001: val_acc improved from -inf to 0.57205, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5781 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.5893 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5826 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5740 - acc: 0.7500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5662 - acc: 0.7422
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5565 - acc: 0.7545
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5604 - acc: 0.7402
 576/1283 [============>.................] - ETA: 0s - loss: 0.5572 - acc: 0.7361
 640/1283 [=============>................] - ETA: 0s - loss: 0.5665 - acc: 0.7250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5629 - acc: 0.7358
 768/1283 [================>.............] - ETA: 0s - loss: 0.5589 - acc: 0.7409
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5513 - acc: 0.7536
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5563 - acc: 0.7444
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5573 - acc: 0.7406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5520 - acc: 0.7461
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5481 - acc: 0.7463
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5478 - acc: 0.7457
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5454 - acc: 0.7484
1280/1283 [============================>.] - ETA: 0s - loss: 0.5446 - acc: 0.7477
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5443 - acc: 0.7482 - val_loss: 0.6808 - val_acc: 0.5939

Epoch 00002: val_acc improved from 0.57205 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4164 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.4076 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4074 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3922 - acc: 0.8633
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3984 - acc: 0.8656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3926 - acc: 0.8802
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3874 - acc: 0.8817
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3854 - acc: 0.8789
 576/1283 [============>.................] - ETA: 0s - loss: 0.3895 - acc: 0.8767
 640/1283 [=============>................] - ETA: 0s - loss: 0.3849 - acc: 0.8844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3829 - acc: 0.8878
 768/1283 [================>.............] - ETA: 0s - loss: 0.3812 - acc: 0.8893
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3828 - acc: 0.8834
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3826 - acc: 0.8806
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3827 - acc: 0.8792
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3848 - acc: 0.8750
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3862 - acc: 0.8722
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3830 - acc: 0.8724
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3811 - acc: 0.8717
1280/1283 [============================>.] - ETA: 0s - loss: 0.3806 - acc: 0.8695
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3806 - acc: 0.8691 - val_loss: 0.6891 - val_acc: 0.6070

Epoch 00003: val_acc improved from 0.59389 to 0.60699, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2988 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.2823 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2734 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2713 - acc: 0.9414
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2723 - acc: 0.9344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2714 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2621 - acc: 0.9397
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2610 - acc: 0.9355
 576/1283 [============>.................] - ETA: 1s - loss: 0.2598 - acc: 0.9340
 640/1283 [=============>................] - ETA: 0s - loss: 0.2577 - acc: 0.9344
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2626 - acc: 0.9261
 768/1283 [================>.............] - ETA: 0s - loss: 0.2629 - acc: 0.9258
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2624 - acc: 0.9255
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2599 - acc: 0.9275
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2566 - acc: 0.9271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2569 - acc: 0.9248
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2579 - acc: 0.9219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2576 - acc: 0.9193
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2543 - acc: 0.9211
1280/1283 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.9219
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2525 - acc: 0.9221 - val_loss: 0.7686 - val_acc: 0.6245

Epoch 00004: val_acc improved from 0.60699 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1680 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1861 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1869 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1736 - acc: 0.9492
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1671 - acc: 0.9500
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1725 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1732 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1743 - acc: 0.9492
 576/1283 [============>.................] - ETA: 1s - loss: 0.1716 - acc: 0.9497
 640/1283 [=============>................] - ETA: 1s - loss: 0.1679 - acc: 0.9531
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1685 - acc: 0.9517
 768/1283 [================>.............] - ETA: 0s - loss: 0.1700 - acc: 0.9531
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1701 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1682 - acc: 0.9542
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1656 - acc: 0.9563
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1654 - acc: 0.9570
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1639 - acc: 0.9577
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1608 - acc: 0.9592
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1579 - acc: 0.9613
1280/1283 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9609
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1608 - acc: 0.9602 - val_loss: 0.8185 - val_acc: 0.6550

Epoch 00005: val_acc improved from 0.62445 to 0.65502, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1088 - acc: 0.9688
 128/1283 [=>............................] - ETA: 2s - loss: 0.1020 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1172 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1110 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1106 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1087 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1078 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1108 - acc: 0.9727
 576/1283 [============>.................] - ETA: 1s - loss: 0.1079 - acc: 0.9740
 640/1283 [=============>................] - ETA: 1s - loss: 0.1055 - acc: 0.9750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1087 - acc: 0.9716
 768/1283 [================>.............] - ETA: 0s - loss: 0.1084 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1102 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1076 - acc: 0.9721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1059 - acc: 0.9719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1044 - acc: 0.9736
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1052 - acc: 0.9724
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1038 - acc: 0.9731
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1029 - acc: 0.9745
1280/1283 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9750
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1009 - acc: 0.9751 - val_loss: 0.8898 - val_acc: 0.6550

Epoch 00006: val_acc improved from 0.65502 to 0.65502, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0686 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0673 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0672 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0586 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0592 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0593 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0612 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0656 - acc: 0.9883
 576/1283 [============>.................] - ETA: 1s - loss: 0.0650 - acc: 0.9896
 640/1283 [=============>................] - ETA: 0s - loss: 0.0649 - acc: 0.9906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0661 - acc: 0.9901
 768/1283 [================>.............] - ETA: 0s - loss: 0.0648 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0625 - acc: 0.9916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0628 - acc: 0.9922
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0619 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0613 - acc: 0.9922
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0630 - acc: 0.9908
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0621 - acc: 0.9913
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0629 - acc: 0.9910
1280/1283 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9914
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0618 - acc: 0.9914 - val_loss: 1.0155 - val_acc: 0.6332

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0523 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0542 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0507 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0467 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0454 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0436 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0419 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0415 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0411 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0408 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0407 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0419 - acc: 0.9922
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0411 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0404 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0406 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0403 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0411 - acc: 0.9917
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0410 - acc: 0.9922
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0410 - acc: 0.9918
1280/1283 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9922
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0403 - acc: 0.9922 - val_loss: 1.0301 - val_acc: 0.6463

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0250 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0251 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0261 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0292 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0316 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0309 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0291 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0304 - acc: 0.9980
 576/1283 [============>.................] - ETA: 1s - loss: 0.0289 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0283 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0291 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0288 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0286 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0289 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0293 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0306 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0306 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0316 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0323 - acc: 0.9951
1280/1283 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9953
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0316 - acc: 0.9953 - val_loss: 1.1837 - val_acc: 0.6376

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0361 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0267 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0337 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0297 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0291 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0284 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0271 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0268 - acc: 0.9941
 576/1283 [============>.................] - ETA: 1s - loss: 0.0270 - acc: 0.9931
 640/1283 [=============>................] - ETA: 1s - loss: 0.0253 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0257 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0256 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0246 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0240 - acc: 0.9944
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0248 - acc: 0.9948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0243 - acc: 0.9951
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0235 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0229 - acc: 0.9957
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0226 - acc: 0.9959
1280/1283 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9953
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0225 - acc: 0.9953 - val_loss: 1.1842 - val_acc: 0.6419

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0134 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0195 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0170 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0166 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0158 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0148 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0169 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0201 - acc: 0.9961
 576/1283 [============>.................] - ETA: 1s - loss: 0.0213 - acc: 0.9948
 640/1283 [=============>................] - ETA: 1s - loss: 0.0199 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0200 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0191 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0184 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0193 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0185 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0179 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0175 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0171 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0168 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9969
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0163 - acc: 0.9969 - val_loss: 1.2432 - val_acc: 0.6507

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0182 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0111 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0096 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0119 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0111 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0105 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0128 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0156 - acc: 0.9902
 576/1283 [============>.................] - ETA: 1s - loss: 0.0154 - acc: 0.9913
 640/1283 [=============>................] - ETA: 1s - loss: 0.0154 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0157 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0150 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0144 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0138 - acc: 0.9944
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0141 - acc: 0.9948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0143 - acc: 0.9951
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0140 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0137 - acc: 0.9957
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0132 - acc: 0.9959
1280/1283 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9961
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0132 - acc: 0.9961 - val_loss: 1.3158 - val_acc: 0.6419

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0054 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0136 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0163 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0135 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0119 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0113 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0116 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0136 - acc: 0.9961
 576/1283 [============>.................] - ETA: 1s - loss: 0.0131 - acc: 0.9965
 640/1283 [=============>................] - ETA: 1s - loss: 0.0135 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0130 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0137 - acc: 0.9948
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0131 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0131 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0126 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0127 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0122 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0118 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0115 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9969
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0112 - acc: 0.9969 - val_loss: 1.3556 - val_acc: 0.6507

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0069 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0082 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0064 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0058 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0095 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0087 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0080 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0076 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0078 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0087 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0092 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0098 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0110 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0107 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0103 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0100 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0099 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0102 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9969
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0099 - acc: 0.9969 - val_loss: 1.4160 - val_acc: 0.6419

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0032 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0081 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0063 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0091 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0085 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0099 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0089 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0086 - acc: 1.0000
 576/1283 [============>.................] - ETA: 1s - loss: 0.0080 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0087 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0082 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0078 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0080 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0079 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0078 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0075 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0075 - acc: 0.9991
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0074 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 0.9984
1280/1283 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9984
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0086 - acc: 0.9984 - val_loss: 1.4450 - val_acc: 0.6419

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0057 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0097 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0075 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0065 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0080 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0074 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0088 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0083 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0081 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0077 - acc: 0.9972
 768/1283 [================>.............] - ETA: 0s - loss: 0.0073 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0077 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0074 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0085 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0082 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0079 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0077 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0075 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9969
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0079 - acc: 0.9969 - val_loss: 1.4901 - val_acc: 0.6376

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
nodes=100
mode=AT
PCA audio=20
PCA visual=15
PCA text=130
accuracy=0.6268221574344023
best_valid_accuracy=0.6311953352769679
