/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 00:20:13.692639: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 19s - loss: 0.7068 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 6s - loss: 0.7117 - acc: 0.4896 
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7046 - acc: 0.4906
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7084 - acc: 0.4792
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7052 - acc: 0.4902
 640/1283 [=============>................] - ETA: 1s - loss: 0.7030 - acc: 0.4875
 768/1283 [================>.............] - ETA: 0s - loss: 0.7019 - acc: 0.5000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7018 - acc: 0.5000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6991 - acc: 0.5104
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6972 - acc: 0.5156
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6965 - acc: 0.5191
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6955 - acc: 0.5238
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6946 - acc: 0.5300 - val_loss: 0.6757 - val_acc: 0.5808

Epoch 00001: val_acc improved from -inf to 0.58079, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6636 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6486 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6440 - acc: 0.6969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6522 - acc: 0.6518
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6509 - acc: 0.6582
 640/1283 [=============>................] - ETA: 0s - loss: 0.6503 - acc: 0.6469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6499 - acc: 0.6449
 768/1283 [================>.............] - ETA: 0s - loss: 0.6491 - acc: 0.6432
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6457 - acc: 0.6462
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6434 - acc: 0.6521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6419 - acc: 0.6535
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6423 - acc: 0.6513
1280/1283 [============================>.] - ETA: 0s - loss: 0.6407 - acc: 0.6547
1283/1283 [==============================] - 1s 825us/step - loss: 0.6409 - acc: 0.6547 - val_loss: 0.6487 - val_acc: 0.6201

Epoch 00002: val_acc improved from 0.58079 to 0.62009, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6023 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6034 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6067 - acc: 0.7250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6034 - acc: 0.7165
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5987 - acc: 0.7227
 640/1283 [=============>................] - ETA: 0s - loss: 0.5899 - acc: 0.7406
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5878 - acc: 0.7429
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5853 - acc: 0.7464
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5841 - acc: 0.7458
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5819 - acc: 0.7480
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5792 - acc: 0.7500
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5774 - acc: 0.7484
1283/1283 [==============================] - 1s 830us/step - loss: 0.5784 - acc: 0.7482 - val_loss: 0.6176 - val_acc: 0.6376

Epoch 00003: val_acc improved from 0.62009 to 0.63755, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5172 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5347 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5506 - acc: 0.7617
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5401 - acc: 0.7917
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5277 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5244 - acc: 0.8027
 576/1283 [============>.................] - ETA: 0s - loss: 0.5282 - acc: 0.7969
 640/1283 [=============>................] - ETA: 0s - loss: 0.5242 - acc: 0.8031
 768/1283 [================>.............] - ETA: 0s - loss: 0.5225 - acc: 0.8008
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5160 - acc: 0.8058
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5111 - acc: 0.8047
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5100 - acc: 0.8033
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5020 - acc: 0.8059
1280/1283 [============================>.] - ETA: 0s - loss: 0.5018 - acc: 0.8031
1283/1283 [==============================] - 1s 851us/step - loss: 0.5012 - acc: 0.8036 - val_loss: 0.5845 - val_acc: 0.6507

Epoch 00004: val_acc improved from 0.63755 to 0.65066, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5701 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4419 - acc: 0.8333
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4453 - acc: 0.8313
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4341 - acc: 0.8326
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4403 - acc: 0.8301
 576/1283 [============>.................] - ETA: 0s - loss: 0.4305 - acc: 0.8385
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4249 - acc: 0.8423
 768/1283 [================>.............] - ETA: 0s - loss: 0.4205 - acc: 0.8424
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4077 - acc: 0.8493
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4123 - acc: 0.8448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4169 - acc: 0.8401
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4208 - acc: 0.8363
1283/1283 [==============================] - 1s 854us/step - loss: 0.4189 - acc: 0.8363 - val_loss: 0.5827 - val_acc: 0.6725

Epoch 00005: val_acc improved from 0.65066 to 0.67249, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4297 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3592 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3427 - acc: 0.8875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3311 - acc: 0.8906
 576/1283 [============>.................] - ETA: 0s - loss: 0.3337 - acc: 0.8872
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3269 - acc: 0.8864
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3251 - acc: 0.8858
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3269 - acc: 0.8812
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3244 - acc: 0.8809
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3244 - acc: 0.8793
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3268 - acc: 0.8791
1280/1283 [============================>.] - ETA: 0s - loss: 0.3320 - acc: 0.8750
1283/1283 [==============================] - 1s 828us/step - loss: 0.3326 - acc: 0.8745 - val_loss: 0.5991 - val_acc: 0.6769

Epoch 00006: val_acc improved from 0.67249 to 0.67686, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3158 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2950 - acc: 0.8698
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3064 - acc: 0.8688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3088 - acc: 0.8638
 576/1283 [============>.................] - ETA: 0s - loss: 0.3009 - acc: 0.8698
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2886 - acc: 0.8807
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2803 - acc: 0.8882
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2720 - acc: 0.8958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2707 - acc: 0.8980
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2638 - acc: 0.9005
1283/1283 [==============================] - 1s 738us/step - loss: 0.2627 - acc: 0.9010 - val_loss: 0.6016 - val_acc: 0.7031

Epoch 00007: val_acc improved from 0.67686 to 0.70306, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2007 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2102 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2285 - acc: 0.9187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2066 - acc: 0.9308
 576/1283 [============>.................] - ETA: 0s - loss: 0.2091 - acc: 0.9306
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2137 - acc: 0.9276
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2115 - acc: 0.9279
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2128 - acc: 0.9281
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2141 - acc: 0.9292
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2119 - acc: 0.9285
1283/1283 [==============================] - 1s 671us/step - loss: 0.2087 - acc: 0.9299 - val_loss: 0.6495 - val_acc: 0.6900

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1494 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1679 - acc: 0.9271
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1703 - acc: 0.9313
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1635 - acc: 0.9397
 576/1283 [============>.................] - ETA: 0s - loss: 0.1553 - acc: 0.9410
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1509 - acc: 0.9432
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1506 - acc: 0.9459
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1502 - acc: 0.9490
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1496 - acc: 0.9494
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1488 - acc: 0.9498
1283/1283 [==============================] - 1s 669us/step - loss: 0.1493 - acc: 0.9486 - val_loss: 0.7417 - val_acc: 0.6769

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1523 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1129 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1144 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1070 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.1087 - acc: 0.9653
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1104 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1117 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1099 - acc: 0.9698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1065 - acc: 0.9715
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1044 - acc: 0.9729
1283/1283 [==============================] - 1s 693us/step - loss: 0.1044 - acc: 0.9735 - val_loss: 0.8562 - val_acc: 0.6769

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0822 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0912 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0865 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0877 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0825 - acc: 0.9722
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0778 - acc: 0.9759
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0774 - acc: 0.9772
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0756 - acc: 0.9788
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0776 - acc: 0.9785
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0769 - acc: 0.9783
1280/1283 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9789
1283/1283 [==============================] - 1s 697us/step - loss: 0.0761 - acc: 0.9790 - val_loss: 0.9078 - val_acc: 0.6725

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0385 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0705 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0652 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0602 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.0620 - acc: 0.9809
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0641 - acc: 0.9801
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0609 - acc: 0.9832
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0573 - acc: 0.9854
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0557 - acc: 0.9863
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0536 - acc: 0.9878
1280/1283 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9875
1283/1283 [==============================] - 1s 685us/step - loss: 0.0538 - acc: 0.9867 - val_loss: 0.9653 - val_acc: 0.6812

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0297 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0268 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0277 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0308 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0337 - acc: 0.9961
 640/1283 [=============>................] - ETA: 0s - loss: 0.0396 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0412 - acc: 0.9922
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0403 - acc: 0.9922
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0402 - acc: 0.9922
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0454 - acc: 0.9905
1280/1283 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9898
1283/1283 [==============================] - 1s 712us/step - loss: 0.0477 - acc: 0.9899 - val_loss: 1.0885 - val_acc: 0.6769

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0448 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0342 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0365 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0339 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0370 - acc: 0.9902
 576/1283 [============>.................] - ETA: 0s - loss: 0.0348 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0356 - acc: 0.9901
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0348 - acc: 0.9916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0334 - acc: 0.9922
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0330 - acc: 0.9922
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0341 - acc: 0.9913
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0340 - acc: 0.9910
1280/1283 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9906
1283/1283 [==============================] - 1s 778us/step - loss: 0.0346 - acc: 0.9899 - val_loss: 1.1600 - val_acc: 0.6900

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0196 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0181 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0241 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0364 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0376 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0426 - acc: 0.9886
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0421 - acc: 0.9892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0401 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0398 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0398 - acc: 0.9901
1283/1283 [==============================] - 1s 635us/step - loss: 0.0385 - acc: 0.9906 - val_loss: 1.2401 - val_acc: 0.6725

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1053 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0739 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0652 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0549 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0541 - acc: 0.9883
 640/1283 [=============>................] - ETA: 0s - loss: 0.0530 - acc: 0.9859
 768/1283 [================>.............] - ETA: 0s - loss: 0.0459 - acc: 0.9883
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0564 - acc: 0.9877
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0527 - acc: 0.9893
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0509 - acc: 0.9896
1280/1283 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9906
1283/1283 [==============================] - 1s 591us/step - loss: 0.0482 - acc: 0.9906 - val_loss: 1.2787 - val_acc: 0.6769

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0292 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0259 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0412 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0362 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0347 - acc: 0.9902
 576/1283 [============>.................] - ETA: 0s - loss: 0.0342 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0327 - acc: 0.9929
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0313 - acc: 0.9940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0285 - acc: 0.9948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0273 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0260 - acc: 0.9959
1283/1283 [==============================] - 1s 619us/step - loss: 0.0257 - acc: 0.9961 - val_loss: 1.3299 - val_acc: 0.6812

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
nodes=100
mode=all
PCA audio=10
PCA visual=25
PCA text=110
accuracy=0.6807580174927114
best_valid_accuracy=0.6836734693877551
