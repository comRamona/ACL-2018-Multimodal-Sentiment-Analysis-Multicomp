/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_blstm.py:147: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_blstm.py:149: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 01:18:26.069724: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 16s - loss: 0.7153 - acc: 0.4531
 192/1283 [===>..........................] - ETA: 5s - loss: 0.6986 - acc: 0.4896 
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6998 - acc: 0.4906
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6920 - acc: 0.5156
 576/1283 [============>.................] - ETA: 1s - loss: 0.6922 - acc: 0.5122
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6891 - acc: 0.5213
 768/1283 [================>.............] - ETA: 0s - loss: 0.6912 - acc: 0.5156
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6887 - acc: 0.5252
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6879 - acc: 0.5279
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6881 - acc: 0.5260
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6863 - acc: 0.5293
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6841 - acc: 0.5377
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6816 - acc: 0.5411
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6811 - acc: 0.5433 - val_loss: 0.6674 - val_acc: 0.5852

Epoch 00001: val_acc improved from -inf to 0.58515, saving model to classification_logs//blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6038 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6033 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6087 - acc: 0.7281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6042 - acc: 0.7411
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6035 - acc: 0.7363
 576/1283 [============>.................] - ETA: 0s - loss: 0.5998 - acc: 0.7413
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6009 - acc: 0.7330
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6021 - acc: 0.7248
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5952 - acc: 0.7333
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5892 - acc: 0.7362
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5877 - acc: 0.7344
1280/1283 [============================>.] - ETA: 0s - loss: 0.5878 - acc: 0.7320
1283/1283 [==============================] - 1s 777us/step - loss: 0.5878 - acc: 0.7319 - val_loss: 0.6186 - val_acc: 0.6943

Epoch 00002: val_acc improved from 0.58515 to 0.69432, saving model to classification_logs//blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5346 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5115 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4982 - acc: 0.8219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5106 - acc: 0.7991
 576/1283 [============>.................] - ETA: 0s - loss: 0.4999 - acc: 0.8142
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4923 - acc: 0.8182
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4930 - acc: 0.8113
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4936 - acc: 0.8031
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4888 - acc: 0.8066
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4910 - acc: 0.8064
1280/1283 [============================>.] - ETA: 0s - loss: 0.4861 - acc: 0.8078
1283/1283 [==============================] - 1s 774us/step - loss: 0.4861 - acc: 0.8075 - val_loss: 0.5770 - val_acc: 0.7031

Epoch 00003: val_acc improved from 0.69432 to 0.70306, saving model to classification_logs//blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3451 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3871 - acc: 0.8802
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3827 - acc: 0.8812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3796 - acc: 0.8802
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3776 - acc: 0.8795
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3751 - acc: 0.8809
 576/1283 [============>.................] - ETA: 0s - loss: 0.3746 - acc: 0.8819
 640/1283 [=============>................] - ETA: 0s - loss: 0.3729 - acc: 0.8797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3728 - acc: 0.8778
 768/1283 [================>.............] - ETA: 0s - loss: 0.3686 - acc: 0.8828
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3757 - acc: 0.8690
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3710 - acc: 0.8717
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3695 - acc: 0.8708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3652 - acc: 0.8730
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3657 - acc: 0.8704
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3664 - acc: 0.8689
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3711 - acc: 0.8660
1280/1283 [============================>.] - ETA: 0s - loss: 0.3675 - acc: 0.8688
1283/1283 [==============================] - 1s 886us/step - loss: 0.3675 - acc: 0.8683 - val_loss: 0.5760 - val_acc: 0.6987

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2919 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2769 - acc: 0.9115
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2652 - acc: 0.9141
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2803 - acc: 0.9000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2745 - acc: 0.9062
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2802 - acc: 0.9023
 576/1283 [============>.................] - ETA: 0s - loss: 0.2792 - acc: 0.9028
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2834 - acc: 0.9034
 768/1283 [================>.............] - ETA: 0s - loss: 0.2855 - acc: 0.9036
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2830 - acc: 0.9026
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2839 - acc: 0.9021
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2814 - acc: 0.9043
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2815 - acc: 0.9035
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2826 - acc: 0.9013
1283/1283 [==============================] - 1s 855us/step - loss: 0.2873 - acc: 0.8987 - val_loss: 0.5885 - val_acc: 0.7162

Epoch 00005: val_acc improved from 0.70306 to 0.71616, saving model to classification_logs//blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2064 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1857 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1930 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2076 - acc: 0.9156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2133 - acc: 0.9141
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2217 - acc: 0.9085
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2188 - acc: 0.9160
 576/1283 [============>.................] - ETA: 0s - loss: 0.2189 - acc: 0.9184
 640/1283 [=============>................] - ETA: 0s - loss: 0.2163 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2208 - acc: 0.9247
 768/1283 [================>.............] - ETA: 0s - loss: 0.2153 - acc: 0.9271
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2117 - acc: 0.9303
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2053 - acc: 0.9313
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2083 - acc: 0.9297
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2071 - acc: 0.9280
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2063 - acc: 0.9276
1280/1283 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9266
1283/1283 [==============================] - 1s 908us/step - loss: 0.2085 - acc: 0.9267 - val_loss: 0.6052 - val_acc: 0.6987

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1089 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1658 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1548 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1437 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1465 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.1439 - acc: 0.9618
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1475 - acc: 0.9560
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1454 - acc: 0.9591
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1378 - acc: 0.9625
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1357 - acc: 0.9632
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1323 - acc: 0.9646
1283/1283 [==============================] - 1s 745us/step - loss: 0.1332 - acc: 0.9634 - val_loss: 0.6833 - val_acc: 0.6856

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0927 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0977 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0898 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0854 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.0842 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0829 - acc: 0.9830
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0879 - acc: 0.9784
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0925 - acc: 0.9740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0883 - acc: 0.9761
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0869 - acc: 0.9766
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0850 - acc: 0.9778
1283/1283 [==============================] - 1s 773us/step - loss: 0.0835 - acc: 0.9782 - val_loss: 0.8159 - val_acc: 0.6594

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0774 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0651 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0658 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0613 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0619 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0620 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0645 - acc: 0.9826
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0646 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0645 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0641 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0609 - acc: 0.9854
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0591 - acc: 0.9870
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0566 - acc: 0.9877
1283/1283 [==============================] - 1s 880us/step - loss: 0.0563 - acc: 0.9883 - val_loss: 0.8452 - val_acc: 0.6507

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0267 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0254 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0338 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0278 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0294 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0279 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0282 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0279 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0270 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0285 - acc: 0.9943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0285 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0306 - acc: 0.9922
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0314 - acc: 0.9922
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0309 - acc: 0.9926
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0303 - acc: 0.9931
1280/1283 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9938
1283/1283 [==============================] - 1s 866us/step - loss: 0.0297 - acc: 0.9938 - val_loss: 0.9585 - val_acc: 0.6594

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0168 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0219 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0228 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0208 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0184 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0188 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0187 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0185 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0177 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0183 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0189 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0192 - acc: 0.9983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0188 - acc: 0.9984
1280/1283 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9984
1283/1283 [==============================] - 1s 896us/step - loss: 0.0187 - acc: 0.9984 - val_loss: 1.0092 - val_acc: 0.6638

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0466 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0193 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0161 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0131 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0125 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0119 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0113 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0108 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0145 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0143 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0138 - acc: 0.9969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0151 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0156 - acc: 0.9951
1283/1283 [==============================] - 1s 861us/step - loss: 0.0168 - acc: 0.9945 - val_loss: 0.9937 - val_acc: 0.6769

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0051 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0078 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0116 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0573 - acc: 0.9818
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0572 - acc: 0.9805
 640/1283 [=============>................] - ETA: 0s - loss: 0.0500 - acc: 0.9828
 768/1283 [================>.............] - ETA: 0s - loss: 0.0468 - acc: 0.9831
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0507 - acc: 0.9810
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0514 - acc: 0.9802
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0516 - acc: 0.9807
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0527 - acc: 0.9803
1280/1283 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9805
1283/1283 [==============================] - 1s 815us/step - loss: 0.0525 - acc: 0.9805 - val_loss: 1.0472 - val_acc: 0.6288

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0152 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0142 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0157 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0183 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0206 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0240 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0231 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0253 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0239 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0234 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0229 - acc: 0.9948
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0218 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0219 - acc: 0.9948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0214 - acc: 0.9951
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0214 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0208 - acc: 0.9957
1280/1283 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9961
1283/1283 [==============================] - 1s 969us/step - loss: 0.0199 - acc: 0.9961 - val_loss: 1.0936 - val_acc: 0.6507

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0169 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0135 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0132 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0136 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0124 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0115 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0110 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0103 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0099 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0096 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0095 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0093 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0096 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0100 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0097 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0098 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0096 - acc: 1.0000
1283/1283 [==============================] - 1s 959us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 1.1576 - val_acc: 0.6507

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=all
PCA audio=10
PCA visual=20
PCA text=110
accuracy=0.7157434402332361
best_valid_accuracy=0.7055393586005831
