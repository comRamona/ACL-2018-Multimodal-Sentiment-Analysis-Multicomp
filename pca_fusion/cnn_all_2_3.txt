/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 01:41:03.324568: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 16s - loss: 0.7276 - acc: 0.4844
 128/1283 [=>............................] - ETA: 8s - loss: 0.6916 - acc: 0.5234 
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7153 - acc: 0.5677
 256/1283 [====>.........................] - ETA: 4s - loss: 0.7403 - acc: 0.5820
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7420 - acc: 0.5844
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7364 - acc: 0.5580
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7373 - acc: 0.5488
 576/1283 [============>.................] - ETA: 1s - loss: 0.7361 - acc: 0.5451
 640/1283 [=============>................] - ETA: 1s - loss: 0.7363 - acc: 0.5375
 768/1283 [================>.............] - ETA: 1s - loss: 0.7268 - acc: 0.5443
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7220 - acc: 0.5481
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7203 - acc: 0.5536
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7221 - acc: 0.5490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7215 - acc: 0.5508
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7193 - acc: 0.5530
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7193 - acc: 0.5477
1280/1283 [============================>.] - ETA: 0s - loss: 0.7211 - acc: 0.5477
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7212 - acc: 0.5479 - val_loss: 0.7051 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5426 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.5629 - acc: 0.7578
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5670 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5830 - acc: 0.7188
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6078 - acc: 0.6615
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6024 - acc: 0.6652
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5974 - acc: 0.6777
 576/1283 [============>.................] - ETA: 0s - loss: 0.5912 - acc: 0.6910
 640/1283 [=============>................] - ETA: 0s - loss: 0.5835 - acc: 0.7016
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5773 - acc: 0.7102
 768/1283 [================>.............] - ETA: 0s - loss: 0.5717 - acc: 0.7122
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5696 - acc: 0.7139
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5647 - acc: 0.7176
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5572 - acc: 0.7281
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5513 - acc: 0.7334
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5496 - acc: 0.7325
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5470 - acc: 0.7309
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5437 - acc: 0.7336
1280/1283 [============================>.] - ETA: 0s - loss: 0.5408 - acc: 0.7391
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5409 - acc: 0.7397 - val_loss: 0.7580 - val_acc: 0.5677

Epoch 00002: val_acc improved from 0.54148 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3937 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.4098 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4061 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4026 - acc: 0.8516
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4112 - acc: 0.8562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4188 - acc: 0.8348
 576/1283 [============>.................] - ETA: 0s - loss: 0.4200 - acc: 0.8212
 640/1283 [=============>................] - ETA: 0s - loss: 0.4274 - acc: 0.8125
 768/1283 [================>.............] - ETA: 0s - loss: 0.4259 - acc: 0.8138
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4200 - acc: 0.8173
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4188 - acc: 0.8177
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4134 - acc: 0.8199
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4117 - acc: 0.8199
1283/1283 [==============================] - 1s 946us/step - loss: 0.4123 - acc: 0.8176 - val_loss: 0.7759 - val_acc: 0.5546

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3292 - acc: 0.8906
 128/1283 [=>............................] - ETA: 0s - loss: 0.3292 - acc: 0.8828
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3181 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2988 - acc: 0.8984
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2994 - acc: 0.8969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2975 - acc: 0.8958
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2920 - acc: 0.8926
 576/1283 [============>.................] - ETA: 0s - loss: 0.2872 - acc: 0.8976
 640/1283 [=============>................] - ETA: 0s - loss: 0.2895 - acc: 0.8938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2921 - acc: 0.8920
 768/1283 [================>.............] - ETA: 0s - loss: 0.2935 - acc: 0.8893
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2911 - acc: 0.8894
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2921 - acc: 0.8873
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2875 - acc: 0.8927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2889 - acc: 0.8916
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2914 - acc: 0.8888
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2890 - acc: 0.8906
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2910 - acc: 0.8857
1280/1283 [============================>.] - ETA: 0s - loss: 0.2958 - acc: 0.8805
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2953 - acc: 0.8807 - val_loss: 0.9028 - val_acc: 0.5677

Epoch 00004: val_acc improved from 0.56769 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1978 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1969 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1956 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1890 - acc: 0.9336
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1874 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1843 - acc: 0.9401
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1840 - acc: 0.9434
 576/1283 [============>.................] - ETA: 0s - loss: 0.1805 - acc: 0.9479
 640/1283 [=============>................] - ETA: 0s - loss: 0.1836 - acc: 0.9469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1862 - acc: 0.9418
 768/1283 [================>.............] - ETA: 0s - loss: 0.1911 - acc: 0.9401
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1893 - acc: 0.9399
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1912 - acc: 0.9364
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1877 - acc: 0.9385
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1848 - acc: 0.9404
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1894 - acc: 0.9375
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1914 - acc: 0.9349
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1946 - acc: 0.9326
1280/1283 [============================>.] - ETA: 0s - loss: 0.1945 - acc: 0.9320
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1941 - acc: 0.9322 - val_loss: 1.0482 - val_acc: 0.5983

Epoch 00005: val_acc improved from 0.56769 to 0.59825, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1490 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.1352 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1466 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1346 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1311 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1267 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1247 - acc: 0.9554
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1281 - acc: 0.9551
 576/1283 [============>.................] - ETA: 0s - loss: 0.1237 - acc: 0.9583
 640/1283 [=============>................] - ETA: 0s - loss: 0.1221 - acc: 0.9594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1241 - acc: 0.9574
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1237 - acc: 0.9567
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1220 - acc: 0.9598
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1208 - acc: 0.9594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1244 - acc: 0.9570
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1270 - acc: 0.9540
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1267 - acc: 0.9539
1280/1283 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9539
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1297 - acc: 0.9532 - val_loss: 1.2628 - val_acc: 0.6026

Epoch 00006: val_acc improved from 0.59825 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0825 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1133 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1025 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0959 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0941 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0971 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0919 - acc: 0.9707
 576/1283 [============>.................] - ETA: 0s - loss: 0.0932 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0903 - acc: 0.9703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0926 - acc: 0.9673
 768/1283 [================>.............] - ETA: 0s - loss: 0.0947 - acc: 0.9648
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0959 - acc: 0.9627
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0995 - acc: 0.9565
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0999 - acc: 0.9563
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0990 - acc: 0.9570
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0994 - acc: 0.9568
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0966 - acc: 0.9583
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0988 - acc: 0.9581
1280/1283 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9602
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0944 - acc: 0.9602 - val_loss: 1.4771 - val_acc: 0.5808

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0314 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0508 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0459 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0522 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0540 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0561 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0637 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0653 - acc: 0.9863
 576/1283 [============>.................] - ETA: 0s - loss: 0.0667 - acc: 0.9826
 640/1283 [=============>................] - ETA: 0s - loss: 0.0731 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0801 - acc: 0.9716
 768/1283 [================>.............] - ETA: 0s - loss: 0.0799 - acc: 0.9727
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0763 - acc: 0.9743
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0766 - acc: 0.9740
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0778 - acc: 0.9727
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0787 - acc: 0.9724
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0799 - acc: 0.9705
1280/1283 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9703
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0815 - acc: 0.9704 - val_loss: 1.6080 - val_acc: 0.6114

Epoch 00008: val_acc improved from 0.60262 to 0.61135, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1195 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0999 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0871 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0930 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0887 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0850 - acc: 0.9661
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0911 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0866 - acc: 0.9629
 640/1283 [=============>................] - ETA: 0s - loss: 0.0854 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0804 - acc: 0.9673
 768/1283 [================>.............] - ETA: 0s - loss: 0.0812 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0820 - acc: 0.9663
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0794 - acc: 0.9677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0788 - acc: 0.9678
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0781 - acc: 0.9669
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0820 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0816 - acc: 0.9655
1280/1283 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9656
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0827 - acc: 0.9649 - val_loss: 1.6541 - val_acc: 0.5895

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1139 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0807 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0834 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0815 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0843 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0904 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0915 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0968 - acc: 0.9570
 576/1283 [============>.................] - ETA: 0s - loss: 0.1046 - acc: 0.9497
 640/1283 [=============>................] - ETA: 0s - loss: 0.1031 - acc: 0.9531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1029 - acc: 0.9545
 768/1283 [================>.............] - ETA: 0s - loss: 0.1066 - acc: 0.9544
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1043 - acc: 0.9555
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1021 - acc: 0.9565
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1130 - acc: 0.9542
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1137 - acc: 0.9541
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1130 - acc: 0.9540
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1146 - acc: 0.9523
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1143 - acc: 0.9523
1280/1283 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9531
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1126 - acc: 0.9532 - val_loss: 1.7695 - val_acc: 0.5764

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1077 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0878 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1091 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1003 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0978 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0889 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0899 - acc: 0.9668
 576/1283 [============>.................] - ETA: 0s - loss: 0.0907 - acc: 0.9618
 640/1283 [=============>................] - ETA: 0s - loss: 0.0878 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0946 - acc: 0.9602
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0917 - acc: 0.9603
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0899 - acc: 0.9621
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0889 - acc: 0.9625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0885 - acc: 0.9619
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0879 - acc: 0.9632
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0864 - acc: 0.9653
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0911 - acc: 0.9638
1280/1283 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9648
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0898 - acc: 0.9649 - val_loss: 1.8653 - val_acc: 0.5633

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0855 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0689 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0786 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0852 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0738 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0743 - acc: 0.9661
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0700 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0679 - acc: 0.9727
 576/1283 [============>.................] - ETA: 0s - loss: 0.0668 - acc: 0.9740
 640/1283 [=============>................] - ETA: 0s - loss: 0.0621 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0708 - acc: 0.9716
 768/1283 [================>.............] - ETA: 0s - loss: 0.0703 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0699 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0698 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0683 - acc: 0.9719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0674 - acc: 0.9727
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0664 - acc: 0.9733
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0666 - acc: 0.9722
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0685 - acc: 0.9720
1280/1283 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9711
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0678 - acc: 0.9712 - val_loss: 1.7930 - val_acc: 0.5808

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0329 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0473 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0530 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0532 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0539 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0541 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0572 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0623 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.0651 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.0646 - acc: 0.9719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0623 - acc: 0.9730
 768/1283 [================>.............] - ETA: 0s - loss: 0.0619 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0607 - acc: 0.9724
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0603 - acc: 0.9732
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0610 - acc: 0.9727
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0584 - acc: 0.9740
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0577 - acc: 0.9745
1280/1283 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9750
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0567 - acc: 0.9751 - val_loss: 2.0768 - val_acc: 0.5721

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0766 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0636 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0554 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0556 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0545 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0576 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0530 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0548 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.0496 - acc: 0.9774
 640/1283 [=============>................] - ETA: 0s - loss: 0.0540 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0540 - acc: 0.9744
 768/1283 [================>.............] - ETA: 0s - loss: 0.0542 - acc: 0.9753
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0537 - acc: 0.9760
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0533 - acc: 0.9754
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0517 - acc: 0.9760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0504 - acc: 0.9766
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0499 - acc: 0.9770
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0483 - acc: 0.9783
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0479 - acc: 0.9786
1280/1283 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9789
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0481 - acc: 0.9790 - val_loss: 2.1129 - val_acc: 0.5677

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0402 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0217 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0350 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0355 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0409 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0405 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0375 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0379 - acc: 0.9746
 576/1283 [============>.................] - ETA: 1s - loss: 0.0362 - acc: 0.9774
 640/1283 [=============>................] - ETA: 0s - loss: 0.0355 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0377 - acc: 0.9759
 768/1283 [================>.............] - ETA: 0s - loss: 0.0410 - acc: 0.9753
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0413 - acc: 0.9760
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0403 - acc: 0.9777
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0432 - acc: 0.9781
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0416 - acc: 0.9795
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0418 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0424 - acc: 0.9786
1280/1283 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9750
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0463 - acc: 0.9751 - val_loss: 2.3430 - val_acc: 0.5808

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0667 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0689 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0536 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0439 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0455 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0465 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0419 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0382 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0351 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0349 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0387 - acc: 0.9830
 768/1283 [================>.............] - ETA: 0s - loss: 0.0396 - acc: 0.9831
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0413 - acc: 0.9808
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0419 - acc: 0.9799
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0414 - acc: 0.9802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0435 - acc: 0.9775
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0423 - acc: 0.9779
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0414 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0413 - acc: 0.9794
1280/1283 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9781
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0434 - acc: 0.9782 - val_loss: 2.3753 - val_acc: 0.5590

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0276 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0233 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0197 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0247 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0254 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0255 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0250 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0251 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0350 - acc: 0.9859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0346 - acc: 0.9858
 768/1283 [================>.............] - ETA: 0s - loss: 0.0332 - acc: 0.9857
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0335 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0329 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0370 - acc: 0.9814
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0383 - acc: 0.9807
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0408 - acc: 0.9783
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0410 - acc: 0.9794
1280/1283 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9797
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0413 - acc: 0.9797 - val_loss: 2.4379 - val_acc: 0.5590

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0651 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0359 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0345 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0318 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0366 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0357 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0362 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0411 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.0404 - acc: 0.9757
 640/1283 [=============>................] - ETA: 0s - loss: 0.0412 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0419 - acc: 0.9759
 768/1283 [================>.............] - ETA: 0s - loss: 0.0433 - acc: 0.9740
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0417 - acc: 0.9760
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0398 - acc: 0.9777
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0391 - acc: 0.9795
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0394 - acc: 0.9800
1280/1283 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9797
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0403 - acc: 0.9790 - val_loss: 2.4917 - val_acc: 0.5677

Epoch 00018: val_acc did not improve
Epoch 00018: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
nodes=100
mode=all
PCA audio=20
PCA visual=15
PCA text=130
accuracy=0.5714285714285714
best_valid_accuracy=0.5641399416909622
