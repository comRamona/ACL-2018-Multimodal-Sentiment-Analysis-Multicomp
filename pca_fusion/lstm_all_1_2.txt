/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 00:20:35.317558: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.6973 - acc: 0.4531
 128/1283 [=>............................] - ETA: 5s - loss: 0.6934 - acc: 0.4844 
 192/1283 [===>..........................] - ETA: 3s - loss: 0.6859 - acc: 0.5521
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6857 - acc: 0.5430
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6891 - acc: 0.5469
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6895 - acc: 0.5391
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6894 - acc: 0.5357
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6892 - acc: 0.5332
 576/1283 [============>.................] - ETA: 1s - loss: 0.6879 - acc: 0.5347
 640/1283 [=============>................] - ETA: 1s - loss: 0.6896 - acc: 0.5266
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6878 - acc: 0.5298
 768/1283 [================>.............] - ETA: 0s - loss: 0.6867 - acc: 0.5339
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6877 - acc: 0.5300
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6868 - acc: 0.5368
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6871 - acc: 0.5385
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6859 - acc: 0.5479
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6847 - acc: 0.5579
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6855 - acc: 0.5521
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6836 - acc: 0.5576
1280/1283 [============================>.] - ETA: 0s - loss: 0.6834 - acc: 0.5617
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6838 - acc: 0.5612 - val_loss: 0.6618 - val_acc: 0.6332

Epoch 00001: val_acc improved from -inf to 0.63319, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6472 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6354 - acc: 0.6797
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6343 - acc: 0.6823
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6347 - acc: 0.6836
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6352 - acc: 0.6927
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6331 - acc: 0.6964
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6320 - acc: 0.6973
 576/1283 [============>.................] - ETA: 0s - loss: 0.6285 - acc: 0.7049
 640/1283 [=============>................] - ETA: 0s - loss: 0.6285 - acc: 0.7000
 768/1283 [================>.............] - ETA: 0s - loss: 0.6245 - acc: 0.7070
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6246 - acc: 0.7031
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6263 - acc: 0.6958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6254 - acc: 0.6982
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6228 - acc: 0.7031
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6217 - acc: 0.7075
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6190 - acc: 0.7113
1280/1283 [============================>.] - ETA: 0s - loss: 0.6196 - acc: 0.7117
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6194 - acc: 0.7124 - val_loss: 0.6280 - val_acc: 0.6463

Epoch 00002: val_acc improved from 0.63319 to 0.64629, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5521 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.5595 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5612 - acc: 0.7917
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5623 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5677 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5652 - acc: 0.7760
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5568 - acc: 0.7857
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5527 - acc: 0.7852
 576/1283 [============>.................] - ETA: 0s - loss: 0.5549 - acc: 0.7847
 640/1283 [=============>................] - ETA: 0s - loss: 0.5546 - acc: 0.7797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5539 - acc: 0.7784
 768/1283 [================>.............] - ETA: 0s - loss: 0.5544 - acc: 0.7773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5497 - acc: 0.7788
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5480 - acc: 0.7779
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5473 - acc: 0.7719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5483 - acc: 0.7695
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5435 - acc: 0.7730
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5421 - acc: 0.7743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5430 - acc: 0.7722
1280/1283 [============================>.] - ETA: 0s - loss: 0.5435 - acc: 0.7703
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5432 - acc: 0.7708 - val_loss: 0.5812 - val_acc: 0.6987

Epoch 00003: val_acc improved from 0.64629 to 0.69869, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4703 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4691 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4657 - acc: 0.8177
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4622 - acc: 0.8203
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4599 - acc: 0.8219
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4465 - acc: 0.8359
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4460 - acc: 0.8304
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4426 - acc: 0.8398
 576/1283 [============>.................] - ETA: 0s - loss: 0.4443 - acc: 0.8420
 640/1283 [=============>................] - ETA: 0s - loss: 0.4464 - acc: 0.8359
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4485 - acc: 0.8310
 768/1283 [================>.............] - ETA: 0s - loss: 0.4520 - acc: 0.8294
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4532 - acc: 0.8281
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4488 - acc: 0.8326
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4473 - acc: 0.8333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4440 - acc: 0.8359
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4462 - acc: 0.8309
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4494 - acc: 0.8248
1280/1283 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8242
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4505 - acc: 0.8246 - val_loss: 0.5513 - val_acc: 0.6943

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3767 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.3739 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3772 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3617 - acc: 0.8844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3637 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3666 - acc: 0.8683
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3702 - acc: 0.8652
 576/1283 [============>.................] - ETA: 0s - loss: 0.3721 - acc: 0.8611
 640/1283 [=============>................] - ETA: 0s - loss: 0.3623 - acc: 0.8672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3722 - acc: 0.8622
 768/1283 [================>.............] - ETA: 0s - loss: 0.3664 - acc: 0.8646
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3639 - acc: 0.8654
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3591 - acc: 0.8661
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3589 - acc: 0.8656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3586 - acc: 0.8662
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3608 - acc: 0.8640
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3599 - acc: 0.8646
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3579 - acc: 0.8651
1280/1283 [============================>.] - ETA: 0s - loss: 0.3600 - acc: 0.8625
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3597 - acc: 0.8628 - val_loss: 0.5556 - val_acc: 0.7118

Epoch 00005: val_acc improved from 0.69869 to 0.71179, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2224 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.2676 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2477 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2901 - acc: 0.9180
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2843 - acc: 0.9219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2794 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2782 - acc: 0.9219
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2738 - acc: 0.9219
 576/1283 [============>.................] - ETA: 0s - loss: 0.2788 - acc: 0.9184
 640/1283 [=============>................] - ETA: 0s - loss: 0.2777 - acc: 0.9141
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2767 - acc: 0.9105
 768/1283 [================>.............] - ETA: 0s - loss: 0.2751 - acc: 0.9089
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2750 - acc: 0.9099
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2806 - acc: 0.9010
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2753 - acc: 0.9043
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2713 - acc: 0.9053
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2684 - acc: 0.9062
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2677 - acc: 0.9062
1280/1283 [============================>.] - ETA: 0s - loss: 0.2690 - acc: 0.9055
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2686 - acc: 0.9057 - val_loss: 0.5762 - val_acc: 0.7249

Epoch 00006: val_acc improved from 0.71179 to 0.72489, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1447 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1688 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1749 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1713 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1724 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1761 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1768 - acc: 0.9554
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1747 - acc: 0.9551
 576/1283 [============>.................] - ETA: 0s - loss: 0.1788 - acc: 0.9497
 640/1283 [=============>................] - ETA: 0s - loss: 0.1807 - acc: 0.9500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1826 - acc: 0.9474
 768/1283 [================>.............] - ETA: 0s - loss: 0.1856 - acc: 0.9453
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1880 - acc: 0.9423
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1901 - acc: 0.9408
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1923 - acc: 0.9396
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1887 - acc: 0.9404
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1903 - acc: 0.9375
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1872 - acc: 0.9401
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1887 - acc: 0.9383
1280/1283 [============================>.] - ETA: 0s - loss: 0.1903 - acc: 0.9367
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1900 - acc: 0.9369 - val_loss: 0.6463 - val_acc: 0.6900

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1059 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1203 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1199 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1225 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1195 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1228 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1259 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1256 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.1214 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.1187 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1194 - acc: 0.9645
 768/1283 [================>.............] - ETA: 0s - loss: 0.1245 - acc: 0.9609
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1211 - acc: 0.9639
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1185 - acc: 0.9643
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1199 - acc: 0.9635
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1189 - acc: 0.9648
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1261 - acc: 0.9632
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1266 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1266 - acc: 0.9646
1280/1283 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9656
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1248 - acc: 0.9657 - val_loss: 0.6816 - val_acc: 0.7118

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0826 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0755 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0698 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0728 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0724 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0704 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0673 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0663 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0652 - acc: 0.9913
 640/1283 [=============>................] - ETA: 0s - loss: 0.0677 - acc: 0.9891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0678 - acc: 0.9886
 768/1283 [================>.............] - ETA: 0s - loss: 0.0680 - acc: 0.9883
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0685 - acc: 0.9880
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0685 - acc: 0.9877
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0668 - acc: 0.9885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0684 - acc: 0.9863
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0714 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0736 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0748 - acc: 0.9827
1280/1283 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9812
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0757 - acc: 0.9813 - val_loss: 0.7634 - val_acc: 0.6900

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0416 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0451 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0404 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0463 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0493 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0493 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0463 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0432 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0432 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0462 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0442 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0435 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0454 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0444 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0441 - acc: 0.9948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0445 - acc: 0.9951
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0443 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0446 - acc: 0.9948
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0461 - acc: 0.9942
1280/1283 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9945
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0464 - acc: 0.9938 - val_loss: 0.8595 - val_acc: 0.7118

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0347 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0321 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0370 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0517 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0528 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0496 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0523 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0493 - acc: 0.9861
 640/1283 [=============>................] - ETA: 0s - loss: 0.0484 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0465 - acc: 0.9886
 768/1283 [================>.............] - ETA: 0s - loss: 0.0507 - acc: 0.9870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0490 - acc: 0.9880
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0484 - acc: 0.9888
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0689 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0718 - acc: 0.9824
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0699 - acc: 0.9825
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0680 - acc: 0.9826
1280/1283 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9820
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0688 - acc: 0.9821 - val_loss: 0.9853 - val_acc: 0.6594

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0639 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0499 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0698 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0594 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0548 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0584 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0544 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0530 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0516 - acc: 0.9913
 640/1283 [=============>................] - ETA: 0s - loss: 0.0500 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0480 - acc: 0.9929
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0448 - acc: 0.9928
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0485 - acc: 0.9917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0514 - acc: 0.9902
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0500 - acc: 0.9908
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0487 - acc: 0.9913
1280/1283 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9922
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0466 - acc: 0.9922 - val_loss: 0.9507 - val_acc: 0.7074

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0334 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0281 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0300 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0283 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0276 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0262 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0311 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0385 - acc: 0.9941
 640/1283 [=============>................] - ETA: 0s - loss: 0.0358 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0348 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0325 - acc: 0.9952
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0313 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0309 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0305 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0303 - acc: 0.9948
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0295 - acc: 0.9951
1280/1283 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9953
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0287 - acc: 0.9953 - val_loss: 0.9774 - val_acc: 0.6900

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0221 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0220 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0190 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0184 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0193 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0188 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0170 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0160 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0189 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0188 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0182 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0195 - acc: 0.9974
1280/1283 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9977
1283/1283 [==============================] - 1s 883us/step - loss: 0.0195 - acc: 0.9977 - val_loss: 1.0729 - val_acc: 0.6943

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0119 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0120 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0135 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0138 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0133 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0142 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0150 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0155 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0155 - acc: 0.9989
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0153 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0158 - acc: 0.9983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0156 - acc: 0.9984
1280/1283 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9984
1283/1283 [==============================] - 1s 929us/step - loss: 0.0157 - acc: 0.9984 - val_loss: 1.0603 - val_acc: 0.7031

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0121 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0113 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0103 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0117 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0154 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0152 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0140 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0137 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0143 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0137 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0140 - acc: 0.9992
1283/1283 [==============================] - 1s 835us/step - loss: 0.0139 - acc: 0.9992 - val_loss: 1.0931 - val_acc: 0.7074

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
nodes=100
mode=all
PCA audio=10
PCA visual=25
PCA text=110
accuracy=0.6836734693877551
best_valid_accuracy=0.6763848396501457
