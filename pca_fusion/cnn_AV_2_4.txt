/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 01:56:53.756851: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.7397 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7243 - acc: 0.5000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7105 - acc: 0.5062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6915 - acc: 0.5446
 576/1283 [============>.................] - ETA: 0s - loss: 0.6894 - acc: 0.5573
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6893 - acc: 0.5625
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6887 - acc: 0.5625
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6943 - acc: 0.5458
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6893 - acc: 0.5487
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6874 - acc: 0.5584
1283/1283 [==============================] - 1s 782us/step - loss: 0.6869 - acc: 0.5581 - val_loss: 0.7027 - val_acc: 0.5240

Epoch 00001: val_acc improved from -inf to 0.52402, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6230 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6266 - acc: 0.6562
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6178 - acc: 0.6594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6007 - acc: 0.6853
 576/1283 [============>.................] - ETA: 0s - loss: 0.6072 - acc: 0.6649
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6087 - acc: 0.6662
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6154 - acc: 0.6587
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6196 - acc: 0.6531
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6151 - acc: 0.6636
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6163 - acc: 0.6653
1283/1283 [==============================] - 1s 610us/step - loss: 0.6175 - acc: 0.6617 - val_loss: 0.6953 - val_acc: 0.5590

Epoch 00002: val_acc improved from 0.52402 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5428 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5867 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5832 - acc: 0.6719
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5793 - acc: 0.6680
 640/1283 [=============>................] - ETA: 0s - loss: 0.5712 - acc: 0.6781
 768/1283 [================>.............] - ETA: 0s - loss: 0.5685 - acc: 0.6875
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5618 - acc: 0.6959
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5697 - acc: 0.6906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5703 - acc: 0.6875
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5680 - acc: 0.6859
1283/1283 [==============================] - 1s 521us/step - loss: 0.5667 - acc: 0.6875 - val_loss: 0.7156 - val_acc: 0.5721

Epoch 00003: val_acc improved from 0.55895 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4902 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4746 - acc: 0.8021
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4733 - acc: 0.7906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4939 - acc: 0.7612
 576/1283 [============>.................] - ETA: 0s - loss: 0.4983 - acc: 0.7569
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5011 - acc: 0.7571
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5000 - acc: 0.7596
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4950 - acc: 0.7637
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4890 - acc: 0.7697
1283/1283 [==============================] - 1s 569us/step - loss: 0.4907 - acc: 0.7638 - val_loss: 0.7445 - val_acc: 0.5197

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4657 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4339 - acc: 0.8073
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4223 - acc: 0.8187
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4113 - acc: 0.8242
 640/1283 [=============>................] - ETA: 0s - loss: 0.4156 - acc: 0.8203
 768/1283 [================>.............] - ETA: 0s - loss: 0.4184 - acc: 0.8086
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4203 - acc: 0.8125
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4185 - acc: 0.8160
1280/1283 [============================>.] - ETA: 0s - loss: 0.4160 - acc: 0.8180
1283/1283 [==============================] - 1s 459us/step - loss: 0.4157 - acc: 0.8176 - val_loss: 0.8068 - val_acc: 0.5284

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3317 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3815 - acc: 0.7969
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3758 - acc: 0.8313
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3770 - acc: 0.8398
 640/1283 [=============>................] - ETA: 0s - loss: 0.3743 - acc: 0.8406
 768/1283 [================>.............] - ETA: 0s - loss: 0.3691 - acc: 0.8438
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3638 - acc: 0.8500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3594 - acc: 0.8529
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3614 - acc: 0.8470
1283/1283 [==============================] - 1s 471us/step - loss: 0.3568 - acc: 0.8504 - val_loss: 0.8151 - val_acc: 0.5502

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2351 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2927 - acc: 0.8789
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3172 - acc: 0.8638
 640/1283 [=============>................] - ETA: 0s - loss: 0.3169 - acc: 0.8672
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3205 - acc: 0.8654
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3115 - acc: 0.8750
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3182 - acc: 0.8692
1283/1283 [==============================] - 0s 377us/step - loss: 0.3165 - acc: 0.8706 - val_loss: 0.9438 - val_acc: 0.5459

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2416 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2262 - acc: 0.8958
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2413 - acc: 0.8938
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2484 - acc: 0.8926
 640/1283 [=============>................] - ETA: 0s - loss: 0.2551 - acc: 0.8875
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2536 - acc: 0.8930
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2493 - acc: 0.8990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2467 - acc: 0.8998
1280/1283 [============================>.] - ETA: 0s - loss: 0.2405 - acc: 0.9047
1283/1283 [==============================] - 1s 440us/step - loss: 0.2404 - acc: 0.9049 - val_loss: 0.9273 - val_acc: 0.5197

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1850 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1686 - acc: 0.9635
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1814 - acc: 0.9557
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1791 - acc: 0.9551
 640/1283 [=============>................] - ETA: 0s - loss: 0.1752 - acc: 0.9547
 768/1283 [================>.............] - ETA: 0s - loss: 0.1771 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1733 - acc: 0.9542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1734 - acc: 0.9540
1280/1283 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9516
1283/1283 [==============================] - 1s 450us/step - loss: 0.1761 - acc: 0.9517 - val_loss: 1.0025 - val_acc: 0.5197

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1288 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1167 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1276 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.1220 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1269 - acc: 0.9627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1262 - acc: 0.9656
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1237 - acc: 0.9688
1283/1283 [==============================] - 1s 401us/step - loss: 0.1244 - acc: 0.9688 - val_loss: 1.1929 - val_acc: 0.5328

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1154 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2019 - acc: 0.8958
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2241 - acc: 0.8938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2177 - acc: 0.8929
 576/1283 [============>.................] - ETA: 0s - loss: 0.2561 - acc: 0.8733
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2403 - acc: 0.8878
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2305 - acc: 0.8930
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2231 - acc: 0.8979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2142 - acc: 0.9017
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2080 - acc: 0.9054
1283/1283 [==============================] - 1s 498us/step - loss: 0.2061 - acc: 0.9057 - val_loss: 1.0929 - val_acc: 0.5284

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0896 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1319 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1588 - acc: 0.9453
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1522 - acc: 0.9551
 640/1283 [=============>................] - ETA: 0s - loss: 0.1565 - acc: 0.9500
 768/1283 [================>.............] - ETA: 0s - loss: 0.1632 - acc: 0.9453
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1585 - acc: 0.9498
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1568 - acc: 0.9512
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1593 - acc: 0.9505
1280/1283 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9500
1283/1283 [==============================] - 1s 576us/step - loss: 0.1550 - acc: 0.9501 - val_loss: 1.2224 - val_acc: 0.5109

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1094 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1569 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1297 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.1244 - acc: 0.9618
 768/1283 [================>.............] - ETA: 0s - loss: 0.1265 - acc: 0.9635
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1229 - acc: 0.9632
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1172 - acc: 0.9658
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1225 - acc: 0.9644
1280/1283 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9648
1283/1283 [==============================] - 1s 475us/step - loss: 0.1197 - acc: 0.9649 - val_loss: 1.2499 - val_acc: 0.5328

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
nodes=100
mode=AV
PCA audio=20
PCA visual=15
PCA text=130
accuracy=0.5743440233236151
best_valid_accuracy=0.5364431486880467
