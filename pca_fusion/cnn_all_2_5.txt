/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 01:41:44.307776: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.7337 - acc: 0.3750
 192/1283 [===>..........................] - ETA: 2s - loss: 0.7462 - acc: 0.4688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.7492 - acc: 0.4844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7545 - acc: 0.4922
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7430 - acc: 0.5059
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7271 - acc: 0.5284
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7206 - acc: 0.5402
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7146 - acc: 0.5404
1280/1283 [============================>.] - ETA: 0s - loss: 0.7064 - acc: 0.5492
1283/1283 [==============================] - 1s 702us/step - loss: 0.7063 - acc: 0.5487 - val_loss: 0.6731 - val_acc: 0.5852

Epoch 00001: val_acc improved from -inf to 0.58515, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5101 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5197 - acc: 0.7760
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5212 - acc: 0.7552
 576/1283 [============>.................] - ETA: 0s - loss: 0.5098 - acc: 0.7899
 768/1283 [================>.............] - ETA: 0s - loss: 0.4942 - acc: 0.8125
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4901 - acc: 0.8094
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4855 - acc: 0.8056
1283/1283 [==============================] - 1s 400us/step - loss: 0.4830 - acc: 0.8067 - val_loss: 0.8311 - val_acc: 0.5721

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3339 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4216 - acc: 0.7708
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3785 - acc: 0.8281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3810 - acc: 0.8348
 640/1283 [=============>................] - ETA: 0s - loss: 0.3643 - acc: 0.8516
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3496 - acc: 0.8594
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3405 - acc: 0.8637
1283/1283 [==============================] - 0s 353us/step - loss: 0.3348 - acc: 0.8636 - val_loss: 0.7462 - val_acc: 0.6245

Epoch 00003: val_acc improved from 0.58515 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2086 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2920 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2907 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2730 - acc: 0.8795
 576/1283 [============>.................] - ETA: 0s - loss: 0.2687 - acc: 0.8854
 768/1283 [================>.............] - ETA: 0s - loss: 0.2722 - acc: 0.8867
 832/1283 [==================>...........] - ETA: 1s - loss: 0.2693 - acc: 0.8846
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2639 - acc: 0.8906
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2566 - acc: 0.8947
1283/1283 [==============================] - 3s 2ms/step - loss: 0.2564 - acc: 0.8948 - val_loss: 0.8125 - val_acc: 0.6332

Epoch 00004: val_acc improved from 0.62445 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1690 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1422 - acc: 0.9740
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1378 - acc: 0.9688
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1345 - acc: 0.9699
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1256 - acc: 0.9740
1283/1283 [==============================] - 0s 230us/step - loss: 0.1234 - acc: 0.9719 - val_loss: 0.9044 - val_acc: 0.6638

Epoch 00005: val_acc improved from 0.63319 to 0.66376, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0668 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0888 - acc: 0.9812
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0824 - acc: 0.9824
 768/1283 [================>.............] - ETA: 0s - loss: 0.0729 - acc: 0.9870
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0714 - acc: 0.9863
1280/1283 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9859
1283/1283 [==============================] - 0s 265us/step - loss: 0.0694 - acc: 0.9860 - val_loss: 1.0484 - val_acc: 0.6638

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0491 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0445 - acc: 0.9906
 576/1283 [============>.................] - ETA: 0s - loss: 0.0408 - acc: 0.9913
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0402 - acc: 0.9928
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0394 - acc: 0.9922
1283/1283 [==============================] - 0s 235us/step - loss: 0.0396 - acc: 0.9922 - val_loss: 1.1573 - val_acc: 0.6725

Epoch 00007: val_acc improved from 0.66376 to 0.67249, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0137 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0192 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0261 - acc: 0.9933
 640/1283 [=============>................] - ETA: 0s - loss: 0.0271 - acc: 0.9938
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0264 - acc: 0.9952
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0254 - acc: 0.9951
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0255 - acc: 0.9942
1283/1283 [==============================] - 0s 324us/step - loss: 0.0251 - acc: 0.9945 - val_loss: 1.2629 - val_acc: 0.6463

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0121 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0202 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0180 - acc: 0.9933
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0153 - acc: 0.9957
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0170 - acc: 0.9948
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0171 - acc: 0.9942
1283/1283 [==============================] - 0s 285us/step - loss: 0.0166 - acc: 0.9945 - val_loss: 1.3699 - val_acc: 0.6638

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0132 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0115 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0129 - acc: 0.9978
 640/1283 [=============>................] - ETA: 0s - loss: 0.0120 - acc: 0.9984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0124 - acc: 0.9976
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0132 - acc: 0.9961
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0123 - acc: 0.9959
1283/1283 [==============================] - 0s 365us/step - loss: 0.0119 - acc: 0.9961 - val_loss: 1.4504 - val_acc: 0.6638

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0084 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0084 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0102 - acc: 0.9978
 640/1283 [=============>................] - ETA: 0s - loss: 0.0085 - acc: 0.9984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0085 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0088 - acc: 0.9979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0088 - acc: 0.9982
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0094 - acc: 0.9975
1283/1283 [==============================] - 1s 461us/step - loss: 0.0095 - acc: 0.9977 - val_loss: 1.5305 - val_acc: 0.6638

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0068 - acc: 0.9974
 576/1283 [============>.................] - ETA: 0s - loss: 0.0091 - acc: 0.9965
 768/1283 [================>.............] - ETA: 0s - loss: 0.0087 - acc: 0.9974
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0080 - acc: 0.9979
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0073 - acc: 0.9983
1283/1283 [==============================] - 0s 383us/step - loss: 0.0075 - acc: 0.9984 - val_loss: 1.5998 - val_acc: 0.6594

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0019 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0096 - acc: 0.9955
 640/1283 [=============>................] - ETA: 0s - loss: 0.0078 - acc: 0.9969
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0066 - acc: 0.9976
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0069 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0069 - acc: 0.9974
1283/1283 [==============================] - 1s 402us/step - loss: 0.0066 - acc: 0.9977 - val_loss: 1.7051 - val_acc: 0.6463

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0138 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0075 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0065 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0057 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0051 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0056 - acc: 0.9990
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0061 - acc: 0.9992
1283/1283 [==============================] - 0s 381us/step - loss: 0.0066 - acc: 0.9984 - val_loss: 1.7481 - val_acc: 0.6463

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0132 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0244 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0173 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0145 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0136 - acc: 0.9983
 768/1283 [================>.............] - ETA: 0s - loss: 0.0117 - acc: 0.9987
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0103 - acc: 0.9989
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0109 - acc: 0.9980
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0123 - acc: 0.9967
1283/1283 [==============================] - 1s 427us/step - loss: 0.0118 - acc: 0.9969 - val_loss: 1.6838 - val_acc: 0.6594

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0155 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0275 - acc: 0.9911
 640/1283 [=============>................] - ETA: 0s - loss: 0.0265 - acc: 0.9891
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0224 - acc: 0.9916
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0223 - acc: 0.9912
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0210 - acc: 0.9926
1283/1283 [==============================] - 0s 359us/step - loss: 0.0231 - acc: 0.9914 - val_loss: 1.5913 - val_acc: 0.6550

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0158 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0157 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0152 - acc: 0.9978
 640/1283 [=============>................] - ETA: 0s - loss: 0.0146 - acc: 0.9969
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0133 - acc: 0.9976
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0121 - acc: 0.9980
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0147 - acc: 0.9959
1283/1283 [==============================] - 0s 353us/step - loss: 0.0145 - acc: 0.9961 - val_loss: 1.6226 - val_acc: 0.6638

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=15
nodes=100
mode=all
PCA audio=20
PCA visual=15
PCA text=130
accuracy=0.6311953352769679
best_valid_accuracy=0.6209912536443148
