/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 02:04:36.204156: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.8069 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 2s - loss: 0.8657 - acc: 0.4896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.8133 - acc: 0.5195
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7978 - acc: 0.5250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7785 - acc: 0.5443
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7696 - acc: 0.5469
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7615 - acc: 0.5449
 576/1283 [============>.................] - ETA: 1s - loss: 0.7498 - acc: 0.5521
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7380 - acc: 0.5568
 768/1283 [================>.............] - ETA: 0s - loss: 0.7314 - acc: 0.5638
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7308 - acc: 0.5625
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7324 - acc: 0.5552
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7246 - acc: 0.5579
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7226 - acc: 0.5600
1280/1283 [============================>.] - ETA: 0s - loss: 0.7212 - acc: 0.5602
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7212 - acc: 0.5596 - val_loss: 0.7094 - val_acc: 0.5240

Epoch 00001: val_acc improved from -inf to 0.52402, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5263 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.5125 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5344 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5415 - acc: 0.7219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5324 - acc: 0.7266
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5326 - acc: 0.7232
 576/1283 [============>.................] - ETA: 0s - loss: 0.5322 - acc: 0.7222
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5215 - acc: 0.7457
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5177 - acc: 0.7548
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5127 - acc: 0.7646
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5084 - acc: 0.7757
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5048 - acc: 0.7812
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5025 - acc: 0.7829
1283/1283 [==============================] - 1s 941us/step - loss: 0.5016 - acc: 0.7857 - val_loss: 0.7003 - val_acc: 0.6026

Epoch 00002: val_acc improved from 0.52402 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3788 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3680 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3715 - acc: 0.9156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3649 - acc: 0.9107
 576/1283 [============>.................] - ETA: 0s - loss: 0.3550 - acc: 0.9097
 640/1283 [=============>................] - ETA: 0s - loss: 0.3602 - acc: 0.8953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3565 - acc: 0.8906
 768/1283 [================>.............] - ETA: 0s - loss: 0.3514 - acc: 0.8945
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3483 - acc: 0.8906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3421 - acc: 0.8916
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3396 - acc: 0.8888
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3416 - acc: 0.8832
1283/1283 [==============================] - 1s 899us/step - loss: 0.3395 - acc: 0.8839 - val_loss: 0.6913 - val_acc: 0.6419

Epoch 00003: val_acc improved from 0.60262 to 0.64192, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1856 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2091 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2060 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2195 - acc: 0.9397
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2181 - acc: 0.9414
 576/1283 [============>.................] - ETA: 0s - loss: 0.2098 - acc: 0.9444
 640/1283 [=============>................] - ETA: 0s - loss: 0.2129 - acc: 0.9437
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2117 - acc: 0.9432
 768/1283 [================>.............] - ETA: 0s - loss: 0.2047 - acc: 0.9453
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2025 - acc: 0.9435
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2011 - acc: 0.9406
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2006 - acc: 0.9375
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1962 - acc: 0.9392
1280/1283 [============================>.] - ETA: 0s - loss: 0.1940 - acc: 0.9406
1283/1283 [==============================] - 1s 784us/step - loss: 0.1936 - acc: 0.9408 - val_loss: 0.7921 - val_acc: 0.6419

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1127 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1110 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1124 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1051 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1054 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1039 - acc: 0.9785
 576/1283 [============>.................] - ETA: 0s - loss: 0.0997 - acc: 0.9792
 640/1283 [=============>................] - ETA: 0s - loss: 0.0982 - acc: 0.9781
 768/1283 [================>.............] - ETA: 0s - loss: 0.0963 - acc: 0.9779
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0981 - acc: 0.9760
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0964 - acc: 0.9766
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0952 - acc: 0.9771
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0944 - acc: 0.9775
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0933 - acc: 0.9779
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0914 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0899 - acc: 0.9786
1280/1283 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9797
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0874 - acc: 0.9797 - val_loss: 1.0807 - val_acc: 0.6463

Epoch 00005: val_acc improved from 0.64192 to 0.64629, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0604 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0594 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0514 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0503 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0463 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0450 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0432 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0420 - acc: 0.9948
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0413 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0419 - acc: 0.9944
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0417 - acc: 0.9932
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0420 - acc: 0.9922
1280/1283 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9930
1283/1283 [==============================] - 1s 765us/step - loss: 0.0414 - acc: 0.9930 - val_loss: 0.9433 - val_acc: 0.6594

Epoch 00006: val_acc improved from 0.64629 to 0.65939, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0207 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0247 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0210 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0202 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0205 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0190 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0186 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0200 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0191 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0189 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0185 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0181 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0183 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0178 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0173 - acc: 0.9983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0172 - acc: 0.9984
1283/1283 [==============================] - 1s 913us/step - loss: 0.0176 - acc: 0.9984 - val_loss: 1.0871 - val_acc: 0.6725

Epoch 00007: val_acc improved from 0.65939 to 0.67249, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0084 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0080 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0081 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0091 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0085 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0084 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0081 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0079 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0077 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 1.0000
1283/1283 [==============================] - 1s 717us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.1182 - val_acc: 0.6769

Epoch 00008: val_acc improved from 0.67249 to 0.67686, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0039 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0037 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0051 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0047 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0046 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0044 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 1.0000
1283/1283 [==============================] - 1s 843us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 1.2193 - val_acc: 0.6725

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0037 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0035 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0031 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0030 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0030 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0029 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 1.0000
1283/1283 [==============================] - 1s 923us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.2764 - val_acc: 0.6900

Epoch 00010: val_acc improved from 0.67686 to 0.68996, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0016 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0029 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0024 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0022 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0021 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0021 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0021 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0021 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0021 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0020 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 1.0000
1283/1283 [==============================] - 1s 958us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.3219 - val_acc: 0.6943

Epoch 00011: val_acc improved from 0.68996 to 0.69432, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 9.4598e-04 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0012 - acc: 1.0000    
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0022 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0021 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0019 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0018 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0016 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1283/1283 [==============================] - 1s 951us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.3524 - val_acc: 0.6943

Epoch 00012: val_acc improved from 0.69432 to 0.69432, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 7.5616e-04 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 8.8517e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 8.0192e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 8.9365e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 8.9627e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 9.9734e-04 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 9.7887e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 9.8893e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0010 - acc: 1.0000    
 768/1283 [================>.............] - ETA: 0s - loss: 0.0011 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 9.8069e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 9.5863e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0011 - acc: 1.0000    
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0011 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 1.0000
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.3885 - val_acc: 0.6943

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 4.6797e-04 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 5.7859e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 6.6521e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0011 - acc: 1.0000    
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0011 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0013 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0012 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0012 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0011 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0011 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 9.9987e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 9.5849e-04 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 9.4787e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 9.4409e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 9.4502e-04 - acc: 1.0000
1283/1283 [==============================] - 2s 1ms/step - loss: 9.4718e-04 - acc: 1.0000 - val_loss: 1.4036 - val_acc: 0.6856

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 7.0109e-04 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 5.6967e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 5.3514e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 5.3750e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 6.8935e-04 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 8.8309e-04 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 8.8989e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 8.4090e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 8.4086e-04 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 8.6933e-04 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 9.2180e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 9.0390e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 8.7312e-04 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 8.7003e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 8.4710e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 8.3269e-04 - acc: 1.0000
1283/1283 [==============================] - 1s 1ms/step - loss: 8.3874e-04 - acc: 1.0000 - val_loss: 1.4575 - val_acc: 0.6856

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 6.8333e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 5.5108e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 5.8951e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 5.9749e-04 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 6.1283e-04 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 6.1896e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 6.2893e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 6.3711e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 6.7433e-04 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 8.0382e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 7.9108e-04 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 7.7199e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 7.5555e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 7.5584e-04 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 7.3513e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 7.5446e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 7.4372e-04 - acc: 1.0000
1283/1283 [==============================] - 2s 1ms/step - loss: 7.5141e-04 - acc: 1.0000 - val_loss: 1.4667 - val_acc: 0.6769

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 5.0893e-04 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 4.9963e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 5.2683e-04 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 4.5951e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 5.1366e-04 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 5.6450e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 5.2740e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 5.8357e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 5.8488e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 5.9324e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 5.7536e-04 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 6.0400e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 7.3801e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 7.1719e-04 - acc: 1.0000
1283/1283 [==============================] - 1s 1ms/step - loss: 7.1551e-04 - acc: 1.0000 - val_loss: 1.4474 - val_acc: 0.6638

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 1s - loss: 3.5050e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 3.7063e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 4.2014e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 4.2763e-04 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 4.0518e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 4.2657e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 4.4287e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 4.2332e-04 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 5.6442e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 5.3571e-04 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 5.4195e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 5.3904e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 5.3388e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 5.2503e-04 - acc: 1.0000
1283/1283 [==============================] - 1s 1ms/step - loss: 5.2404e-04 - acc: 1.0000 - val_loss: 1.5436 - val_acc: 0.6681

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 3.6738e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 3.9972e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 4.0034e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 4.3955e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 4.0251e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 4.5530e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 5.1190e-04 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 4.9421e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 1s - loss: 5.1266e-04 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 1s - loss: 4.9350e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 1s - loss: 4.7093e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 4.6187e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 4.3957e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 4.2931e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 4.4779e-04 - acc: 1.0000
1283/1283 [==============================] - 4s 3ms/step - loss: 4.4778e-04 - acc: 1.0000 - val_loss: 1.5367 - val_acc: 0.6769

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 2s - loss: 2.4097e-04 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 2.8211e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 2.3682e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 3.5977e-04 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 3.6037e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 3.4180e-04 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 3.3502e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 3.2720e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 3.3330e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 1s - loss: 3.2097e-04 - acc: 1.0000
 768/1283 [================>.............] - ETA: 1s - loss: 3.0978e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 3.2099e-04 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 3.6253e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 3.7776e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 3.6271e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 3.5212e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 3.6732e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 3.6022e-04 - acc: 1.0000
1283/1283 [==============================] - 4s 3ms/step - loss: 3.5951e-04 - acc: 1.0000 - val_loss: 1.5877 - val_acc: 0.6769

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 2.2080e-04 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 5.1648e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 2s - loss: 4.0787e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 4.0863e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 3.9616e-04 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 3.6588e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 1s - loss: 3.3370e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 1s - loss: 3.2313e-04 - acc: 1.0000
 768/1283 [================>.............] - ETA: 1s - loss: 3.1991e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 1s - loss: 3.4639e-04 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 1s - loss: 3.3475e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 1s - loss: 3.1982e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 3.0973e-04 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 3.1249e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 3.1226e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 3.1469e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 3.1084e-04 - acc: 1.0000
1283/1283 [==============================] - 7s 5ms/step - loss: 3.1044e-04 - acc: 1.0000 - val_loss: 1.5950 - val_acc: 0.6812

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 2.5909e-04 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 3.3762e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 2s - loss: 3.0188e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 2s - loss: 2.6569e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 2s - loss: 2.4621e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 2.1758e-04 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 2.0196e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 1s - loss: 2.7537e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 2s - loss: 2.9256e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 1s - loss: 2.7780e-04 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 1s - loss: 2.7196e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 1s - loss: 2.7521e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 2.6849e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 2.8805e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 2.8967e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 2.9086e-04 - acc: 1.0000
1283/1283 [==============================] - 6s 5ms/step - loss: 3.0387e-04 - acc: 1.0000 - val_loss: 1.6122 - val_acc: 0.6725

Epoch 00022: val_acc did not improve
Epoch 00022: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=30
nodes=100
mode=AT
PCA audio=20
PCA visual=15
PCA text=130
accuracy=0.6559766763848397
best_valid_accuracy=0.6516034985422741
