/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 02:05:47.512727: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.7368 - acc: 0.4062
 192/1283 [===>..........................] - ETA: 2s - loss: 0.7369 - acc: 0.5104
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7294 - acc: 0.5344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7193 - acc: 0.5339
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7178 - acc: 0.5312
 576/1283 [============>.................] - ETA: 0s - loss: 0.7159 - acc: 0.5347
 640/1283 [=============>................] - ETA: 0s - loss: 0.7135 - acc: 0.5391
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7106 - acc: 0.5440
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7060 - acc: 0.5505
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7048 - acc: 0.5417
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7052 - acc: 0.5358
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7089 - acc: 0.5312
1280/1283 [============================>.] - ETA: 0s - loss: 0.7122 - acc: 0.5273
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7125 - acc: 0.5269 - val_loss: 0.7019 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6344 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6315 - acc: 0.6510
 256/1283 [====>.........................] - ETA: 0s - loss: 0.7011 - acc: 0.5859
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6935 - acc: 0.5651
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6925 - acc: 0.5558
 576/1283 [============>.................] - ETA: 0s - loss: 0.6842 - acc: 0.5694
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6780 - acc: 0.5866
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6709 - acc: 0.6034
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6651 - acc: 0.6006
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6605 - acc: 0.6068
1280/1283 [============================>.] - ETA: 0s - loss: 0.6576 - acc: 0.6078
1283/1283 [==============================] - 1s 610us/step - loss: 0.6573 - acc: 0.6087 - val_loss: 0.7178 - val_acc: 0.5546

Epoch 00002: val_acc improved from 0.52838 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5608 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5511 - acc: 0.7396
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5517 - acc: 0.7292
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5520 - acc: 0.7277
 576/1283 [============>.................] - ETA: 0s - loss: 0.5497 - acc: 0.7170
 640/1283 [=============>................] - ETA: 0s - loss: 0.5505 - acc: 0.7094
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5462 - acc: 0.7131
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5418 - acc: 0.7200
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5382 - acc: 0.7266
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5335 - acc: 0.7383
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5319 - acc: 0.7396
1280/1283 [============================>.] - ETA: 0s - loss: 0.5266 - acc: 0.7492
1283/1283 [==============================] - 1s 747us/step - loss: 0.5268 - acc: 0.7490 - val_loss: 0.7842 - val_acc: 0.5677

Epoch 00003: val_acc improved from 0.55459 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3363 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4928 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4484 - acc: 0.7750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4367 - acc: 0.7902
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4394 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4363 - acc: 0.7917
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4262 - acc: 0.8026
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4171 - acc: 0.8017
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4085 - acc: 0.8092
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4095 - acc: 0.8063
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4051 - acc: 0.8115
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4091 - acc: 0.8082
1280/1283 [============================>.] - ETA: 0s - loss: 0.3981 - acc: 0.8156
1283/1283 [==============================] - 1s 807us/step - loss: 0.3992 - acc: 0.8145 - val_loss: 0.8126 - val_acc: 0.5852

Epoch 00004: val_acc improved from 0.56769 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2844 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.2455 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3162 - acc: 0.8789
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3358 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3279 - acc: 0.8772
 576/1283 [============>.................] - ETA: 0s - loss: 0.3443 - acc: 0.8559
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3408 - acc: 0.8523
 768/1283 [================>.............] - ETA: 0s - loss: 0.3330 - acc: 0.8581
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3263 - acc: 0.8627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3268 - acc: 0.8604
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3240 - acc: 0.8585
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3192 - acc: 0.8586
1283/1283 [==============================] - 1s 736us/step - loss: 0.3159 - acc: 0.8605 - val_loss: 0.9097 - val_acc: 0.5939

Epoch 00005: val_acc improved from 0.58515 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2149 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2061 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2138 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2080 - acc: 0.9196
 576/1283 [============>.................] - ETA: 0s - loss: 0.2085 - acc: 0.9115
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2082 - acc: 0.9134
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1996 - acc: 0.9147
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1983 - acc: 0.9177
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1988 - acc: 0.9210
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1979 - acc: 0.9235
1280/1283 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9250
1283/1283 [==============================] - 1s 642us/step - loss: 0.1960 - acc: 0.9252 - val_loss: 1.1001 - val_acc: 0.5939

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1261 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1335 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1486 - acc: 0.9453
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1315 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1351 - acc: 0.9576
 576/1283 [============>.................] - ETA: 0s - loss: 0.1323 - acc: 0.9566
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1280 - acc: 0.9560
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1255 - acc: 0.9555
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1289 - acc: 0.9500
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1322 - acc: 0.9453
1280/1283 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9469
1283/1283 [==============================] - 1s 686us/step - loss: 0.1307 - acc: 0.9470 - val_loss: 1.3473 - val_acc: 0.5808

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0816 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0832 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0774 - acc: 0.9727
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0853 - acc: 0.9661
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0864 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.0868 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0842 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0834 - acc: 0.9700
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0846 - acc: 0.9677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0841 - acc: 0.9678
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0835 - acc: 0.9679
1280/1283 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9656
1283/1283 [==============================] - 1s 632us/step - loss: 0.0864 - acc: 0.9657 - val_loss: 1.7233 - val_acc: 0.5546

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0686 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0853 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1002 - acc: 0.9563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1037 - acc: 0.9509
 576/1283 [============>.................] - ETA: 0s - loss: 0.1094 - acc: 0.9479
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1286 - acc: 0.9418
 768/1283 [================>.............] - ETA: 0s - loss: 0.1214 - acc: 0.9466
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1171 - acc: 0.9487
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1150 - acc: 0.9479
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1111 - acc: 0.9513
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1074 - acc: 0.9540
1280/1283 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9570
1283/1283 [==============================] - 1s 662us/step - loss: 0.1029 - acc: 0.9571 - val_loss: 1.7806 - val_acc: 0.5633

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0644 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0728 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0687 - acc: 0.9781
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0698 - acc: 0.9746
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0800 - acc: 0.9673
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0750 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0786 - acc: 0.9660
1280/1283 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9688
1283/1283 [==============================] - 1s 480us/step - loss: 0.0741 - acc: 0.9688 - val_loss: 1.8260 - val_acc: 0.5677

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0265 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0511 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0607 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.0611 - acc: 0.9722
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0595 - acc: 0.9716
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0550 - acc: 0.9736
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0578 - acc: 0.9719
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0607 - acc: 0.9706
1280/1283 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9703
1283/1283 [==============================] - 1s 442us/step - loss: 0.0612 - acc: 0.9704 - val_loss: 2.0548 - val_acc: 0.5590

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0799 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0686 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0642 - acc: 0.9635
 576/1283 [============>.................] - ETA: 0s - loss: 0.0611 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0566 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0571 - acc: 0.9700
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0605 - acc: 0.9717
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0557 - acc: 0.9729
1283/1283 [==============================] - 1s 403us/step - loss: 0.0555 - acc: 0.9743 - val_loss: 2.2383 - val_acc: 0.5546

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0287 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0832 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0919 - acc: 0.9621
 576/1283 [============>.................] - ETA: 0s - loss: 0.0870 - acc: 0.9618
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1298 - acc: 0.9489
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1363 - acc: 0.9431
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1287 - acc: 0.9458
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1322 - acc: 0.9449
1283/1283 [==============================] - 1s 448us/step - loss: 0.1279 - acc: 0.9470 - val_loss: 2.1800 - val_acc: 0.5721

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0563 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0757 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1047 - acc: 0.9397
 640/1283 [=============>................] - ETA: 0s - loss: 0.0907 - acc: 0.9516
 768/1283 [================>.............] - ETA: 0s - loss: 0.0890 - acc: 0.9570
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0897 - acc: 0.9565
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0891 - acc: 0.9563
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0867 - acc: 0.9596
1280/1283 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9586
1283/1283 [==============================] - 1s 461us/step - loss: 0.0921 - acc: 0.9579 - val_loss: 1.8110 - val_acc: 0.5764

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0644 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0649 - acc: 0.9740
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0758 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0695 - acc: 0.9746
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0792 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0848 - acc: 0.9625
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0887 - acc: 0.9632
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0912 - acc: 0.9622
1283/1283 [==============================] - 1s 442us/step - loss: 0.0922 - acc: 0.9626 - val_loss: 1.6154 - val_acc: 0.5590

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=3
max_len=25
nodes=100
mode=AT
PCA audio=20
PCA visual=15
PCA text=130
accuracy=0.6034985422740525
best_valid_accuracy=0.5801749271137027
