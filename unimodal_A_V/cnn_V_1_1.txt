/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:15:25.263805: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.7024 - acc: 0.4062
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6971 - acc: 0.4980
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6930 - acc: 0.4877
1280/1283 [============================>.] - ETA: 0s - loss: 0.6845 - acc: 0.5133
1283/1283 [==============================] - 0s 277us/step - loss: 0.6844 - acc: 0.5144 - val_loss: 0.6833 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6450 - acc: 0.6562
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6451 - acc: 0.6146
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6458 - acc: 0.6108
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6615 - acc: 0.6161
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6555 - acc: 0.6172
1283/1283 [==============================] - 0s 216us/step - loss: 0.6533 - acc: 0.6150 - val_loss: 0.7299 - val_acc: 0.5022

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6432 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6684 - acc: 0.6188
 640/1283 [=============>................] - ETA: 0s - loss: 0.6464 - acc: 0.6219
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6565 - acc: 0.6260
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6503 - acc: 0.6242
1283/1283 [==============================] - 0s 235us/step - loss: 0.6505 - acc: 0.6243 - val_loss: 0.6937 - val_acc: 0.5546

Epoch 00003: val_acc improved from 0.52838 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5989 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6792 - acc: 0.6500
 576/1283 [============>.................] - ETA: 0s - loss: 0.6579 - acc: 0.6337
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6437 - acc: 0.6382
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6344 - acc: 0.6406
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6345 - acc: 0.6439
1283/1283 [==============================] - 0s 289us/step - loss: 0.6309 - acc: 0.6461 - val_loss: 0.7073 - val_acc: 0.4978

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5405 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5852 - acc: 0.6781
 576/1283 [============>.................] - ETA: 0s - loss: 0.6242 - acc: 0.6562
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6175 - acc: 0.6659
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6113 - acc: 0.6660
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6171 - acc: 0.6538
1283/1283 [==============================] - 0s 291us/step - loss: 0.6184 - acc: 0.6524 - val_loss: 0.7338 - val_acc: 0.5197

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6022 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6342 - acc: 0.6094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6168 - acc: 0.6317
 640/1283 [=============>................] - ETA: 0s - loss: 0.6346 - acc: 0.6375
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6155 - acc: 0.6518
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6102 - acc: 0.6543
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6106 - acc: 0.6571
1283/1283 [==============================] - 0s 323us/step - loss: 0.6098 - acc: 0.6602 - val_loss: 0.7371 - val_acc: 0.5109

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6000 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5555 - acc: 0.6953
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5730 - acc: 0.6875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5772 - acc: 0.6932
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5852 - acc: 0.6833
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5922 - acc: 0.6900
1283/1283 [==============================] - 0s 302us/step - loss: 0.5889 - acc: 0.6929 - val_loss: 0.7512 - val_acc: 0.4803

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5830 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6413 - acc: 0.7188
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6273 - acc: 0.7057
 576/1283 [============>.................] - ETA: 0s - loss: 0.5985 - acc: 0.7031
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6056 - acc: 0.6839
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5950 - acc: 0.6958
1283/1283 [==============================] - 0s 272us/step - loss: 0.5905 - acc: 0.6952 - val_loss: 0.7367 - val_acc: 0.5546

Epoch 00008: val_acc improved from 0.55459 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5491 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6492 - acc: 0.6844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6618 - acc: 0.6406
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6462 - acc: 0.6534
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6337 - acc: 0.6585
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6249 - acc: 0.6580
1283/1283 [==============================] - 0s 289us/step - loss: 0.6259 - acc: 0.6547 - val_loss: 0.7456 - val_acc: 0.5109

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5620 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6245 - acc: 0.6914
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6066 - acc: 0.6964
 640/1283 [=============>................] - ETA: 0s - loss: 0.6054 - acc: 0.6828
 768/1283 [================>.............] - ETA: 0s - loss: 0.5950 - acc: 0.6953
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5936 - acc: 0.6975
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5992 - acc: 0.6866
1283/1283 [==============================] - 0s 360us/step - loss: 0.5898 - acc: 0.7007 - val_loss: 0.7535 - val_acc: 0.4803

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.8538 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6043 - acc: 0.7227
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5748 - acc: 0.7266
 768/1283 [================>.............] - ETA: 0s - loss: 0.5710 - acc: 0.7070
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5692 - acc: 0.7094
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5663 - acc: 0.7151
1280/1283 [============================>.] - ETA: 0s - loss: 0.5628 - acc: 0.7211
1283/1283 [==============================] - 0s 342us/step - loss: 0.5622 - acc: 0.7217 - val_loss: 0.7557 - val_acc: 0.5240

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5953 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5407 - acc: 0.7094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5339 - acc: 0.7232
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5331 - acc: 0.7287
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5308 - acc: 0.7254
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5449 - acc: 0.7325
1280/1283 [============================>.] - ETA: 0s - loss: 0.5493 - acc: 0.7258
1283/1283 [==============================] - 0s 350us/step - loss: 0.5496 - acc: 0.7249 - val_loss: 0.7909 - val_acc: 0.5240

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4496 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4862 - acc: 0.7708
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5350 - acc: 0.7135
 576/1283 [============>.................] - ETA: 0s - loss: 0.5369 - acc: 0.7170
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5418 - acc: 0.7145
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5317 - acc: 0.7132
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5426 - acc: 0.7059
1280/1283 [============================>.] - ETA: 0s - loss: 0.5527 - acc: 0.7094
1283/1283 [==============================] - 0s 376us/step - loss: 0.5519 - acc: 0.7101 - val_loss: 0.7934 - val_acc: 0.4541

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4771 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5024 - acc: 0.7695
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5087 - acc: 0.7411
 576/1283 [============>.................] - ETA: 0s - loss: 0.4976 - acc: 0.7569
 768/1283 [================>.............] - ETA: 0s - loss: 0.5075 - acc: 0.7487
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5233 - acc: 0.7479
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5233 - acc: 0.7413
1283/1283 [==============================] - 0s 359us/step - loss: 0.5180 - acc: 0.7451 - val_loss: 0.8043 - val_acc: 0.4716

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5008 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5035 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5518 - acc: 0.7522
 640/1283 [=============>................] - ETA: 0s - loss: 0.5514 - acc: 0.7391
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5507 - acc: 0.7404
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5338 - acc: 0.7454
1280/1283 [============================>.] - ETA: 0s - loss: 0.5358 - acc: 0.7375
1283/1283 [==============================] - 0s 326us/step - loss: 0.5355 - acc: 0.7381 - val_loss: 0.8413 - val_acc: 0.5197

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3524 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4583 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4749 - acc: 0.7778
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5045 - acc: 0.7668
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5071 - acc: 0.7564
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5041 - acc: 0.7582
1283/1283 [==============================] - 0s 307us/step - loss: 0.5015 - acc: 0.7592 - val_loss: 0.9744 - val_acc: 0.4585

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5182 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5894 - acc: 0.6687
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5375 - acc: 0.7168
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5382 - acc: 0.7145
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5453 - acc: 0.7208
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5409 - acc: 0.7283
1283/1283 [==============================] - 0s 295us/step - loss: 0.5314 - acc: 0.7389 - val_loss: 0.8422 - val_acc: 0.4760

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5664 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4868 - acc: 0.7695
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4666 - acc: 0.7946
 640/1283 [=============>................] - ETA: 0s - loss: 0.4666 - acc: 0.7922
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4952 - acc: 0.7746
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4927 - acc: 0.7700
1283/1283 [==============================] - 0s 289us/step - loss: 0.4891 - acc: 0.7716 - val_loss: 0.8028 - val_acc: 0.5153

Epoch 00018: val_acc did not improve
Epoch 00018: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
epochs=100
mode=V
accuracy=0.49271137026239065
best_valid_accuracy=0.532069970845481
