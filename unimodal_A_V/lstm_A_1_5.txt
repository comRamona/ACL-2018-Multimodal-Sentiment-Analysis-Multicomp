/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 08:38:48.176279: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 12s - loss: 0.6808 - acc: 0.5156
 128/1283 [=>............................] - ETA: 6s - loss: 0.6724 - acc: 0.5234 
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6772 - acc: 0.5625
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6815 - acc: 0.5443
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6875 - acc: 0.5312
 640/1283 [=============>................] - ETA: 1s - loss: 0.6840 - acc: 0.5453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6831 - acc: 0.5497
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6846 - acc: 0.5481
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6876 - acc: 0.5385
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6854 - acc: 0.5395
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6880 - acc: 0.5370
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6883 - acc: 0.5355 - val_loss: 0.6753 - val_acc: 0.6070

Epoch 00001: val_acc improved from -inf to 0.60699, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6380 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6601 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6612 - acc: 0.6125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6594 - acc: 0.6161
 576/1283 [============>.................] - ETA: 0s - loss: 0.6563 - acc: 0.6215
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6606 - acc: 0.6136
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6614 - acc: 0.6082
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6621 - acc: 0.6094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6611 - acc: 0.6074
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6604 - acc: 0.6094
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6598 - acc: 0.6127
1280/1283 [============================>.] - ETA: 0s - loss: 0.6598 - acc: 0.6102
1283/1283 [==============================] - 1s 762us/step - loss: 0.6600 - acc: 0.6103 - val_loss: 0.6729 - val_acc: 0.6201

Epoch 00002: val_acc improved from 0.60699 to 0.62009, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6551 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6491 - acc: 0.6354
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6357 - acc: 0.6344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6369 - acc: 0.6295
 576/1283 [============>.................] - ETA: 0s - loss: 0.6333 - acc: 0.6302
 640/1283 [=============>................] - ETA: 0s - loss: 0.6311 - acc: 0.6375
 768/1283 [================>.............] - ETA: 0s - loss: 0.6299 - acc: 0.6406
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6316 - acc: 0.6382
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6283 - acc: 0.6429
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6310 - acc: 0.6348
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6308 - acc: 0.6363
1280/1283 [============================>.] - ETA: 0s - loss: 0.6321 - acc: 0.6297
1283/1283 [==============================] - 1s 763us/step - loss: 0.6319 - acc: 0.6306 - val_loss: 0.6763 - val_acc: 0.6114

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5946 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5928 - acc: 0.6771
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6027 - acc: 0.6758
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6050 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6105 - acc: 0.6738
 576/1283 [============>.................] - ETA: 0s - loss: 0.6029 - acc: 0.6806
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6111 - acc: 0.6690
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6102 - acc: 0.6647
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6114 - acc: 0.6615
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6147 - acc: 0.6535
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6195 - acc: 0.6472
1283/1283 [==============================] - 1s 806us/step - loss: 0.6161 - acc: 0.6508 - val_loss: 0.6643 - val_acc: 0.6463

Epoch 00004: val_acc improved from 0.62009 to 0.64629, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5696 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5917 - acc: 0.6302
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5882 - acc: 0.6523
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6067 - acc: 0.6438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5995 - acc: 0.6585
 576/1283 [============>.................] - ETA: 0s - loss: 0.5883 - acc: 0.6667
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5952 - acc: 0.6562
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5960 - acc: 0.6599
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5990 - acc: 0.6585
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6018 - acc: 0.6521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6006 - acc: 0.6498
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6054 - acc: 0.6467
1280/1283 [============================>.] - ETA: 0s - loss: 0.6066 - acc: 0.6492
1283/1283 [==============================] - 1s 853us/step - loss: 0.6067 - acc: 0.6493 - val_loss: 0.6724 - val_acc: 0.6332

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5400 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5409 - acc: 0.7240
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5496 - acc: 0.7281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5639 - acc: 0.7009
 576/1283 [============>.................] - ETA: 0s - loss: 0.5758 - acc: 0.6892
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5721 - acc: 0.6974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5755 - acc: 0.6959
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5754 - acc: 0.6917
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5808 - acc: 0.6801
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5829 - acc: 0.6826
1283/1283 [==============================] - 1s 800us/step - loss: 0.5852 - acc: 0.6828 - val_loss: 0.6778 - val_acc: 0.6419

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5750 - acc: 0.7188
 128/1283 [=>............................] - ETA: 0s - loss: 0.5352 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5874 - acc: 0.6953
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5762 - acc: 0.6979
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5774 - acc: 0.6964
 576/1283 [============>.................] - ETA: 0s - loss: 0.5705 - acc: 0.7014
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5706 - acc: 0.7074
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5760 - acc: 0.6935
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5760 - acc: 0.6917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5805 - acc: 0.6855
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5792 - acc: 0.6875
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5797 - acc: 0.6840
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5777 - acc: 0.6850
1283/1283 [==============================] - 1s 891us/step - loss: 0.5786 - acc: 0.6843 - val_loss: 0.6820 - val_acc: 0.6157

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4870 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5584 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5382 - acc: 0.7375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5527 - acc: 0.7240
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5571 - acc: 0.7188
 640/1283 [=============>................] - ETA: 0s - loss: 0.5538 - acc: 0.7156
 768/1283 [================>.............] - ETA: 0s - loss: 0.5539 - acc: 0.7188
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5545 - acc: 0.7199
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5500 - acc: 0.7250
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5537 - acc: 0.7215
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5576 - acc: 0.7179
1280/1283 [============================>.] - ETA: 0s - loss: 0.5606 - acc: 0.7141
1283/1283 [==============================] - 1s 863us/step - loss: 0.5604 - acc: 0.7147 - val_loss: 0.6915 - val_acc: 0.6245

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5192 - acc: 0.7656
 128/1283 [=>............................] - ETA: 1s - loss: 0.5490 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5329 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5456 - acc: 0.7250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5377 - acc: 0.7165
 576/1283 [============>.................] - ETA: 0s - loss: 0.5248 - acc: 0.7292
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5263 - acc: 0.7287
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5217 - acc: 0.7308
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5171 - acc: 0.7396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5209 - acc: 0.7408
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5229 - acc: 0.7418
1283/1283 [==============================] - 1s 877us/step - loss: 0.5258 - acc: 0.7397 - val_loss: 0.6921 - val_acc: 0.6157

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5631 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5050 - acc: 0.7760
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5134 - acc: 0.7383
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4987 - acc: 0.7526
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4970 - acc: 0.7539
 640/1283 [=============>................] - ETA: 0s - loss: 0.5025 - acc: 0.7578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5077 - acc: 0.7514
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5006 - acc: 0.7572
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5064 - acc: 0.7545
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5022 - acc: 0.7578
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5040 - acc: 0.7537
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5114 - acc: 0.7457
1280/1283 [============================>.] - ETA: 0s - loss: 0.5142 - acc: 0.7461
1283/1283 [==============================] - 1s 825us/step - loss: 0.5161 - acc: 0.7451 - val_loss: 0.7132 - val_acc: 0.5939

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4856 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4865 - acc: 0.7708
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5091 - acc: 0.7688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5044 - acc: 0.7708
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4957 - acc: 0.7852
 640/1283 [=============>................] - ETA: 0s - loss: 0.5110 - acc: 0.7609
 768/1283 [================>.............] - ETA: 0s - loss: 0.5116 - acc: 0.7578
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5068 - acc: 0.7545
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4982 - acc: 0.7646
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5008 - acc: 0.7648
1280/1283 [============================>.] - ETA: 0s - loss: 0.5123 - acc: 0.7578
1283/1283 [==============================] - 1s 790us/step - loss: 0.5128 - acc: 0.7576 - val_loss: 0.7286 - val_acc: 0.5983

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4935 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4778 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4751 - acc: 0.7781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4914 - acc: 0.7545
 576/1283 [============>.................] - ETA: 0s - loss: 0.4882 - acc: 0.7587
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4958 - acc: 0.7585
 768/1283 [================>.............] - ETA: 0s - loss: 0.4935 - acc: 0.7617
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4917 - acc: 0.7667
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4938 - acc: 0.7607
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4935 - acc: 0.7619
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4922 - acc: 0.7604
1280/1283 [============================>.] - ETA: 0s - loss: 0.4913 - acc: 0.7617
1283/1283 [==============================] - 1s 790us/step - loss: 0.4911 - acc: 0.7623 - val_loss: 0.7299 - val_acc: 0.5983

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4792 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.4816 - acc: 0.7891
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5116 - acc: 0.7422
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4903 - acc: 0.7448
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4852 - acc: 0.7480
 640/1283 [=============>................] - ETA: 0s - loss: 0.4796 - acc: 0.7562
 768/1283 [================>.............] - ETA: 0s - loss: 0.4816 - acc: 0.7604
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4791 - acc: 0.7600
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4720 - acc: 0.7705
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4784 - acc: 0.7647
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4799 - acc: 0.7615
1283/1283 [==============================] - 1s 743us/step - loss: 0.4802 - acc: 0.7607 - val_loss: 0.7279 - val_acc: 0.5633

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5717 - acc: 0.7344
 128/1283 [=>............................] - ETA: 0s - loss: 0.5179 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4543 - acc: 0.8008
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4474 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4514 - acc: 0.7871
 640/1283 [=============>................] - ETA: 0s - loss: 0.4433 - acc: 0.7922
 768/1283 [================>.............] - ETA: 0s - loss: 0.4481 - acc: 0.7865
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4479 - acc: 0.7902
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4482 - acc: 0.7920
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4464 - acc: 0.7934
1280/1283 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.7922
1283/1283 [==============================] - 1s 798us/step - loss: 0.4476 - acc: 0.7919 - val_loss: 0.7358 - val_acc: 0.6245

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
mode=A
accuracy=0.4897959183673469
best_valid_accuracy=0.5072886297376094
