/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:20:37.207981: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.6840 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7297 - acc: 0.5406
 640/1283 [=============>................] - ETA: 0s - loss: 0.7073 - acc: 0.5391
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7001 - acc: 0.5349
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6905 - acc: 0.5443
1283/1283 [==============================] - 1s 470us/step - loss: 0.6885 - acc: 0.5386 - val_loss: 0.6780 - val_acc: 0.5546

Epoch 00001: val_acc improved from -inf to 0.55459, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6547 - acc: 0.5156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6552 - acc: 0.5703
 640/1283 [=============>................] - ETA: 0s - loss: 0.6534 - acc: 0.5891
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6682 - acc: 0.5896
1283/1283 [==============================] - 0s 199us/step - loss: 0.6631 - acc: 0.5931 - val_loss: 0.7123 - val_acc: 0.5371

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6604 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6895 - acc: 0.5844
 576/1283 [============>.................] - ETA: 0s - loss: 0.6670 - acc: 0.5955
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6560 - acc: 0.6138
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6677 - acc: 0.6016
1283/1283 [==============================] - 0s 226us/step - loss: 0.6647 - acc: 0.6080 - val_loss: 0.6845 - val_acc: 0.5633

Epoch 00003: val_acc improved from 0.55459 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5988 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6822 - acc: 0.6276
 640/1283 [=============>................] - ETA: 0s - loss: 0.6584 - acc: 0.6328
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6479 - acc: 0.6312
1280/1283 [============================>.] - ETA: 0s - loss: 0.6418 - acc: 0.6359
1283/1283 [==============================] - 0s 220us/step - loss: 0.6416 - acc: 0.6360 - val_loss: 0.7022 - val_acc: 0.5197

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5662 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5994 - acc: 0.6500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6317 - acc: 0.6449
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6215 - acc: 0.6583
1283/1283 [==============================] - 0s 192us/step - loss: 0.6309 - acc: 0.6438 - val_loss: 0.7518 - val_acc: 0.5240

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6260 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6667 - acc: 0.6068
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6727 - acc: 0.6094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6494 - acc: 0.6270
1280/1283 [============================>.] - ETA: 0s - loss: 0.6458 - acc: 0.6289
1283/1283 [==============================] - 0s 216us/step - loss: 0.6457 - acc: 0.6290 - val_loss: 0.7225 - val_acc: 0.4716

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6062 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6056 - acc: 0.6531
 576/1283 [============>.................] - ETA: 0s - loss: 0.6072 - acc: 0.6580
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6076 - acc: 0.6538
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6064 - acc: 0.6553
1280/1283 [============================>.] - ETA: 0s - loss: 0.6074 - acc: 0.6656
1283/1283 [==============================] - 0s 260us/step - loss: 0.6077 - acc: 0.6648 - val_loss: 0.7503 - val_acc: 0.4585

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5937 - acc: 0.6562
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5826 - acc: 0.6750
 576/1283 [============>.................] - ETA: 0s - loss: 0.5841 - acc: 0.6858
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5972 - acc: 0.6683
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5900 - acc: 0.6816
1280/1283 [============================>.] - ETA: 0s - loss: 0.5902 - acc: 0.6805
1283/1283 [==============================] - 0s 291us/step - loss: 0.5910 - acc: 0.6797 - val_loss: 0.7269 - val_acc: 0.5066

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5299 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6359 - acc: 0.6531
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6334 - acc: 0.6270
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6201 - acc: 0.6378
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6221 - acc: 0.6562
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6213 - acc: 0.6545
1283/1283 [==============================] - 0s 286us/step - loss: 0.6168 - acc: 0.6586 - val_loss: 0.7101 - val_acc: 0.5153

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5458 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6339 - acc: 0.6914
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6180 - acc: 0.6758
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6175 - acc: 0.6662
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6135 - acc: 0.6708
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6057 - acc: 0.6735
1283/1283 [==============================] - 0s 291us/step - loss: 0.6027 - acc: 0.6797 - val_loss: 0.7429 - val_acc: 0.4891

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6010 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5509 - acc: 0.7188
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5568 - acc: 0.7109
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5550 - acc: 0.7031
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5628 - acc: 0.6979
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5576 - acc: 0.7146
1283/1283 [==============================] - 0s 304us/step - loss: 0.5575 - acc: 0.7155 - val_loss: 0.7859 - val_acc: 0.5109

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6210 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5514 - acc: 0.6781
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5378 - acc: 0.7031
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5383 - acc: 0.7102
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5393 - acc: 0.7063
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5397 - acc: 0.7127
1283/1283 [==============================] - 0s 288us/step - loss: 0.5441 - acc: 0.7054 - val_loss: 0.7906 - val_acc: 0.5066

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4722 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5221 - acc: 0.7305
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5275 - acc: 0.7129
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5347 - acc: 0.7159
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5281 - acc: 0.7146
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5333 - acc: 0.7179
1283/1283 [==============================] - 0s 293us/step - loss: 0.5295 - acc: 0.7210 - val_loss: 0.7837 - val_acc: 0.5022

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=15
epochs=100
mode=V
accuracy=0.5029154518950437
best_valid_accuracy=0.5247813411078717
