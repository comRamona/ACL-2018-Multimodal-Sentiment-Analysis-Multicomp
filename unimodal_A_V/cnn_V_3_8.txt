/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:20:57.305917: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.6936 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 2s - loss: 0.6943 - acc: 0.4792
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6844 - acc: 0.5219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6927 - acc: 0.5335
 576/1283 [============>.................] - ETA: 0s - loss: 0.6881 - acc: 0.5521
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6844 - acc: 0.5568
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6841 - acc: 0.5457
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6831 - acc: 0.5490
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6837 - acc: 0.5478
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6832 - acc: 0.5567
1283/1283 [==============================] - 1s 832us/step - loss: 0.6831 - acc: 0.5565 - val_loss: 0.6805 - val_acc: 0.5546

Epoch 00001: val_acc improved from -inf to 0.55459, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6172 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6494 - acc: 0.6354
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6607 - acc: 0.6125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6759 - acc: 0.6161
 576/1283 [============>.................] - ETA: 0s - loss: 0.6835 - acc: 0.5903
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6801 - acc: 0.5895
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6771 - acc: 0.5950
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6752 - acc: 0.5948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6724 - acc: 0.6020
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6728 - acc: 0.6024
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6725 - acc: 0.6012
1283/1283 [==============================] - 1s 637us/step - loss: 0.6705 - acc: 0.5994 - val_loss: 0.6968 - val_acc: 0.5502

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6246 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6373 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6537 - acc: 0.5938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6496 - acc: 0.6049
 576/1283 [============>.................] - ETA: 0s - loss: 0.6438 - acc: 0.6128
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6458 - acc: 0.6094
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6450 - acc: 0.6106
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6443 - acc: 0.6071
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6409 - acc: 0.6104
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6465 - acc: 0.6024
1280/1283 [============================>.] - ETA: 0s - loss: 0.6471 - acc: 0.6023
1283/1283 [==============================] - 1s 715us/step - loss: 0.6464 - acc: 0.6033 - val_loss: 0.7000 - val_acc: 0.5153

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6615 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6610 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6305 - acc: 0.6531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6170 - acc: 0.6719
 576/1283 [============>.................] - ETA: 0s - loss: 0.6211 - acc: 0.6597
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6241 - acc: 0.6506
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6352 - acc: 0.6370
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6335 - acc: 0.6333
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6370 - acc: 0.6324
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6364 - acc: 0.6319
1280/1283 [============================>.] - ETA: 0s - loss: 0.6340 - acc: 0.6281
1283/1283 [==============================] - 1s 654us/step - loss: 0.6342 - acc: 0.6282 - val_loss: 0.6932 - val_acc: 0.5546

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6089 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6255 - acc: 0.5833
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6325 - acc: 0.6094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6430 - acc: 0.6161
 576/1283 [============>.................] - ETA: 0s - loss: 0.6650 - acc: 0.6076
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6561 - acc: 0.6136
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6463 - acc: 0.6274
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6438 - acc: 0.6295
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6419 - acc: 0.6240
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6389 - acc: 0.6224
1280/1283 [============================>.] - ETA: 0s - loss: 0.6362 - acc: 0.6242
1283/1283 [==============================] - 1s 635us/step - loss: 0.6364 - acc: 0.6235 - val_loss: 0.7091 - val_acc: 0.5459

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5684 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5862 - acc: 0.6979
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5917 - acc: 0.6906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5958 - acc: 0.6875
 576/1283 [============>.................] - ETA: 0s - loss: 0.5920 - acc: 0.6823
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5871 - acc: 0.6903
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5935 - acc: 0.6911
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5970 - acc: 0.6823
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6029 - acc: 0.6746
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6046 - acc: 0.6735
1283/1283 [==============================] - 1s 540us/step - loss: 0.6060 - acc: 0.6750 - val_loss: 0.7412 - val_acc: 0.4978

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5839 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6348 - acc: 0.6458
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6318 - acc: 0.6312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6265 - acc: 0.6272
 576/1283 [============>.................] - ETA: 0s - loss: 0.6190 - acc: 0.6372
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6137 - acc: 0.6449
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6115 - acc: 0.6478
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6108 - acc: 0.6448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6043 - acc: 0.6498
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5958 - acc: 0.6595
1283/1283 [==============================] - 1s 593us/step - loss: 0.5962 - acc: 0.6602 - val_loss: 0.7383 - val_acc: 0.5459

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6328 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5850 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5647 - acc: 0.7000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5557 - acc: 0.6987
 576/1283 [============>.................] - ETA: 0s - loss: 0.5613 - acc: 0.6927
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5743 - acc: 0.6889
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5779 - acc: 0.6839
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5775 - acc: 0.6802
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5767 - acc: 0.6774
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5883 - acc: 0.6809
1283/1283 [==============================] - 1s 480us/step - loss: 0.5863 - acc: 0.6828 - val_loss: 0.7949 - val_acc: 0.4934

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5506 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5743 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5756 - acc: 0.7031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5714 - acc: 0.7165
 576/1283 [============>.................] - ETA: 0s - loss: 0.5711 - acc: 0.7135
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5603 - acc: 0.7202
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5539 - acc: 0.7248
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5507 - acc: 0.7292
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5558 - acc: 0.7169
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5594 - acc: 0.7113
1283/1283 [==============================] - 1s 481us/step - loss: 0.5562 - acc: 0.7140 - val_loss: 0.7937 - val_acc: 0.4934

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6275 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5430 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5581 - acc: 0.6625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5584 - acc: 0.6741
 576/1283 [============>.................] - ETA: 0s - loss: 0.5511 - acc: 0.6892
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5434 - acc: 0.7017
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5364 - acc: 0.7200
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5319 - acc: 0.7188
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5330 - acc: 0.7206
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5330 - acc: 0.7237
1283/1283 [==============================] - 1s 461us/step - loss: 0.5329 - acc: 0.7249 - val_loss: 0.8189 - val_acc: 0.4760

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5045 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5195 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5122 - acc: 0.7562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5561 - acc: 0.7227
 640/1283 [=============>................] - ETA: 0s - loss: 0.5440 - acc: 0.7312
 768/1283 [================>.............] - ETA: 0s - loss: 0.5464 - acc: 0.7331
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5444 - acc: 0.7277
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5391 - acc: 0.7305
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5403 - acc: 0.7326
1280/1283 [============================>.] - ETA: 0s - loss: 0.5372 - acc: 0.7383
1283/1283 [==============================] - 1s 477us/step - loss: 0.5369 - acc: 0.7381 - val_loss: 0.8099 - val_acc: 0.5153

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=3
max_len=30
epochs=100
mode=V
accuracy=0.521865889212828
best_valid_accuracy=0.4956268221574344
