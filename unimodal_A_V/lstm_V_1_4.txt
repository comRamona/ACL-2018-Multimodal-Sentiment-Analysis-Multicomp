/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 09:39:44.153258: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.6899 - acc: 0.4531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6864 - acc: 0.5000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6794 - acc: 0.5335
 640/1283 [=============>................] - ETA: 0s - loss: 0.6761 - acc: 0.5547
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6731 - acc: 0.5613
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6766 - acc: 0.5547
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6757 - acc: 0.5658
1283/1283 [==============================] - 1s 450us/step - loss: 0.6766 - acc: 0.5666 - val_loss: 0.7010 - val_acc: 0.5240

Epoch 00001: val_acc improved from -inf to 0.52402, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6774 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6675 - acc: 0.5820
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6659 - acc: 0.5893
 576/1283 [============>.................] - ETA: 0s - loss: 0.6601 - acc: 0.6042
 768/1283 [================>.............] - ETA: 0s - loss: 0.6592 - acc: 0.6120
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6587 - acc: 0.6172
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6552 - acc: 0.6143
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6551 - acc: 0.6110
1283/1283 [==============================] - 1s 420us/step - loss: 0.6542 - acc: 0.6111 - val_loss: 0.7200 - val_acc: 0.5109

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6026 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6224 - acc: 0.6055
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6320 - acc: 0.6004
 576/1283 [============>.................] - ETA: 0s - loss: 0.6375 - acc: 0.6042
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6367 - acc: 0.6136
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6356 - acc: 0.6094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6412 - acc: 0.6045
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6375 - acc: 0.6085
1283/1283 [==============================] - 1s 409us/step - loss: 0.6383 - acc: 0.6111 - val_loss: 0.7375 - val_acc: 0.4672

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6342 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6180 - acc: 0.6641
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6252 - acc: 0.6339
 576/1283 [============>.................] - ETA: 0s - loss: 0.6244 - acc: 0.6319
 768/1283 [================>.............] - ETA: 0s - loss: 0.6262 - acc: 0.6315
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6214 - acc: 0.6479
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6217 - acc: 0.6406
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6256 - acc: 0.6299
1283/1283 [==============================] - 1s 432us/step - loss: 0.6287 - acc: 0.6321 - val_loss: 0.7310 - val_acc: 0.4803

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5988 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6330 - acc: 0.5938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6266 - acc: 0.6224
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6256 - acc: 0.6250
 640/1283 [=============>................] - ETA: 0s - loss: 0.6227 - acc: 0.6328
 768/1283 [================>.............] - ETA: 0s - loss: 0.6227 - acc: 0.6341
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6230 - acc: 0.6362
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6195 - acc: 0.6406
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6252 - acc: 0.6332
1283/1283 [==============================] - 1s 435us/step - loss: 0.6274 - acc: 0.6306 - val_loss: 0.7586 - val_acc: 0.4585

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6488 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6212 - acc: 0.6641
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6176 - acc: 0.6641
 576/1283 [============>.................] - ETA: 0s - loss: 0.6088 - acc: 0.6736
 768/1283 [================>.............] - ETA: 0s - loss: 0.6168 - acc: 0.6576
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6174 - acc: 0.6604
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6173 - acc: 0.6632
1283/1283 [==============================] - 1s 429us/step - loss: 0.6205 - acc: 0.6586 - val_loss: 0.7367 - val_acc: 0.5066

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6897 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6204 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6151 - acc: 0.6250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6288 - acc: 0.6094
 576/1283 [============>.................] - ETA: 0s - loss: 0.6207 - acc: 0.6319
 768/1283 [================>.............] - ETA: 0s - loss: 0.6175 - acc: 0.6432
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6148 - acc: 0.6473
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6167 - acc: 0.6426
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6154 - acc: 0.6467
1280/1283 [============================>.] - ETA: 0s - loss: 0.6150 - acc: 0.6438
1283/1283 [==============================] - 1s 438us/step - loss: 0.6151 - acc: 0.6438 - val_loss: 0.7311 - val_acc: 0.4934

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6439 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6110 - acc: 0.6927
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6029 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6001 - acc: 0.6808
 576/1283 [============>.................] - ETA: 0s - loss: 0.6043 - acc: 0.6719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6138 - acc: 0.6520
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6156 - acc: 0.6454
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6078 - acc: 0.6562
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6085 - acc: 0.6572
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6068 - acc: 0.6628
1283/1283 [==============================] - 1s 443us/step - loss: 0.6069 - acc: 0.6610 - val_loss: 0.7411 - val_acc: 0.4760

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5130 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5618 - acc: 0.7083
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5692 - acc: 0.7000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5771 - acc: 0.6964
 576/1283 [============>.................] - ETA: 0s - loss: 0.5920 - acc: 0.6736
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5988 - acc: 0.6619
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5986 - acc: 0.6562
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5925 - acc: 0.6689
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5909 - acc: 0.6684
1280/1283 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.6719
1283/1283 [==============================] - 1s 442us/step - loss: 0.5933 - acc: 0.6703 - val_loss: 0.7708 - val_acc: 0.4934

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5565 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6019 - acc: 0.6445
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5882 - acc: 0.6615
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5833 - acc: 0.6680
 640/1283 [=============>................] - ETA: 0s - loss: 0.5825 - acc: 0.6641
 768/1283 [================>.............] - ETA: 0s - loss: 0.5878 - acc: 0.6562
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5866 - acc: 0.6573
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5948 - acc: 0.6553
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5943 - acc: 0.6579
1283/1283 [==============================] - 1s 438us/step - loss: 0.5963 - acc: 0.6563 - val_loss: 0.7561 - val_acc: 0.4454

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6459 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6248 - acc: 0.6055
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6249 - acc: 0.6272
 576/1283 [============>.................] - ETA: 0s - loss: 0.6167 - acc: 0.6354
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6032 - acc: 0.6520
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5959 - acc: 0.6683
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5974 - acc: 0.6677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5935 - acc: 0.6682
1280/1283 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.6664
1283/1283 [==============================] - 1s 438us/step - loss: 0.5918 - acc: 0.6656 - val_loss: 0.7607 - val_acc: 0.4716

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=30
mode=V
accuracy=0.5087463556851312
best_valid_accuracy=0.4868804664723032
