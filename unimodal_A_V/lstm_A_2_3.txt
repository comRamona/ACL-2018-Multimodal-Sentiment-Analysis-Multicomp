/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 08:43:31.749808: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.6885 - acc: 0.5156
 128/1283 [=>............................] - ETA: 5s - loss: 0.6897 - acc: 0.5469 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.6899 - acc: 0.5573
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6875 - acc: 0.5508
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6901 - acc: 0.5344
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6906 - acc: 0.5312
 448/1283 [=========>....................] - ETA: 2s - loss: 0.6887 - acc: 0.5424
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6887 - acc: 0.5371
 576/1283 [============>.................] - ETA: 1s - loss: 0.6892 - acc: 0.5347
 640/1283 [=============>................] - ETA: 1s - loss: 0.6895 - acc: 0.5328
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6892 - acc: 0.5341
 768/1283 [================>.............] - ETA: 1s - loss: 0.6883 - acc: 0.5365
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6886 - acc: 0.5325
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6870 - acc: 0.5368
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6894 - acc: 0.5333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6872 - acc: 0.5381
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6853 - acc: 0.5414
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6848 - acc: 0.5425
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6843 - acc: 0.5436
1280/1283 [============================>.] - ETA: 0s - loss: 0.6850 - acc: 0.5414
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6851 - acc: 0.5417 - val_loss: 0.6943 - val_acc: 0.5197

Epoch 00001: val_acc improved from -inf to 0.51965, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.6760 - acc: 0.5938
 128/1283 [=>............................] - ETA: 1s - loss: 0.6673 - acc: 0.6172
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6755 - acc: 0.5833
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6687 - acc: 0.5859
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6698 - acc: 0.5750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6634 - acc: 0.5911
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6619 - acc: 0.5893
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6625 - acc: 0.5898
 576/1283 [============>.................] - ETA: 1s - loss: 0.6591 - acc: 0.6059
 640/1283 [=============>................] - ETA: 1s - loss: 0.6583 - acc: 0.6125
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6590 - acc: 0.6080
 768/1283 [================>.............] - ETA: 0s - loss: 0.6589 - acc: 0.6068
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6630 - acc: 0.5998
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6632 - acc: 0.6004
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6624 - acc: 0.6010
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6605 - acc: 0.6025
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6565 - acc: 0.6103
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6560 - acc: 0.6111
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6555 - acc: 0.6102
1280/1283 [============================>.] - ETA: 0s - loss: 0.6550 - acc: 0.6133
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6551 - acc: 0.6126 - val_loss: 0.7042 - val_acc: 0.5153

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6098 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6370 - acc: 0.6172
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6520 - acc: 0.5833
 256/1283 [====>.........................] - ETA: 2s - loss: 0.6557 - acc: 0.5898
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6405 - acc: 0.6156
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6373 - acc: 0.6224
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6338 - acc: 0.6339
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6303 - acc: 0.6406
 576/1283 [============>.................] - ETA: 1s - loss: 0.6289 - acc: 0.6406
 640/1283 [=============>................] - ETA: 1s - loss: 0.6274 - acc: 0.6406
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6311 - acc: 0.6364
 768/1283 [================>.............] - ETA: 0s - loss: 0.6296 - acc: 0.6393
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6275 - acc: 0.6454
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6243 - acc: 0.6507
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6206 - acc: 0.6573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6251 - acc: 0.6523
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6226 - acc: 0.6562
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6289 - acc: 0.6458
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6302 - acc: 0.6439
1280/1283 [============================>.] - ETA: 0s - loss: 0.6303 - acc: 0.6453
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6299 - acc: 0.6461 - val_loss: 0.7016 - val_acc: 0.5502

Epoch 00003: val_acc improved from 0.51965 to 0.55022, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5962 - acc: 0.6250
 128/1283 [=>............................] - ETA: 2s - loss: 0.5782 - acc: 0.6641
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5958 - acc: 0.6302
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5894 - acc: 0.6445
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5894 - acc: 0.6625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5959 - acc: 0.6589
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5979 - acc: 0.6562
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6081 - acc: 0.6367
 576/1283 [============>.................] - ETA: 1s - loss: 0.6086 - acc: 0.6337
 640/1283 [=============>................] - ETA: 0s - loss: 0.6061 - acc: 0.6375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6052 - acc: 0.6520
 768/1283 [================>.............] - ETA: 0s - loss: 0.6037 - acc: 0.6523
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5961 - acc: 0.6635
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5989 - acc: 0.6574
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6043 - acc: 0.6531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6053 - acc: 0.6514
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6000 - acc: 0.6562
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6017 - acc: 0.6571
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6006 - acc: 0.6587
1280/1283 [============================>.] - ETA: 0s - loss: 0.5980 - acc: 0.6641
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5979 - acc: 0.6641 - val_loss: 0.7115 - val_acc: 0.5502

Epoch 00004: val_acc improved from 0.55022 to 0.55022, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5562 - acc: 0.7188
 128/1283 [=>............................] - ETA: 2s - loss: 0.5608 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 2s - loss: 0.5758 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5661 - acc: 0.6992
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5639 - acc: 0.6937
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5715 - acc: 0.6901
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5662 - acc: 0.7054
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5690 - acc: 0.7090
 576/1283 [============>.................] - ETA: 1s - loss: 0.5657 - acc: 0.7031
 640/1283 [=============>................] - ETA: 1s - loss: 0.5601 - acc: 0.7078
 704/1283 [===============>..............] - ETA: 1s - loss: 0.5671 - acc: 0.7088
 768/1283 [================>.............] - ETA: 0s - loss: 0.5725 - acc: 0.7018
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5747 - acc: 0.7019
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5732 - acc: 0.7031
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5747 - acc: 0.7010
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5677 - acc: 0.7080
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5698 - acc: 0.7059
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5653 - acc: 0.7083
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5668 - acc: 0.7081
1280/1283 [============================>.] - ETA: 0s - loss: 0.5637 - acc: 0.7102
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5646 - acc: 0.7093 - val_loss: 0.7325 - val_acc: 0.5852

Epoch 00005: val_acc improved from 0.55022 to 0.58515, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5944 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.5668 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5513 - acc: 0.7552
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5532 - acc: 0.7422
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5477 - acc: 0.7344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5331 - acc: 0.7448
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5326 - acc: 0.7411
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5375 - acc: 0.7305
 576/1283 [============>.................] - ETA: 1s - loss: 0.5365 - acc: 0.7326
 640/1283 [=============>................] - ETA: 1s - loss: 0.5332 - acc: 0.7281
 704/1283 [===============>..............] - ETA: 1s - loss: 0.5428 - acc: 0.7202
 768/1283 [================>.............] - ETA: 1s - loss: 0.5369 - acc: 0.7240
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5403 - acc: 0.7200
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5369 - acc: 0.7254
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5366 - acc: 0.7260
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5352 - acc: 0.7295
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5301 - acc: 0.7289
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5263 - acc: 0.7300
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5300 - acc: 0.7278
1280/1283 [============================>.] - ETA: 0s - loss: 0.5321 - acc: 0.7258
1283/1283 [==============================] - 3s 2ms/step - loss: 0.5318 - acc: 0.7256 - val_loss: 0.7485 - val_acc: 0.5721

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5878 - acc: 0.7344
 128/1283 [=>............................] - ETA: 2s - loss: 0.5326 - acc: 0.7578
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5336 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5486 - acc: 0.7461
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5191 - acc: 0.7625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5136 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5050 - acc: 0.7746
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5122 - acc: 0.7676
 576/1283 [============>.................] - ETA: 1s - loss: 0.5200 - acc: 0.7604
 640/1283 [=============>................] - ETA: 1s - loss: 0.5200 - acc: 0.7594
 704/1283 [===============>..............] - ETA: 1s - loss: 0.5175 - acc: 0.7628
 768/1283 [================>.............] - ETA: 0s - loss: 0.5114 - acc: 0.7617
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5146 - acc: 0.7548
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5065 - acc: 0.7578
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5063 - acc: 0.7542
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5066 - acc: 0.7520
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5093 - acc: 0.7500
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5087 - acc: 0.7500
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5065 - acc: 0.7508
1280/1283 [============================>.] - ETA: 0s - loss: 0.5046 - acc: 0.7547
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5066 - acc: 0.7545 - val_loss: 0.7862 - val_acc: 0.5328

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.4574 - acc: 0.7344
 128/1283 [=>............................] - ETA: 1s - loss: 0.4081 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4178 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4248 - acc: 0.8359
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4314 - acc: 0.8344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4393 - acc: 0.8229
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4399 - acc: 0.8214
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4516 - acc: 0.8105
 576/1283 [============>.................] - ETA: 1s - loss: 0.4602 - acc: 0.8090
 640/1283 [=============>................] - ETA: 1s - loss: 0.4674 - acc: 0.8000
 704/1283 [===============>..............] - ETA: 1s - loss: 0.4691 - acc: 0.7969
 768/1283 [================>.............] - ETA: 0s - loss: 0.4669 - acc: 0.8021
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4586 - acc: 0.8065
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4583 - acc: 0.8058
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4653 - acc: 0.8021
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4659 - acc: 0.7979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4710 - acc: 0.7932
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4748 - acc: 0.7925
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4762 - acc: 0.7936
1280/1283 [============================>.] - ETA: 0s - loss: 0.4770 - acc: 0.7914
1283/1283 [==============================] - 3s 2ms/step - loss: 0.4769 - acc: 0.7911 - val_loss: 0.7953 - val_acc: 0.5546

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5304 - acc: 0.7344
 128/1283 [=>............................] - ETA: 2s - loss: 0.4896 - acc: 0.7734
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5068 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4828 - acc: 0.7734
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4739 - acc: 0.7781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4628 - acc: 0.7865
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4689 - acc: 0.7835
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4634 - acc: 0.7832
 576/1283 [============>.................] - ETA: 1s - loss: 0.4590 - acc: 0.7865
 640/1283 [=============>................] - ETA: 0s - loss: 0.4673 - acc: 0.7750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4622 - acc: 0.7798
 768/1283 [================>.............] - ETA: 0s - loss: 0.4579 - acc: 0.7826
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4630 - acc: 0.7776
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4600 - acc: 0.7812
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4631 - acc: 0.7781
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4595 - acc: 0.7793
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4585 - acc: 0.7785
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4491 - acc: 0.7839
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4469 - acc: 0.7845
1280/1283 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.7852
1283/1283 [==============================] - 2s 2ms/step - loss: 0.4475 - acc: 0.7849 - val_loss: 0.8620 - val_acc: 0.5240

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.3541 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.3994 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4100 - acc: 0.8229
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4182 - acc: 0.8164
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4260 - acc: 0.8094
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4271 - acc: 0.8047
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4171 - acc: 0.8058
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4307 - acc: 0.7871
 576/1283 [============>.................] - ETA: 1s - loss: 0.4350 - acc: 0.7812
 640/1283 [=============>................] - ETA: 1s - loss: 0.4386 - acc: 0.7781
 704/1283 [===============>..............] - ETA: 1s - loss: 0.4391 - acc: 0.7841
 768/1283 [================>.............] - ETA: 0s - loss: 0.4308 - acc: 0.7917
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4265 - acc: 0.7957
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4208 - acc: 0.8013
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4144 - acc: 0.8073
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4133 - acc: 0.8086
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4147 - acc: 0.8079
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4152 - acc: 0.8099
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4158 - acc: 0.8067
1280/1283 [============================>.] - ETA: 0s - loss: 0.4176 - acc: 0.8063
1283/1283 [==============================] - 2s 2ms/step - loss: 0.4172 - acc: 0.8067 - val_loss: 0.8353 - val_acc: 0.5240

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.3917 - acc: 0.8281
 128/1283 [=>............................] - ETA: 2s - loss: 0.3925 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 2s - loss: 0.3833 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 2s - loss: 0.3932 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3914 - acc: 0.8313
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3931 - acc: 0.8255
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3863 - acc: 0.8281
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3787 - acc: 0.8340
 576/1283 [============>.................] - ETA: 1s - loss: 0.3764 - acc: 0.8368
 640/1283 [=============>................] - ETA: 1s - loss: 0.3800 - acc: 0.8359
 704/1283 [===============>..............] - ETA: 1s - loss: 0.3793 - acc: 0.8366
 768/1283 [================>.............] - ETA: 0s - loss: 0.3802 - acc: 0.8424
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3780 - acc: 0.8474
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3828 - acc: 0.8449
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3921 - acc: 0.8385
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3875 - acc: 0.8389
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3836 - acc: 0.8382
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3806 - acc: 0.8403
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3786 - acc: 0.8413
1280/1283 [============================>.] - ETA: 0s - loss: 0.3803 - acc: 0.8398
1283/1283 [==============================] - 2s 2ms/step - loss: 0.3806 - acc: 0.8394 - val_loss: 0.8653 - val_acc: 0.5590

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2570 - acc: 0.9219
 128/1283 [=>............................] - ETA: 2s - loss: 0.2911 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 2s - loss: 0.2943 - acc: 0.8698
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3236 - acc: 0.8516
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3125 - acc: 0.8656
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3145 - acc: 0.8620
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3214 - acc: 0.8571
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3304 - acc: 0.8535
 576/1283 [============>.................] - ETA: 1s - loss: 0.3414 - acc: 0.8455
 640/1283 [=============>................] - ETA: 1s - loss: 0.3515 - acc: 0.8438
 704/1283 [===============>..............] - ETA: 1s - loss: 0.3570 - acc: 0.8409
 768/1283 [================>.............] - ETA: 0s - loss: 0.3583 - acc: 0.8385
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3553 - acc: 0.8425
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3565 - acc: 0.8404
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3543 - acc: 0.8406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3612 - acc: 0.8369
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3566 - acc: 0.8401
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3572 - acc: 0.8394
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3523 - acc: 0.8429
1280/1283 [============================>.] - ETA: 0s - loss: 0.3548 - acc: 0.8414
1283/1283 [==============================] - 2s 2ms/step - loss: 0.3546 - acc: 0.8418 - val_loss: 0.8928 - val_acc: 0.5415

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2975 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.2842 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2813 - acc: 0.8854
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2802 - acc: 0.8828
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2836 - acc: 0.8812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2835 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2882 - acc: 0.8728
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2945 - acc: 0.8730
 576/1283 [============>.................] - ETA: 1s - loss: 0.2897 - acc: 0.8767
 640/1283 [=============>................] - ETA: 0s - loss: 0.2851 - acc: 0.8797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3024 - acc: 0.8750
 768/1283 [================>.............] - ETA: 0s - loss: 0.2955 - acc: 0.8802
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2953 - acc: 0.8810
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2956 - acc: 0.8795
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2932 - acc: 0.8812
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2942 - acc: 0.8809
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2972 - acc: 0.8787
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2911 - acc: 0.8802
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2894 - acc: 0.8791
1280/1283 [============================>.] - ETA: 0s - loss: 0.2879 - acc: 0.8781
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2931 - acc: 0.8769 - val_loss: 0.9913 - val_acc: 0.5502

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2074 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2415 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2221 - acc: 0.9115
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2442 - acc: 0.8984
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2724 - acc: 0.8812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2677 - acc: 0.8828
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2884 - acc: 0.8683
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2934 - acc: 0.8691
 576/1283 [============>.................] - ETA: 0s - loss: 0.3119 - acc: 0.8646
 640/1283 [=============>................] - ETA: 0s - loss: 0.3135 - acc: 0.8641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3266 - acc: 0.8551
 768/1283 [================>.............] - ETA: 0s - loss: 0.3359 - acc: 0.8503
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3353 - acc: 0.8558
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3434 - acc: 0.8493
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3532 - acc: 0.8427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3520 - acc: 0.8418
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3542 - acc: 0.8401
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3502 - acc: 0.8438
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3476 - acc: 0.8429
1280/1283 [============================>.] - ETA: 0s - loss: 0.3454 - acc: 0.8453
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3463 - acc: 0.8449 - val_loss: 0.9510 - val_acc: 0.5415

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3348 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.3363 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3028 - acc: 0.8854
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3110 - acc: 0.8828
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3377 - acc: 0.8594
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3185 - acc: 0.8724
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3147 - acc: 0.8772
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3098 - acc: 0.8809
 576/1283 [============>.................] - ETA: 0s - loss: 0.3187 - acc: 0.8715
 640/1283 [=============>................] - ETA: 0s - loss: 0.3161 - acc: 0.8750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3109 - acc: 0.8764
 768/1283 [================>.............] - ETA: 0s - loss: 0.3119 - acc: 0.8737
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3084 - acc: 0.8750
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3047 - acc: 0.8783
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3185 - acc: 0.8688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3148 - acc: 0.8711
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3098 - acc: 0.8750
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3162 - acc: 0.8733
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3149 - acc: 0.8734
1280/1283 [============================>.] - ETA: 0s - loss: 0.3102 - acc: 0.8766
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3096 - acc: 0.8769 - val_loss: 0.8655 - val_acc: 0.5677

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
mode=A
accuracy=0.5087463556851312
best_valid_accuracy=0.5364431486880467
