/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:15:30.350055: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 12s - loss: 0.7437 - acc: 0.4688
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7175 - acc: 0.5078 
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7115 - acc: 0.4777
 576/1283 [============>.................] - ETA: 1s - loss: 0.7047 - acc: 0.4948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7003 - acc: 0.5057
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7114 - acc: 0.5246
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7044 - acc: 0.5312
1280/1283 [============================>.] - ETA: 0s - loss: 0.6953 - acc: 0.5445
1283/1283 [==============================] - 1s 982us/step - loss: 0.6951 - acc: 0.5448 - val_loss: 0.7073 - val_acc: 0.5240

Epoch 00001: val_acc improved from -inf to 0.52402, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6391 - acc: 0.5938
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6686 - acc: 0.5813
 576/1283 [============>.................] - ETA: 0s - loss: 0.6794 - acc: 0.5799
 768/1283 [================>.............] - ETA: 0s - loss: 0.6701 - acc: 0.5898
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6617 - acc: 0.6052
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6627 - acc: 0.6007
1283/1283 [==============================] - 0s 290us/step - loss: 0.6567 - acc: 0.6111 - val_loss: 0.7025 - val_acc: 0.5240

Epoch 00002: val_acc improved from 0.52402 to 0.52402, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6547 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6276 - acc: 0.6250
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6352 - acc: 0.6191
 768/1283 [================>.............] - ETA: 0s - loss: 0.6282 - acc: 0.6354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6305 - acc: 0.6309
1280/1283 [============================>.] - ETA: 0s - loss: 0.6415 - acc: 0.6250
1283/1283 [==============================] - 0s 264us/step - loss: 0.6413 - acc: 0.6251 - val_loss: 0.7170 - val_acc: 0.5197

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6361 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6064 - acc: 0.6656
 576/1283 [============>.................] - ETA: 0s - loss: 0.6253 - acc: 0.6476
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6198 - acc: 0.6683
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6114 - acc: 0.6727
1283/1283 [==============================] - 0s 211us/step - loss: 0.6128 - acc: 0.6633 - val_loss: 0.7494 - val_acc: 0.4891

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5838 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5957 - acc: 0.6500
 576/1283 [============>.................] - ETA: 0s - loss: 0.5853 - acc: 0.6719
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5928 - acc: 0.6695
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6057 - acc: 0.6526
1283/1283 [==============================] - 0s 249us/step - loss: 0.6039 - acc: 0.6586 - val_loss: 0.7409 - val_acc: 0.5197

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5429 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5776 - acc: 0.6844
 576/1283 [============>.................] - ETA: 0s - loss: 0.5653 - acc: 0.7135
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5809 - acc: 0.6851
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5902 - acc: 0.6771
1283/1283 [==============================] - 0s 218us/step - loss: 0.5858 - acc: 0.6820 - val_loss: 0.7725 - val_acc: 0.5066

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5962 - acc: 0.6562
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5838 - acc: 0.6781
 576/1283 [============>.................] - ETA: 0s - loss: 0.5672 - acc: 0.6910
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5707 - acc: 0.6971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5745 - acc: 0.6903
1283/1283 [==============================] - 0s 225us/step - loss: 0.5727 - acc: 0.6945 - val_loss: 0.8648 - val_acc: 0.4716

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6411 - acc: 0.6250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5613 - acc: 0.7188
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5560 - acc: 0.7230
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5682 - acc: 0.7178
1283/1283 [==============================] - 0s 181us/step - loss: 0.5651 - acc: 0.7264 - val_loss: 0.7580 - val_acc: 0.5022

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5321 - acc: 0.6562
 576/1283 [============>.................] - ETA: 0s - loss: 0.5647 - acc: 0.7014
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5409 - acc: 0.7224
1283/1283 [==============================] - 0s 129us/step - loss: 0.5481 - acc: 0.7178 - val_loss: 0.8252 - val_acc: 0.4672

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4716 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.5328 - acc: 0.7500
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5473 - acc: 0.7283
1283/1283 [==============================] - 0s 109us/step - loss: 0.5423 - acc: 0.7303 - val_loss: 0.7744 - val_acc: 0.5415

Epoch 00010: val_acc improved from 0.52402 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4882 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4952 - acc: 0.7569
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5142 - acc: 0.7457
1283/1283 [==============================] - 0s 106us/step - loss: 0.5181 - acc: 0.7436 - val_loss: 0.8545 - val_acc: 0.4716

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4912 - acc: 0.7500
 640/1283 [=============>................] - ETA: 0s - loss: 0.5025 - acc: 0.7500
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4967 - acc: 0.7582
1283/1283 [==============================] - 0s 106us/step - loss: 0.4968 - acc: 0.7584 - val_loss: 0.8051 - val_acc: 0.5022

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4177 - acc: 0.8125
 576/1283 [============>.................] - ETA: 0s - loss: 0.5285 - acc: 0.7569
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5178 - acc: 0.7517
1283/1283 [==============================] - 0s 108us/step - loss: 0.5086 - acc: 0.7592 - val_loss: 0.8243 - val_acc: 0.4934

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4725 - acc: 0.7969
 640/1283 [=============>................] - ETA: 0s - loss: 0.4730 - acc: 0.7875
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4665 - acc: 0.7903
1283/1283 [==============================] - 0s 100us/step - loss: 0.4643 - acc: 0.7935 - val_loss: 0.8679 - val_acc: 0.4629

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4821 - acc: 0.7188
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4760 - acc: 0.7543
1283/1283 [==============================] - 0s 94us/step - loss: 0.4600 - acc: 0.7724 - val_loss: 0.9272 - val_acc: 0.4367

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4578 - acc: 0.8281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4269 - acc: 0.8097
1283/1283 [==============================] - 0s 93us/step - loss: 0.4336 - acc: 0.8020 - val_loss: 0.9539 - val_acc: 0.4672

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3671 - acc: 0.8281
 640/1283 [=============>................] - ETA: 0s - loss: 0.4256 - acc: 0.8172
1280/1283 [============================>.] - ETA: 0s - loss: 0.4207 - acc: 0.8148
1283/1283 [==============================] - 0s 95us/step - loss: 0.4202 - acc: 0.8153 - val_loss: 0.9552 - val_acc: 0.4498

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2757 - acc: 0.9219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3800 - acc: 0.8480
1283/1283 [==============================] - 0s 93us/step - loss: 0.3762 - acc: 0.8504 - val_loss: 1.0549 - val_acc: 0.4672

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4621 - acc: 0.8594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3532 - acc: 0.8707
1283/1283 [==============================] - 0s 94us/step - loss: 0.3904 - acc: 0.8410 - val_loss: 1.0263 - val_acc: 0.4803

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3881 - acc: 0.8281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3670 - acc: 0.8665
1283/1283 [==============================] - 0s 94us/step - loss: 0.3946 - acc: 0.8402 - val_loss: 1.0151 - val_acc: 0.4803

Epoch 00020: val_acc did not improve
Epoch 00020: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=20
epochs=100
mode=V
accuracy=0.5262390670553936
best_valid_accuracy=0.5043731778425656
