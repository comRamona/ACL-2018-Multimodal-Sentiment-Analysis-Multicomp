/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:21:07.957620: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.7006 - acc: 0.4688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6896 - acc: 0.5000
 576/1283 [============>.................] - ETA: 0s - loss: 0.7027 - acc: 0.5122
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6933 - acc: 0.5312
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6911 - acc: 0.5340
1283/1283 [==============================] - 0s 301us/step - loss: 0.6876 - acc: 0.5347 - val_loss: 0.7015 - val_acc: 0.5459

Epoch 00001: val_acc improved from -inf to 0.54585, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6334 - acc: 0.6250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6758 - acc: 0.5573
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6711 - acc: 0.5710
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6685 - acc: 0.5726
1283/1283 [==============================] - 0s 174us/step - loss: 0.6681 - acc: 0.5744 - val_loss: 0.6939 - val_acc: 0.5371

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6482 - acc: 0.5938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6457 - acc: 0.6004
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6452 - acc: 0.6094
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6535 - acc: 0.6102
1283/1283 [==============================] - 0s 156us/step - loss: 0.6535 - acc: 0.6080 - val_loss: 0.7126 - val_acc: 0.5109

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6977 - acc: 0.5156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6365 - acc: 0.6518
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6372 - acc: 0.6334
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6286 - acc: 0.6406
1283/1283 [==============================] - 0s 161us/step - loss: 0.6313 - acc: 0.6360 - val_loss: 0.7094 - val_acc: 0.5371

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5894 - acc: 0.6562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6419 - acc: 0.6094
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6347 - acc: 0.6298
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6380 - acc: 0.6398
1283/1283 [==============================] - 0s 157us/step - loss: 0.6364 - acc: 0.6415 - val_loss: 0.7031 - val_acc: 0.5022

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5961 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6294 - acc: 0.6741
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6194 - acc: 0.6635
1280/1283 [============================>.] - ETA: 0s - loss: 0.6254 - acc: 0.6523
1283/1283 [==============================] - 0s 143us/step - loss: 0.6254 - acc: 0.6524 - val_loss: 0.6990 - val_acc: 0.5153

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6103 - acc: 0.7188
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6154 - acc: 0.6406
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6068 - acc: 0.6618
1280/1283 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.6656
1283/1283 [==============================] - 0s 143us/step - loss: 0.6030 - acc: 0.6656 - val_loss: 0.7167 - val_acc: 0.5240

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6221 - acc: 0.6406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5856 - acc: 0.6652
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5984 - acc: 0.6635
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5883 - acc: 0.6809
1283/1283 [==============================] - 0s 143us/step - loss: 0.5906 - acc: 0.6812 - val_loss: 0.7585 - val_acc: 0.5153

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6200 - acc: 0.5938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5721 - acc: 0.6741
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5817 - acc: 0.6671
1280/1283 [============================>.] - ETA: 0s - loss: 0.5795 - acc: 0.6898
1283/1283 [==============================] - 0s 144us/step - loss: 0.5788 - acc: 0.6906 - val_loss: 0.7694 - val_acc: 0.4934

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5315 - acc: 0.7812
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5458 - acc: 0.7285
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5559 - acc: 0.7087
1280/1283 [============================>.] - ETA: 0s - loss: 0.5405 - acc: 0.7156
1283/1283 [==============================] - 0s 143us/step - loss: 0.5412 - acc: 0.7155 - val_loss: 0.8037 - val_acc: 0.4934

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5355 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5300 - acc: 0.7344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5252 - acc: 0.7416
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5269 - acc: 0.7500
1283/1283 [==============================] - 0s 144us/step - loss: 0.5245 - acc: 0.7482 - val_loss: 0.8137 - val_acc: 0.5153

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
epochs=100
mode=V
accuracy=0.49416909620991256
best_valid_accuracy=0.4329446064139942
