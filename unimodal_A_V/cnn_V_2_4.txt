/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:20:38.851421: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.6895 - acc: 0.4688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6763 - acc: 0.5312
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6950 - acc: 0.5078
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6969 - acc: 0.5039
 640/1283 [=============>................] - ETA: 0s - loss: 0.6869 - acc: 0.5359
 768/1283 [================>.............] - ETA: 0s - loss: 0.6878 - acc: 0.5286
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6864 - acc: 0.5279
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6862 - acc: 0.5283
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6853 - acc: 0.5356
1283/1283 [==============================] - 1s 798us/step - loss: 0.6824 - acc: 0.5472 - val_loss: 0.6894 - val_acc: 0.5153

Epoch 00001: val_acc improved from -inf to 0.51528, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6128 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6431 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6478 - acc: 0.6469
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6634 - acc: 0.6250
 640/1283 [=============>................] - ETA: 0s - loss: 0.6629 - acc: 0.6156
 768/1283 [================>.............] - ETA: 0s - loss: 0.6635 - acc: 0.6198
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6612 - acc: 0.6261
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6598 - acc: 0.6250
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6586 - acc: 0.6285
1280/1283 [============================>.] - ETA: 0s - loss: 0.6563 - acc: 0.6250
1283/1283 [==============================] - 1s 619us/step - loss: 0.6562 - acc: 0.6251 - val_loss: 0.7002 - val_acc: 0.4978

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6103 - acc: 0.6875
 128/1283 [=>............................] - ETA: 0s - loss: 0.6113 - acc: 0.6328
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6203 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6360 - acc: 0.5938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6297 - acc: 0.6183
 576/1283 [============>.................] - ETA: 0s - loss: 0.6246 - acc: 0.6302
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6297 - acc: 0.6264
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6290 - acc: 0.6310
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6266 - acc: 0.6271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6259 - acc: 0.6268
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6317 - acc: 0.6242
1283/1283 [==============================] - 1s 699us/step - loss: 0.6299 - acc: 0.6274 - val_loss: 0.7100 - val_acc: 0.5153

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6335 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6243 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5889 - acc: 0.6813
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5745 - acc: 0.7098
 640/1283 [=============>................] - ETA: 0s - loss: 0.5990 - acc: 0.6828
 768/1283 [================>.............] - ETA: 0s - loss: 0.6040 - acc: 0.6706
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6055 - acc: 0.6594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6189 - acc: 0.6608
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6175 - acc: 0.6604
1283/1283 [==============================] - 1s 468us/step - loss: 0.6180 - acc: 0.6571 - val_loss: 0.7275 - val_acc: 0.5415

Epoch 00004: val_acc improved from 0.51528 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6106 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5800 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5914 - acc: 0.6781
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6125 - acc: 0.6484
 640/1283 [=============>................] - ETA: 0s - loss: 0.6374 - acc: 0.6422
 768/1283 [================>.............] - ETA: 0s - loss: 0.6264 - acc: 0.6523
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6181 - acc: 0.6596
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6167 - acc: 0.6535
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6156 - acc: 0.6497
1283/1283 [==============================] - 1s 465us/step - loss: 0.6145 - acc: 0.6493 - val_loss: 0.7433 - val_acc: 0.5153

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5329 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5592 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5617 - acc: 0.7344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5693 - acc: 0.7188
 640/1283 [=============>................] - ETA: 0s - loss: 0.5620 - acc: 0.7266
 768/1283 [================>.............] - ETA: 0s - loss: 0.5613 - acc: 0.7292
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5714 - acc: 0.7143
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5757 - acc: 0.7061
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5815 - acc: 0.6979
1280/1283 [============================>.] - ETA: 0s - loss: 0.5788 - acc: 0.6992
1283/1283 [==============================] - 1s 470us/step - loss: 0.5783 - acc: 0.6999 - val_loss: 0.7724 - val_acc: 0.4978

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5361 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5861 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5842 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5810 - acc: 0.6830
 576/1283 [============>.................] - ETA: 0s - loss: 0.5742 - acc: 0.6823
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5716 - acc: 0.6889
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5708 - acc: 0.6923
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5654 - acc: 0.7000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5600 - acc: 0.7013
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5524 - acc: 0.7072
1283/1283 [==============================] - 1s 508us/step - loss: 0.5533 - acc: 0.7038 - val_loss: 0.7933 - val_acc: 0.5240

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5812 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5487 - acc: 0.6979
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5218 - acc: 0.7292
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5114 - acc: 0.7363
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5241 - acc: 0.7273
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5286 - acc: 0.7154
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5337 - acc: 0.7061
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5304 - acc: 0.7118
1280/1283 [============================>.] - ETA: 0s - loss: 0.5288 - acc: 0.7156
1283/1283 [==============================] - 1s 473us/step - loss: 0.5288 - acc: 0.7155 - val_loss: 0.8239 - val_acc: 0.4847

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4802 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5483 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5675 - acc: 0.7094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5452 - acc: 0.7277
 576/1283 [============>.................] - ETA: 0s - loss: 0.5358 - acc: 0.7292
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5318 - acc: 0.7330
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5158 - acc: 0.7404
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5087 - acc: 0.7427
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5202 - acc: 0.7387
1280/1283 [============================>.] - ETA: 0s - loss: 0.5336 - acc: 0.7312
1283/1283 [==============================] - 1s 464us/step - loss: 0.5338 - acc: 0.7311 - val_loss: 0.8296 - val_acc: 0.4672

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4872 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4741 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4934 - acc: 0.7589
 576/1283 [============>.................] - ETA: 0s - loss: 0.4902 - acc: 0.7743
 768/1283 [================>.............] - ETA: 0s - loss: 0.4852 - acc: 0.7904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4862 - acc: 0.7833
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5034 - acc: 0.7726
1283/1283 [==============================] - 1s 414us/step - loss: 0.4991 - acc: 0.7732 - val_loss: 0.9583 - val_acc: 0.4629

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6695 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6008 - acc: 0.7227
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5776 - acc: 0.7210
 640/1283 [=============>................] - ETA: 0s - loss: 0.5591 - acc: 0.7250
 768/1283 [================>.............] - ETA: 0s - loss: 0.5467 - acc: 0.7370
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5379 - acc: 0.7400
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5228 - acc: 0.7564
1280/1283 [============================>.] - ETA: 0s - loss: 0.5165 - acc: 0.7586
1283/1283 [==============================] - 1s 418us/step - loss: 0.5159 - acc: 0.7592 - val_loss: 0.8195 - val_acc: 0.4760

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3806 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4486 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4599 - acc: 0.7708
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4605 - acc: 0.7695
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4803 - acc: 0.7685
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4794 - acc: 0.7623
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4699 - acc: 0.7757
1280/1283 [============================>.] - ETA: 0s - loss: 0.4624 - acc: 0.7844
1283/1283 [==============================] - 1s 406us/step - loss: 0.4629 - acc: 0.7833 - val_loss: 0.8858 - val_acc: 0.4716

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3802 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4358 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4548 - acc: 0.7625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4599 - acc: 0.7500
 576/1283 [============>.................] - ETA: 0s - loss: 0.4574 - acc: 0.7500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4688 - acc: 0.7486
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4814 - acc: 0.7488
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4739 - acc: 0.7510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4721 - acc: 0.7500
1280/1283 [============================>.] - ETA: 0s - loss: 0.4776 - acc: 0.7500
1283/1283 [==============================] - 1s 480us/step - loss: 0.4770 - acc: 0.7506 - val_loss: 0.8969 - val_acc: 0.4891

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4459 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4941 - acc: 0.7760
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4878 - acc: 0.7875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4420 - acc: 0.8237
 576/1283 [============>.................] - ETA: 0s - loss: 0.4297 - acc: 0.8247
 768/1283 [================>.............] - ETA: 0s - loss: 0.4557 - acc: 0.8008
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4404 - acc: 0.8115
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4372 - acc: 0.8151
1283/1283 [==============================] - 1s 469us/step - loss: 0.4351 - acc: 0.8129 - val_loss: 0.8726 - val_acc: 0.4891

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
epochs=100
mode=V
accuracy=0.532069970845481
best_valid_accuracy=0.5102040816326531
