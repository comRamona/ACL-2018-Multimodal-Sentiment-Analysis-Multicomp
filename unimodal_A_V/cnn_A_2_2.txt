/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:08:26.847220: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 12s - loss: 0.7582 - acc: 0.4375
 192/1283 [===>..........................] - ETA: 4s - loss: 0.8082 - acc: 0.4740 
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7720 - acc: 0.4719
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7676 - acc: 0.4732
 576/1283 [============>.................] - ETA: 1s - loss: 0.7587 - acc: 0.4844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7481 - acc: 0.4886
 768/1283 [================>.............] - ETA: 0s - loss: 0.7470 - acc: 0.4909
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7450 - acc: 0.4944
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7380 - acc: 0.5068
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7339 - acc: 0.5069
1280/1283 [============================>.] - ETA: 0s - loss: 0.7287 - acc: 0.5156
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7283 - acc: 0.5160 - val_loss: 0.7057 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6609 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6576 - acc: 0.5990
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6592 - acc: 0.6000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6593 - acc: 0.5964
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6529 - acc: 0.6211
 640/1283 [=============>................] - ETA: 0s - loss: 0.6488 - acc: 0.6328
 768/1283 [================>.............] - ETA: 0s - loss: 0.6471 - acc: 0.6380
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6472 - acc: 0.6373
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6439 - acc: 0.6416
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6390 - acc: 0.6489
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6370 - acc: 0.6447
1283/1283 [==============================] - 1s 663us/step - loss: 0.6383 - acc: 0.6438 - val_loss: 0.7473 - val_acc: 0.5459

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6149 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6162 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5944 - acc: 0.6750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5902 - acc: 0.6745
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5939 - acc: 0.6738
 640/1283 [=============>................] - ETA: 0s - loss: 0.5891 - acc: 0.6719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5904 - acc: 0.6733
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5887 - acc: 0.6839
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5870 - acc: 0.6896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5843 - acc: 0.6912
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5860 - acc: 0.6883
1283/1283 [==============================] - 1s 735us/step - loss: 0.5875 - acc: 0.6843 - val_loss: 0.7297 - val_acc: 0.5415

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5947 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.5484 - acc: 0.6797
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5383 - acc: 0.7109
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5320 - acc: 0.7156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5264 - acc: 0.7161
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5351 - acc: 0.7121
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5353 - acc: 0.7109
 576/1283 [============>.................] - ETA: 0s - loss: 0.5340 - acc: 0.7170
 640/1283 [=============>................] - ETA: 0s - loss: 0.5376 - acc: 0.7156
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5384 - acc: 0.7173
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5419 - acc: 0.7151
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5419 - acc: 0.7165
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5426 - acc: 0.7197
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5406 - acc: 0.7231
1280/1283 [============================>.] - ETA: 0s - loss: 0.5381 - acc: 0.7266
1283/1283 [==============================] - 1s 837us/step - loss: 0.5374 - acc: 0.7272 - val_loss: 0.8099 - val_acc: 0.4978

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5195 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5232 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4982 - acc: 0.7625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4849 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4810 - acc: 0.7743
 640/1283 [=============>................] - ETA: 0s - loss: 0.4790 - acc: 0.7719
 768/1283 [================>.............] - ETA: 0s - loss: 0.4684 - acc: 0.7891
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4625 - acc: 0.7958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4635 - acc: 0.7930
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4683 - acc: 0.7908
1280/1283 [============================>.] - ETA: 0s - loss: 0.4634 - acc: 0.7922
1283/1283 [==============================] - 1s 759us/step - loss: 0.4630 - acc: 0.7927 - val_loss: 0.8016 - val_acc: 0.5808

Epoch 00005: val_acc improved from 0.55022 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3992 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3257 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3700 - acc: 0.8656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3734 - acc: 0.8568
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3806 - acc: 0.8457
 640/1283 [=============>................] - ETA: 0s - loss: 0.3755 - acc: 0.8469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3806 - acc: 0.8381
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3686 - acc: 0.8462
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3731 - acc: 0.8427
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3743 - acc: 0.8419
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3741 - acc: 0.8388
1283/1283 [==============================] - 1s 683us/step - loss: 0.3796 - acc: 0.8309 - val_loss: 0.8152 - val_acc: 0.5240

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2956 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3745 - acc: 0.8021
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3773 - acc: 0.8063
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3660 - acc: 0.8237
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3690 - acc: 0.8242
 576/1283 [============>.................] - ETA: 0s - loss: 0.3682 - acc: 0.8299
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3734 - acc: 0.8281
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3679 - acc: 0.8365
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3801 - acc: 0.8292
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3825 - acc: 0.8281
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3794 - acc: 0.8299
1280/1283 [============================>.] - ETA: 0s - loss: 0.3758 - acc: 0.8305
1283/1283 [==============================] - 1s 761us/step - loss: 0.3754 - acc: 0.8309 - val_loss: 0.8833 - val_acc: 0.5764

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2788 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2995 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2849 - acc: 0.9000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2922 - acc: 0.8880
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2851 - acc: 0.8926
 640/1283 [=============>................] - ETA: 0s - loss: 0.2812 - acc: 0.8938
 768/1283 [================>.............] - ETA: 0s - loss: 0.2809 - acc: 0.8906
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2753 - acc: 0.8929
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2767 - acc: 0.8877
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2760 - acc: 0.8863
1280/1283 [============================>.] - ETA: 0s - loss: 0.2709 - acc: 0.8922
1283/1283 [==============================] - 1s 682us/step - loss: 0.2704 - acc: 0.8924 - val_loss: 0.9234 - val_acc: 0.5459

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2012 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1935 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2006 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2050 - acc: 0.9397
 576/1283 [============>.................] - ETA: 0s - loss: 0.2093 - acc: 0.9340
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2037 - acc: 0.9304
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1979 - acc: 0.9327
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1954 - acc: 0.9313
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2034 - acc: 0.9258
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1998 - acc: 0.9271
1280/1283 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9273
1283/1283 [==============================] - 1s 701us/step - loss: 0.1981 - acc: 0.9275 - val_loss: 1.0307 - val_acc: 0.5415

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1660 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1503 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1422 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1390 - acc: 0.9557
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1422 - acc: 0.9512
 576/1283 [============>.................] - ETA: 0s - loss: 0.1511 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1501 - acc: 0.9446
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1531 - acc: 0.9435
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1491 - acc: 0.9469
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1504 - acc: 0.9476
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1486 - acc: 0.9498
1283/1283 [==============================] - 1s 713us/step - loss: 0.1469 - acc: 0.9509 - val_loss: 1.1012 - val_acc: 0.5546

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1065 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1092 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1336 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1368 - acc: 0.9464
 576/1283 [============>.................] - ETA: 0s - loss: 0.1277 - acc: 0.9549
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1308 - acc: 0.9531
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1279 - acc: 0.9567
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1298 - acc: 0.9583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1256 - acc: 0.9605
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1214 - acc: 0.9622
1283/1283 [==============================] - 1s 722us/step - loss: 0.1235 - acc: 0.9602 - val_loss: 1.2176 - val_acc: 0.5371

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0601 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0701 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0709 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0717 - acc: 0.9866
 576/1283 [============>.................] - ETA: 0s - loss: 0.0772 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0806 - acc: 0.9797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0808 - acc: 0.9801
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0810 - acc: 0.9820
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0873 - acc: 0.9781
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0924 - acc: 0.9733
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0951 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9711
1283/1283 [==============================] - 1s 660us/step - loss: 0.0938 - acc: 0.9712 - val_loss: 1.4197 - val_acc: 0.5459

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1115 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0982 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0947 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0866 - acc: 0.9643
 576/1283 [============>.................] - ETA: 0s - loss: 0.0905 - acc: 0.9635
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0874 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0827 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0804 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0797 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0778 - acc: 0.9704
1283/1283 [==============================] - 1s 656us/step - loss: 0.0764 - acc: 0.9719 - val_loss: 1.5066 - val_acc: 0.5153

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0520 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0489 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0504 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0532 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0558 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0522 - acc: 0.9859
 768/1283 [================>.............] - ETA: 0s - loss: 0.0531 - acc: 0.9857
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0517 - acc: 0.9855
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0511 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0535 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9836
1283/1283 [==============================] - 1s 604us/step - loss: 0.0551 - acc: 0.9836 - val_loss: 1.6260 - val_acc: 0.5633

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0322 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0373 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0437 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0406 - acc: 0.9824
 640/1283 [=============>................] - ETA: 0s - loss: 0.0416 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0409 - acc: 0.9857
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0400 - acc: 0.9866
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0423 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0409 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9836
1283/1283 [==============================] - 1s 479us/step - loss: 0.0411 - acc: 0.9836 - val_loss: 1.9560 - val_acc: 0.5415

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
epochs=100
mode=A
accuracy=0.47959183673469385
best_valid_accuracy=0.478134110787172
