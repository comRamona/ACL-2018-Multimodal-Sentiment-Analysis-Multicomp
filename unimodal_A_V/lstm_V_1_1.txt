/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 09:39:24.144686: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.6894 - acc: 0.5781
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6780 - acc: 0.6172
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6788 - acc: 0.5826
 640/1283 [=============>................] - ETA: 0s - loss: 0.6795 - acc: 0.5703
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6751 - acc: 0.5889
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6750 - acc: 0.5889
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6770 - acc: 0.5814
1283/1283 [==============================] - 1s 538us/step - loss: 0.6762 - acc: 0.5799 - val_loss: 0.6898 - val_acc: 0.5328

Epoch 00001: val_acc improved from -inf to 0.53275, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6384 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6502 - acc: 0.6211
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6568 - acc: 0.6016
 576/1283 [============>.................] - ETA: 0s - loss: 0.6613 - acc: 0.5972
 768/1283 [================>.............] - ETA: 0s - loss: 0.6552 - acc: 0.6107
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6566 - acc: 0.6150
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6577 - acc: 0.6123
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6612 - acc: 0.5987
1283/1283 [==============================] - 1s 426us/step - loss: 0.6616 - acc: 0.5939 - val_loss: 0.7009 - val_acc: 0.5197

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6176 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6512 - acc: 0.5742
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6506 - acc: 0.6004
 576/1283 [============>.................] - ETA: 0s - loss: 0.6525 - acc: 0.6042
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6495 - acc: 0.6051
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6465 - acc: 0.6070
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6488 - acc: 0.6016
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6475 - acc: 0.6012
1283/1283 [==============================] - 1s 461us/step - loss: 0.6484 - acc: 0.6041 - val_loss: 0.7109 - val_acc: 0.5197

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6626 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6489 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6375 - acc: 0.6219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6442 - acc: 0.6116
 576/1283 [============>.................] - ETA: 0s - loss: 0.6382 - acc: 0.6233
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6451 - acc: 0.6193
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6453 - acc: 0.6166
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6473 - acc: 0.6167
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6472 - acc: 0.6213
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6466 - acc: 0.6184
1283/1283 [==============================] - 1s 561us/step - loss: 0.6457 - acc: 0.6204 - val_loss: 0.7484 - val_acc: 0.5022

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5604 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6167 - acc: 0.6146
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6294 - acc: 0.6000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6253 - acc: 0.6205
 576/1283 [============>.................] - ETA: 0s - loss: 0.6289 - acc: 0.6250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6399 - acc: 0.6151
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6395 - acc: 0.6142
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6400 - acc: 0.6188
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6383 - acc: 0.6222
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6390 - acc: 0.6250
1283/1283 [==============================] - 1s 592us/step - loss: 0.6390 - acc: 0.6251 - val_loss: 0.7406 - val_acc: 0.4498

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5942 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6243 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6375 - acc: 0.6531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6313 - acc: 0.6629
 576/1283 [============>.................] - ETA: 0s - loss: 0.6352 - acc: 0.6528
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6378 - acc: 0.6449
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6398 - acc: 0.6346
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6376 - acc: 0.6323
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6382 - acc: 0.6268
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6402 - acc: 0.6250
1283/1283 [==============================] - 1s 633us/step - loss: 0.6389 - acc: 0.6306 - val_loss: 0.7473 - val_acc: 0.4760

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5857 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5939 - acc: 0.6979
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6037 - acc: 0.6750
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6202 - acc: 0.6367
 640/1283 [=============>................] - ETA: 0s - loss: 0.6250 - acc: 0.6438
 768/1283 [================>.............] - ETA: 0s - loss: 0.6286 - acc: 0.6393
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6268 - acc: 0.6384
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6330 - acc: 0.6270
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6307 - acc: 0.6319
1280/1283 [============================>.] - ETA: 0s - loss: 0.6279 - acc: 0.6344
1283/1283 [==============================] - 1s 626us/step - loss: 0.6284 - acc: 0.6345 - val_loss: 0.7371 - val_acc: 0.4847

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.7010 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6503 - acc: 0.5833
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6430 - acc: 0.5938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6441 - acc: 0.5960
 576/1283 [============>.................] - ETA: 0s - loss: 0.6425 - acc: 0.5955
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6363 - acc: 0.5980
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6321 - acc: 0.6178
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6295 - acc: 0.6177
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6292 - acc: 0.6176
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6318 - acc: 0.6176
1283/1283 [==============================] - 1s 556us/step - loss: 0.6285 - acc: 0.6243 - val_loss: 0.7581 - val_acc: 0.4629

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6214 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6226 - acc: 0.6458
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6232 - acc: 0.6375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6216 - acc: 0.6272
 576/1283 [============>.................] - ETA: 0s - loss: 0.6115 - acc: 0.6424
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6147 - acc: 0.6392
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6136 - acc: 0.6466
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6108 - acc: 0.6479
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6178 - acc: 0.6351
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6160 - acc: 0.6390
1283/1283 [==============================] - 1s 582us/step - loss: 0.6182 - acc: 0.6345 - val_loss: 0.7722 - val_acc: 0.4629

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6706 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6257 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6055 - acc: 0.6625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6051 - acc: 0.6652
 640/1283 [=============>................] - ETA: 0s - loss: 0.6160 - acc: 0.6453
 768/1283 [================>.............] - ETA: 0s - loss: 0.6135 - acc: 0.6432
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6127 - acc: 0.6384
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6070 - acc: 0.6475
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6092 - acc: 0.6502
1283/1283 [==============================] - 1s 479us/step - loss: 0.6120 - acc: 0.6430 - val_loss: 0.7811 - val_acc: 0.4716

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6088 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5765 - acc: 0.7083
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5930 - acc: 0.6844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5985 - acc: 0.6674
 576/1283 [============>.................] - ETA: 0s - loss: 0.6031 - acc: 0.6632
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6152 - acc: 0.6548
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6059 - acc: 0.6635
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6036 - acc: 0.6635
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6068 - acc: 0.6608
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6147 - acc: 0.6587
1283/1283 [==============================] - 1s 547us/step - loss: 0.6138 - acc: 0.6594 - val_loss: 0.7591 - val_acc: 0.4934

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
mode=V
accuracy=0.5116618075801749
best_valid_accuracy=0.49854227405247814
