/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:20:50.832663: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.6840 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 1s - loss: 0.7314 - acc: 0.5586
 576/1283 [============>.................] - ETA: 0s - loss: 0.7122 - acc: 0.5243
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6970 - acc: 0.5413
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6900 - acc: 0.5411
1283/1283 [==============================] - 1s 469us/step - loss: 0.6885 - acc: 0.5401 - val_loss: 0.6777 - val_acc: 0.5677

Epoch 00001: val_acc improved from -inf to 0.56769, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6544 - acc: 0.5156
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6547 - acc: 0.5844
 576/1283 [============>.................] - ETA: 0s - loss: 0.6533 - acc: 0.5885
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6697 - acc: 0.5913
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6674 - acc: 0.5882
1283/1283 [==============================] - 0s 245us/step - loss: 0.6631 - acc: 0.5963 - val_loss: 0.7134 - val_acc: 0.5459

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6648 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6899 - acc: 0.5938
 576/1283 [============>.................] - ETA: 0s - loss: 0.6673 - acc: 0.6024
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6563 - acc: 0.6116
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6681 - acc: 0.6016
1283/1283 [==============================] - 0s 219us/step - loss: 0.6649 - acc: 0.6064 - val_loss: 0.6836 - val_acc: 0.5721

Epoch 00003: val_acc improved from 0.56769 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5980 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6818 - acc: 0.6344
 576/1283 [============>.................] - ETA: 0s - loss: 0.6624 - acc: 0.6267
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6527 - acc: 0.6238
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6442 - acc: 0.6318
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6442 - acc: 0.6349
1283/1283 [==============================] - 0s 298us/step - loss: 0.6408 - acc: 0.6383 - val_loss: 0.6993 - val_acc: 0.5284

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5591 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5981 - acc: 0.6438
 576/1283 [============>.................] - ETA: 0s - loss: 0.6358 - acc: 0.6372
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6292 - acc: 0.6502
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6281 - acc: 0.6398
1283/1283 [==============================] - 0s 230us/step - loss: 0.6307 - acc: 0.6399 - val_loss: 0.7520 - val_acc: 0.5240

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6249 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.7022 - acc: 0.5820
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6849 - acc: 0.6074
 768/1283 [================>.............] - ETA: 0s - loss: 0.6573 - acc: 0.6211
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6469 - acc: 0.6309
1280/1283 [============================>.] - ETA: 0s - loss: 0.6429 - acc: 0.6344
1283/1283 [==============================] - 0s 243us/step - loss: 0.6428 - acc: 0.6337 - val_loss: 0.7248 - val_acc: 0.4716

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6028 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6024 - acc: 0.6594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5973 - acc: 0.6699
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6032 - acc: 0.6634
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6062 - acc: 0.6562
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6101 - acc: 0.6606
1283/1283 [==============================] - 0s 279us/step - loss: 0.6050 - acc: 0.6680 - val_loss: 0.7563 - val_acc: 0.4629

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5928 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5807 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5965 - acc: 0.6763
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5959 - acc: 0.6761
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5926 - acc: 0.6842
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5918 - acc: 0.6875
1283/1283 [==============================] - 0s 302us/step - loss: 0.5912 - acc: 0.6859 - val_loss: 0.7184 - val_acc: 0.5197

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5380 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6462 - acc: 0.6750
 576/1283 [============>.................] - ETA: 0s - loss: 0.6371 - acc: 0.6424
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6267 - acc: 0.6611
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6235 - acc: 0.6592
1280/1283 [============================>.] - ETA: 0s - loss: 0.6231 - acc: 0.6578
1283/1283 [==============================] - 0s 274us/step - loss: 0.6225 - acc: 0.6586 - val_loss: 0.7125 - val_acc: 0.5371

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5543 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6203 - acc: 0.6687
 640/1283 [=============>................] - ETA: 0s - loss: 0.6137 - acc: 0.6641
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6050 - acc: 0.6786
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6002 - acc: 0.6809
1283/1283 [==============================] - 0s 217us/step - loss: 0.5978 - acc: 0.6859 - val_loss: 0.7269 - val_acc: 0.5066

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6059 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5535 - acc: 0.7448
 640/1283 [=============>................] - ETA: 0s - loss: 0.5529 - acc: 0.7203
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5592 - acc: 0.7151
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5549 - acc: 0.7196
1283/1283 [==============================] - 0s 219us/step - loss: 0.5523 - acc: 0.7241 - val_loss: 0.7855 - val_acc: 0.5284

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6083 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5479 - acc: 0.7109
 640/1283 [=============>................] - ETA: 0s - loss: 0.5363 - acc: 0.7188
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5353 - acc: 0.7217
1283/1283 [==============================] - 0s 201us/step - loss: 0.5356 - acc: 0.7241 - val_loss: 0.8250 - val_acc: 0.4716

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4936 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5522 - acc: 0.7083
 640/1283 [=============>................] - ETA: 0s - loss: 0.5278 - acc: 0.7266
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5283 - acc: 0.7198
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5455 - acc: 0.7171
1283/1283 [==============================] - 0s 219us/step - loss: 0.5401 - acc: 0.7194 - val_loss: 0.7603 - val_acc: 0.5109

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=15
epochs=100
mode=V
accuracy=0.5335276967930029
best_valid_accuracy=0.5116618075801749
