/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:07:57.056204: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.7344 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.7717 - acc: 0.5703
 448/1283 [=========>....................] - ETA: 0s - loss: 0.8050 - acc: 0.5491
 576/1283 [============>.................] - ETA: 0s - loss: 0.7886 - acc: 0.5347
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7743 - acc: 0.5398
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7604 - acc: 0.5505
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7490 - acc: 0.5531
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7452 - acc: 0.5579
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7409 - acc: 0.5625
1283/1283 [==============================] - 1s 526us/step - loss: 0.7386 - acc: 0.5596 - val_loss: 0.7237 - val_acc: 0.5066

Epoch 00001: val_acc improved from -inf to 0.50655, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6005 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6115 - acc: 0.6823
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6252 - acc: 0.6625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6501 - acc: 0.6205
 640/1283 [=============>................] - ETA: 0s - loss: 0.6430 - acc: 0.6266
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6438 - acc: 0.6214
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6372 - acc: 0.6406
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6336 - acc: 0.6447
1283/1283 [==============================] - 1s 407us/step - loss: 0.6334 - acc: 0.6446 - val_loss: 0.7106 - val_acc: 0.5459

Epoch 00002: val_acc improved from 0.50655 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5977 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5875 - acc: 0.6667
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5898 - acc: 0.6562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5733 - acc: 0.6816
 640/1283 [=============>................] - ETA: 0s - loss: 0.5811 - acc: 0.6766
 768/1283 [================>.............] - ETA: 0s - loss: 0.5837 - acc: 0.6797
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5835 - acc: 0.6797
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5769 - acc: 0.6865
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5682 - acc: 0.6979
1283/1283 [==============================] - 1s 504us/step - loss: 0.5702 - acc: 0.6937 - val_loss: 0.7227 - val_acc: 0.5590

Epoch 00003: val_acc improved from 0.54585 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5246 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5041 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4782 - acc: 0.7844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4666 - acc: 0.7857
 640/1283 [=============>................] - ETA: 0s - loss: 0.4702 - acc: 0.7703
 768/1283 [================>.............] - ETA: 0s - loss: 0.4674 - acc: 0.7760
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4705 - acc: 0.7757
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4746 - acc: 0.7702
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4816 - acc: 0.7640
1283/1283 [==============================] - 1s 473us/step - loss: 0.4818 - acc: 0.7631 - val_loss: 0.8084 - val_acc: 0.5633

Epoch 00004: val_acc improved from 0.55895 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4896 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4507 - acc: 0.7917
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4483 - acc: 0.8047
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4447 - acc: 0.7949
 640/1283 [=============>................] - ETA: 0s - loss: 0.4422 - acc: 0.7906
 768/1283 [================>.............] - ETA: 0s - loss: 0.4445 - acc: 0.7930
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4393 - acc: 0.8021
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4292 - acc: 0.8116
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4298 - acc: 0.8117
1283/1283 [==============================] - 1s 502us/step - loss: 0.4291 - acc: 0.8129 - val_loss: 0.8005 - val_acc: 0.5415

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3995 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3773 - acc: 0.8646
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3678 - acc: 0.8568
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3659 - acc: 0.8516
 640/1283 [=============>................] - ETA: 0s - loss: 0.3741 - acc: 0.8391
 768/1283 [================>.............] - ETA: 0s - loss: 0.3667 - acc: 0.8424
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3640 - acc: 0.8482
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3586 - acc: 0.8516
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3610 - acc: 0.8533
1280/1283 [============================>.] - ETA: 0s - loss: 0.3603 - acc: 0.8531
1283/1283 [==============================] - 1s 520us/step - loss: 0.3597 - acc: 0.8535 - val_loss: 0.9551 - val_acc: 0.5546

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3283 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3011 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2702 - acc: 0.9031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2853 - acc: 0.8884
 576/1283 [============>.................] - ETA: 0s - loss: 0.2846 - acc: 0.8889
 768/1283 [================>.............] - ETA: 0s - loss: 0.2913 - acc: 0.8919
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3009 - acc: 0.8895
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3029 - acc: 0.8848
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3052 - acc: 0.8811
1280/1283 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.8789
1283/1283 [==============================] - 1s 514us/step - loss: 0.3073 - acc: 0.8792 - val_loss: 0.8828 - val_acc: 0.5240

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2679 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2950 - acc: 0.9115
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2600 - acc: 0.9245
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2541 - acc: 0.9219
 640/1283 [=============>................] - ETA: 0s - loss: 0.2571 - acc: 0.9187
 768/1283 [================>.............] - ETA: 0s - loss: 0.2595 - acc: 0.9167
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2557 - acc: 0.9185
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2519 - acc: 0.9219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2518 - acc: 0.9201
1280/1283 [============================>.] - ETA: 0s - loss: 0.2502 - acc: 0.9195
1283/1283 [==============================] - 1s 568us/step - loss: 0.2503 - acc: 0.9189 - val_loss: 1.0247 - val_acc: 0.5459

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2082 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2705 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2552 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2428 - acc: 0.9152
 640/1283 [=============>................] - ETA: 0s - loss: 0.2334 - acc: 0.9187
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2215 - acc: 0.9255
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2184 - acc: 0.9248
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2185 - acc: 0.9243
1283/1283 [==============================] - 1s 421us/step - loss: 0.2217 - acc: 0.9205 - val_loss: 0.9558 - val_acc: 0.5284

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1777 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2077 - acc: 0.9258
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1973 - acc: 0.9353
 640/1283 [=============>................] - ETA: 0s - loss: 0.2011 - acc: 0.9344
 768/1283 [================>.............] - ETA: 0s - loss: 0.1981 - acc: 0.9375
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2017 - acc: 0.9344
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1936 - acc: 0.9384
1283/1283 [==============================] - 0s 368us/step - loss: 0.1929 - acc: 0.9392 - val_loss: 1.0763 - val_acc: 0.5197

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1820 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2156 - acc: 0.9271
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2237 - acc: 0.9187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2167 - acc: 0.9196
 576/1283 [============>.................] - ETA: 0s - loss: 0.2262 - acc: 0.9132
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2091 - acc: 0.9261
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2077 - acc: 0.9267
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2002 - acc: 0.9344
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1936 - acc: 0.9349
1280/1283 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9328
1283/1283 [==============================] - 1s 505us/step - loss: 0.1977 - acc: 0.9330 - val_loss: 1.0129 - val_acc: 0.5371

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1713 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1446 - acc: 0.9570
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1370 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.1431 - acc: 0.9566
 768/1283 [================>.............] - ETA: 0s - loss: 0.1440 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1420 - acc: 0.9565
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1379 - acc: 0.9580
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1329 - acc: 0.9627
1280/1283 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9641
1283/1283 [==============================] - 1s 456us/step - loss: 0.1303 - acc: 0.9641 - val_loss: 1.1072 - val_acc: 0.5459

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0801 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0843 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0883 - acc: 0.9812
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0950 - acc: 0.9805
 640/1283 [=============>................] - ETA: 0s - loss: 0.0916 - acc: 0.9812
 768/1283 [================>.............] - ETA: 0s - loss: 0.0894 - acc: 0.9831
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0850 - acc: 0.9854
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0829 - acc: 0.9853
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0848 - acc: 0.9844
1283/1283 [==============================] - 1s 491us/step - loss: 0.0865 - acc: 0.9844 - val_loss: 1.2487 - val_acc: 0.5459

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0609 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0651 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0741 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0757 - acc: 0.9888
 640/1283 [=============>................] - ETA: 0s - loss: 0.0805 - acc: 0.9891
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0782 - acc: 0.9892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0774 - acc: 0.9896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0760 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0754 - acc: 0.9885
1283/1283 [==============================] - 1s 466us/step - loss: 0.0750 - acc: 0.9891 - val_loss: 1.1860 - val_acc: 0.5502

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
epochs=100
mode=A
accuracy=0.5043731778425656
best_valid_accuracy=0.5583090379008746
