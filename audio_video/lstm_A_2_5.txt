/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 08:44:09.070930: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.7046 - acc: 0.4688
 192/1283 [===>..........................] - ETA: 2s - loss: 0.6945 - acc: 0.4948
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6941 - acc: 0.5062
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6921 - acc: 0.5134
 576/1283 [============>.................] - ETA: 0s - loss: 0.6928 - acc: 0.5000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6897 - acc: 0.5128
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6896 - acc: 0.5144
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6899 - acc: 0.5240
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6881 - acc: 0.5257
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6862 - acc: 0.5296
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6887 - acc: 0.5253 - val_loss: 0.6914 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6648 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6559 - acc: 0.6354
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6565 - acc: 0.6156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6637 - acc: 0.5938
 576/1283 [============>.................] - ETA: 0s - loss: 0.6689 - acc: 0.5799
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6680 - acc: 0.5866
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6687 - acc: 0.5877
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6705 - acc: 0.5875
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6672 - acc: 0.5947
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6705 - acc: 0.5872
1283/1283 [==============================] - 1s 660us/step - loss: 0.6705 - acc: 0.5892 - val_loss: 0.6959 - val_acc: 0.5284

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6546 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6675 - acc: 0.5885
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6698 - acc: 0.5969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6568 - acc: 0.6161
 576/1283 [============>.................] - ETA: 0s - loss: 0.6573 - acc: 0.6042
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6517 - acc: 0.6193
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6508 - acc: 0.6190
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6501 - acc: 0.6198
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6495 - acc: 0.6232
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6488 - acc: 0.6209
1283/1283 [==============================] - 1s 636us/step - loss: 0.6465 - acc: 0.6267 - val_loss: 0.6969 - val_acc: 0.5546

Epoch 00003: val_acc improved from 0.55022 to 0.55459, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6882 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6439 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6380 - acc: 0.6406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6326 - acc: 0.6451
 576/1283 [============>.................] - ETA: 0s - loss: 0.6226 - acc: 0.6597
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6153 - acc: 0.6662
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6191 - acc: 0.6599
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6251 - acc: 0.6510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6221 - acc: 0.6526
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6206 - acc: 0.6538
1283/1283 [==============================] - 1s 567us/step - loss: 0.6211 - acc: 0.6547 - val_loss: 0.7199 - val_acc: 0.5109

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5773 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5934 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5827 - acc: 0.6781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6095 - acc: 0.6540
 576/1283 [============>.................] - ETA: 0s - loss: 0.6100 - acc: 0.6545
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6130 - acc: 0.6562
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6140 - acc: 0.6526
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6116 - acc: 0.6583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6058 - acc: 0.6654
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6080 - acc: 0.6612
1283/1283 [==============================] - 1s 499us/step - loss: 0.6038 - acc: 0.6656 - val_loss: 0.7215 - val_acc: 0.5852

Epoch 00005: val_acc improved from 0.55459 to 0.58515, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5808 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5813 - acc: 0.6927
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5688 - acc: 0.6906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5680 - acc: 0.6875
 576/1283 [============>.................] - ETA: 0s - loss: 0.5613 - acc: 0.6979
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5641 - acc: 0.6989
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5718 - acc: 0.6923
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5762 - acc: 0.6896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5743 - acc: 0.6949
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5734 - acc: 0.6957
1283/1283 [==============================] - 1s 499us/step - loss: 0.5744 - acc: 0.6937 - val_loss: 0.7441 - val_acc: 0.5939

Epoch 00006: val_acc improved from 0.58515 to 0.59389, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5496 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5237 - acc: 0.7344
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5623 - acc: 0.7063
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5688 - acc: 0.6897
 576/1283 [============>.................] - ETA: 0s - loss: 0.5819 - acc: 0.6771
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5768 - acc: 0.6832
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5707 - acc: 0.6839
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5646 - acc: 0.6906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5657 - acc: 0.6884
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5675 - acc: 0.6924
1283/1283 [==============================] - 1s 498us/step - loss: 0.5635 - acc: 0.6976 - val_loss: 0.7740 - val_acc: 0.4716

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4968 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5070 - acc: 0.7552
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5388 - acc: 0.7250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5291 - acc: 0.7344
 576/1283 [============>.................] - ETA: 0s - loss: 0.5130 - acc: 0.7587
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5157 - acc: 0.7642
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5118 - acc: 0.7608
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5134 - acc: 0.7490
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5146 - acc: 0.7518
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5172 - acc: 0.7500
1283/1283 [==============================] - 1s 504us/step - loss: 0.5187 - acc: 0.7467 - val_loss: 0.7548 - val_acc: 0.5459

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4993 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5189 - acc: 0.7760
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4952 - acc: 0.7812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4835 - acc: 0.7723
 576/1283 [============>.................] - ETA: 0s - loss: 0.4919 - acc: 0.7604
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4869 - acc: 0.7599
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4890 - acc: 0.7536
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4884 - acc: 0.7583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4921 - acc: 0.7574
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4873 - acc: 0.7615
1283/1283 [==============================] - 1s 494us/step - loss: 0.4865 - acc: 0.7615 - val_loss: 0.7746 - val_acc: 0.5808

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4122 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4855 - acc: 0.7865
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4702 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4671 - acc: 0.7924
 576/1283 [============>.................] - ETA: 0s - loss: 0.4646 - acc: 0.7969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4610 - acc: 0.7955
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4503 - acc: 0.8053
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4528 - acc: 0.8042
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4568 - acc: 0.7987
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4569 - acc: 0.7952
1283/1283 [==============================] - 1s 502us/step - loss: 0.4581 - acc: 0.7927 - val_loss: 0.8142 - val_acc: 0.5895

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3439 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4475 - acc: 0.7552
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4576 - acc: 0.7625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4553 - acc: 0.7701
 576/1283 [============>.................] - ETA: 0s - loss: 0.4478 - acc: 0.7760
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4432 - acc: 0.7784
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4350 - acc: 0.7885
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4347 - acc: 0.7906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4341 - acc: 0.7923
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4255 - acc: 0.7993
1283/1283 [==============================] - 1s 493us/step - loss: 0.4267 - acc: 0.7989 - val_loss: 0.8370 - val_acc: 0.5808

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3188 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3559 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3618 - acc: 0.8406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3534 - acc: 0.8571
 576/1283 [============>.................] - ETA: 0s - loss: 0.3653 - acc: 0.8524
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3599 - acc: 0.8480
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3717 - acc: 0.8365
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3902 - acc: 0.8187
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3902 - acc: 0.8162
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3852 - acc: 0.8183
1283/1283 [==============================] - 1s 496us/step - loss: 0.3879 - acc: 0.8153 - val_loss: 0.8914 - val_acc: 0.5939

Epoch 00012: val_acc improved from 0.59389 to 0.59389, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3905 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3754 - acc: 0.8073
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3763 - acc: 0.8156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3726 - acc: 0.8147
 576/1283 [============>.................] - ETA: 0s - loss: 0.3780 - acc: 0.8090
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3717 - acc: 0.8210
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3644 - acc: 0.8269
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3633 - acc: 0.8313
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3676 - acc: 0.8327
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3688 - acc: 0.8306
1283/1283 [==============================] - 1s 500us/step - loss: 0.3645 - acc: 0.8332 - val_loss: 0.8766 - val_acc: 0.6201

Epoch 00013: val_acc improved from 0.59389 to 0.62009, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3719 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3285 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3244 - acc: 0.8719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3302 - acc: 0.8683
 576/1283 [============>.................] - ETA: 0s - loss: 0.3207 - acc: 0.8698
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3139 - acc: 0.8679
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3125 - acc: 0.8690
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3131 - acc: 0.8656
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3166 - acc: 0.8628
1283/1283 [==============================] - 1s 478us/step - loss: 0.3124 - acc: 0.8644 - val_loss: 0.9466 - val_acc: 0.5546

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3971 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3677 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3519 - acc: 0.8406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3262 - acc: 0.8616
 640/1283 [=============>................] - ETA: 0s - loss: 0.3120 - acc: 0.8703
 768/1283 [================>.............] - ETA: 0s - loss: 0.3114 - acc: 0.8698
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3141 - acc: 0.8705
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3100 - acc: 0.8740
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3221 - acc: 0.8681
1283/1283 [==============================] - 1s 464us/step - loss: 0.3206 - acc: 0.8644 - val_loss: 1.0178 - val_acc: 0.5764

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3050 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2735 - acc: 0.8555
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2757 - acc: 0.8549
 640/1283 [=============>................] - ETA: 0s - loss: 0.2668 - acc: 0.8688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2736 - acc: 0.8702
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2867 - acc: 0.8633
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2879 - acc: 0.8651
1283/1283 [==============================] - 0s 362us/step - loss: 0.2896 - acc: 0.8644 - val_loss: 0.9149 - val_acc: 0.5939

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2645 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2842 - acc: 0.8789
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2618 - acc: 0.8929
 640/1283 [=============>................] - ETA: 0s - loss: 0.2527 - acc: 0.8984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2469 - acc: 0.9038
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2439 - acc: 0.9023
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2374 - acc: 0.9038
1283/1283 [==============================] - 0s 324us/step - loss: 0.2348 - acc: 0.9049 - val_loss: 1.1710 - val_acc: 0.5590

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1751 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1463 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1689 - acc: 0.9286
 640/1283 [=============>................] - ETA: 0s - loss: 0.1754 - acc: 0.9234
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1895 - acc: 0.9195
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2116 - acc: 0.9141
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2186 - acc: 0.9079
1283/1283 [==============================] - 0s 313us/step - loss: 0.2253 - acc: 0.9072 - val_loss: 1.1004 - val_acc: 0.5852

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2067 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1750 - acc: 0.9180
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2776 - acc: 0.8772
 640/1283 [=============>................] - ETA: 0s - loss: 0.2991 - acc: 0.8703
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2935 - acc: 0.8738
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2818 - acc: 0.8799
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2777 - acc: 0.8799
1283/1283 [==============================] - 0s 314us/step - loss: 0.2754 - acc: 0.8815 - val_loss: 1.0116 - val_acc: 0.5764

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1685 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2247 - acc: 0.8984
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2511 - acc: 0.8884
 640/1283 [=============>................] - ETA: 0s - loss: 0.2369 - acc: 0.9016
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2327 - acc: 0.9075
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2266 - acc: 0.9121
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2242 - acc: 0.9128
1283/1283 [==============================] - 0s 314us/step - loss: 0.2211 - acc: 0.9150 - val_loss: 1.0779 - val_acc: 0.5677

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1342 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1366 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1554 - acc: 0.9308
 640/1283 [=============>................] - ETA: 0s - loss: 0.1565 - acc: 0.9328
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1644 - acc: 0.9303
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1630 - acc: 0.9326
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1605 - acc: 0.9326
1283/1283 [==============================] - 0s 312us/step - loss: 0.1637 - acc: 0.9306 - val_loss: 1.2160 - val_acc: 0.5852

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1333 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1249 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1273 - acc: 0.9531
 640/1283 [=============>................] - ETA: 0s - loss: 0.1353 - acc: 0.9516
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1240 - acc: 0.9579
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1308 - acc: 0.9512
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1297 - acc: 0.9507
1283/1283 [==============================] - 0s 311us/step - loss: 0.1373 - acc: 0.9486 - val_loss: 1.3661 - val_acc: 0.5939

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1101 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1120 - acc: 0.9570
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1699 - acc: 0.9420
 640/1283 [=============>................] - ETA: 0s - loss: 0.1567 - acc: 0.9469
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1630 - acc: 0.9399
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1553 - acc: 0.9434
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1570 - acc: 0.9408
1283/1283 [==============================] - 0s 315us/step - loss: 0.1623 - acc: 0.9384 - val_loss: 1.2666 - val_acc: 0.5983

Epoch 00023: val_acc did not improve
Epoch 00023: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=15
mode=A
accuracy=0.4839650145772595
best_valid_accuracy=0.4650145772594752
