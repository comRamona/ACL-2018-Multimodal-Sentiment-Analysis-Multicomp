/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 09:39:24.547735: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.6889 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 3s - loss: 0.6868 - acc: 0.5677
 256/1283 [====>.........................] - ETA: 2s - loss: 0.6887 - acc: 0.5547
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6848 - acc: 0.5755
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6858 - acc: 0.5703
 640/1283 [=============>................] - ETA: 0s - loss: 0.6831 - acc: 0.5703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6829 - acc: 0.5653
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6804 - acc: 0.5721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6787 - acc: 0.5729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6769 - acc: 0.5735
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6754 - acc: 0.5773
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6775 - acc: 0.5740
1280/1283 [============================>.] - ETA: 0s - loss: 0.6776 - acc: 0.5750
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6774 - acc: 0.5752 - val_loss: 0.6935 - val_acc: 0.5633

Epoch 00001: val_acc improved from -inf to 0.56332, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6499 - acc: 0.5781
 128/1283 [=>............................] - ETA: 0s - loss: 0.6545 - acc: 0.6016
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6505 - acc: 0.5938
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6545 - acc: 0.6156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6601 - acc: 0.6120
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6562 - acc: 0.6183
 576/1283 [============>.................] - ETA: 0s - loss: 0.6536 - acc: 0.6163
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6528 - acc: 0.6037
 768/1283 [================>.............] - ETA: 0s - loss: 0.6525 - acc: 0.6042
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6560 - acc: 0.6016
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6555 - acc: 0.5958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6579 - acc: 0.5956
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6574 - acc: 0.5946
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6571 - acc: 0.5938
1280/1283 [============================>.] - ETA: 0s - loss: 0.6562 - acc: 0.5945
1283/1283 [==============================] - 1s 915us/step - loss: 0.6561 - acc: 0.5947 - val_loss: 0.7053 - val_acc: 0.5284

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6682 - acc: 0.6094
 128/1283 [=>............................] - ETA: 1s - loss: 0.6701 - acc: 0.5547
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6586 - acc: 0.5833
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6577 - acc: 0.5664
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6596 - acc: 0.5656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6605 - acc: 0.5703
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6558 - acc: 0.5938
 576/1283 [============>.................] - ETA: 0s - loss: 0.6518 - acc: 0.5990
 640/1283 [=============>................] - ETA: 0s - loss: 0.6525 - acc: 0.5953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6541 - acc: 0.5966
 768/1283 [================>.............] - ETA: 0s - loss: 0.6533 - acc: 0.5951
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6520 - acc: 0.5986
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6501 - acc: 0.6031
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6467 - acc: 0.6112
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6452 - acc: 0.6127
1283/1283 [==============================] - 1s 919us/step - loss: 0.6433 - acc: 0.6134 - val_loss: 0.7176 - val_acc: 0.5284

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6260 - acc: 0.5781
 128/1283 [=>............................] - ETA: 1s - loss: 0.6023 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6278 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6111 - acc: 0.6531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6242 - acc: 0.6384
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6277 - acc: 0.6328
 576/1283 [============>.................] - ETA: 0s - loss: 0.6233 - acc: 0.6389
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6302 - acc: 0.6321
 768/1283 [================>.............] - ETA: 0s - loss: 0.6337 - acc: 0.6315
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6376 - acc: 0.6228
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6367 - acc: 0.6219
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6385 - acc: 0.6149
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6400 - acc: 0.6128
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6369 - acc: 0.6168
1280/1283 [============================>.] - ETA: 0s - loss: 0.6370 - acc: 0.6180
1283/1283 [==============================] - 1s 887us/step - loss: 0.6372 - acc: 0.6181 - val_loss: 0.7263 - val_acc: 0.5109

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6290 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6449 - acc: 0.6458
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6360 - acc: 0.6469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6274 - acc: 0.6615
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6272 - acc: 0.6607
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6287 - acc: 0.6523
 576/1283 [============>.................] - ETA: 0s - loss: 0.6246 - acc: 0.6580
 640/1283 [=============>................] - ETA: 0s - loss: 0.6245 - acc: 0.6594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6235 - acc: 0.6548
 768/1283 [================>.............] - ETA: 0s - loss: 0.6220 - acc: 0.6589
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6209 - acc: 0.6635
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6202 - acc: 0.6585
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6237 - acc: 0.6523
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6216 - acc: 0.6544
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6221 - acc: 0.6536
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6219 - acc: 0.6530
1283/1283 [==============================] - 1s 934us/step - loss: 0.6199 - acc: 0.6555 - val_loss: 0.7330 - val_acc: 0.5022

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6332 - acc: 0.6406
 128/1283 [=>............................] - ETA: 0s - loss: 0.6156 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6368 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6284 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6305 - acc: 0.6125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6230 - acc: 0.6198
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6180 - acc: 0.6250
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6208 - acc: 0.6250
 576/1283 [============>.................] - ETA: 0s - loss: 0.6267 - acc: 0.6163
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6190 - acc: 0.6307
 768/1283 [================>.............] - ETA: 0s - loss: 0.6147 - acc: 0.6367
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6124 - acc: 0.6395
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6132 - acc: 0.6377
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6175 - acc: 0.6389
1280/1283 [============================>.] - ETA: 0s - loss: 0.6175 - acc: 0.6383
1283/1283 [==============================] - 1s 856us/step - loss: 0.6178 - acc: 0.6376 - val_loss: 0.7326 - val_acc: 0.5284

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5954 - acc: 0.7031
 128/1283 [=>............................] - ETA: 0s - loss: 0.6488 - acc: 0.6172
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6097 - acc: 0.6641
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6105 - acc: 0.6641
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6080 - acc: 0.6585
 576/1283 [============>.................] - ETA: 0s - loss: 0.6027 - acc: 0.6562
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6039 - acc: 0.6591
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6099 - acc: 0.6538
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6113 - acc: 0.6458
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6065 - acc: 0.6544
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6110 - acc: 0.6488
1283/1283 [==============================] - 1s 660us/step - loss: 0.6121 - acc: 0.6469 - val_loss: 0.7267 - val_acc: 0.5066

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6402 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6172 - acc: 0.6354
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6123 - acc: 0.6469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6142 - acc: 0.6362
 576/1283 [============>.................] - ETA: 0s - loss: 0.6122 - acc: 0.6476
 640/1283 [=============>................] - ETA: 0s - loss: 0.6130 - acc: 0.6469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6176 - acc: 0.6335
 768/1283 [================>.............] - ETA: 0s - loss: 0.6174 - acc: 0.6302
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6170 - acc: 0.6358
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6164 - acc: 0.6385
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6173 - acc: 0.6357
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6154 - acc: 0.6389
1280/1283 [============================>.] - ETA: 0s - loss: 0.6165 - acc: 0.6438
1283/1283 [==============================] - 1s 791us/step - loss: 0.6169 - acc: 0.6430 - val_loss: 0.7266 - val_acc: 0.4891

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5641 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5947 - acc: 0.6979
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6002 - acc: 0.6781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5876 - acc: 0.6830
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5896 - acc: 0.6777
 640/1283 [=============>................] - ETA: 0s - loss: 0.5845 - acc: 0.6844
 768/1283 [================>.............] - ETA: 0s - loss: 0.5925 - acc: 0.6758
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5919 - acc: 0.6730
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5953 - acc: 0.6689
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5947 - acc: 0.6641
1280/1283 [============================>.] - ETA: 0s - loss: 0.6012 - acc: 0.6625
1283/1283 [==============================] - 1s 660us/step - loss: 0.6022 - acc: 0.6610 - val_loss: 0.7609 - val_acc: 0.4847

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5787 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5767 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5913 - acc: 0.6687
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5917 - acc: 0.6629
 576/1283 [============>.................] - ETA: 0s - loss: 0.5939 - acc: 0.6597
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5902 - acc: 0.6619
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5881 - acc: 0.6623
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5979 - acc: 0.6594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5950 - acc: 0.6664
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5996 - acc: 0.6554
1280/1283 [============================>.] - ETA: 0s - loss: 0.5974 - acc: 0.6586
1283/1283 [==============================] - 1s 667us/step - loss: 0.5972 - acc: 0.6586 - val_loss: 0.7538 - val_acc: 0.4803

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5873 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5612 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5960 - acc: 0.6562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5888 - acc: 0.6585
 576/1283 [============>.................] - ETA: 0s - loss: 0.5929 - acc: 0.6545
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5960 - acc: 0.6562
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6032 - acc: 0.6454
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5984 - acc: 0.6573
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5950 - acc: 0.6572
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5951 - acc: 0.6546
1283/1283 [==============================] - 1s 577us/step - loss: 0.5943 - acc: 0.6555 - val_loss: 0.7432 - val_acc: 0.5109

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=25
mode=V
accuracy=0.5014577259475219
best_valid_accuracy=0.49271137026239065
