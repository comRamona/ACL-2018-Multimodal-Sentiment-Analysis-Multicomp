/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 08:38:48.176284: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.7038 - acc: 0.5469
 128/1283 [=>............................] - ETA: 6s - loss: 0.6871 - acc: 0.5703 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.6919 - acc: 0.5625
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7013 - acc: 0.5312
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6996 - acc: 0.5312
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6969 - acc: 0.5391
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7024 - acc: 0.5179
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7037 - acc: 0.5273
 576/1283 [============>.................] - ETA: 1s - loss: 0.7042 - acc: 0.5226
 640/1283 [=============>................] - ETA: 1s - loss: 0.7011 - acc: 0.5359
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6999 - acc: 0.5355
 768/1283 [================>.............] - ETA: 1s - loss: 0.6987 - acc: 0.5299
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6978 - acc: 0.5240
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6961 - acc: 0.5279
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6959 - acc: 0.5260
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6976 - acc: 0.5205
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6959 - acc: 0.5276
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6958 - acc: 0.5286
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6943 - acc: 0.5321
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6934 - acc: 0.5316 - val_loss: 0.6870 - val_acc: 0.5633

Epoch 00001: val_acc improved from -inf to 0.56332, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6720 - acc: 0.5781
 128/1283 [=>............................] - ETA: 1s - loss: 0.6795 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6743 - acc: 0.5677
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6679 - acc: 0.5844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6723 - acc: 0.5859
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6718 - acc: 0.5871
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6692 - acc: 0.5938
 576/1283 [============>.................] - ETA: 0s - loss: 0.6711 - acc: 0.5920
 640/1283 [=============>................] - ETA: 0s - loss: 0.6726 - acc: 0.5859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6732 - acc: 0.5881
 768/1283 [================>.............] - ETA: 0s - loss: 0.6715 - acc: 0.5951
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6701 - acc: 0.5974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6695 - acc: 0.5971
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6720 - acc: 0.5896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6732 - acc: 0.5889
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6724 - acc: 0.5882
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6737 - acc: 0.5842
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6727 - acc: 0.5863
1280/1283 [============================>.] - ETA: 0s - loss: 0.6718 - acc: 0.5867
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6714 - acc: 0.5869 - val_loss: 0.6846 - val_acc: 0.5590

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.6544 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.6677 - acc: 0.6016
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6535 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6460 - acc: 0.6211
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6504 - acc: 0.6125
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6494 - acc: 0.6120
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6514 - acc: 0.6027
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6478 - acc: 0.6113
 576/1283 [============>.................] - ETA: 0s - loss: 0.6497 - acc: 0.6094
 640/1283 [=============>................] - ETA: 0s - loss: 0.6503 - acc: 0.6141
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6508 - acc: 0.6065
 768/1283 [================>.............] - ETA: 0s - loss: 0.6488 - acc: 0.6081
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6457 - acc: 0.6082
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6459 - acc: 0.6049
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6438 - acc: 0.6125
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6454 - acc: 0.6113
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6458 - acc: 0.6085
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6482 - acc: 0.6042
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6457 - acc: 0.6110
1280/1283 [============================>.] - ETA: 0s - loss: 0.6430 - acc: 0.6180
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6428 - acc: 0.6181 - val_loss: 0.6881 - val_acc: 0.5808

Epoch 00003: val_acc improved from 0.56332 to 0.58079, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6164 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.6274 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6250 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6261 - acc: 0.6680
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6178 - acc: 0.6750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6207 - acc: 0.6615
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6210 - acc: 0.6540
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6198 - acc: 0.6504
 576/1283 [============>.................] - ETA: 0s - loss: 0.6125 - acc: 0.6632
 640/1283 [=============>................] - ETA: 0s - loss: 0.6165 - acc: 0.6594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6211 - acc: 0.6534
 768/1283 [================>.............] - ETA: 0s - loss: 0.6264 - acc: 0.6458
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6268 - acc: 0.6418
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6266 - acc: 0.6417
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6218 - acc: 0.6521
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6239 - acc: 0.6494
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6258 - acc: 0.6452
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6288 - acc: 0.6406
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6284 - acc: 0.6414
1280/1283 [============================>.] - ETA: 0s - loss: 0.6277 - acc: 0.6438
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6282 - acc: 0.6430 - val_loss: 0.6899 - val_acc: 0.5633

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5784 - acc: 0.7344
 128/1283 [=>............................] - ETA: 2s - loss: 0.6095 - acc: 0.6797
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6039 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5977 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6111 - acc: 0.6594
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6236 - acc: 0.6458
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6164 - acc: 0.6518
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6158 - acc: 0.6504
 576/1283 [============>.................] - ETA: 0s - loss: 0.6106 - acc: 0.6562
 640/1283 [=============>................] - ETA: 0s - loss: 0.6094 - acc: 0.6531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6131 - acc: 0.6520
 768/1283 [================>.............] - ETA: 0s - loss: 0.6128 - acc: 0.6576
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6110 - acc: 0.6587
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6121 - acc: 0.6562
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6122 - acc: 0.6521
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6121 - acc: 0.6523
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6125 - acc: 0.6507
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6173 - acc: 0.6484
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6152 - acc: 0.6521
1280/1283 [============================>.] - ETA: 0s - loss: 0.6135 - acc: 0.6555
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6136 - acc: 0.6547 - val_loss: 0.6923 - val_acc: 0.5590

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5994 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6067 - acc: 0.6641
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6076 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5902 - acc: 0.6797
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5847 - acc: 0.6844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5937 - acc: 0.6693
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5814 - acc: 0.6942
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5898 - acc: 0.6855
 576/1283 [============>.................] - ETA: 0s - loss: 0.5958 - acc: 0.6806
 640/1283 [=============>................] - ETA: 0s - loss: 0.6026 - acc: 0.6687
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6020 - acc: 0.6761
 768/1283 [================>.............] - ETA: 0s - loss: 0.6011 - acc: 0.6758
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5967 - acc: 0.6827
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5921 - acc: 0.6875
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5900 - acc: 0.6896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5902 - acc: 0.6895
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5913 - acc: 0.6884
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5900 - acc: 0.6892
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5855 - acc: 0.6891
1280/1283 [============================>.] - ETA: 0s - loss: 0.5899 - acc: 0.6852
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5902 - acc: 0.6843 - val_loss: 0.6978 - val_acc: 0.5808

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5510 - acc: 0.7188
 128/1283 [=>............................] - ETA: 1s - loss: 0.5740 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5699 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5757 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5737 - acc: 0.6813
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5644 - acc: 0.7031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5644 - acc: 0.7076
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5627 - acc: 0.7090
 576/1283 [============>.................] - ETA: 0s - loss: 0.5612 - acc: 0.7083
 640/1283 [=============>................] - ETA: 0s - loss: 0.5556 - acc: 0.7172
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5543 - acc: 0.7202
 768/1283 [================>.............] - ETA: 0s - loss: 0.5582 - acc: 0.7161
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5637 - acc: 0.7103
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5623 - acc: 0.7087
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5624 - acc: 0.7083
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5609 - acc: 0.7100
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5605 - acc: 0.7059
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5602 - acc: 0.7031
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5649 - acc: 0.7007
1280/1283 [============================>.] - ETA: 0s - loss: 0.5678 - acc: 0.6969
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5680 - acc: 0.6968 - val_loss: 0.7164 - val_acc: 0.5502

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6581 - acc: 0.5938
 128/1283 [=>............................] - ETA: 1s - loss: 0.6217 - acc: 0.6016
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5942 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5657 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5615 - acc: 0.6906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5518 - acc: 0.7031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5524 - acc: 0.7121
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5513 - acc: 0.7109
 576/1283 [============>.................] - ETA: 0s - loss: 0.5528 - acc: 0.7014
 640/1283 [=============>................] - ETA: 0s - loss: 0.5489 - acc: 0.7109
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5533 - acc: 0.7116
 768/1283 [================>.............] - ETA: 0s - loss: 0.5607 - acc: 0.7096
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5563 - acc: 0.7115
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5519 - acc: 0.7188
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5506 - acc: 0.7167
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5494 - acc: 0.7217
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5512 - acc: 0.7169
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5472 - acc: 0.7222
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5523 - acc: 0.7163
1280/1283 [============================>.] - ETA: 0s - loss: 0.5504 - acc: 0.7148
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5512 - acc: 0.7132 - val_loss: 0.7230 - val_acc: 0.5633

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5102 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.5394 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5474 - acc: 0.6927
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5304 - acc: 0.7266
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5308 - acc: 0.7312
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5255 - acc: 0.7318
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5229 - acc: 0.7478
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5278 - acc: 0.7305
 576/1283 [============>.................] - ETA: 0s - loss: 0.5245 - acc: 0.7309
 640/1283 [=============>................] - ETA: 0s - loss: 0.5250 - acc: 0.7297
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5319 - acc: 0.7244
 768/1283 [================>.............] - ETA: 0s - loss: 0.5270 - acc: 0.7253
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5247 - acc: 0.7308
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5278 - acc: 0.7333
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5298 - acc: 0.7312
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5297 - acc: 0.7314
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5317 - acc: 0.7335
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5304 - acc: 0.7352
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5292 - acc: 0.7360
1280/1283 [============================>.] - ETA: 0s - loss: 0.5333 - acc: 0.7289
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5338 - acc: 0.7280 - val_loss: 0.7130 - val_acc: 0.5764

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4442 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.4704 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4929 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5079 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5063 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5070 - acc: 0.7578
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5125 - acc: 0.7500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5110 - acc: 0.7520
 576/1283 [============>.................] - ETA: 0s - loss: 0.5144 - acc: 0.7517
 640/1283 [=============>................] - ETA: 0s - loss: 0.5139 - acc: 0.7469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5130 - acc: 0.7457
 768/1283 [================>.............] - ETA: 0s - loss: 0.5090 - acc: 0.7513
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5075 - acc: 0.7512
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5097 - acc: 0.7478
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5119 - acc: 0.7479
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5120 - acc: 0.7480
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5146 - acc: 0.7445
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5191 - acc: 0.7396
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5180 - acc: 0.7401
1280/1283 [============================>.] - ETA: 0s - loss: 0.5172 - acc: 0.7391
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5171 - acc: 0.7389 - val_loss: 0.7256 - val_acc: 0.5371

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5030 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5065 - acc: 0.7578
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5029 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5032 - acc: 0.7383
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5105 - acc: 0.7312
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5060 - acc: 0.7526
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5017 - acc: 0.7433
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5017 - acc: 0.7383
 576/1283 [============>.................] - ETA: 0s - loss: 0.4991 - acc: 0.7448
 640/1283 [=============>................] - ETA: 0s - loss: 0.5014 - acc: 0.7422
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5081 - acc: 0.7372
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5013 - acc: 0.7428
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4939 - acc: 0.7500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4988 - acc: 0.7490
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4963 - acc: 0.7528
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4953 - acc: 0.7561
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4916 - acc: 0.7590
1280/1283 [============================>.] - ETA: 0s - loss: 0.4907 - acc: 0.7594
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4903 - acc: 0.7599 - val_loss: 0.7427 - val_acc: 0.5721

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4186 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.4144 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4126 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4378 - acc: 0.8094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4370 - acc: 0.8021
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4460 - acc: 0.7969
 576/1283 [============>.................] - ETA: 0s - loss: 0.4504 - acc: 0.7934
 640/1283 [=============>................] - ETA: 0s - loss: 0.4525 - acc: 0.7922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4563 - acc: 0.7912
 768/1283 [================>.............] - ETA: 0s - loss: 0.4508 - acc: 0.7982
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4531 - acc: 0.7981
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4521 - acc: 0.7969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4475 - acc: 0.7959
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4450 - acc: 0.7987
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4476 - acc: 0.7944
1280/1283 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.7875
1283/1283 [==============================] - 1s 932us/step - loss: 0.4549 - acc: 0.7872 - val_loss: 0.7663 - val_acc: 0.5677

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3684 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.3843 - acc: 0.8516
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4024 - acc: 0.8203
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4074 - acc: 0.8203
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4125 - acc: 0.8192
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4175 - acc: 0.8125
 640/1283 [=============>................] - ETA: 0s - loss: 0.4289 - acc: 0.8078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4356 - acc: 0.8082
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4293 - acc: 0.8137
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4363 - acc: 0.8058
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4344 - acc: 0.8010
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4343 - acc: 0.7998
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4332 - acc: 0.8024
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4332 - acc: 0.8003
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4378 - acc: 0.7985
1280/1283 [============================>.] - ETA: 0s - loss: 0.4340 - acc: 0.8008
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4340 - acc: 0.8005 - val_loss: 0.7814 - val_acc: 0.5677

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
mode=A
accuracy=0.5276967930029155
best_valid_accuracy=0.4970845481049563
