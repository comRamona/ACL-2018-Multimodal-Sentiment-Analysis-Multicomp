/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:14:44.896172: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.7310 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 2s - loss: 0.7684 - acc: 0.4896
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7507 - acc: 0.4969
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7552 - acc: 0.4821
 576/1283 [============>.................] - ETA: 0s - loss: 0.7398 - acc: 0.4913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7385 - acc: 0.5028
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7391 - acc: 0.4988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7324 - acc: 0.5062
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7286 - acc: 0.5037
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7237 - acc: 0.5123
1283/1283 [==============================] - 1s 943us/step - loss: 0.7234 - acc: 0.5113 - val_loss: 0.6898 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6677 - acc: 0.6406
 128/1283 [=>............................] - ETA: 0s - loss: 0.6682 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6679 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6656 - acc: 0.6289
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6708 - acc: 0.6016
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6732 - acc: 0.5840
 640/1283 [=============>................] - ETA: 0s - loss: 0.6740 - acc: 0.5859
 768/1283 [================>.............] - ETA: 0s - loss: 0.6710 - acc: 0.5924
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6691 - acc: 0.5971
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6680 - acc: 0.5969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6662 - acc: 0.6066
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6670 - acc: 0.6003
1283/1283 [==============================] - 1s 811us/step - loss: 0.6653 - acc: 0.6009 - val_loss: 0.7072 - val_acc: 0.5328

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6479 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6653 - acc: 0.5885
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6485 - acc: 0.6055
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6503 - acc: 0.5911
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6383 - acc: 0.6055
 640/1283 [=============>................] - ETA: 0s - loss: 0.6358 - acc: 0.6125
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6395 - acc: 0.6108
 768/1283 [================>.............] - ETA: 0s - loss: 0.6343 - acc: 0.6224
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6272 - acc: 0.6339
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6309 - acc: 0.6289
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6298 - acc: 0.6324
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6286 - acc: 0.6316
1283/1283 [==============================] - 1s 807us/step - loss: 0.6272 - acc: 0.6329 - val_loss: 0.7237 - val_acc: 0.5153

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5762 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6069 - acc: 0.6354
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6029 - acc: 0.6594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5845 - acc: 0.6745
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5844 - acc: 0.6738
 640/1283 [=============>................] - ETA: 0s - loss: 0.5883 - acc: 0.6656
 768/1283 [================>.............] - ETA: 0s - loss: 0.5901 - acc: 0.6615
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5896 - acc: 0.6671
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5910 - acc: 0.6760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5879 - acc: 0.6797
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5884 - acc: 0.6745
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5879 - acc: 0.6776
1283/1283 [==============================] - 1s 828us/step - loss: 0.5880 - acc: 0.6773 - val_loss: 0.7305 - val_acc: 0.5197

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5109 - acc: 0.7500
 128/1283 [=>............................] - ETA: 0s - loss: 0.4893 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4914 - acc: 0.8008
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5089 - acc: 0.7760
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5149 - acc: 0.7656
 576/1283 [============>.................] - ETA: 0s - loss: 0.5195 - acc: 0.7552
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5133 - acc: 0.7472
 768/1283 [================>.............] - ETA: 0s - loss: 0.5129 - acc: 0.7435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5098 - acc: 0.7467
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5104 - acc: 0.7427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5070 - acc: 0.7422
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5059 - acc: 0.7436
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5040 - acc: 0.7426
1283/1283 [==============================] - 1s 850us/step - loss: 0.5032 - acc: 0.7451 - val_loss: 0.7409 - val_acc: 0.5502

Epoch 00005: val_acc improved from 0.54148 to 0.55022, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3728 - acc: 0.8594
 128/1283 [=>............................] - ETA: 0s - loss: 0.3652 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4332 - acc: 0.7865
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4168 - acc: 0.8047
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4223 - acc: 0.8000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4047 - acc: 0.8147
 576/1283 [============>.................] - ETA: 0s - loss: 0.4053 - acc: 0.8125
 640/1283 [=============>................] - ETA: 0s - loss: 0.4018 - acc: 0.8172
 768/1283 [================>.............] - ETA: 0s - loss: 0.4010 - acc: 0.8216
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3989 - acc: 0.8248
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3979 - acc: 0.8242
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3934 - acc: 0.8290
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3925 - acc: 0.8273
1280/1283 [============================>.] - ETA: 0s - loss: 0.3940 - acc: 0.8227
1283/1283 [==============================] - 1s 875us/step - loss: 0.3940 - acc: 0.8231 - val_loss: 1.2560 - val_acc: 0.5328

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4870 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.7188 - acc: 0.6458
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5864 - acc: 0.7188
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5744 - acc: 0.7165
 576/1283 [============>.................] - ETA: 0s - loss: 0.5662 - acc: 0.7205
 640/1283 [=============>................] - ETA: 0s - loss: 0.5485 - acc: 0.7344
 768/1283 [================>.............] - ETA: 0s - loss: 0.5287 - acc: 0.7435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5174 - acc: 0.7467
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5089 - acc: 0.7500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5041 - acc: 0.7529
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4861 - acc: 0.7639
1280/1283 [============================>.] - ETA: 0s - loss: 0.4774 - acc: 0.7703
1283/1283 [==============================] - 1s 832us/step - loss: 0.4783 - acc: 0.7693 - val_loss: 0.7469 - val_acc: 0.5240

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3802 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.3545 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3483 - acc: 0.8789
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3520 - acc: 0.8844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3504 - acc: 0.8828
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3485 - acc: 0.8862
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3433 - acc: 0.8906
 640/1283 [=============>................] - ETA: 0s - loss: 0.3415 - acc: 0.8906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3415 - acc: 0.8821
 768/1283 [================>.............] - ETA: 0s - loss: 0.3471 - acc: 0.8815
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3380 - acc: 0.8884
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3376 - acc: 0.8854
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3343 - acc: 0.8838
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3285 - acc: 0.8819
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3252 - acc: 0.8816
1283/1283 [==============================] - 1s 883us/step - loss: 0.3217 - acc: 0.8831 - val_loss: 0.9240 - val_acc: 0.5677

Epoch 00008: val_acc improved from 0.55022 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2230 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3365 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3069 - acc: 0.8633
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3406 - acc: 0.8490
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3455 - acc: 0.8398
 576/1283 [============>.................] - ETA: 0s - loss: 0.3358 - acc: 0.8438
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3214 - acc: 0.8551
 768/1283 [================>.............] - ETA: 0s - loss: 0.3253 - acc: 0.8542
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3193 - acc: 0.8594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3165 - acc: 0.8623
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3142 - acc: 0.8646
1280/1283 [============================>.] - ETA: 0s - loss: 0.3051 - acc: 0.8711
1283/1283 [==============================] - 1s 830us/step - loss: 0.3062 - acc: 0.8706 - val_loss: 0.8002 - val_acc: 0.6026

Epoch 00009: val_acc improved from 0.56769 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2136 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1991 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2147 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2386 - acc: 0.9129
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2358 - acc: 0.9141
 640/1283 [=============>................] - ETA: 0s - loss: 0.2344 - acc: 0.9156
 768/1283 [================>.............] - ETA: 0s - loss: 0.2254 - acc: 0.9167
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2261 - acc: 0.9171
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2369 - acc: 0.9073
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2249 - acc: 0.9154
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2196 - acc: 0.9211
1283/1283 [==============================] - 1s 827us/step - loss: 0.2142 - acc: 0.9244 - val_loss: 1.0323 - val_acc: 0.5983

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0944 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1031 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1091 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1109 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1141 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.1156 - acc: 0.9792
 640/1283 [=============>................] - ETA: 0s - loss: 0.1192 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1213 - acc: 0.9716
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1215 - acc: 0.9712
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1155 - acc: 0.9729
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1128 - acc: 0.9736
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1155 - acc: 0.9714
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1165 - acc: 0.9688
1283/1283 [==============================] - 1s 847us/step - loss: 0.1177 - acc: 0.9665 - val_loss: 1.3532 - val_acc: 0.5415

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0966 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1217 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1509 - acc: 0.9336
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1393 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1398 - acc: 0.9420
 576/1283 [============>.................] - ETA: 0s - loss: 0.1438 - acc: 0.9392
 640/1283 [=============>................] - ETA: 0s - loss: 0.1398 - acc: 0.9406
 768/1283 [================>.............] - ETA: 0s - loss: 0.1660 - acc: 0.9362
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1592 - acc: 0.9399
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1549 - acc: 0.9417
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1591 - acc: 0.9395
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1482 - acc: 0.9453
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1446 - acc: 0.9482
1283/1283 [==============================] - 1s 832us/step - loss: 0.1453 - acc: 0.9478 - val_loss: 1.2252 - val_acc: 0.5502

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0681 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0621 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0652 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0728 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0733 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0703 - acc: 0.9809
 640/1283 [=============>................] - ETA: 0s - loss: 0.0693 - acc: 0.9812
 768/1283 [================>.............] - ETA: 0s - loss: 0.0640 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0651 - acc: 0.9855
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0620 - acc: 0.9873
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0604 - acc: 0.9878
1280/1283 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9883
1283/1283 [==============================] - 1s 854us/step - loss: 0.0610 - acc: 0.9875 - val_loss: 1.5118 - val_acc: 0.5677

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0553 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.1534 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2389 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2470 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2595 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2386 - acc: 0.9442
 576/1283 [============>.................] - ETA: 0s - loss: 0.2348 - acc: 0.9375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2244 - acc: 0.9332
 768/1283 [================>.............] - ETA: 0s - loss: 0.2148 - acc: 0.9362
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2111 - acc: 0.9387
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2118 - acc: 0.9333
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2039 - acc: 0.9366
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1933 - acc: 0.9416
1280/1283 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.9414
1283/1283 [==============================] - 1s 825us/step - loss: 0.1941 - acc: 0.9415 - val_loss: 1.3815 - val_acc: 0.5852

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2282 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1823 - acc: 0.9271
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1699 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1572 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1433 - acc: 0.9487
 576/1283 [============>.................] - ETA: 0s - loss: 0.1253 - acc: 0.9549
 640/1283 [=============>................] - ETA: 0s - loss: 0.1182 - acc: 0.9578
 768/1283 [================>.............] - ETA: 0s - loss: 0.1149 - acc: 0.9583
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1126 - acc: 0.9609
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1079 - acc: 0.9619
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1072 - acc: 0.9618
1280/1283 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9625
1283/1283 [==============================] - 1s 838us/step - loss: 0.1054 - acc: 0.9626 - val_loss: 1.6007 - val_acc: 0.5633

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0171 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0446 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0581 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0595 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0586 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0543 - acc: 0.9826
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0607 - acc: 0.9815
 768/1283 [================>.............] - ETA: 0s - loss: 0.0572 - acc: 0.9831
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0568 - acc: 0.9844
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0525 - acc: 0.9865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0531 - acc: 0.9862
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0517 - acc: 0.9868
1283/1283 [==============================] - 1s 823us/step - loss: 0.0504 - acc: 0.9875 - val_loss: 2.1789 - val_acc: 0.5197

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1507 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1433 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1211 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1017 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0810 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0783 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.0923 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.0862 - acc: 0.9734
 768/1283 [================>.............] - ETA: 0s - loss: 0.0832 - acc: 0.9740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0849 - acc: 0.9732
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0801 - acc: 0.9756
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0775 - acc: 0.9748
1280/1283 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9766
1283/1283 [==============================] - 1s 753us/step - loss: 0.0745 - acc: 0.9766 - val_loss: 1.8374 - val_acc: 0.5808

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0489 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0548 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0508 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0461 - acc: 0.9888
 576/1283 [============>.................] - ETA: 0s - loss: 0.0440 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0434 - acc: 0.9886
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0427 - acc: 0.9904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0412 - acc: 0.9896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0390 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0372 - acc: 0.9910
1283/1283 [==============================] - 1s 681us/step - loss: 0.0383 - acc: 0.9906 - val_loss: 1.7715 - val_acc: 0.5721

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0065 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0130 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0266 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0277 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0242 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0232 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0224 - acc: 0.9972
 768/1283 [================>.............] - ETA: 0s - loss: 0.0217 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0229 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0225 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0208 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0209 - acc: 0.9972
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0197 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9977
1283/1283 [==============================] - 1s 799us/step - loss: 0.0190 - acc: 0.9977 - val_loss: 1.9710 - val_acc: 0.5590

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=3
max_len=30
epochs=100
mode=A
accuracy=0.5043731778425656
best_valid_accuracy=0.5422740524781341
