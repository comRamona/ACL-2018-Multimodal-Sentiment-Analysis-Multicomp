/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 09:39:24.431736: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.6940 - acc: 0.4688
 128/1283 [=>............................] - ETA: 3s - loss: 0.6903 - acc: 0.5234
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6907 - acc: 0.5039
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6848 - acc: 0.5208
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6796 - acc: 0.5352
 576/1283 [============>.................] - ETA: 0s - loss: 0.6776 - acc: 0.5503
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6762 - acc: 0.5483
 768/1283 [================>.............] - ETA: 0s - loss: 0.6765 - acc: 0.5482
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6771 - acc: 0.5458
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6765 - acc: 0.5458
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6780 - acc: 0.5432
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6782 - acc: 0.5485
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6789 - acc: 0.5479 - val_loss: 0.7009 - val_acc: 0.5066

Epoch 00001: val_acc improved from -inf to 0.50655, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6888 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.6766 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6756 - acc: 0.5677
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6727 - acc: 0.5820
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6723 - acc: 0.5859
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6688 - acc: 0.5898
 640/1283 [=============>................] - ETA: 0s - loss: 0.6623 - acc: 0.6109
 768/1283 [================>.............] - ETA: 0s - loss: 0.6641 - acc: 0.6081
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6629 - acc: 0.6106
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6634 - acc: 0.6150
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6615 - acc: 0.6156
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6603 - acc: 0.6123
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6613 - acc: 0.6131
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6603 - acc: 0.6120
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6587 - acc: 0.6118
1280/1283 [============================>.] - ETA: 0s - loss: 0.6583 - acc: 0.6109
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6583 - acc: 0.6111 - val_loss: 0.7174 - val_acc: 0.5022

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6059 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.6313 - acc: 0.6016
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6251 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6281 - acc: 0.6094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6405 - acc: 0.5885
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6366 - acc: 0.5938
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6417 - acc: 0.5879
 576/1283 [============>.................] - ETA: 0s - loss: 0.6417 - acc: 0.5903
 640/1283 [=============>................] - ETA: 0s - loss: 0.6445 - acc: 0.5828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6419 - acc: 0.5923
 768/1283 [================>.............] - ETA: 0s - loss: 0.6390 - acc: 0.5964
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6412 - acc: 0.5925
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6411 - acc: 0.5926
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6431 - acc: 0.5885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6455 - acc: 0.5850
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6436 - acc: 0.5901
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6420 - acc: 0.5929
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6419 - acc: 0.5970
1280/1283 [============================>.] - ETA: 0s - loss: 0.6431 - acc: 0.5977
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6431 - acc: 0.5978 - val_loss: 0.7395 - val_acc: 0.4803

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6297 - acc: 0.5938
 128/1283 [=>............................] - ETA: 1s - loss: 0.6297 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6163 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6245 - acc: 0.6289
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6205 - acc: 0.6312
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6204 - acc: 0.6328
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6348 - acc: 0.6116
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6349 - acc: 0.6074
 576/1283 [============>.................] - ETA: 0s - loss: 0.6331 - acc: 0.6163
 640/1283 [=============>................] - ETA: 0s - loss: 0.6389 - acc: 0.6125
 768/1283 [================>.............] - ETA: 0s - loss: 0.6334 - acc: 0.6237
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6320 - acc: 0.6286
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6312 - acc: 0.6295
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6281 - acc: 0.6396
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6290 - acc: 0.6357
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6332 - acc: 0.6276
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6324 - acc: 0.6283
1280/1283 [============================>.] - ETA: 0s - loss: 0.6350 - acc: 0.6273
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6347 - acc: 0.6282 - val_loss: 0.7332 - val_acc: 0.4803

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6011 - acc: 0.6719
 128/1283 [=>............................] - ETA: 1s - loss: 0.6185 - acc: 0.6172
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6206 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6336 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6289 - acc: 0.6344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6297 - acc: 0.6406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6329 - acc: 0.6317
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6305 - acc: 0.6309
 576/1283 [============>.................] - ETA: 0s - loss: 0.6288 - acc: 0.6337
 640/1283 [=============>................] - ETA: 0s - loss: 0.6264 - acc: 0.6375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6293 - acc: 0.6349
 768/1283 [================>.............] - ETA: 0s - loss: 0.6267 - acc: 0.6354
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6260 - acc: 0.6362
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6252 - acc: 0.6365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6246 - acc: 0.6396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6222 - acc: 0.6434
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6244 - acc: 0.6380
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6276 - acc: 0.6365
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6303 - acc: 0.6321 - val_loss: 0.7604 - val_acc: 0.4454

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6616 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.6381 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6273 - acc: 0.6615
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6299 - acc: 0.6602
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6253 - acc: 0.6594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6155 - acc: 0.6652
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6178 - acc: 0.6621
 640/1283 [=============>................] - ETA: 0s - loss: 0.6187 - acc: 0.6719
 768/1283 [================>.............] - ETA: 0s - loss: 0.6224 - acc: 0.6576
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6200 - acc: 0.6551
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6271 - acc: 0.6436
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6224 - acc: 0.6519
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6257 - acc: 0.6488
1280/1283 [============================>.] - ETA: 0s - loss: 0.6249 - acc: 0.6469
1283/1283 [==============================] - 1s 874us/step - loss: 0.6249 - acc: 0.6469 - val_loss: 0.7420 - val_acc: 0.4934

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6878 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6231 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6182 - acc: 0.6312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6339 - acc: 0.6094
 576/1283 [============>.................] - ETA: 0s - loss: 0.6268 - acc: 0.6319
 640/1283 [=============>................] - ETA: 0s - loss: 0.6226 - acc: 0.6359
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6220 - acc: 0.6335
 768/1283 [================>.............] - ETA: 0s - loss: 0.6234 - acc: 0.6393
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6215 - acc: 0.6429
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6188 - acc: 0.6458
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6212 - acc: 0.6489
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6210 - acc: 0.6476
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6187 - acc: 0.6497
1283/1283 [==============================] - 1s 874us/step - loss: 0.6213 - acc: 0.6415 - val_loss: 0.7394 - val_acc: 0.4803

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6445 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6138 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6087 - acc: 0.6625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6070 - acc: 0.6607
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6106 - acc: 0.6504
 640/1283 [=============>................] - ETA: 0s - loss: 0.6090 - acc: 0.6516
 768/1283 [================>.............] - ETA: 0s - loss: 0.6207 - acc: 0.6276
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6178 - acc: 0.6334
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6147 - acc: 0.6395
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6092 - acc: 0.6514
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6092 - acc: 0.6476
1280/1283 [============================>.] - ETA: 0s - loss: 0.6104 - acc: 0.6445
1283/1283 [==============================] - 1s 789us/step - loss: 0.6106 - acc: 0.6446 - val_loss: 0.7540 - val_acc: 0.4803

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5127 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5665 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5755 - acc: 0.7000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5855 - acc: 0.6875
 576/1283 [============>.................] - ETA: 0s - loss: 0.6001 - acc: 0.6597
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6057 - acc: 0.6506
 768/1283 [================>.............] - ETA: 0s - loss: 0.6003 - acc: 0.6576
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6034 - acc: 0.6526
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6071 - acc: 0.6542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5972 - acc: 0.6654
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5985 - acc: 0.6628
1283/1283 [==============================] - 1s 727us/step - loss: 0.6013 - acc: 0.6625 - val_loss: 0.7890 - val_acc: 0.5066

Epoch 00009: val_acc improved from 0.50655 to 0.50655, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5768 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6194 - acc: 0.6042
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6000 - acc: 0.6500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5905 - acc: 0.6674
 576/1283 [============>.................] - ETA: 0s - loss: 0.5922 - acc: 0.6580
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6000 - acc: 0.6534
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6017 - acc: 0.6442
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5980 - acc: 0.6542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6059 - acc: 0.6507
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6061 - acc: 0.6546
1283/1283 [==============================] - 1s 688us/step - loss: 0.6067 - acc: 0.6547 - val_loss: 0.7601 - val_acc: 0.4367

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6489 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6415 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6176 - acc: 0.6562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6350 - acc: 0.6406
 576/1283 [============>.................] - ETA: 0s - loss: 0.6265 - acc: 0.6528
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6130 - acc: 0.6648
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6048 - acc: 0.6803
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6068 - acc: 0.6802
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6033 - acc: 0.6756
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6029 - acc: 0.6669
1283/1283 [==============================] - 1s 510us/step - loss: 0.6031 - acc: 0.6656 - val_loss: 0.7613 - val_acc: 0.4934

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5729 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5765 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5675 - acc: 0.6979
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5850 - acc: 0.6836
 640/1283 [=============>................] - ETA: 0s - loss: 0.5866 - acc: 0.6781
 768/1283 [================>.............] - ETA: 0s - loss: 0.5935 - acc: 0.6680
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6011 - acc: 0.6574
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5934 - acc: 0.6590
1280/1283 [============================>.] - ETA: 0s - loss: 0.5951 - acc: 0.6609
1283/1283 [==============================] - 1s 421us/step - loss: 0.5947 - acc: 0.6610 - val_loss: 0.7772 - val_acc: 0.4716

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5659 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6098 - acc: 0.6758
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6192 - acc: 0.6540
 640/1283 [=============>................] - ETA: 0s - loss: 0.6133 - acc: 0.6547
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6118 - acc: 0.6611
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6086 - acc: 0.6689
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6033 - acc: 0.6711
1283/1283 [==============================] - 0s 379us/step - loss: 0.5978 - acc: 0.6742 - val_loss: 0.7860 - val_acc: 0.4454

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6848 - acc: 0.5469
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5934 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5835 - acc: 0.6830
 640/1283 [=============>................] - ETA: 0s - loss: 0.5847 - acc: 0.6781
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5873 - acc: 0.6779
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5876 - acc: 0.6719
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5866 - acc: 0.6694
1283/1283 [==============================] - 0s 380us/step - loss: 0.5871 - acc: 0.6656 - val_loss: 0.7762 - val_acc: 0.5022

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5735 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5838 - acc: 0.6992
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5625 - acc: 0.7232
 640/1283 [=============>................] - ETA: 0s - loss: 0.5755 - acc: 0.6969
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5694 - acc: 0.6863
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5751 - acc: 0.6758
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5853 - acc: 0.6702
1283/1283 [==============================] - 0s 379us/step - loss: 0.5834 - acc: 0.6719 - val_loss: 0.7743 - val_acc: 0.4585

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5820 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5938 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5736 - acc: 0.7009
 640/1283 [=============>................] - ETA: 0s - loss: 0.5634 - acc: 0.7094
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5754 - acc: 0.6995
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5745 - acc: 0.7021
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5699 - acc: 0.7039
1283/1283 [==============================] - 0s 376us/step - loss: 0.5717 - acc: 0.7054 - val_loss: 0.7626 - val_acc: 0.4978

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5119 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5321 - acc: 0.7227
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5610 - acc: 0.7054
 640/1283 [=============>................] - ETA: 0s - loss: 0.5695 - acc: 0.6937
 768/1283 [================>.............] - ETA: 0s - loss: 0.5782 - acc: 0.6836
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5760 - acc: 0.6823
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5772 - acc: 0.6832
1283/1283 [==============================] - 1s 392us/step - loss: 0.5735 - acc: 0.6898 - val_loss: 0.7765 - val_acc: 0.4847

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5687 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5437 - acc: 0.7109
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5591 - acc: 0.7098
 640/1283 [=============>................] - ETA: 0s - loss: 0.5560 - acc: 0.7109
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5636 - acc: 0.7007
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5591 - acc: 0.7061
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5628 - acc: 0.7031
1283/1283 [==============================] - 0s 378us/step - loss: 0.5597 - acc: 0.7062 - val_loss: 0.7977 - val_acc: 0.4760

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5911 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5515 - acc: 0.7148
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5543 - acc: 0.7031
 640/1283 [=============>................] - ETA: 0s - loss: 0.5610 - acc: 0.7016
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5512 - acc: 0.7115
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5606 - acc: 0.6973
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5594 - acc: 0.7007
1283/1283 [==============================] - 0s 378us/step - loss: 0.5588 - acc: 0.7038 - val_loss: 0.8145 - val_acc: 0.4934

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
mode=V
accuracy=0.5276967930029155
best_valid_accuracy=0.5014577259475219
