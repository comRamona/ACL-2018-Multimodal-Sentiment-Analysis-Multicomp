/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:08:17.710090: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 11s - loss: 0.7206 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 3s - loss: 0.8354 - acc: 0.5469 
 320/1283 [======>.......................] - ETA: 2s - loss: 0.9314 - acc: 0.5125
 448/1283 [=========>....................] - ETA: 1s - loss: 0.8781 - acc: 0.5312
 576/1283 [============>.................] - ETA: 1s - loss: 0.8583 - acc: 0.5208
 704/1283 [===============>..............] - ETA: 0s - loss: 0.8269 - acc: 0.5369
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8127 - acc: 0.5385
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7980 - acc: 0.5406
1088/1283 [========================>.....] - ETA: 0s - loss: 0.8000 - acc: 0.5285
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7895 - acc: 0.5304
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7827 - acc: 0.5323 - val_loss: 0.7074 - val_acc: 0.5677

Epoch 00001: val_acc improved from -inf to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5889 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6167 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6141 - acc: 0.6484
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6219 - acc: 0.6281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6141 - acc: 0.6562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6183 - acc: 0.6523
 640/1283 [=============>................] - ETA: 0s - loss: 0.6188 - acc: 0.6609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6206 - acc: 0.6548
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6174 - acc: 0.6575
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6160 - acc: 0.6562
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6102 - acc: 0.6689
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6046 - acc: 0.6774
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5998 - acc: 0.6768
1280/1283 [============================>.] - ETA: 0s - loss: 0.6005 - acc: 0.6773
1283/1283 [==============================] - 1s 753us/step - loss: 0.6001 - acc: 0.6781 - val_loss: 0.7353 - val_acc: 0.5328

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5782 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5708 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5551 - acc: 0.7250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5495 - acc: 0.7188
 576/1283 [============>.................] - ETA: 0s - loss: 0.5532 - acc: 0.7170
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5404 - acc: 0.7315
 768/1283 [================>.............] - ETA: 0s - loss: 0.5380 - acc: 0.7344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5409 - acc: 0.7320
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5379 - acc: 0.7365
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5342 - acc: 0.7371
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5341 - acc: 0.7352
1280/1283 [============================>.] - ETA: 0s - loss: 0.5342 - acc: 0.7344
1283/1283 [==============================] - 1s 728us/step - loss: 0.5344 - acc: 0.7342 - val_loss: 0.7591 - val_acc: 0.5284

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5807 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5269 - acc: 0.7240
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5151 - acc: 0.7375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5000 - acc: 0.7522
 576/1283 [============>.................] - ETA: 0s - loss: 0.4891 - acc: 0.7656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4967 - acc: 0.7656
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4979 - acc: 0.7596
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5009 - acc: 0.7542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5022 - acc: 0.7546
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4971 - acc: 0.7607
1283/1283 [==============================] - 1s 685us/step - loss: 0.5020 - acc: 0.7560 - val_loss: 0.8221 - val_acc: 0.4934

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4917 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4833 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4677 - acc: 0.7617
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4677 - acc: 0.7552
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4500 - acc: 0.7832
 640/1283 [=============>................] - ETA: 0s - loss: 0.4450 - acc: 0.7859
 768/1283 [================>.............] - ETA: 0s - loss: 0.4366 - acc: 0.7956
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4321 - acc: 0.8002
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4314 - acc: 0.8047
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4318 - acc: 0.8059
1283/1283 [==============================] - 1s 634us/step - loss: 0.4300 - acc: 0.8083 - val_loss: 0.7775 - val_acc: 0.5677

Epoch 00005: val_acc improved from 0.56769 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3510 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3054 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3693 - acc: 0.8625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3671 - acc: 0.8683
 640/1283 [=============>................] - ETA: 0s - loss: 0.3759 - acc: 0.8578
 768/1283 [================>.............] - ETA: 0s - loss: 0.3716 - acc: 0.8568
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3649 - acc: 0.8627
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3679 - acc: 0.8613
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3665 - acc: 0.8621
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3653 - acc: 0.8627
1283/1283 [==============================] - 1s 583us/step - loss: 0.3706 - acc: 0.8566 - val_loss: 0.7875 - val_acc: 0.5721

Epoch 00006: val_acc improved from 0.56769 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3100 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3260 - acc: 0.8594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3362 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3394 - acc: 0.8633
 640/1283 [=============>................] - ETA: 0s - loss: 0.3406 - acc: 0.8625
 768/1283 [================>.............] - ETA: 0s - loss: 0.3352 - acc: 0.8737
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3365 - acc: 0.8705
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3413 - acc: 0.8633
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3415 - acc: 0.8628
1280/1283 [============================>.] - ETA: 0s - loss: 0.3379 - acc: 0.8617
1283/1283 [==============================] - 1s 489us/step - loss: 0.3387 - acc: 0.8613 - val_loss: 0.8031 - val_acc: 0.5633

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2260 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2561 - acc: 0.9271
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2709 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2993 - acc: 0.8817
 576/1283 [============>.................] - ETA: 0s - loss: 0.3136 - acc: 0.8733
 768/1283 [================>.............] - ETA: 0s - loss: 0.3205 - acc: 0.8646
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3175 - acc: 0.8672
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3145 - acc: 0.8721
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3132 - acc: 0.8733
1280/1283 [============================>.] - ETA: 0s - loss: 0.3138 - acc: 0.8719
1283/1283 [==============================] - 1s 582us/step - loss: 0.3137 - acc: 0.8722 - val_loss: 0.8215 - val_acc: 0.5852

Epoch 00008: val_acc improved from 0.57205 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2270 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2765 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2683 - acc: 0.9062
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2828 - acc: 0.8906
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2874 - acc: 0.8828
 640/1283 [=============>................] - ETA: 0s - loss: 0.2803 - acc: 0.8922
 768/1283 [================>.............] - ETA: 0s - loss: 0.2721 - acc: 0.8971
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2671 - acc: 0.8979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2675 - acc: 0.8971
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2641 - acc: 0.9005
1280/1283 [============================>.] - ETA: 0s - loss: 0.2627 - acc: 0.9016
1283/1283 [==============================] - 1s 619us/step - loss: 0.2623 - acc: 0.9018 - val_loss: 0.8695 - val_acc: 0.5546

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2011 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1972 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1938 - acc: 0.9563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1875 - acc: 0.9554
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1860 - acc: 0.9551
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1947 - acc: 0.9474
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1928 - acc: 0.9495
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1944 - acc: 0.9487
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1905 - acc: 0.9492
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1923 - acc: 0.9488
1280/1283 [============================>.] - ETA: 0s - loss: 0.1909 - acc: 0.9484
1283/1283 [==============================] - 1s 594us/step - loss: 0.1915 - acc: 0.9478 - val_loss: 1.0053 - val_acc: 0.5459

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1043 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1570 - acc: 0.9570
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1669 - acc: 0.9464
 576/1283 [============>.................] - ETA: 0s - loss: 0.1756 - acc: 0.9427
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1777 - acc: 0.9460
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1724 - acc: 0.9483
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1777 - acc: 0.9490
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1760 - acc: 0.9485
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1747 - acc: 0.9497
1280/1283 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9508
1283/1283 [==============================] - 1s 572us/step - loss: 0.1729 - acc: 0.9509 - val_loss: 1.0692 - val_acc: 0.5633

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1236 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1330 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1360 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1252 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.1214 - acc: 0.9809
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1257 - acc: 0.9830
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1238 - acc: 0.9820
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1268 - acc: 0.9792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1335 - acc: 0.9743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1368 - acc: 0.9720
1283/1283 [==============================] - 1s 587us/step - loss: 0.1352 - acc: 0.9735 - val_loss: 1.0713 - val_acc: 0.5677

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0870 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1157 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1028 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1027 - acc: 0.9883
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1039 - acc: 0.9872
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1011 - acc: 0.9880
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1006 - acc: 0.9873
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0971 - acc: 0.9885
1283/1283 [==============================] - 1s 462us/step - loss: 0.0973 - acc: 0.9867 - val_loss: 1.1398 - val_acc: 0.5546

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0798 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1103 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1133 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1108 - acc: 0.9766
 640/1283 [=============>................] - ETA: 0s - loss: 0.1124 - acc: 0.9703
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1148 - acc: 0.9675
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1162 - acc: 0.9667
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1155 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1241 - acc: 0.9638
1283/1283 [==============================] - 1s 536us/step - loss: 0.1226 - acc: 0.9649 - val_loss: 1.2327 - val_acc: 0.5459

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0902 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0795 - acc: 0.9766
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0889 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0837 - acc: 0.9766
 640/1283 [=============>................] - ETA: 0s - loss: 0.0851 - acc: 0.9781
 768/1283 [================>.............] - ETA: 0s - loss: 0.0844 - acc: 0.9805
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0842 - acc: 0.9799
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0842 - acc: 0.9802
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0826 - acc: 0.9807
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0796 - acc: 0.9819
1283/1283 [==============================] - 1s 584us/step - loss: 0.0789 - acc: 0.9829 - val_loss: 1.2891 - val_acc: 0.5677

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0768 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0607 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0620 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0551 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0582 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0592 - acc: 0.9943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0574 - acc: 0.9952
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0579 - acc: 0.9941
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0568 - acc: 0.9939
1280/1283 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9938
1283/1283 [==============================] - 1s 470us/step - loss: 0.0556 - acc: 0.9938 - val_loss: 1.3062 - val_acc: 0.5415

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0576 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0436 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0494 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0471 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0491 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0489 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0484 - acc: 0.9961
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0484 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0476 - acc: 0.9961
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0464 - acc: 0.9965
1280/1283 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9969
1283/1283 [==============================] - 1s 651us/step - loss: 0.0448 - acc: 0.9969 - val_loss: 1.5169 - val_acc: 0.5371

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0218 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0285 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0326 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0321 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0304 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0327 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0327 - acc: 0.9935
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0320 - acc: 0.9944
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0318 - acc: 0.9951
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0315 - acc: 0.9948
1280/1283 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9953
1283/1283 [==============================] - 1s 626us/step - loss: 0.0318 - acc: 0.9953 - val_loss: 1.6191 - val_acc: 0.5808

Epoch 00018: val_acc did not improve
Epoch 00018: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
epochs=100
mode=A
accuracy=0.48250728862973763
best_valid_accuracy=0.5189504373177842
