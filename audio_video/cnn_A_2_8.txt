/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:08:09.575383: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 9s - loss: 0.9096 - acc: 0.4844
 128/1283 [=>............................] - ETA: 4s - loss: 0.9103 - acc: 0.4688
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7970 - acc: 0.5352
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7685 - acc: 0.5443
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7546 - acc: 0.5513
 576/1283 [============>.................] - ETA: 1s - loss: 0.7358 - acc: 0.5660
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7342 - acc: 0.5597
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7317 - acc: 0.5481
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7249 - acc: 0.5573
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7216 - acc: 0.5579
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7221 - acc: 0.5521
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7184 - acc: 0.5576
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7187 - acc: 0.5495 - val_loss: 0.6899 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6374 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6487 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6543 - acc: 0.6133
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6685 - acc: 0.5833
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6678 - acc: 0.5840
 640/1283 [=============>................] - ETA: 0s - loss: 0.6634 - acc: 0.5891
 768/1283 [================>.............] - ETA: 0s - loss: 0.6632 - acc: 0.5885
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6624 - acc: 0.5938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6565 - acc: 0.6035
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6550 - acc: 0.6068
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6542 - acc: 0.6077
1280/1283 [============================>.] - ETA: 0s - loss: 0.6521 - acc: 0.6078
1283/1283 [==============================] - 1s 801us/step - loss: 0.6519 - acc: 0.6080 - val_loss: 0.6998 - val_acc: 0.5197

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6146 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6309 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6138 - acc: 0.6438
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6098 - acc: 0.6484
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6037 - acc: 0.6607
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5945 - acc: 0.6719
 576/1283 [============>.................] - ETA: 0s - loss: 0.5925 - acc: 0.6753
 640/1283 [=============>................] - ETA: 0s - loss: 0.5955 - acc: 0.6687
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5997 - acc: 0.6648
 768/1283 [================>.............] - ETA: 0s - loss: 0.5964 - acc: 0.6745
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5915 - acc: 0.6851
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5900 - acc: 0.6886
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5946 - acc: 0.6844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5938 - acc: 0.6857
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5963 - acc: 0.6814
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5941 - acc: 0.6834
1280/1283 [============================>.] - ETA: 0s - loss: 0.5938 - acc: 0.6844
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5938 - acc: 0.6843 - val_loss: 0.6798 - val_acc: 0.6201

Epoch 00003: val_acc improved from 0.55022 to 0.62009, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5431 - acc: 0.7344
 128/1283 [=>............................] - ETA: 1s - loss: 0.5283 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5349 - acc: 0.7135
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5066 - acc: 0.7422
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5410 - acc: 0.7125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5258 - acc: 0.7292
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5311 - acc: 0.7344
 576/1283 [============>.................] - ETA: 0s - loss: 0.5340 - acc: 0.7274
 640/1283 [=============>................] - ETA: 0s - loss: 0.5302 - acc: 0.7250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5298 - acc: 0.7259
 768/1283 [================>.............] - ETA: 0s - loss: 0.5377 - acc: 0.7174
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5340 - acc: 0.7260
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5331 - acc: 0.7299
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5335 - acc: 0.7323
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5331 - acc: 0.7314
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5310 - acc: 0.7361
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5332 - acc: 0.7360
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5344 - acc: 0.7311 - val_loss: 0.7426 - val_acc: 0.5371

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4186 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4556 - acc: 0.7578
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4670 - acc: 0.7552
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4740 - acc: 0.7625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4847 - acc: 0.7578
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4824 - acc: 0.7612
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4919 - acc: 0.7461
 576/1283 [============>.................] - ETA: 0s - loss: 0.5009 - acc: 0.7431
 640/1283 [=============>................] - ETA: 0s - loss: 0.4966 - acc: 0.7453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4927 - acc: 0.7486
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4869 - acc: 0.7536
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4835 - acc: 0.7552
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4813 - acc: 0.7564
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4748 - acc: 0.7632
1283/1283 [==============================] - 1s 874us/step - loss: 0.4747 - acc: 0.7662 - val_loss: 0.7388 - val_acc: 0.5371

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3364 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.3466 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3673 - acc: 0.8958
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3748 - acc: 0.8875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3754 - acc: 0.8750
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3725 - acc: 0.8691
 640/1283 [=============>................] - ETA: 0s - loss: 0.3705 - acc: 0.8609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3708 - acc: 0.8622
 768/1283 [================>.............] - ETA: 0s - loss: 0.3680 - acc: 0.8633
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3670 - acc: 0.8606
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3644 - acc: 0.8627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3631 - acc: 0.8625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3671 - acc: 0.8574
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3674 - acc: 0.8575
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3653 - acc: 0.8569
1280/1283 [============================>.] - ETA: 0s - loss: 0.3692 - acc: 0.8500
1283/1283 [==============================] - 1s 973us/step - loss: 0.3690 - acc: 0.8504 - val_loss: 0.9969 - val_acc: 0.5502

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3131 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.3919 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4185 - acc: 0.7708
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3991 - acc: 0.7930
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3753 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3819 - acc: 0.8021
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3666 - acc: 0.8170
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3631 - acc: 0.8184
 576/1283 [============>.................] - ETA: 0s - loss: 0.3558 - acc: 0.8264
 640/1283 [=============>................] - ETA: 0s - loss: 0.3492 - acc: 0.8328
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3493 - acc: 0.8295
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3525 - acc: 0.8341
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3470 - acc: 0.8382
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3436 - acc: 0.8417
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3408 - acc: 0.8447
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3394 - acc: 0.8474
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3364 - acc: 0.8516
1280/1283 [============================>.] - ETA: 0s - loss: 0.3302 - acc: 0.8562
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3309 - acc: 0.8558 - val_loss: 0.8398 - val_acc: 0.5808

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1881 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1970 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2186 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2245 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2379 - acc: 0.9250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2408 - acc: 0.9193
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2375 - acc: 0.9196
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2302 - acc: 0.9277
 576/1283 [============>.................] - ETA: 1s - loss: 0.2313 - acc: 0.9253
 640/1283 [=============>................] - ETA: 0s - loss: 0.2357 - acc: 0.9250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2366 - acc: 0.9276
 768/1283 [================>.............] - ETA: 0s - loss: 0.2408 - acc: 0.9258
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2438 - acc: 0.9231
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2443 - acc: 0.9219
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2446 - acc: 0.9198
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2452 - acc: 0.9189
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2420 - acc: 0.9191
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2380 - acc: 0.9219
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2386 - acc: 0.9219
1280/1283 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.9234
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2363 - acc: 0.9236 - val_loss: 0.9391 - val_acc: 0.5546

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1762 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1811 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1931 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1783 - acc: 0.9414
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1778 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1797 - acc: 0.9330
 576/1283 [============>.................] - ETA: 0s - loss: 0.1749 - acc: 0.9392
 640/1283 [=============>................] - ETA: 0s - loss: 0.1684 - acc: 0.9437
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1713 - acc: 0.9403
 768/1283 [================>.............] - ETA: 0s - loss: 0.1732 - acc: 0.9375
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1659 - acc: 0.9423
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1668 - acc: 0.9420
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1637 - acc: 0.9437
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1648 - acc: 0.9424
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1630 - acc: 0.9453
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1617 - acc: 0.9457
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1596 - acc: 0.9462 - val_loss: 0.9982 - val_acc: 0.5677

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1112 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1408 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1464 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1511 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1782 - acc: 0.9353
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1782 - acc: 0.9336
 640/1283 [=============>................] - ETA: 0s - loss: 0.1733 - acc: 0.9375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1705 - acc: 0.9389
 768/1283 [================>.............] - ETA: 0s - loss: 0.1643 - acc: 0.9414
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1729 - acc: 0.9353
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1743 - acc: 0.9354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1699 - acc: 0.9365
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1664 - acc: 0.9384
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1651 - acc: 0.9391
1280/1283 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9422
1283/1283 [==============================] - 1s 994us/step - loss: 0.1609 - acc: 0.9423 - val_loss: 1.1668 - val_acc: 0.5459

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0903 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0824 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0804 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0828 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0818 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0878 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0911 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0940 - acc: 0.9805
 576/1283 [============>.................] - ETA: 0s - loss: 0.0922 - acc: 0.9826
 640/1283 [=============>................] - ETA: 0s - loss: 0.0971 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0994 - acc: 0.9744
 768/1283 [================>.............] - ETA: 0s - loss: 0.0983 - acc: 0.9766
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0987 - acc: 0.9772
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0961 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0951 - acc: 0.9781
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0942 - acc: 0.9785
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0985 - acc: 0.9761
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1000 - acc: 0.9757
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0993 - acc: 0.9762
1280/1283 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9773
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0979 - acc: 0.9774 - val_loss: 1.2431 - val_acc: 0.5677

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0377 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0602 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0690 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0690 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0677 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0678 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0644 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0700 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0684 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0687 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0656 - acc: 0.9830
 768/1283 [================>.............] - ETA: 0s - loss: 0.0671 - acc: 0.9831
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0666 - acc: 0.9832
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0659 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0659 - acc: 0.9834
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0659 - acc: 0.9835
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0646 - acc: 0.9835
1280/1283 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9836
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0640 - acc: 0.9836 - val_loss: 1.3327 - val_acc: 0.5590

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0453 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0340 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0360 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0395 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0441 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0422 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0422 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0411 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0401 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0392 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0391 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0385 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0380 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0380 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0368 - acc: 0.9972
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0369 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9977
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0360 - acc: 0.9977 - val_loss: 1.5256 - val_acc: 0.5590

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=30
epochs=100
mode=A
accuracy=0.49271137026239065
best_valid_accuracy=0.49854227405247814
