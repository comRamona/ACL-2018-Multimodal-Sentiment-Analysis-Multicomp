/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 08:38:48.176275: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 12s - loss: 0.6971 - acc: 0.4844
 128/1283 [=>............................] - ETA: 6s - loss: 0.7053 - acc: 0.5000 
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7051 - acc: 0.5000
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7055 - acc: 0.4844
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7021 - acc: 0.5000
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7045 - acc: 0.4821
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7028 - acc: 0.4785
 576/1283 [============>.................] - ETA: 1s - loss: 0.7010 - acc: 0.4844
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6986 - acc: 0.4943
 768/1283 [================>.............] - ETA: 0s - loss: 0.6996 - acc: 0.4870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6991 - acc: 0.4892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6994 - acc: 0.4979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6975 - acc: 0.5088
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6978 - acc: 0.5055
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6967 - acc: 0.5078
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6960 - acc: 0.5107
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6961 - acc: 0.5066 - val_loss: 0.6843 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6700 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6609 - acc: 0.5990
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6602 - acc: 0.6016
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6632 - acc: 0.6146
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6663 - acc: 0.5918
 640/1283 [=============>................] - ETA: 0s - loss: 0.6659 - acc: 0.5984
 768/1283 [================>.............] - ETA: 0s - loss: 0.6633 - acc: 0.5977
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6598 - acc: 0.6105
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6593 - acc: 0.6162
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6586 - acc: 0.6158
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6578 - acc: 0.6151
1280/1283 [============================>.] - ETA: 0s - loss: 0.6571 - acc: 0.6172
1283/1283 [==============================] - 1s 744us/step - loss: 0.6574 - acc: 0.6165 - val_loss: 0.6813 - val_acc: 0.5546

Epoch 00002: val_acc improved from 0.52838 to 0.55459, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6269 - acc: 0.6875
 128/1283 [=>............................] - ETA: 0s - loss: 0.6322 - acc: 0.6953
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6234 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6294 - acc: 0.6687
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6300 - acc: 0.6693
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6272 - acc: 0.6741
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6274 - acc: 0.6777
 576/1283 [============>.................] - ETA: 0s - loss: 0.6279 - acc: 0.6736
 640/1283 [=============>................] - ETA: 0s - loss: 0.6249 - acc: 0.6781
 768/1283 [================>.............] - ETA: 0s - loss: 0.6319 - acc: 0.6562
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6281 - acc: 0.6647
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6278 - acc: 0.6652
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6295 - acc: 0.6615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6290 - acc: 0.6641
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6280 - acc: 0.6664
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6306 - acc: 0.6632
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6325 - acc: 0.6587
1280/1283 [============================>.] - ETA: 0s - loss: 0.6333 - acc: 0.6531
1283/1283 [==============================] - 1s 972us/step - loss: 0.6335 - acc: 0.6532 - val_loss: 0.6834 - val_acc: 0.5328

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6419 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.6324 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6241 - acc: 0.6667
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6133 - acc: 0.6836
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6180 - acc: 0.6719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6083 - acc: 0.6849
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6094 - acc: 0.6808
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6090 - acc: 0.6855
 640/1283 [=============>................] - ETA: 0s - loss: 0.6088 - acc: 0.6891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6118 - acc: 0.6790
 768/1283 [================>.............] - ETA: 0s - loss: 0.6094 - acc: 0.6810
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6076 - acc: 0.6839
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6089 - acc: 0.6750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6088 - acc: 0.6738
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6045 - acc: 0.6814
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6021 - acc: 0.6842
1280/1283 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.6820
1283/1283 [==============================] - 1s 951us/step - loss: 0.6021 - acc: 0.6828 - val_loss: 0.6829 - val_acc: 0.5852

Epoch 00004: val_acc improved from 0.55459 to 0.58515, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5425 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5655 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5546 - acc: 0.7578
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5678 - acc: 0.7406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5667 - acc: 0.7318
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5746 - acc: 0.7165
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5860 - acc: 0.7012
 576/1283 [============>.................] - ETA: 0s - loss: 0.5884 - acc: 0.6962
 640/1283 [=============>................] - ETA: 0s - loss: 0.5861 - acc: 0.6953
 768/1283 [================>.............] - ETA: 0s - loss: 0.5812 - acc: 0.6953
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5833 - acc: 0.6947
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5836 - acc: 0.6931
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5859 - acc: 0.6906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5833 - acc: 0.6903
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5847 - acc: 0.6858
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5832 - acc: 0.6850
1280/1283 [============================>.] - ETA: 0s - loss: 0.5820 - acc: 0.6875
1283/1283 [==============================] - 1s 995us/step - loss: 0.5822 - acc: 0.6875 - val_loss: 0.6826 - val_acc: 0.5677

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4560 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.5125 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5229 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5286 - acc: 0.7539
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5296 - acc: 0.7594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5176 - acc: 0.7708
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5263 - acc: 0.7723
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5310 - acc: 0.7676
 576/1283 [============>.................] - ETA: 0s - loss: 0.5446 - acc: 0.7517
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5525 - acc: 0.7415
 768/1283 [================>.............] - ETA: 0s - loss: 0.5578 - acc: 0.7292
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5551 - acc: 0.7308
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5559 - acc: 0.7277
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5536 - acc: 0.7302
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5546 - acc: 0.7314
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5520 - acc: 0.7362
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5531 - acc: 0.7361
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5486 - acc: 0.7368
1280/1283 [============================>.] - ETA: 0s - loss: 0.5478 - acc: 0.7367
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5479 - acc: 0.7366 - val_loss: 0.6803 - val_acc: 0.5677

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4423 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.4771 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4855 - acc: 0.8073
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4973 - acc: 0.7969
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4836 - acc: 0.8031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4712 - acc: 0.8099
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4832 - acc: 0.7902
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4862 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4909 - acc: 0.7778
 640/1283 [=============>................] - ETA: 0s - loss: 0.4911 - acc: 0.7766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4939 - acc: 0.7713
 768/1283 [================>.............] - ETA: 0s - loss: 0.4977 - acc: 0.7656
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4953 - acc: 0.7668
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4987 - acc: 0.7623
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4966 - acc: 0.7617
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5046 - acc: 0.7569
1280/1283 [============================>.] - ETA: 0s - loss: 0.5074 - acc: 0.7500
1283/1283 [==============================] - 1s 979us/step - loss: 0.5087 - acc: 0.7490 - val_loss: 0.6905 - val_acc: 0.5764

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4404 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4627 - acc: 0.7734
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4701 - acc: 0.7552
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4878 - acc: 0.7383
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5046 - acc: 0.7375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5044 - acc: 0.7422
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5052 - acc: 0.7411
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4960 - acc: 0.7520
 576/1283 [============>.................] - ETA: 0s - loss: 0.4974 - acc: 0.7483
 640/1283 [=============>................] - ETA: 0s - loss: 0.4984 - acc: 0.7516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5037 - acc: 0.7486
 768/1283 [================>.............] - ETA: 0s - loss: 0.5012 - acc: 0.7513
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4988 - acc: 0.7548
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4972 - acc: 0.7567
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4984 - acc: 0.7521
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4995 - acc: 0.7510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5088 - acc: 0.7445
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5078 - acc: 0.7465
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5057 - acc: 0.7500
1280/1283 [============================>.] - ETA: 0s - loss: 0.5056 - acc: 0.7492
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5058 - acc: 0.7490 - val_loss: 0.6929 - val_acc: 0.5939

Epoch 00008: val_acc improved from 0.58515 to 0.59389, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5354 - acc: 0.7188
 128/1283 [=>............................] - ETA: 0s - loss: 0.4782 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4726 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4768 - acc: 0.7734
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4883 - acc: 0.7688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4863 - acc: 0.7812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4885 - acc: 0.7812
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4812 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4853 - acc: 0.7795
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4859 - acc: 0.7827
 768/1283 [================>.............] - ETA: 0s - loss: 0.4855 - acc: 0.7773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4849 - acc: 0.7740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4811 - acc: 0.7779
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4779 - acc: 0.7802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4711 - acc: 0.7871
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4681 - acc: 0.7914
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4657 - acc: 0.7934
1280/1283 [============================>.] - ETA: 0s - loss: 0.4680 - acc: 0.7883
1283/1283 [==============================] - 1s 989us/step - loss: 0.4676 - acc: 0.7888 - val_loss: 0.7082 - val_acc: 0.5983

Epoch 00009: val_acc improved from 0.59389 to 0.59825, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3829 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.3884 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3929 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4051 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4047 - acc: 0.8344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3966 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3987 - acc: 0.8348
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3930 - acc: 0.8320
 576/1283 [============>.................] - ETA: 0s - loss: 0.4075 - acc: 0.8299
 640/1283 [=============>................] - ETA: 0s - loss: 0.4038 - acc: 0.8359
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3988 - acc: 0.8338
 768/1283 [================>.............] - ETA: 0s - loss: 0.4012 - acc: 0.8346
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4062 - acc: 0.8293
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4061 - acc: 0.8304
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4071 - acc: 0.8281
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4047 - acc: 0.8301
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4092 - acc: 0.8244
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4119 - acc: 0.8212
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4149 - acc: 0.8174
1280/1283 [============================>.] - ETA: 0s - loss: 0.4154 - acc: 0.8195
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4148 - acc: 0.8200 - val_loss: 0.7552 - val_acc: 0.6070

Epoch 00010: val_acc improved from 0.59825 to 0.60699, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3901 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.3648 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3812 - acc: 0.8542
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3768 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3874 - acc: 0.8438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3744 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3742 - acc: 0.8594
 576/1283 [============>.................] - ETA: 0s - loss: 0.3660 - acc: 0.8663
 640/1283 [=============>................] - ETA: 0s - loss: 0.3723 - acc: 0.8609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3724 - acc: 0.8551
 768/1283 [================>.............] - ETA: 0s - loss: 0.3731 - acc: 0.8555
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3740 - acc: 0.8534
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3771 - acc: 0.8504
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3764 - acc: 0.8490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3806 - acc: 0.8486
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3865 - acc: 0.8438
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3869 - acc: 0.8420
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3824 - acc: 0.8470
1280/1283 [============================>.] - ETA: 0s - loss: 0.3784 - acc: 0.8508
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3785 - acc: 0.8504 - val_loss: 0.7827 - val_acc: 0.5852

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4891 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.3700 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3452 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3467 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3534 - acc: 0.8531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3608 - acc: 0.8516
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3555 - acc: 0.8504
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3589 - acc: 0.8477
 576/1283 [============>.................] - ETA: 0s - loss: 0.3531 - acc: 0.8472
 640/1283 [=============>................] - ETA: 0s - loss: 0.3592 - acc: 0.8453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3605 - acc: 0.8423
 768/1283 [================>.............] - ETA: 0s - loss: 0.3605 - acc: 0.8451
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3556 - acc: 0.8449
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3569 - acc: 0.8396
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3558 - acc: 0.8408
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3539 - acc: 0.8410
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3532 - acc: 0.8429
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3530 - acc: 0.8438
1280/1283 [============================>.] - ETA: 0s - loss: 0.3562 - acc: 0.8414
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3566 - acc: 0.8410 - val_loss: 0.8059 - val_acc: 0.5764

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2544 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.2827 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2874 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3115 - acc: 0.8711
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3004 - acc: 0.8781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3114 - acc: 0.8672
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3194 - acc: 0.8638
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3216 - acc: 0.8633
 576/1283 [============>.................] - ETA: 0s - loss: 0.3343 - acc: 0.8576
 640/1283 [=============>................] - ETA: 0s - loss: 0.3305 - acc: 0.8578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3385 - acc: 0.8565
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3338 - acc: 0.8594
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3254 - acc: 0.8698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3271 - acc: 0.8676
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3250 - acc: 0.8672
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3245 - acc: 0.8684
1280/1283 [============================>.] - ETA: 0s - loss: 0.3257 - acc: 0.8688
1283/1283 [==============================] - 1s 935us/step - loss: 0.3262 - acc: 0.8691 - val_loss: 0.8166 - val_acc: 0.6157

Epoch 00013: val_acc improved from 0.60699 to 0.61572, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3345 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.2673 - acc: 0.9141
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2753 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2745 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2895 - acc: 0.8996
 576/1283 [============>.................] - ETA: 0s - loss: 0.2972 - acc: 0.8906
 640/1283 [=============>................] - ETA: 0s - loss: 0.3086 - acc: 0.8797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3156 - acc: 0.8793
 768/1283 [================>.............] - ETA: 0s - loss: 0.3090 - acc: 0.8841
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3112 - acc: 0.8870
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3047 - acc: 0.8929
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2988 - acc: 0.8975
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3074 - acc: 0.8924
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3034 - acc: 0.8939
1283/1283 [==============================] - 1s 865us/step - loss: 0.3063 - acc: 0.8948 - val_loss: 0.8240 - val_acc: 0.6376

Epoch 00014: val_acc improved from 0.61572 to 0.63755, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2339 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.2183 - acc: 0.9297
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2402 - acc: 0.9102
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2530 - acc: 0.8969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2516 - acc: 0.8929
 576/1283 [============>.................] - ETA: 0s - loss: 0.2534 - acc: 0.8958
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2599 - acc: 0.8878
 768/1283 [================>.............] - ETA: 0s - loss: 0.2588 - acc: 0.8906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2593 - acc: 0.8918
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2576 - acc: 0.8951
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2557 - acc: 0.8965
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2531 - acc: 0.8984
1280/1283 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.8953
1283/1283 [==============================] - 1s 787us/step - loss: 0.2619 - acc: 0.8948 - val_loss: 0.8914 - val_acc: 0.5939

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2669 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2493 - acc: 0.9115
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2323 - acc: 0.9102
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2507 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2468 - acc: 0.9040
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2533 - acc: 0.9043
 640/1283 [=============>................] - ETA: 0s - loss: 0.2505 - acc: 0.9094
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2473 - acc: 0.9091
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2494 - acc: 0.9026
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2532 - acc: 0.9021
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2491 - acc: 0.9007
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2476 - acc: 0.9030
1283/1283 [==============================] - 1s 834us/step - loss: 0.2517 - acc: 0.9002 - val_loss: 0.9880 - val_acc: 0.5721

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2753 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2730 - acc: 0.8698
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2243 - acc: 0.9031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2314 - acc: 0.9010
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2283 - acc: 0.9040
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2282 - acc: 0.9062
 640/1283 [=============>................] - ETA: 0s - loss: 0.2303 - acc: 0.9016
 768/1283 [================>.............] - ETA: 0s - loss: 0.2360 - acc: 0.9062
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2309 - acc: 0.9075
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2325 - acc: 0.9074
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2269 - acc: 0.9121
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2283 - acc: 0.9080
1280/1283 [============================>.] - ETA: 0s - loss: 0.2280 - acc: 0.9117
1283/1283 [==============================] - 1s 812us/step - loss: 0.2278 - acc: 0.9119 - val_loss: 1.0289 - val_acc: 0.5852

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1606 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1827 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1834 - acc: 0.9344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1681 - acc: 0.9464
 576/1283 [============>.................] - ETA: 0s - loss: 0.1742 - acc: 0.9392
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1797 - acc: 0.9389
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1771 - acc: 0.9411
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1813 - acc: 0.9406
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1777 - acc: 0.9403
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1815 - acc: 0.9375
1280/1283 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9359
1283/1283 [==============================] - 1s 654us/step - loss: 0.1872 - acc: 0.9361 - val_loss: 1.0519 - val_acc: 0.5590

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0946 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1145 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1332 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1610 - acc: 0.9509
 576/1283 [============>.................] - ETA: 0s - loss: 0.1910 - acc: 0.9340
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1990 - acc: 0.9332
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1945 - acc: 0.9351
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2083 - acc: 0.9292
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2069 - acc: 0.9292
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2099 - acc: 0.9285
1283/1283 [==============================] - 1s 719us/step - loss: 0.2058 - acc: 0.9306 - val_loss: 1.0541 - val_acc: 0.5808

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2220 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1946 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1763 - acc: 0.9406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1798 - acc: 0.9353
 576/1283 [============>.................] - ETA: 0s - loss: 0.1747 - acc: 0.9340
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1654 - acc: 0.9389
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1631 - acc: 0.9411
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1636 - acc: 0.9427
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1652 - acc: 0.9430
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1707 - acc: 0.9375
1283/1283 [==============================] - 1s 632us/step - loss: 0.1684 - acc: 0.9384 - val_loss: 1.1042 - val_acc: 0.5677

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1269 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1244 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1331 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1239 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.1247 - acc: 0.9705
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1204 - acc: 0.9716
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1171 - acc: 0.9724
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1211 - acc: 0.9698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1225 - acc: 0.9669
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1222 - acc: 0.9655
1283/1283 [==============================] - 1s 562us/step - loss: 0.1225 - acc: 0.9657 - val_loss: 1.1671 - val_acc: 0.5764

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1000 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0874 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0909 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0996 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.1178 - acc: 0.9601
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1100 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1051 - acc: 0.9724
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1067 - acc: 0.9729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1053 - acc: 0.9706
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1112 - acc: 0.9679
1283/1283 [==============================] - 1s 575us/step - loss: 0.1102 - acc: 0.9673 - val_loss: 1.2150 - val_acc: 0.5852

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1586 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1319 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1172 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1030 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.0937 - acc: 0.9757
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0917 - acc: 0.9744
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0909 - acc: 0.9760
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0894 - acc: 0.9771
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0871 - acc: 0.9779
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0847 - acc: 0.9794
1283/1283 [==============================] - 1s 550us/step - loss: 0.0839 - acc: 0.9805 - val_loss: 1.2647 - val_acc: 0.5764

Epoch 00023: val_acc did not improve
Epoch 24/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0565 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0631 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0741 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0808 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.0821 - acc: 0.9792
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0808 - acc: 0.9815
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0804 - acc: 0.9796
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0756 - acc: 0.9812
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0764 - acc: 0.9816
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0777 - acc: 0.9811
1283/1283 [==============================] - 1s 562us/step - loss: 0.0782 - acc: 0.9813 - val_loss: 1.3613 - val_acc: 0.6157

Epoch 00024: val_acc did not improve
Epoch 00024: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
mode=A
accuracy=0.5087463556851312
best_valid_accuracy=0.48833819241982507
