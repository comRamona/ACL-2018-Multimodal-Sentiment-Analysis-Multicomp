/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:08:10.104314: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.9548 - acc: 0.5000
 192/1283 [===>..........................] - ETA: 2s - loss: 1.2642 - acc: 0.5000
 384/1283 [=======>......................] - ETA: 1s - loss: 1.0309 - acc: 0.5026
 576/1283 [============>.................] - ETA: 0s - loss: 0.9449 - acc: 0.5226
 704/1283 [===============>..............] - ETA: 0s - loss: 0.8959 - acc: 0.5284
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8658 - acc: 0.5361
 960/1283 [=====================>........] - ETA: 0s - loss: 0.8484 - acc: 0.5271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.8372 - acc: 0.5332
1088/1283 [========================>.....] - ETA: 0s - loss: 0.8287 - acc: 0.5340
1216/1283 [===========================>..] - ETA: 0s - loss: 0.8146 - acc: 0.5354
1280/1283 [============================>.] - ETA: 0s - loss: 0.8100 - acc: 0.5320
1283/1283 [==============================] - 1s 920us/step - loss: 0.8096 - acc: 0.5323 - val_loss: 0.6954 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6266 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6388 - acc: 0.6354
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6623 - acc: 0.6000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6595 - acc: 0.5964
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6764 - acc: 0.5645
 640/1283 [=============>................] - ETA: 0s - loss: 0.6709 - acc: 0.5641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6696 - acc: 0.5639
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6650 - acc: 0.5769
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6618 - acc: 0.5938
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6638 - acc: 0.5864
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6616 - acc: 0.5888
1280/1283 [============================>.] - ETA: 0s - loss: 0.6610 - acc: 0.5914
1283/1283 [==============================] - 1s 828us/step - loss: 0.6612 - acc: 0.5900 - val_loss: 0.6920 - val_acc: 0.5371

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6355 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6114 - acc: 0.7083
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6072 - acc: 0.7070
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6138 - acc: 0.6844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6077 - acc: 0.6830
 576/1283 [============>.................] - ETA: 0s - loss: 0.6108 - acc: 0.6736
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6181 - acc: 0.6562
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6168 - acc: 0.6599
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6189 - acc: 0.6500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6148 - acc: 0.6618
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6102 - acc: 0.6678
1283/1283 [==============================] - 1s 782us/step - loss: 0.6097 - acc: 0.6695 - val_loss: 0.7169 - val_acc: 0.5590

Epoch 00003: val_acc improved from 0.54148 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5734 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5359 - acc: 0.7552
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5508 - acc: 0.7266
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5655 - acc: 0.7005
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5735 - acc: 0.6897
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5716 - acc: 0.6953
 576/1283 [============>.................] - ETA: 0s - loss: 0.5745 - acc: 0.6927
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5819 - acc: 0.6960
 768/1283 [================>.............] - ETA: 0s - loss: 0.5762 - acc: 0.7044
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5726 - acc: 0.7103
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5750 - acc: 0.7065
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5687 - acc: 0.7178
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5653 - acc: 0.7153
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5658 - acc: 0.7130
1283/1283 [==============================] - 1s 929us/step - loss: 0.5653 - acc: 0.7147 - val_loss: 0.7087 - val_acc: 0.5808

Epoch 00004: val_acc improved from 0.55895 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5410 - acc: 0.7188
 128/1283 [=>............................] - ETA: 0s - loss: 0.5456 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5207 - acc: 0.7266
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5318 - acc: 0.7063
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5173 - acc: 0.7318
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5207 - acc: 0.7299
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5239 - acc: 0.7227
 640/1283 [=============>................] - ETA: 0s - loss: 0.5256 - acc: 0.7188
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5238 - acc: 0.7116
 768/1283 [================>.............] - ETA: 0s - loss: 0.5252 - acc: 0.7070
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5200 - acc: 0.7210
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5188 - acc: 0.7236
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5128 - acc: 0.7335
1280/1283 [============================>.] - ETA: 0s - loss: 0.5138 - acc: 0.7375
1283/1283 [==============================] - 1s 763us/step - loss: 0.5144 - acc: 0.7373 - val_loss: 0.6978 - val_acc: 0.5939

Epoch 00005: val_acc improved from 0.58079 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4504 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4837 - acc: 0.7865
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4863 - acc: 0.7906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4775 - acc: 0.7917
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4835 - acc: 0.7835
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4773 - acc: 0.7910
 576/1283 [============>.................] - ETA: 0s - loss: 0.4758 - acc: 0.7951
 640/1283 [=============>................] - ETA: 0s - loss: 0.4823 - acc: 0.7844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4779 - acc: 0.7884
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4707 - acc: 0.7909
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4693 - acc: 0.7913
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4655 - acc: 0.7881
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4654 - acc: 0.7895
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4674 - acc: 0.7895
1283/1283 [==============================] - 1s 935us/step - loss: 0.4648 - acc: 0.7935 - val_loss: 0.7421 - val_acc: 0.5590

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3739 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.3963 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4322 - acc: 0.8164
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4242 - acc: 0.8187
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4159 - acc: 0.8255
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4214 - acc: 0.8203
 576/1283 [============>.................] - ETA: 0s - loss: 0.4235 - acc: 0.8194
 640/1283 [=============>................] - ETA: 0s - loss: 0.4171 - acc: 0.8281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4156 - acc: 0.8267
 768/1283 [================>.............] - ETA: 0s - loss: 0.4138 - acc: 0.8268
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4185 - acc: 0.8185
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4077 - acc: 0.8281
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4028 - acc: 0.8320
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4020 - acc: 0.8290
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4023 - acc: 0.8298
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4036 - acc: 0.8301 - val_loss: 0.7393 - val_acc: 0.5852

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2805 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.3196 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3043 - acc: 0.9180
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3176 - acc: 0.9031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3140 - acc: 0.9141
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3214 - acc: 0.9043
 576/1283 [============>.................] - ETA: 0s - loss: 0.3196 - acc: 0.8993
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3257 - acc: 0.8963
 768/1283 [================>.............] - ETA: 0s - loss: 0.3294 - acc: 0.8906
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3212 - acc: 0.8940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3241 - acc: 0.8896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3210 - acc: 0.8943
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3205 - acc: 0.8941
1280/1283 [============================>.] - ETA: 0s - loss: 0.3183 - acc: 0.8953
1283/1283 [==============================] - 1s 976us/step - loss: 0.3188 - acc: 0.8948 - val_loss: 0.7686 - val_acc: 0.5721

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2585 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2800 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2782 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2849 - acc: 0.8945
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2853 - acc: 0.8932
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2822 - acc: 0.8929
 576/1283 [============>.................] - ETA: 0s - loss: 0.2827 - acc: 0.8958
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2811 - acc: 0.8977
 768/1283 [================>.............] - ETA: 0s - loss: 0.2877 - acc: 0.8919
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2942 - acc: 0.8862
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2992 - acc: 0.8838
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3005 - acc: 0.8833
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2975 - acc: 0.8837
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2938 - acc: 0.8890
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3001 - acc: 0.8846 - val_loss: 0.8198 - val_acc: 0.6026

Epoch 00009: val_acc improved from 0.59389 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2373 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2321 - acc: 0.9271
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2438 - acc: 0.9250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2515 - acc: 0.9263
 576/1283 [============>.................] - ETA: 0s - loss: 0.2511 - acc: 0.9253
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2467 - acc: 0.9247
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2370 - acc: 0.9339
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2349 - acc: 0.9354
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2358 - acc: 0.9357
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2325 - acc: 0.9367
1283/1283 [==============================] - 1s 655us/step - loss: 0.2343 - acc: 0.9345 - val_loss: 0.8878 - val_acc: 0.5590

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1830 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1819 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1739 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1723 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1763 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1800 - acc: 0.9629
 640/1283 [=============>................] - ETA: 0s - loss: 0.1767 - acc: 0.9625
 768/1283 [================>.............] - ETA: 0s - loss: 0.1862 - acc: 0.9557
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1876 - acc: 0.9509
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1856 - acc: 0.9510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1850 - acc: 0.9513
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1836 - acc: 0.9548
1283/1283 [==============================] - 1s 803us/step - loss: 0.1826 - acc: 0.9540 - val_loss: 0.8807 - val_acc: 0.5939

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0889 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.1173 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1243 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1337 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1363 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1411 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.1464 - acc: 0.9653
 640/1283 [=============>................] - ETA: 0s - loss: 0.1479 - acc: 0.9656
 768/1283 [================>.............] - ETA: 0s - loss: 0.1450 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1425 - acc: 0.9700
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1404 - acc: 0.9708
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1355 - acc: 0.9733
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1348 - acc: 0.9740
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1363 - acc: 0.9720
1280/1283 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9727
1283/1283 [==============================] - 1s 940us/step - loss: 0.1369 - acc: 0.9727 - val_loss: 0.9372 - val_acc: 0.5284

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1400 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.1176 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1210 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1188 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1169 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1113 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1155 - acc: 0.9785
 576/1283 [============>.................] - ETA: 0s - loss: 0.1161 - acc: 0.9774
 640/1283 [=============>................] - ETA: 0s - loss: 0.1141 - acc: 0.9781
 768/1283 [================>.............] - ETA: 0s - loss: 0.1177 - acc: 0.9740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1179 - acc: 0.9743
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1183 - acc: 0.9740
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1198 - acc: 0.9746
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1220 - acc: 0.9733
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1207 - acc: 0.9740
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1194 - acc: 0.9737
1280/1283 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9750
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1171 - acc: 0.9751 - val_loss: 1.0041 - val_acc: 0.5721

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0727 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0792 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0726 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0717 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0725 - acc: 0.9961
 640/1283 [=============>................] - ETA: 0s - loss: 0.0718 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0764 - acc: 0.9948
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0783 - acc: 0.9940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0762 - acc: 0.9948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0770 - acc: 0.9922
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0759 - acc: 0.9926
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0758 - acc: 0.9931
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0759 - acc: 0.9918
1280/1283 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9914
1283/1283 [==============================] - 1s 919us/step - loss: 0.0752 - acc: 0.9914 - val_loss: 1.0254 - val_acc: 0.6114

Epoch 00014: val_acc improved from 0.60262 to 0.61135, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0409 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0618 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0701 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0667 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0623 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0618 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0621 - acc: 0.9929
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0591 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0572 - acc: 0.9944
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0584 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0574 - acc: 0.9936
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0567 - acc: 0.9939
1280/1283 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9938
1283/1283 [==============================] - 1s 779us/step - loss: 0.0574 - acc: 0.9938 - val_loss: 1.1703 - val_acc: 0.6026

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0433 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0772 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0910 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0981 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1011 - acc: 0.9766
 640/1283 [=============>................] - ETA: 0s - loss: 0.0946 - acc: 0.9797
 768/1283 [================>.............] - ETA: 0s - loss: 0.0953 - acc: 0.9792
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0947 - acc: 0.9777
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0938 - acc: 0.9766
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0904 - acc: 0.9774
1280/1283 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9789
1283/1283 [==============================] - 1s 636us/step - loss: 0.0889 - acc: 0.9790 - val_loss: 1.0950 - val_acc: 0.6026

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0363 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0607 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0534 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0527 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0522 - acc: 0.9961
 640/1283 [=============>................] - ETA: 0s - loss: 0.0529 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0515 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0504 - acc: 0.9964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0485 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0480 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0473 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0477 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0470 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9977
1283/1283 [==============================] - 1s 871us/step - loss: 0.0468 - acc: 0.9977 - val_loss: 1.4004 - val_acc: 0.5546

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0452 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0483 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0497 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0442 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0362 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0351 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0349 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0334 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0340 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0324 - acc: 0.9979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0310 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0307 - acc: 0.9983
1280/1283 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9984
1283/1283 [==============================] - 1s 865us/step - loss: 0.0309 - acc: 0.9984 - val_loss: 1.2180 - val_acc: 0.5677

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0423 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0319 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0330 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0314 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0284 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0277 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0293 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0302 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0288 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0296 - acc: 0.9978
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0297 - acc: 0.9980
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0289 - acc: 0.9983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0282 - acc: 0.9984
1283/1283 [==============================] - 1s 837us/step - loss: 0.0278 - acc: 0.9984 - val_loss: 1.4400 - val_acc: 0.5983

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0197 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0278 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0312 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0278 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0279 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0291 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0290 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0276 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0259 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0249 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0244 - acc: 0.9992
1280/1283 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9992
1283/1283 [==============================] - 1s 815us/step - loss: 0.0239 - acc: 0.9992 - val_loss: 1.3100 - val_acc: 0.6026

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0154 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0158 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0142 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0125 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0129 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0122 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0127 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0124 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0119 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0117 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0118 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0125 - acc: 0.9991
1280/1283 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9992
1283/1283 [==============================] - 1s 893us/step - loss: 0.0121 - acc: 0.9992 - val_loss: 1.3756 - val_acc: 0.5983

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0070 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0091 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0088 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0089 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0086 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0090 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0094 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0090 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0091 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0090 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0089 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0090 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 1.0000
1283/1283 [==============================] - 1s 871us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 1.7556 - val_acc: 0.5633

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0100 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0212 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0422 - acc: 0.9883
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0509 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0568 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0542 - acc: 0.9826
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0592 - acc: 0.9815
 768/1283 [================>.............] - ETA: 0s - loss: 0.0580 - acc: 0.9818
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0653 - acc: 0.9820
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0634 - acc: 0.9833
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0647 - acc: 0.9833
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0603 - acc: 0.9853
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0587 - acc: 0.9861
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0583 - acc: 0.9844
1283/1283 [==============================] - 1s 905us/step - loss: 0.0587 - acc: 0.9844 - val_loss: 1.5757 - val_acc: 0.5939

Epoch 00023: val_acc did not improve
Epoch 24/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0311 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0252 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0354 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0393 - acc: 0.9922
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0401 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0374 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0378 - acc: 0.9948
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0367 - acc: 0.9952
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0335 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0336 - acc: 0.9945
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0319 - acc: 0.9951
1283/1283 [==============================] - 1s 782us/step - loss: 0.0310 - acc: 0.9953 - val_loss: 1.5961 - val_acc: 0.5721

Epoch 00024: val_acc did not improve
Epoch 00024: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=30
epochs=100
mode=A
accuracy=0.5204081632653061
best_valid_accuracy=0.5204081632653061
