/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:07:51.007582: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.9548 - acc: 0.5000
 256/1283 [====>.........................] - ETA: 0s - loss: 1.1243 - acc: 0.5039
 384/1283 [=======>......................] - ETA: 0s - loss: 1.0275 - acc: 0.5026
 576/1283 [============>.................] - ETA: 0s - loss: 0.9386 - acc: 0.5208
 768/1283 [================>.............] - ETA: 0s - loss: 0.8748 - acc: 0.5247
 960/1283 [=====================>........] - ETA: 0s - loss: 0.8443 - acc: 0.5260
1152/1283 [=========================>....] - ETA: 0s - loss: 0.8191 - acc: 0.5321
1283/1283 [==============================] - 1s 478us/step - loss: 0.8061 - acc: 0.5316 - val_loss: 0.6992 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6236 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6382 - acc: 0.6302
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6592 - acc: 0.5964
 576/1283 [============>.................] - ETA: 0s - loss: 0.6692 - acc: 0.5677
 768/1283 [================>.............] - ETA: 0s - loss: 0.6639 - acc: 0.5807
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6588 - acc: 0.5990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6597 - acc: 0.5938
1283/1283 [==============================] - 0s 349us/step - loss: 0.6586 - acc: 0.5963 - val_loss: 0.6936 - val_acc: 0.5284

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6311 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6014 - acc: 0.7305
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6013 - acc: 0.6920
 640/1283 [=============>................] - ETA: 0s - loss: 0.6068 - acc: 0.6828
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6101 - acc: 0.6791
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6113 - acc: 0.6737
1280/1283 [============================>.] - ETA: 0s - loss: 0.6058 - acc: 0.6813
1283/1283 [==============================] - 0s 341us/step - loss: 0.6059 - acc: 0.6812 - val_loss: 0.7085 - val_acc: 0.5590

Epoch 00003: val_acc improved from 0.54148 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5705 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5360 - acc: 0.7188
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5548 - acc: 0.7009
 640/1283 [=============>................] - ETA: 0s - loss: 0.5603 - acc: 0.7078
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5586 - acc: 0.7139
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5542 - acc: 0.7227
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5520 - acc: 0.7204
1283/1283 [==============================] - 0s 340us/step - loss: 0.5518 - acc: 0.7210 - val_loss: 0.7015 - val_acc: 0.5677

Epoch 00004: val_acc improved from 0.55895 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5308 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5132 - acc: 0.7383
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5150 - acc: 0.7411
 640/1283 [=============>................] - ETA: 0s - loss: 0.5235 - acc: 0.7188
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5135 - acc: 0.7368
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5123 - acc: 0.7373
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5042 - acc: 0.7451
1283/1283 [==============================] - 0s 343us/step - loss: 0.5096 - acc: 0.7405 - val_loss: 0.7012 - val_acc: 0.6026

Epoch 00005: val_acc improved from 0.56769 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4332 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4597 - acc: 0.8008
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4712 - acc: 0.7835
 640/1283 [=============>................] - ETA: 0s - loss: 0.4690 - acc: 0.7891
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4576 - acc: 0.7957
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4541 - acc: 0.7930
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4548 - acc: 0.7960
1283/1283 [==============================] - 0s 326us/step - loss: 0.4562 - acc: 0.7966 - val_loss: 0.7161 - val_acc: 0.5677

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3686 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4204 - acc: 0.8281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4049 - acc: 0.8326
 640/1283 [=============>................] - ETA: 0s - loss: 0.4063 - acc: 0.8344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4114 - acc: 0.8185
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3970 - acc: 0.8320
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3982 - acc: 0.8273
1283/1283 [==============================] - 0s 348us/step - loss: 0.3993 - acc: 0.8270 - val_loss: 0.7304 - val_acc: 0.5895

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2804 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2960 - acc: 0.9219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3031 - acc: 0.9167
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3113 - acc: 0.9121
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3177 - acc: 0.9020
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3131 - acc: 0.8996
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3131 - acc: 0.8998
1280/1283 [============================>.] - ETA: 0s - loss: 0.3117 - acc: 0.9000
1283/1283 [==============================] - 0s 359us/step - loss: 0.3127 - acc: 0.8987 - val_loss: 0.7439 - val_acc: 0.6026

Epoch 00008: val_acc improved from 0.60262 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2513 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2723 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2765 - acc: 0.8906
 576/1283 [============>.................] - ETA: 0s - loss: 0.2776 - acc: 0.8941
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2731 - acc: 0.8963
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2907 - acc: 0.8739
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2982 - acc: 0.8704
1280/1283 [============================>.] - ETA: 0s - loss: 0.2955 - acc: 0.8766
1283/1283 [==============================] - 0s 373us/step - loss: 0.2951 - acc: 0.8769 - val_loss: 0.8431 - val_acc: 0.6201

Epoch 00009: val_acc improved from 0.60262 to 0.62009, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2663 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2392 - acc: 0.9479
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2582 - acc: 0.9297
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2571 - acc: 0.9238
 640/1283 [=============>................] - ETA: 0s - loss: 0.2462 - acc: 0.9297
 768/1283 [================>.............] - ETA: 0s - loss: 0.2420 - acc: 0.9284
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2359 - acc: 0.9302
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2354 - acc: 0.9323
1283/1283 [==============================] - 1s 400us/step - loss: 0.2361 - acc: 0.9337 - val_loss: 0.8768 - val_acc: 0.6026

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1889 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1722 - acc: 0.9766
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1736 - acc: 0.9714
 576/1283 [============>.................] - ETA: 0s - loss: 0.1749 - acc: 0.9635
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1733 - acc: 0.9645
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1801 - acc: 0.9576
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1770 - acc: 0.9568
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1760 - acc: 0.9589
1283/1283 [==============================] - 1s 419us/step - loss: 0.1752 - acc: 0.9587 - val_loss: 0.8711 - val_acc: 0.5808

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0881 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1307 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1373 - acc: 0.9643
 576/1283 [============>.................] - ETA: 0s - loss: 0.1397 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1386 - acc: 0.9659
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1337 - acc: 0.9700
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1288 - acc: 0.9736
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1282 - acc: 0.9740
1283/1283 [==============================] - 1s 460us/step - loss: 0.1304 - acc: 0.9735 - val_loss: 0.9071 - val_acc: 0.5546

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1321 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1216 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1135 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1217 - acc: 0.9754
 640/1283 [=============>................] - ETA: 0s - loss: 0.1124 - acc: 0.9781
 768/1283 [================>.............] - ETA: 0s - loss: 0.1143 - acc: 0.9779
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1161 - acc: 0.9760
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1208 - acc: 0.9743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1187 - acc: 0.9737
1283/1283 [==============================] - 1s 469us/step - loss: 0.1165 - acc: 0.9751 - val_loss: 0.9715 - val_acc: 0.5983

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0764 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0763 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0715 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0711 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0727 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0733 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0779 - acc: 0.9952
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0757 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0748 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0754 - acc: 0.9934
1283/1283 [==============================] - 1s 562us/step - loss: 0.0745 - acc: 0.9930 - val_loss: 0.9890 - val_acc: 0.5983

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0369 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0606 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0704 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0674 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0629 - acc: 0.9931
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0627 - acc: 0.9929
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0600 - acc: 0.9940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0591 - acc: 0.9927
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0581 - acc: 0.9936
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0569 - acc: 0.9942
1283/1283 [==============================] - 1s 562us/step - loss: 0.0583 - acc: 0.9938 - val_loss: 1.1110 - val_acc: 0.5983

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0430 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0566 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0774 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0933 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.0935 - acc: 0.9792
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0880 - acc: 0.9815
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0891 - acc: 0.9808
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0901 - acc: 0.9812
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0891 - acc: 0.9789
1280/1283 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9805
1283/1283 [==============================] - 1s 589us/step - loss: 0.0861 - acc: 0.9805 - val_loss: 1.1017 - val_acc: 0.6114

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0437 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0673 - acc: 0.9948
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0566 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0563 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0565 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0559 - acc: 0.9961
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0536 - acc: 0.9955
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0520 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0508 - acc: 0.9963
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0497 - acc: 0.9967
1283/1283 [==============================] - 1s 570us/step - loss: 0.0493 - acc: 0.9969 - val_loss: 1.3782 - val_acc: 0.6070

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0474 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0452 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0359 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0326 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0343 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0324 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0325 - acc: 0.9964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0309 - acc: 0.9969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0295 - acc: 0.9972
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0297 - acc: 0.9975
1283/1283 [==============================] - 1s 620us/step - loss: 0.0299 - acc: 0.9977 - val_loss: 1.1913 - val_acc: 0.5721

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0380 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0310 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0283 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0255 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0266 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0278 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0260 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0258 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0259 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0250 - acc: 0.9992
1283/1283 [==============================] - 1s 645us/step - loss: 0.0246 - acc: 0.9992 - val_loss: 1.3919 - val_acc: 0.6026

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
epochs=100
mode=A
accuracy=0.4752186588921283
best_valid_accuracy=0.46355685131195334
