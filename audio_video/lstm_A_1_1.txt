/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 08:38:48.176442: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 12s - loss: 0.6752 - acc: 0.5625
 128/1283 [=>............................] - ETA: 6s - loss: 0.6696 - acc: 0.5469 
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6748 - acc: 0.5781
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6799 - acc: 0.5625
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6804 - acc: 0.5625
 576/1283 [============>.................] - ETA: 1s - loss: 0.6866 - acc: 0.5486
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6825 - acc: 0.5668
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6838 - acc: 0.5637
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6863 - acc: 0.5563
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6832 - acc: 0.5607
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6856 - acc: 0.5567
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6860 - acc: 0.5565 - val_loss: 0.6728 - val_acc: 0.6070

Epoch 00001: val_acc improved from -inf to 0.60699, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6237 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6450 - acc: 0.6302
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6502 - acc: 0.6344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6485 - acc: 0.6406
 576/1283 [============>.................] - ETA: 0s - loss: 0.6449 - acc: 0.6424
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6485 - acc: 0.6392
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6509 - acc: 0.6310
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6509 - acc: 0.6350
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6516 - acc: 0.6279
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6489 - acc: 0.6319
1280/1283 [============================>.] - ETA: 0s - loss: 0.6512 - acc: 0.6281
1283/1283 [==============================] - 1s 754us/step - loss: 0.6515 - acc: 0.6282 - val_loss: 0.6695 - val_acc: 0.6157

Epoch 00002: val_acc improved from 0.60699 to 0.61572, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6621 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6496 - acc: 0.6354
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6331 - acc: 0.6469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6381 - acc: 0.6406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6353 - acc: 0.6451
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6357 - acc: 0.6445
 576/1283 [============>.................] - ETA: 0s - loss: 0.6316 - acc: 0.6493
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6261 - acc: 0.6605
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6243 - acc: 0.6599
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6195 - acc: 0.6594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6249 - acc: 0.6517
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6240 - acc: 0.6554
1280/1283 [============================>.] - ETA: 0s - loss: 0.6268 - acc: 0.6500
1283/1283 [==============================] - 1s 872us/step - loss: 0.6265 - acc: 0.6508 - val_loss: 0.6733 - val_acc: 0.5939

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5809 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5864 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5943 - acc: 0.6953
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5963 - acc: 0.6927
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5941 - acc: 0.6920
 576/1283 [============>.................] - ETA: 0s - loss: 0.5925 - acc: 0.6910
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5960 - acc: 0.6889
 768/1283 [================>.............] - ETA: 0s - loss: 0.5954 - acc: 0.6875
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5942 - acc: 0.6887
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5976 - acc: 0.6844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6004 - acc: 0.6801
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6060 - acc: 0.6719
1283/1283 [==============================] - 1s 763us/step - loss: 0.6031 - acc: 0.6742 - val_loss: 0.6636 - val_acc: 0.6114

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5612 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5792 - acc: 0.6823
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5768 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5879 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5741 - acc: 0.7090
 640/1283 [=============>................] - ETA: 0s - loss: 0.5825 - acc: 0.6922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5808 - acc: 0.6946
 768/1283 [================>.............] - ETA: 0s - loss: 0.5835 - acc: 0.6875
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5813 - acc: 0.6908
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5868 - acc: 0.6836
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5879 - acc: 0.6762
1280/1283 [============================>.] - ETA: 0s - loss: 0.5900 - acc: 0.6789
1283/1283 [==============================] - 1s 821us/step - loss: 0.5900 - acc: 0.6789 - val_loss: 0.6779 - val_acc: 0.6157

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4953 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.5069 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5095 - acc: 0.7865
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5280 - acc: 0.7594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5304 - acc: 0.7500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5445 - acc: 0.7344
 640/1283 [=============>................] - ETA: 0s - loss: 0.5474 - acc: 0.7281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5506 - acc: 0.7230
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5526 - acc: 0.7224
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5518 - acc: 0.7188
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5592 - acc: 0.7086
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5600 - acc: 0.7105
1283/1283 [==============================] - 1s 858us/step - loss: 0.5622 - acc: 0.7077 - val_loss: 0.6882 - val_acc: 0.6245

Epoch 00006: val_acc improved from 0.61572 to 0.62445, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5381 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.5053 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5451 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5454 - acc: 0.7406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5442 - acc: 0.7370
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5413 - acc: 0.7344
 640/1283 [=============>................] - ETA: 0s - loss: 0.5414 - acc: 0.7344
 768/1283 [================>.............] - ETA: 0s - loss: 0.5434 - acc: 0.7370
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5498 - acc: 0.7243
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5515 - acc: 0.7168
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5515 - acc: 0.7188
1280/1283 [============================>.] - ETA: 0s - loss: 0.5534 - acc: 0.7164
1283/1283 [==============================] - 1s 748us/step - loss: 0.5534 - acc: 0.7171 - val_loss: 0.6822 - val_acc: 0.6245

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4656 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5338 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5182 - acc: 0.7531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5311 - acc: 0.7422
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5310 - acc: 0.7433
 576/1283 [============>.................] - ETA: 0s - loss: 0.5301 - acc: 0.7378
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5244 - acc: 0.7443
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5320 - acc: 0.7428
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5309 - acc: 0.7455
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5236 - acc: 0.7549
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5273 - acc: 0.7482
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5286 - acc: 0.7465
1280/1283 [============================>.] - ETA: 0s - loss: 0.5317 - acc: 0.7453
1283/1283 [==============================] - 1s 821us/step - loss: 0.5315 - acc: 0.7459 - val_loss: 0.7074 - val_acc: 0.6114

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4723 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4858 - acc: 0.7917
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4943 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4919 - acc: 0.7567
 576/1283 [============>.................] - ETA: 0s - loss: 0.4820 - acc: 0.7726
 640/1283 [=============>................] - ETA: 0s - loss: 0.4789 - acc: 0.7812
 768/1283 [================>.............] - ETA: 0s - loss: 0.4805 - acc: 0.7773
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4849 - acc: 0.7757
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4785 - acc: 0.7793
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4857 - acc: 0.7717
1280/1283 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.7758
1283/1283 [==============================] - 1s 819us/step - loss: 0.4838 - acc: 0.7763 - val_loss: 0.7125 - val_acc: 0.6157

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4853 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4426 - acc: 0.7917
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4469 - acc: 0.7812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4475 - acc: 0.7857
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4425 - acc: 0.7949
 576/1283 [============>.................] - ETA: 0s - loss: 0.4459 - acc: 0.7917
 640/1283 [=============>................] - ETA: 0s - loss: 0.4515 - acc: 0.7875
 768/1283 [================>.............] - ETA: 0s - loss: 0.4506 - acc: 0.7904
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4567 - acc: 0.7824
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4531 - acc: 0.7832
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4616 - acc: 0.7769
1280/1283 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.7750
1283/1283 [==============================] - 1s 825us/step - loss: 0.4665 - acc: 0.7747 - val_loss: 0.7384 - val_acc: 0.6026

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4266 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4262 - acc: 0.8177
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4263 - acc: 0.8164
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4491 - acc: 0.7937
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4396 - acc: 0.8036
 576/1283 [============>.................] - ETA: 0s - loss: 0.4423 - acc: 0.7969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4504 - acc: 0.7912
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4489 - acc: 0.7945
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4459 - acc: 0.7948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4396 - acc: 0.8015
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4423 - acc: 0.7986
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4510 - acc: 0.7952
1283/1283 [==============================] - 1s 813us/step - loss: 0.4545 - acc: 0.7966 - val_loss: 0.7609 - val_acc: 0.5939

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4326 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3937 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4113 - acc: 0.8187
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4191 - acc: 0.8151
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4345 - acc: 0.7988
 576/1283 [============>.................] - ETA: 0s - loss: 0.4348 - acc: 0.8003
 640/1283 [=============>................] - ETA: 0s - loss: 0.4395 - acc: 0.7953
 768/1283 [================>.............] - ETA: 0s - loss: 0.4399 - acc: 0.7982
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4365 - acc: 0.7980
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4359 - acc: 0.7969
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4319 - acc: 0.8003
1280/1283 [============================>.] - ETA: 0s - loss: 0.4306 - acc: 0.8016
1283/1283 [==============================] - 1s 828us/step - loss: 0.4305 - acc: 0.8020 - val_loss: 0.7845 - val_acc: 0.6114

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3851 - acc: 0.8438
 128/1283 [=>............................] - ETA: 0s - loss: 0.3784 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3813 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4221 - acc: 0.8313
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4156 - acc: 0.8229
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4166 - acc: 0.8259
 576/1283 [============>.................] - ETA: 0s - loss: 0.4044 - acc: 0.8316
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3970 - acc: 0.8366
 768/1283 [================>.............] - ETA: 0s - loss: 0.3997 - acc: 0.8346
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3978 - acc: 0.8326
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3896 - acc: 0.8379
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3964 - acc: 0.8307
1280/1283 [============================>.] - ETA: 0s - loss: 0.3931 - acc: 0.8352
1283/1283 [==============================] - 1s 881us/step - loss: 0.3945 - acc: 0.8340 - val_loss: 0.7760 - val_acc: 0.6201

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4416 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4180 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4252 - acc: 0.8219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4187 - acc: 0.8170
 576/1283 [============>.................] - ETA: 0s - loss: 0.4254 - acc: 0.8073
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4129 - acc: 0.8239
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4168 - acc: 0.8221
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4157 - acc: 0.8237
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4131 - acc: 0.8242
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4085 - acc: 0.8255
1280/1283 [============================>.] - ETA: 0s - loss: 0.4044 - acc: 0.8297
1283/1283 [==============================] - 1s 802us/step - loss: 0.4046 - acc: 0.8293 - val_loss: 0.7939 - val_acc: 0.6201

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2709 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.3190 - acc: 0.8828
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3461 - acc: 0.8516
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3447 - acc: 0.8656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3445 - acc: 0.8672
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3499 - acc: 0.8672
 640/1283 [=============>................] - ETA: 0s - loss: 0.3496 - acc: 0.8625
 768/1283 [================>.............] - ETA: 0s - loss: 0.3526 - acc: 0.8659
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3580 - acc: 0.8650
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3563 - acc: 0.8656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3579 - acc: 0.8652
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3607 - acc: 0.8533
1280/1283 [============================>.] - ETA: 0s - loss: 0.3567 - acc: 0.8539
1283/1283 [==============================] - 1s 841us/step - loss: 0.3564 - acc: 0.8542 - val_loss: 0.8052 - val_acc: 0.6201

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4181 - acc: 0.8438
 128/1283 [=>............................] - ETA: 0s - loss: 0.3562 - acc: 0.8672
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3426 - acc: 0.8802
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3326 - acc: 0.8781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3190 - acc: 0.8795
 576/1283 [============>.................] - ETA: 0s - loss: 0.3150 - acc: 0.8854
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3205 - acc: 0.8835
 768/1283 [================>.............] - ETA: 0s - loss: 0.3160 - acc: 0.8854
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3169 - acc: 0.8761
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3149 - acc: 0.8789
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3100 - acc: 0.8802
1280/1283 [============================>.] - ETA: 0s - loss: 0.3056 - acc: 0.8836
1283/1283 [==============================] - 1s 767us/step - loss: 0.3056 - acc: 0.8839 - val_loss: 0.8450 - val_acc: 0.6070

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
mode=A
accuracy=0.4956268221574344
best_valid_accuracy=0.5014577259475219
