/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:08:31.245960: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.6796 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7035 - acc: 0.5573
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7481 - acc: 0.5250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7380 - acc: 0.5179
 576/1283 [============>.................] - ETA: 0s - loss: 0.7367 - acc: 0.5156
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7276 - acc: 0.5256
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7242 - acc: 0.5349
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7210 - acc: 0.5333
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7161 - acc: 0.5423
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7131 - acc: 0.5411
1283/1283 [==============================] - 1s 837us/step - loss: 0.7118 - acc: 0.5417 - val_loss: 0.7133 - val_acc: 0.5109

Epoch 00001: val_acc improved from -inf to 0.51092, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6393 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6508 - acc: 0.6250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6383 - acc: 0.6380
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6378 - acc: 0.6426
 640/1283 [=============>................] - ETA: 0s - loss: 0.6355 - acc: 0.6500
 768/1283 [================>.............] - ETA: 0s - loss: 0.6331 - acc: 0.6458
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6278 - acc: 0.6585
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6293 - acc: 0.6562
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6263 - acc: 0.6623
1283/1283 [==============================] - 1s 510us/step - loss: 0.6290 - acc: 0.6532 - val_loss: 0.7157 - val_acc: 0.5633

Epoch 00002: val_acc improved from 0.51092 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5710 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5748 - acc: 0.7188
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5994 - acc: 0.6797
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6005 - acc: 0.6808
 640/1283 [=============>................] - ETA: 0s - loss: 0.5881 - acc: 0.6969
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5887 - acc: 0.6935
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5919 - acc: 0.6885
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5894 - acc: 0.6976
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5921 - acc: 0.6900
1283/1283 [==============================] - 1s 521us/step - loss: 0.5883 - acc: 0.6929 - val_loss: 0.7191 - val_acc: 0.5633

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4591 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4827 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5135 - acc: 0.8000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5186 - acc: 0.7991
 640/1283 [=============>................] - ETA: 0s - loss: 0.5204 - acc: 0.7781
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5233 - acc: 0.7620
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5204 - acc: 0.7646
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5203 - acc: 0.7599
1283/1283 [==============================] - 1s 465us/step - loss: 0.5212 - acc: 0.7568 - val_loss: 0.7896 - val_acc: 0.5852

Epoch 00004: val_acc improved from 0.56332 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4149 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4536 - acc: 0.8008
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4657 - acc: 0.7891
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4596 - acc: 0.7930
 640/1283 [=============>................] - ETA: 0s - loss: 0.4562 - acc: 0.7937
 768/1283 [================>.............] - ETA: 0s - loss: 0.4679 - acc: 0.7839
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4605 - acc: 0.7835
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4612 - acc: 0.7812
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4652 - acc: 0.7796
1283/1283 [==============================] - 1s 507us/step - loss: 0.4650 - acc: 0.7779 - val_loss: 0.7775 - val_acc: 0.5808

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4378 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4106 - acc: 0.7917
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4055 - acc: 0.8063
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3993 - acc: 0.8301
 640/1283 [=============>................] - ETA: 0s - loss: 0.3970 - acc: 0.8297
 768/1283 [================>.............] - ETA: 0s - loss: 0.3892 - acc: 0.8307
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3851 - acc: 0.8326
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3865 - acc: 0.8271
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3855 - acc: 0.8264
1280/1283 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8258
1283/1283 [==============================] - 1s 526us/step - loss: 0.3878 - acc: 0.8254 - val_loss: 0.8064 - val_acc: 0.5633

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3037 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3292 - acc: 0.8698
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3045 - acc: 0.8938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3184 - acc: 0.8772
 576/1283 [============>.................] - ETA: 0s - loss: 0.3232 - acc: 0.8750
 768/1283 [================>.............] - ETA: 0s - loss: 0.3245 - acc: 0.8672
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3158 - acc: 0.8739
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3157 - acc: 0.8778
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3111 - acc: 0.8775
1283/1283 [==============================] - 1s 516us/step - loss: 0.3085 - acc: 0.8807 - val_loss: 0.8732 - val_acc: 0.5328

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2750 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2494 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2681 - acc: 0.8969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2550 - acc: 0.9085
 640/1283 [=============>................] - ETA: 0s - loss: 0.2539 - acc: 0.9047
 768/1283 [================>.............] - ETA: 0s - loss: 0.2565 - acc: 0.9049
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2518 - acc: 0.9074
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2473 - acc: 0.9062
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2476 - acc: 0.9071
1280/1283 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9062
1283/1283 [==============================] - 1s 513us/step - loss: 0.2465 - acc: 0.9065 - val_loss: 1.0565 - val_acc: 0.5590

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1381 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1618 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1842 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1932 - acc: 0.9375
 576/1283 [============>.................] - ETA: 0s - loss: 0.1891 - acc: 0.9375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1921 - acc: 0.9332
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1823 - acc: 0.9399
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1803 - acc: 0.9414
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1764 - acc: 0.9444
1280/1283 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9430
1283/1283 [==============================] - 1s 523us/step - loss: 0.1770 - acc: 0.9423 - val_loss: 1.2698 - val_acc: 0.5721

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1315 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2554 - acc: 0.8698
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2683 - acc: 0.8724
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2462 - acc: 0.8867
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2661 - acc: 0.8693
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2490 - acc: 0.8783
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2503 - acc: 0.8789
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2375 - acc: 0.8906
1283/1283 [==============================] - 1s 457us/step - loss: 0.2329 - acc: 0.8932 - val_loss: 1.2044 - val_acc: 0.5590

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2589 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1698 - acc: 0.9115
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2028 - acc: 0.9094
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1745 - acc: 0.9277
 640/1283 [=============>................] - ETA: 0s - loss: 0.1697 - acc: 0.9328
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1665 - acc: 0.9375
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1611 - acc: 0.9437
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1590 - acc: 0.9462
1283/1283 [==============================] - 1s 472us/step - loss: 0.1527 - acc: 0.9493 - val_loss: 1.3319 - val_acc: 0.5415

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1165 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1150 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1055 - acc: 0.9583
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0983 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.0962 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0948 - acc: 0.9712
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0935 - acc: 0.9708
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0887 - acc: 0.9743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0897 - acc: 0.9720
1283/1283 [==============================] - 1s 471us/step - loss: 0.0872 - acc: 0.9735 - val_loss: 1.3253 - val_acc: 0.5284

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0725 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0625 - acc: 0.9883
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0580 - acc: 0.9911
 640/1283 [=============>................] - ETA: 0s - loss: 0.0556 - acc: 0.9906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0541 - acc: 0.9916
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0531 - acc: 0.9932
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0534 - acc: 0.9918
1283/1283 [==============================] - 1s 404us/step - loss: 0.0528 - acc: 0.9914 - val_loss: 1.4893 - val_acc: 0.5284

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0295 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0265 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0543 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0497 - acc: 0.9883
 640/1283 [=============>................] - ETA: 0s - loss: 0.0531 - acc: 0.9875
 768/1283 [================>.............] - ETA: 0s - loss: 0.0510 - acc: 0.9883
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0481 - acc: 0.9885
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0481 - acc: 0.9887
1283/1283 [==============================] - 1s 404us/step - loss: 0.0490 - acc: 0.9883 - val_loss: 1.6155 - val_acc: 0.4978

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=15
epochs=100
mode=A
accuracy=0.5524781341107872
best_valid_accuracy=0.4620991253644315
