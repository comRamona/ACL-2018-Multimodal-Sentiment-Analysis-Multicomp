/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 09:39:24.995578: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.6843 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 3s - loss: 0.6855 - acc: 0.5573 
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6918 - acc: 0.5281
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6917 - acc: 0.5268
 576/1283 [============>.................] - ETA: 1s - loss: 0.6904 - acc: 0.5208
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6896 - acc: 0.5312
 768/1283 [================>.............] - ETA: 0s - loss: 0.6887 - acc: 0.5352
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6876 - acc: 0.5357
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6873 - acc: 0.5410
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6860 - acc: 0.5450
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6833 - acc: 0.5518
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6815 - acc: 0.5534 - val_loss: 0.6943 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6557 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6543 - acc: 0.6667
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6560 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6614 - acc: 0.6172
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6664 - acc: 0.6172
 640/1283 [=============>................] - ETA: 0s - loss: 0.6632 - acc: 0.6234
 768/1283 [================>.............] - ETA: 0s - loss: 0.6647 - acc: 0.6185
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6622 - acc: 0.6161
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6605 - acc: 0.6084
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6627 - acc: 0.6068
1280/1283 [============================>.] - ETA: 0s - loss: 0.6640 - acc: 0.6047
1283/1283 [==============================] - 1s 676us/step - loss: 0.6644 - acc: 0.6033 - val_loss: 0.7008 - val_acc: 0.5284

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6814 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6632 - acc: 0.5781
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6574 - acc: 0.5781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6561 - acc: 0.5759
 576/1283 [============>.................] - ETA: 0s - loss: 0.6514 - acc: 0.6059
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6499 - acc: 0.6080
 768/1283 [================>.............] - ETA: 0s - loss: 0.6498 - acc: 0.6068
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6493 - acc: 0.6071
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6515 - acc: 0.6016
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6521 - acc: 0.5983
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6536 - acc: 0.5964
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6538 - acc: 0.5987
1283/1283 [==============================] - 1s 740us/step - loss: 0.6520 - acc: 0.6041 - val_loss: 0.7109 - val_acc: 0.5153

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6183 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6306 - acc: 0.6042
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6372 - acc: 0.6156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6352 - acc: 0.6161
 576/1283 [============>.................] - ETA: 0s - loss: 0.6354 - acc: 0.6163
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6348 - acc: 0.6207
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6344 - acc: 0.6226
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6397 - acc: 0.6135
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6414 - acc: 0.6140
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6422 - acc: 0.6160
1283/1283 [==============================] - 1s 641us/step - loss: 0.6429 - acc: 0.6134 - val_loss: 0.7261 - val_acc: 0.5022

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6052 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5927 - acc: 0.6615
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5865 - acc: 0.6906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6153 - acc: 0.6629
 576/1283 [============>.................] - ETA: 0s - loss: 0.6456 - acc: 0.6285
 640/1283 [=============>................] - ETA: 0s - loss: 0.6419 - acc: 0.6359
 768/1283 [================>.............] - ETA: 0s - loss: 0.6413 - acc: 0.6302
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6440 - acc: 0.6295
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6402 - acc: 0.6289
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6413 - acc: 0.6267
1280/1283 [============================>.] - ETA: 0s - loss: 0.6411 - acc: 0.6266
1283/1283 [==============================] - 1s 669us/step - loss: 0.6417 - acc: 0.6259 - val_loss: 0.7183 - val_acc: 0.4716

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6194 - acc: 0.5938
 128/1283 [=>............................] - ETA: 0s - loss: 0.6061 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6208 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6296 - acc: 0.6031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6283 - acc: 0.6049
 576/1283 [============>.................] - ETA: 0s - loss: 0.6319 - acc: 0.6094
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6387 - acc: 0.6009
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6383 - acc: 0.5938
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6374 - acc: 0.5969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6365 - acc: 0.5977
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6357 - acc: 0.5993
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6340 - acc: 0.6059
1280/1283 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.6133
1283/1283 [==============================] - 1s 799us/step - loss: 0.6336 - acc: 0.6134 - val_loss: 0.7151 - val_acc: 0.5109

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5945 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6248 - acc: 0.6146
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6100 - acc: 0.6562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6115 - acc: 0.6607
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6190 - acc: 0.6504
 640/1283 [=============>................] - ETA: 0s - loss: 0.6178 - acc: 0.6500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6172 - acc: 0.6506
 768/1283 [================>.............] - ETA: 0s - loss: 0.6171 - acc: 0.6484
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6208 - acc: 0.6417
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6212 - acc: 0.6417
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6221 - acc: 0.6379
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6235 - acc: 0.6357
1283/1283 [==============================] - 1s 819us/step - loss: 0.6241 - acc: 0.6368 - val_loss: 0.7254 - val_acc: 0.5153

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6179 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6310 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6397 - acc: 0.6133
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6418 - acc: 0.6125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6163 - acc: 0.6272
 576/1283 [============>.................] - ETA: 0s - loss: 0.6119 - acc: 0.6372
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6173 - acc: 0.6335
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6162 - acc: 0.6334
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6139 - acc: 0.6448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6150 - acc: 0.6425
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6123 - acc: 0.6423
1283/1283 [==============================] - 1s 664us/step - loss: 0.6124 - acc: 0.6454 - val_loss: 0.7443 - val_acc: 0.4978

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6349 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5839 - acc: 0.7240
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5902 - acc: 0.6969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5943 - acc: 0.6875
 576/1283 [============>.................] - ETA: 0s - loss: 0.5899 - acc: 0.6858
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6017 - acc: 0.6648
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6048 - acc: 0.6647
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6064 - acc: 0.6615
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6109 - acc: 0.6526
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6129 - acc: 0.6530
1283/1283 [==============================] - 1s 632us/step - loss: 0.6115 - acc: 0.6532 - val_loss: 0.7667 - val_acc: 0.4716

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6295 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5990 - acc: 0.6615
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6053 - acc: 0.6844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5947 - acc: 0.6853
 576/1283 [============>.................] - ETA: 0s - loss: 0.6063 - acc: 0.6615
 768/1283 [================>.............] - ETA: 0s - loss: 0.6016 - acc: 0.6602
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6044 - acc: 0.6585
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6076 - acc: 0.6553
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6115 - acc: 0.6484
1280/1283 [============================>.] - ETA: 0s - loss: 0.6094 - acc: 0.6484
1283/1283 [==============================] - 1s 601us/step - loss: 0.6094 - acc: 0.6485 - val_loss: 0.7652 - val_acc: 0.4672

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6023 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6010 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5862 - acc: 0.6594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5838 - acc: 0.6719
 576/1283 [============>.................] - ETA: 0s - loss: 0.5799 - acc: 0.6771
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5839 - acc: 0.6776
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5882 - acc: 0.6755
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5888 - acc: 0.6750
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5984 - acc: 0.6615
1280/1283 [============================>.] - ETA: 0s - loss: 0.6000 - acc: 0.6578
1283/1283 [==============================] - 1s 529us/step - loss: 0.5995 - acc: 0.6586 - val_loss: 0.7806 - val_acc: 0.4541

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=20
mode=V
accuracy=0.5422740524781341
best_valid_accuracy=0.5029154518950437
