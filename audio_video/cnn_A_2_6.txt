/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:07:57.372639: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 9s - loss: 0.7582 - acc: 0.4375
 192/1283 [===>..........................] - ETA: 3s - loss: 0.7948 - acc: 0.4688
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7550 - acc: 0.4948
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7541 - acc: 0.5098
 640/1283 [=============>................] - ETA: 0s - loss: 0.7505 - acc: 0.4984
 768/1283 [================>.............] - ETA: 0s - loss: 0.7442 - acc: 0.5078
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7424 - acc: 0.5100
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7358 - acc: 0.5225
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7331 - acc: 0.5165
1280/1283 [============================>.] - ETA: 0s - loss: 0.7277 - acc: 0.5242
1283/1283 [==============================] - 1s 883us/step - loss: 0.7273 - acc: 0.5246 - val_loss: 0.7031 - val_acc: 0.5590

Epoch 00001: val_acc improved from -inf to 0.55895, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6475 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6532 - acc: 0.5885
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6537 - acc: 0.5969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6508 - acc: 0.6042
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6472 - acc: 0.6250
 640/1283 [=============>................] - ETA: 0s - loss: 0.6435 - acc: 0.6375
 768/1283 [================>.............] - ETA: 0s - loss: 0.6430 - acc: 0.6432
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6427 - acc: 0.6417
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6381 - acc: 0.6475
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6319 - acc: 0.6580
1283/1283 [==============================] - 1s 525us/step - loss: 0.6323 - acc: 0.6555 - val_loss: 0.7612 - val_acc: 0.5284

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6078 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5810 - acc: 0.6797
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5788 - acc: 0.6719
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5871 - acc: 0.6738
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5819 - acc: 0.6804
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5811 - acc: 0.6851
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5760 - acc: 0.6992
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5751 - acc: 0.6998
1283/1283 [==============================] - 1s 417us/step - loss: 0.5771 - acc: 0.6968 - val_loss: 0.7365 - val_acc: 0.5546

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5946 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5404 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5221 - acc: 0.7281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5244 - acc: 0.7143
 576/1283 [============>.................] - ETA: 0s - loss: 0.5204 - acc: 0.7240
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5274 - acc: 0.7202
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5304 - acc: 0.7188
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5293 - acc: 0.7271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5315 - acc: 0.7261
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5260 - acc: 0.7303
1283/1283 [==============================] - 1s 531us/step - loss: 0.5292 - acc: 0.7264 - val_loss: 0.8356 - val_acc: 0.4891

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5125 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5076 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4918 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4799 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4759 - acc: 0.7760
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4659 - acc: 0.7855
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4589 - acc: 0.7945
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4560 - acc: 0.7990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4552 - acc: 0.7996
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4553 - acc: 0.7969
1283/1283 [==============================] - 1s 553us/step - loss: 0.4529 - acc: 0.8005 - val_loss: 0.7845 - val_acc: 0.5764

Epoch 00005: val_acc improved from 0.55895 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3747 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3119 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3403 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3567 - acc: 0.8875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3657 - acc: 0.8683
 576/1283 [============>.................] - ETA: 0s - loss: 0.3600 - acc: 0.8663
 640/1283 [=============>................] - ETA: 0s - loss: 0.3646 - acc: 0.8641
 768/1283 [================>.............] - ETA: 0s - loss: 0.3624 - acc: 0.8633
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3554 - acc: 0.8661
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3622 - acc: 0.8613
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3647 - acc: 0.8576
1280/1283 [============================>.] - ETA: 0s - loss: 0.3658 - acc: 0.8523
1283/1283 [==============================] - 1s 679us/step - loss: 0.3669 - acc: 0.8511 - val_loss: 0.8396 - val_acc: 0.5197

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2883 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3385 - acc: 0.8333
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3463 - acc: 0.8187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3510 - acc: 0.8259
 576/1283 [============>.................] - ETA: 0s - loss: 0.3486 - acc: 0.8351
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3623 - acc: 0.8281
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3590 - acc: 0.8365
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3670 - acc: 0.8313
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3662 - acc: 0.8300
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3679 - acc: 0.8314
1283/1283 [==============================] - 1s 547us/step - loss: 0.3657 - acc: 0.8332 - val_loss: 0.8880 - val_acc: 0.5721

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2994 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2951 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2851 - acc: 0.8875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2818 - acc: 0.8951
 576/1283 [============>.................] - ETA: 0s - loss: 0.2827 - acc: 0.9010
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2732 - acc: 0.9048
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2728 - acc: 0.9002
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2704 - acc: 0.9010
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2685 - acc: 0.8980
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2637 - acc: 0.9005
1283/1283 [==============================] - 1s 530us/step - loss: 0.2636 - acc: 0.8987 - val_loss: 0.9151 - val_acc: 0.5371

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1971 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1931 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1974 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1971 - acc: 0.9353
 576/1283 [============>.................] - ETA: 0s - loss: 0.2048 - acc: 0.9271
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1966 - acc: 0.9304
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1916 - acc: 0.9339
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1921 - acc: 0.9333
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1953 - acc: 0.9320
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1914 - acc: 0.9326
1283/1283 [==============================] - 1s 535us/step - loss: 0.1922 - acc: 0.9314 - val_loss: 1.0099 - val_acc: 0.5764

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1785 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1555 - acc: 0.9427
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1413 - acc: 0.9479
 576/1283 [============>.................] - ETA: 0s - loss: 0.1464 - acc: 0.9427
 768/1283 [================>.............] - ETA: 0s - loss: 0.1445 - acc: 0.9453
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1417 - acc: 0.9510
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1418 - acc: 0.9505
1280/1283 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9531
1283/1283 [==============================] - 1s 420us/step - loss: 0.1371 - acc: 0.9525 - val_loss: 1.0551 - val_acc: 0.5502

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0998 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1122 - acc: 0.9570
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1305 - acc: 0.9442
 640/1283 [=============>................] - ETA: 0s - loss: 0.1269 - acc: 0.9484
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1196 - acc: 0.9567
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1175 - acc: 0.9609
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1135 - acc: 0.9635
1283/1283 [==============================] - 1s 429us/step - loss: 0.1132 - acc: 0.9634 - val_loss: 1.1961 - val_acc: 0.5153

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0797 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0613 - acc: 0.9805
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0680 - acc: 0.9866
 576/1283 [============>.................] - ETA: 0s - loss: 0.0771 - acc: 0.9809
 768/1283 [================>.............] - ETA: 0s - loss: 0.0842 - acc: 0.9779
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0905 - acc: 0.9740
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0982 - acc: 0.9679
1283/1283 [==============================] - 1s 415us/step - loss: 0.0963 - acc: 0.9680 - val_loss: 1.4689 - val_acc: 0.5197

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1185 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1005 - acc: 0.9648
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0885 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0932 - acc: 0.9656
 768/1283 [================>.............] - ETA: 0s - loss: 0.0850 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0801 - acc: 0.9719
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0808 - acc: 0.9722
1280/1283 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9742
1283/1283 [==============================] - 1s 399us/step - loss: 0.0777 - acc: 0.9743 - val_loss: 1.4187 - val_acc: 0.4978

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0463 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0450 - acc: 0.9948
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0502 - acc: 0.9896
 576/1283 [============>.................] - ETA: 0s - loss: 0.0527 - acc: 0.9861
 768/1283 [================>.............] - ETA: 0s - loss: 0.0504 - acc: 0.9870
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0503 - acc: 0.9855
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0473 - acc: 0.9862
1280/1283 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9844
1283/1283 [==============================] - 1s 397us/step - loss: 0.0504 - acc: 0.9844 - val_loss: 1.4776 - val_acc: 0.5109

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0314 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0319 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0402 - acc: 0.9766
 576/1283 [============>.................] - ETA: 0s - loss: 0.0374 - acc: 0.9809
 768/1283 [================>.............] - ETA: 0s - loss: 0.0372 - acc: 0.9818
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0378 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0382 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9859
1283/1283 [==============================] - 0s 370us/step - loss: 0.0370 - acc: 0.9860 - val_loss: 1.8459 - val_acc: 0.5371

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=20
epochs=100
mode=A
accuracy=0.5072886297376094
best_valid_accuracy=0.47959183673469385
