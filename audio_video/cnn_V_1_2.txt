/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:15:25.539778: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.7437 - acc: 0.4688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.7195 - acc: 0.4906
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7040 - acc: 0.4941
 640/1283 [=============>................] - ETA: 0s - loss: 0.7036 - acc: 0.4906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7137 - acc: 0.5180
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7090 - acc: 0.5271
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7013 - acc: 0.5339
1283/1283 [==============================] - 1s 515us/step - loss: 0.6954 - acc: 0.5425 - val_loss: 0.7067 - val_acc: 0.5240

Epoch 00001: val_acc improved from -inf to 0.52402, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6386 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6673 - acc: 0.5898
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6622 - acc: 0.5871
 576/1283 [============>.................] - ETA: 0s - loss: 0.6793 - acc: 0.5851
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6742 - acc: 0.5866
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6639 - acc: 0.6027
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6625 - acc: 0.6066
1280/1283 [============================>.] - ETA: 0s - loss: 0.6560 - acc: 0.6156
1283/1283 [==============================] - 0s 380us/step - loss: 0.6561 - acc: 0.6157 - val_loss: 0.7038 - val_acc: 0.5240

Epoch 00002: val_acc improved from 0.52402 to 0.52402, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6544 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6353 - acc: 0.6219
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6344 - acc: 0.6250
 640/1283 [=============>................] - ETA: 0s - loss: 0.6306 - acc: 0.6344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6325 - acc: 0.6370
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6304 - acc: 0.6348
1280/1283 [============================>.] - ETA: 0s - loss: 0.6411 - acc: 0.6305
1283/1283 [==============================] - 0s 306us/step - loss: 0.6409 - acc: 0.6306 - val_loss: 0.7168 - val_acc: 0.5284

Epoch 00003: val_acc improved from 0.52402 to 0.52838, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6375 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6064 - acc: 0.6656
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6156 - acc: 0.6602
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6229 - acc: 0.6548
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6173 - acc: 0.6730
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6099 - acc: 0.6736
1283/1283 [==============================] - 0s 344us/step - loss: 0.6116 - acc: 0.6648 - val_loss: 0.7458 - val_acc: 0.5022

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5839 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5896 - acc: 0.6562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5891 - acc: 0.6629
 640/1283 [=============>................] - ETA: 0s - loss: 0.5883 - acc: 0.6750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5941 - acc: 0.6695
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6009 - acc: 0.6646
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6064 - acc: 0.6528
1283/1283 [==============================] - 0s 376us/step - loss: 0.6043 - acc: 0.6578 - val_loss: 0.7404 - val_acc: 0.5197

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5454 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5708 - acc: 0.6953
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5750 - acc: 0.6979
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5690 - acc: 0.7090
 640/1283 [=============>................] - ETA: 0s - loss: 0.5705 - acc: 0.7000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5794 - acc: 0.6863
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5905 - acc: 0.6807
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5864 - acc: 0.6834
1283/1283 [==============================] - 1s 401us/step - loss: 0.5844 - acc: 0.6843 - val_loss: 0.7745 - val_acc: 0.4585

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5934 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5637 - acc: 0.6992
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5671 - acc: 0.6942
 640/1283 [=============>................] - ETA: 0s - loss: 0.5684 - acc: 0.6953
 768/1283 [================>.............] - ETA: 0s - loss: 0.5718 - acc: 0.6953
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5661 - acc: 0.6987
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5721 - acc: 0.6934
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5718 - acc: 0.6949
1283/1283 [==============================] - 0s 382us/step - loss: 0.5707 - acc: 0.6968 - val_loss: 0.8546 - val_acc: 0.4672

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6663 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5725 - acc: 0.6953
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5593 - acc: 0.7121
 640/1283 [=============>................] - ETA: 0s - loss: 0.5558 - acc: 0.7203
 768/1283 [================>.............] - ETA: 0s - loss: 0.5669 - acc: 0.7109
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5702 - acc: 0.7054
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5688 - acc: 0.7061
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5668 - acc: 0.7130
1283/1283 [==============================] - 1s 395us/step - loss: 0.5649 - acc: 0.7194 - val_loss: 0.7745 - val_acc: 0.4672

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5431 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5751 - acc: 0.7083
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5687 - acc: 0.7031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5621 - acc: 0.7143
 640/1283 [=============>................] - ETA: 0s - loss: 0.5579 - acc: 0.7125
 768/1283 [================>.............] - ETA: 0s - loss: 0.5549 - acc: 0.7070
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5465 - acc: 0.7188
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5398 - acc: 0.7256
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5472 - acc: 0.7170
1283/1283 [==============================] - 1s 472us/step - loss: 0.5503 - acc: 0.7155 - val_loss: 0.8404 - val_acc: 0.4672

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4787 - acc: 0.7969
 128/1283 [=>............................] - ETA: 0s - loss: 0.4868 - acc: 0.7891
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5216 - acc: 0.7469
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5353 - acc: 0.7520
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5375 - acc: 0.7415
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5467 - acc: 0.7333
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5487 - acc: 0.7316
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5417 - acc: 0.7360
1283/1283 [==============================] - 1s 419us/step - loss: 0.5416 - acc: 0.7350 - val_loss: 0.7827 - val_acc: 0.5022

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4909 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4890 - acc: 0.7500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4949 - acc: 0.7545
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4964 - acc: 0.7520
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5066 - acc: 0.7457
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5203 - acc: 0.7333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5198 - acc: 0.7383
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5155 - acc: 0.7413
1280/1283 [============================>.] - ETA: 0s - loss: 0.5191 - acc: 0.7398
1283/1283 [==============================] - 1s 459us/step - loss: 0.5192 - acc: 0.7397 - val_loss: 0.8575 - val_acc: 0.4760

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4936 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4995 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4950 - acc: 0.7688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4915 - acc: 0.7656
 640/1283 [=============>................] - ETA: 0s - loss: 0.4985 - acc: 0.7609
 768/1283 [================>.............] - ETA: 0s - loss: 0.4926 - acc: 0.7669
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4876 - acc: 0.7734
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4906 - acc: 0.7675
1280/1283 [============================>.] - ETA: 0s - loss: 0.4914 - acc: 0.7633
1283/1283 [==============================] - 1s 453us/step - loss: 0.4916 - acc: 0.7631 - val_loss: 0.8145 - val_acc: 0.4934

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4198 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5148 - acc: 0.7344
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5133 - acc: 0.7520
 640/1283 [=============>................] - ETA: 0s - loss: 0.5285 - acc: 0.7453
 768/1283 [================>.............] - ETA: 0s - loss: 0.5304 - acc: 0.7487
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5227 - acc: 0.7478
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5159 - acc: 0.7555
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5126 - acc: 0.7558
1283/1283 [==============================] - 1s 408us/step - loss: 0.5061 - acc: 0.7607 - val_loss: 0.8350 - val_acc: 0.4760

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
epochs=100
mode=V
accuracy=0.5408163265306123
best_valid_accuracy=0.5262390670553936
