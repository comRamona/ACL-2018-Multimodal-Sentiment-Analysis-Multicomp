/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 09:39:44.652825: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.6872 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6897 - acc: 0.5469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6871 - acc: 0.5558
 640/1283 [=============>................] - ETA: 0s - loss: 0.6847 - acc: 0.5641
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6826 - acc: 0.5625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6799 - acc: 0.5684
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6799 - acc: 0.5740
1283/1283 [==============================] - 1s 515us/step - loss: 0.6797 - acc: 0.5721 - val_loss: 0.6904 - val_acc: 0.5721

Epoch 00001: val_acc improved from -inf to 0.57205, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6494 - acc: 0.5781
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6645 - acc: 0.5898
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6613 - acc: 0.6183
 640/1283 [=============>................] - ETA: 0s - loss: 0.6575 - acc: 0.5984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6586 - acc: 0.5938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6619 - acc: 0.5898
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6619 - acc: 0.5888
1283/1283 [==============================] - 0s 384us/step - loss: 0.6611 - acc: 0.5885 - val_loss: 0.7005 - val_acc: 0.5415

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6660 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6557 - acc: 0.5742
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6577 - acc: 0.5938
 640/1283 [=============>................] - ETA: 0s - loss: 0.6568 - acc: 0.6000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6564 - acc: 0.5901
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6537 - acc: 0.5967
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6496 - acc: 0.6102
1283/1283 [==============================] - 0s 387us/step - loss: 0.6479 - acc: 0.6126 - val_loss: 0.7138 - val_acc: 0.5459

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6371 - acc: 0.5781
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6278 - acc: 0.6367
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6326 - acc: 0.6250
 640/1283 [=============>................] - ETA: 0s - loss: 0.6382 - acc: 0.6156
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6391 - acc: 0.6178
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6417 - acc: 0.6191
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6423 - acc: 0.6135
1283/1283 [==============================] - 0s 382us/step - loss: 0.6429 - acc: 0.6150 - val_loss: 0.7247 - val_acc: 0.5197

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6310 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6411 - acc: 0.6523
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6306 - acc: 0.6607
 640/1283 [=============>................] - ETA: 0s - loss: 0.6297 - acc: 0.6562
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6265 - acc: 0.6611
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6286 - acc: 0.6445
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6285 - acc: 0.6390
1283/1283 [==============================] - 0s 379us/step - loss: 0.6264 - acc: 0.6422 - val_loss: 0.7267 - val_acc: 0.5153

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6360 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6332 - acc: 0.6133
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6211 - acc: 0.6116
 640/1283 [=============>................] - ETA: 0s - loss: 0.6294 - acc: 0.6016
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6200 - acc: 0.6190
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6191 - acc: 0.6250
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6200 - acc: 0.6324
1283/1283 [==============================] - 0s 379us/step - loss: 0.6220 - acc: 0.6290 - val_loss: 0.7258 - val_acc: 0.5109

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6007 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6142 - acc: 0.6445
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6162 - acc: 0.6429
 640/1283 [=============>................] - ETA: 0s - loss: 0.6100 - acc: 0.6547
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6162 - acc: 0.6430
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6144 - acc: 0.6455
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6169 - acc: 0.6398
1283/1283 [==============================] - 0s 382us/step - loss: 0.6191 - acc: 0.6360 - val_loss: 0.7261 - val_acc: 0.5197

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6528 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6110 - acc: 0.6445
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6181 - acc: 0.6295
 640/1283 [=============>................] - ETA: 0s - loss: 0.6184 - acc: 0.6391
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6237 - acc: 0.6322
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6231 - acc: 0.6318
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6234 - acc: 0.6316
1283/1283 [==============================] - 0s 375us/step - loss: 0.6240 - acc: 0.6329 - val_loss: 0.7265 - val_acc: 0.4760

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5766 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6031 - acc: 0.6758
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5997 - acc: 0.6808
 640/1283 [=============>................] - ETA: 0s - loss: 0.5959 - acc: 0.6797
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6019 - acc: 0.6767
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6052 - acc: 0.6689
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6069 - acc: 0.6653
1283/1283 [==============================] - 0s 376us/step - loss: 0.6110 - acc: 0.6594 - val_loss: 0.7640 - val_acc: 0.4760

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5863 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5784 - acc: 0.6562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6019 - acc: 0.6451
 640/1283 [=============>................] - ETA: 0s - loss: 0.6040 - acc: 0.6438
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5997 - acc: 0.6514
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6056 - acc: 0.6533
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6099 - acc: 0.6456
1283/1283 [==============================] - 0s 389us/step - loss: 0.6062 - acc: 0.6508 - val_loss: 0.7520 - val_acc: 0.4585

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6029 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6053 - acc: 0.6562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6012 - acc: 0.6362
 640/1283 [=============>................] - ETA: 0s - loss: 0.6040 - acc: 0.6344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6128 - acc: 0.6262
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6050 - acc: 0.6348
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6050 - acc: 0.6382
1283/1283 [==============================] - 0s 377us/step - loss: 0.6029 - acc: 0.6438 - val_loss: 0.7485 - val_acc: 0.4716

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
mode=V
accuracy=0.5
best_valid_accuracy=0.4956268221574344
