/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 08:38:48.176238: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.7063 - acc: 0.4375
 128/1283 [=>............................] - ETA: 6s - loss: 0.7024 - acc: 0.5000 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.6948 - acc: 0.5312
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7036 - acc: 0.5039
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7034 - acc: 0.5062
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7011 - acc: 0.5078
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7040 - acc: 0.5000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7027 - acc: 0.4961
 640/1283 [=============>................] - ETA: 1s - loss: 0.7023 - acc: 0.5000
 768/1283 [================>.............] - ETA: 0s - loss: 0.7018 - acc: 0.4987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7000 - acc: 0.5060
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6980 - acc: 0.5123
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6994 - acc: 0.5146
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6971 - acc: 0.5264
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6973 - acc: 0.5239
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6959 - acc: 0.5269
1280/1283 [============================>.] - ETA: 0s - loss: 0.6954 - acc: 0.5266
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6952 - acc: 0.5269 - val_loss: 0.6853 - val_acc: 0.5240

Epoch 00001: val_acc improved from -inf to 0.52402, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6720 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6676 - acc: 0.5885
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6649 - acc: 0.5977
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6694 - acc: 0.6042
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6701 - acc: 0.6027
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6691 - acc: 0.5977
 576/1283 [============>.................] - ETA: 0s - loss: 0.6673 - acc: 0.6024
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6724 - acc: 0.5881
 768/1283 [================>.............] - ETA: 0s - loss: 0.6689 - acc: 0.5938
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6656 - acc: 0.6046
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6641 - acc: 0.6104
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6641 - acc: 0.6094
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6622 - acc: 0.6120
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6620 - acc: 0.6118
1283/1283 [==============================] - 1s 894us/step - loss: 0.6614 - acc: 0.6126 - val_loss: 0.6820 - val_acc: 0.5546

Epoch 00002: val_acc improved from 0.52402 to 0.55459, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6450 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6361 - acc: 0.6615
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6402 - acc: 0.6500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6410 - acc: 0.6380
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6371 - acc: 0.6429
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6371 - acc: 0.6387
 576/1283 [============>.................] - ETA: 0s - loss: 0.6370 - acc: 0.6337
 640/1283 [=============>................] - ETA: 0s - loss: 0.6342 - acc: 0.6391
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6356 - acc: 0.6321
 768/1283 [================>.............] - ETA: 0s - loss: 0.6389 - acc: 0.6276
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6344 - acc: 0.6370
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6341 - acc: 0.6373
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6372 - acc: 0.6323
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6376 - acc: 0.6318
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6369 - acc: 0.6305
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6396 - acc: 0.6259
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6419 - acc: 0.6225
1280/1283 [============================>.] - ETA: 0s - loss: 0.6446 - acc: 0.6156
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6447 - acc: 0.6157 - val_loss: 0.6851 - val_acc: 0.5502

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6496 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6452 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6411 - acc: 0.6458
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6352 - acc: 0.6484
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6389 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6299 - acc: 0.6432
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6318 - acc: 0.6473
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6303 - acc: 0.6504
 640/1283 [=============>................] - ETA: 0s - loss: 0.6306 - acc: 0.6562
 768/1283 [================>.............] - ETA: 0s - loss: 0.6279 - acc: 0.6562
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6275 - acc: 0.6526
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6287 - acc: 0.6458
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6282 - acc: 0.6455
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6276 - acc: 0.6461
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6206 - acc: 0.6546
1280/1283 [============================>.] - ETA: 0s - loss: 0.6204 - acc: 0.6531
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6200 - acc: 0.6539 - val_loss: 0.6806 - val_acc: 0.5808

Epoch 00004: val_acc improved from 0.55459 to 0.58079, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5480 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5794 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5736 - acc: 0.7227
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5817 - acc: 0.7094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5813 - acc: 0.7005
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5891 - acc: 0.6897
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6045 - acc: 0.6758
 576/1283 [============>.................] - ETA: 0s - loss: 0.6090 - acc: 0.6684
 640/1283 [=============>................] - ETA: 0s - loss: 0.6078 - acc: 0.6719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6064 - acc: 0.6719
 768/1283 [================>.............] - ETA: 0s - loss: 0.6051 - acc: 0.6719
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6069 - acc: 0.6731
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6089 - acc: 0.6685
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6101 - acc: 0.6635
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6103 - acc: 0.6641
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6072 - acc: 0.6664
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6088 - acc: 0.6632
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6075 - acc: 0.6645
1280/1283 [============================>.] - ETA: 0s - loss: 0.6063 - acc: 0.6664
1283/1283 [==============================] - 1s 986us/step - loss: 0.6067 - acc: 0.6664 - val_loss: 0.6824 - val_acc: 0.5895

Epoch 00005: val_acc improved from 0.58079 to 0.58952, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4740 - acc: 0.8125
 128/1283 [=>............................] - ETA: 0s - loss: 0.5444 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5475 - acc: 0.7292
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5573 - acc: 0.7227
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5612 - acc: 0.7125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5549 - acc: 0.7240
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5614 - acc: 0.7254
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5629 - acc: 0.7305
 576/1283 [============>.................] - ETA: 0s - loss: 0.5752 - acc: 0.7170
 640/1283 [=============>................] - ETA: 0s - loss: 0.5788 - acc: 0.7109
 768/1283 [================>.............] - ETA: 0s - loss: 0.5883 - acc: 0.6914
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5848 - acc: 0.6935
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5847 - acc: 0.6953
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5828 - acc: 0.6973
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5821 - acc: 0.6994
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5836 - acc: 0.6970
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5801 - acc: 0.6998
1280/1283 [============================>.] - ETA: 0s - loss: 0.5797 - acc: 0.6977
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5799 - acc: 0.6976 - val_loss: 0.6738 - val_acc: 0.5590

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4794 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.5105 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5147 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5305 - acc: 0.7734
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5097 - acc: 0.7812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5217 - acc: 0.7656
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5227 - acc: 0.7598
 576/1283 [============>.................] - ETA: 0s - loss: 0.5308 - acc: 0.7535
 640/1283 [=============>................] - ETA: 0s - loss: 0.5301 - acc: 0.7516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5339 - acc: 0.7472
 768/1283 [================>.............] - ETA: 0s - loss: 0.5385 - acc: 0.7370
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5350 - acc: 0.7392
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5366 - acc: 0.7400
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5380 - acc: 0.7396
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5349 - acc: 0.7412
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5415 - acc: 0.7371
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5433 - acc: 0.7361
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5450 - acc: 0.7360
1280/1283 [============================>.] - ETA: 0s - loss: 0.5460 - acc: 0.7359
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5474 - acc: 0.7350 - val_loss: 0.6757 - val_acc: 0.5633

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4867 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.5049 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4987 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5120 - acc: 0.7344
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5301 - acc: 0.7156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5299 - acc: 0.7214
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5320 - acc: 0.7143
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5220 - acc: 0.7324
 640/1283 [=============>................] - ETA: 0s - loss: 0.5229 - acc: 0.7328
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5285 - acc: 0.7344
 768/1283 [================>.............] - ETA: 0s - loss: 0.5300 - acc: 0.7370
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5281 - acc: 0.7368
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5252 - acc: 0.7377
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5267 - acc: 0.7344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5271 - acc: 0.7314
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5370 - acc: 0.7215
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5356 - acc: 0.7240
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5362 - acc: 0.7229
1280/1283 [============================>.] - ETA: 0s - loss: 0.5383 - acc: 0.7219
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5383 - acc: 0.7217 - val_loss: 0.6766 - val_acc: 0.5983

Epoch 00008: val_acc improved from 0.58952 to 0.59825, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5717 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5182 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5068 - acc: 0.8021
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5187 - acc: 0.7812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5192 - acc: 0.7679
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5110 - acc: 0.7734
 576/1283 [============>.................] - ETA: 0s - loss: 0.5183 - acc: 0.7622
 640/1283 [=============>................] - ETA: 0s - loss: 0.5224 - acc: 0.7625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5272 - acc: 0.7557
 768/1283 [================>.............] - ETA: 0s - loss: 0.5257 - acc: 0.7500
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5251 - acc: 0.7500
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5202 - acc: 0.7545
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5173 - acc: 0.7562
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5129 - acc: 0.7588
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5121 - acc: 0.7592
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5093 - acc: 0.7639
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5116 - acc: 0.7582
1280/1283 [============================>.] - ETA: 0s - loss: 0.5111 - acc: 0.7578
1283/1283 [==============================] - 1s 998us/step - loss: 0.5109 - acc: 0.7584 - val_loss: 0.6775 - val_acc: 0.5852

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4633 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.4595 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4634 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4774 - acc: 0.7734
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4741 - acc: 0.7812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4618 - acc: 0.7865
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4678 - acc: 0.7790
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4608 - acc: 0.7832
 576/1283 [============>.................] - ETA: 0s - loss: 0.4775 - acc: 0.7691
 640/1283 [=============>................] - ETA: 0s - loss: 0.4703 - acc: 0.7797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4641 - acc: 0.7827
 768/1283 [================>.............] - ETA: 0s - loss: 0.4658 - acc: 0.7878
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4705 - acc: 0.7837
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4711 - acc: 0.7790
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4691 - acc: 0.7781
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4725 - acc: 0.7776
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4733 - acc: 0.7743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4753 - acc: 0.7697
1280/1283 [============================>.] - ETA: 0s - loss: 0.4739 - acc: 0.7727
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4732 - acc: 0.7732 - val_loss: 0.7175 - val_acc: 0.5808

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4531 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.4335 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4337 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4352 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4423 - acc: 0.8344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4361 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4295 - acc: 0.8393
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4326 - acc: 0.8359
 576/1283 [============>.................] - ETA: 0s - loss: 0.4292 - acc: 0.8333
 640/1283 [=============>................] - ETA: 0s - loss: 0.4372 - acc: 0.8234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4338 - acc: 0.8224
 768/1283 [================>.............] - ETA: 0s - loss: 0.4366 - acc: 0.8216
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4351 - acc: 0.8209
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4375 - acc: 0.8181
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4372 - acc: 0.8177
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4409 - acc: 0.8135
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4501 - acc: 0.8070
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4513 - acc: 0.8038
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4469 - acc: 0.8067
1280/1283 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.8063
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4441 - acc: 0.8051 - val_loss: 0.7263 - val_acc: 0.5939

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5496 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.4281 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4243 - acc: 0.8021
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4162 - acc: 0.8086
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4159 - acc: 0.8063
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4257 - acc: 0.8047
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4198 - acc: 0.8027
 640/1283 [=============>................] - ETA: 0s - loss: 0.4263 - acc: 0.8047
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4285 - acc: 0.8026
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4224 - acc: 0.8041
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4308 - acc: 0.7958
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4333 - acc: 0.7937
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4322 - acc: 0.7939
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4313 - acc: 0.7960
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4290 - acc: 0.8003
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4313 - acc: 0.7985
1280/1283 [============================>.] - ETA: 0s - loss: 0.4338 - acc: 0.7945
1283/1283 [==============================] - 1s 948us/step - loss: 0.4336 - acc: 0.7942 - val_loss: 0.7507 - val_acc: 0.5590

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3489 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3707 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4064 - acc: 0.8086
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3994 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4081 - acc: 0.8021
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4103 - acc: 0.8058
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4109 - acc: 0.8047
 640/1283 [=============>................] - ETA: 0s - loss: 0.4183 - acc: 0.8063
 768/1283 [================>.............] - ETA: 0s - loss: 0.4190 - acc: 0.7982
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4177 - acc: 0.7969
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4066 - acc: 0.8080
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4066 - acc: 0.8094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4082 - acc: 0.8096
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4054 - acc: 0.8134
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4024 - acc: 0.8133
1283/1283 [==============================] - 1s 906us/step - loss: 0.4047 - acc: 0.8106 - val_loss: 0.7559 - val_acc: 0.5852

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3615 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3112 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3205 - acc: 0.8633
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3195 - acc: 0.8719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3464 - acc: 0.8415
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3507 - acc: 0.8379
 576/1283 [============>.................] - ETA: 0s - loss: 0.3565 - acc: 0.8333
 640/1283 [=============>................] - ETA: 0s - loss: 0.3680 - acc: 0.8281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3700 - acc: 0.8295
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3713 - acc: 0.8329
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3643 - acc: 0.8406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3654 - acc: 0.8398
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3791 - acc: 0.8342
1280/1283 [============================>.] - ETA: 0s - loss: 0.3753 - acc: 0.8383
1283/1283 [==============================] - 1s 861us/step - loss: 0.3747 - acc: 0.8387 - val_loss: 0.7302 - val_acc: 0.5852

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3363 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3182 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3345 - acc: 0.8672
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3486 - acc: 0.8531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3452 - acc: 0.8542
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3449 - acc: 0.8504
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3447 - acc: 0.8457
 576/1283 [============>.................] - ETA: 0s - loss: 0.3416 - acc: 0.8490
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3508 - acc: 0.8352
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3488 - acc: 0.8329
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3467 - acc: 0.8359
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3419 - acc: 0.8389
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3424 - acc: 0.8382
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3459 - acc: 0.8339
1280/1283 [============================>.] - ETA: 0s - loss: 0.3491 - acc: 0.8320
1283/1283 [==============================] - 1s 900us/step - loss: 0.3518 - acc: 0.8309 - val_loss: 0.7948 - val_acc: 0.5764

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3195 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.3304 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2992 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3264 - acc: 0.8724
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3259 - acc: 0.8672
 576/1283 [============>.................] - ETA: 0s - loss: 0.3332 - acc: 0.8611
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3308 - acc: 0.8580
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3343 - acc: 0.8570
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3322 - acc: 0.8573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3281 - acc: 0.8604
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3269 - acc: 0.8603
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3251 - acc: 0.8627
1283/1283 [==============================] - 1s 807us/step - loss: 0.3274 - acc: 0.8597 - val_loss: 0.8260 - val_acc: 0.5459

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3705 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3668 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3430 - acc: 0.8164
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3290 - acc: 0.8281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3266 - acc: 0.8348
 576/1283 [============>.................] - ETA: 0s - loss: 0.3269 - acc: 0.8351
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3346 - acc: 0.8423
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3297 - acc: 0.8462
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3240 - acc: 0.8510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3227 - acc: 0.8529
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3141 - acc: 0.8602
1280/1283 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.8594
1283/1283 [==============================] - 1s 726us/step - loss: 0.3167 - acc: 0.8597 - val_loss: 0.9290 - val_acc: 0.5633

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2549 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2760 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2827 - acc: 0.8828
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2667 - acc: 0.8984
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2636 - acc: 0.8984
 640/1283 [=============>................] - ETA: 0s - loss: 0.2620 - acc: 0.9000
 768/1283 [================>.............] - ETA: 0s - loss: 0.2560 - acc: 0.9049
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2665 - acc: 0.8984
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2611 - acc: 0.9014
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2671 - acc: 0.8958
1280/1283 [============================>.] - ETA: 0s - loss: 0.2735 - acc: 0.8906
1283/1283 [==============================] - 1s 698us/step - loss: 0.2736 - acc: 0.8909 - val_loss: 0.9319 - val_acc: 0.5808

Epoch 00018: val_acc did not improve
Epoch 00018: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=20
mode=A
accuracy=0.5014577259475219
best_valid_accuracy=0.4912536443148688
