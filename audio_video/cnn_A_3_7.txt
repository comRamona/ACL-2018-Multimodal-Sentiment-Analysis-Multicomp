/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:14:44.936343: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.7457 - acc: 0.4375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7169 - acc: 0.4948
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7384 - acc: 0.4875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7231 - acc: 0.5067
 576/1283 [============>.................] - ETA: 0s - loss: 0.7183 - acc: 0.5087
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7148 - acc: 0.5071
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7108 - acc: 0.5108
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7092 - acc: 0.5104
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7062 - acc: 0.5156
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7027 - acc: 0.5238
1283/1283 [==============================] - 1s 791us/step - loss: 0.7020 - acc: 0.5253 - val_loss: 0.7171 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6605 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6980 - acc: 0.5469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6931 - acc: 0.5469
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6834 - acc: 0.5586
 640/1283 [=============>................] - ETA: 0s - loss: 0.6852 - acc: 0.5531
 768/1283 [================>.............] - ETA: 0s - loss: 0.6792 - acc: 0.5625
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6759 - acc: 0.5759
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6743 - acc: 0.5801
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6730 - acc: 0.5799
1280/1283 [============================>.] - ETA: 0s - loss: 0.6702 - acc: 0.5852
1283/1283 [==============================] - 1s 513us/step - loss: 0.6701 - acc: 0.5853 - val_loss: 0.6981 - val_acc: 0.5371

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6513 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6411 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6312 - acc: 0.6523
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6235 - acc: 0.6745
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6271 - acc: 0.6641
 640/1283 [=============>................] - ETA: 0s - loss: 0.6234 - acc: 0.6625
 768/1283 [================>.............] - ETA: 0s - loss: 0.6255 - acc: 0.6615
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6231 - acc: 0.6585
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6261 - acc: 0.6543
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6248 - acc: 0.6545
1280/1283 [============================>.] - ETA: 0s - loss: 0.6287 - acc: 0.6469
1283/1283 [==============================] - 1s 666us/step - loss: 0.6291 - acc: 0.6454 - val_loss: 0.7349 - val_acc: 0.5066

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5958 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6229 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5793 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5861 - acc: 0.6875
 576/1283 [============>.................] - ETA: 0s - loss: 0.6021 - acc: 0.6684
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6082 - acc: 0.6662
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5982 - acc: 0.6827
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5973 - acc: 0.6792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6007 - acc: 0.6765
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6016 - acc: 0.6752
1283/1283 [==============================] - 1s 653us/step - loss: 0.6012 - acc: 0.6734 - val_loss: 0.7771 - val_acc: 0.4978

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6384 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6469 - acc: 0.5521
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6283 - acc: 0.5906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6284 - acc: 0.6250
 576/1283 [============>.................] - ETA: 0s - loss: 0.6318 - acc: 0.6372
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6110 - acc: 0.6548
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6086 - acc: 0.6599
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6001 - acc: 0.6698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6004 - acc: 0.6673
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5941 - acc: 0.6760
1283/1283 [==============================] - 1s 659us/step - loss: 0.5929 - acc: 0.6765 - val_loss: 0.7287 - val_acc: 0.5022

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5331 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5125 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5168 - acc: 0.7562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5181 - acc: 0.7567
 576/1283 [============>.................] - ETA: 0s - loss: 0.5106 - acc: 0.7674
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5018 - acc: 0.7812
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4922 - acc: 0.7800
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4907 - acc: 0.7719
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4889 - acc: 0.7730
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4824 - acc: 0.7796
1283/1283 [==============================] - 1s 667us/step - loss: 0.4801 - acc: 0.7810 - val_loss: 0.8079 - val_acc: 0.5590

Epoch 00006: val_acc improved from 0.54148 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4208 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3908 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3781 - acc: 0.8531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3891 - acc: 0.8259
 576/1283 [============>.................] - ETA: 0s - loss: 0.3874 - acc: 0.8281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3893 - acc: 0.8253
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3965 - acc: 0.8185
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4072 - acc: 0.8094
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4205 - acc: 0.7987
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4162 - acc: 0.8002
1283/1283 [==============================] - 1s 655us/step - loss: 0.4199 - acc: 0.7958 - val_loss: 0.8243 - val_acc: 0.5328

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2910 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3140 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3325 - acc: 0.8562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3426 - acc: 0.8393
 576/1283 [============>.................] - ETA: 0s - loss: 0.3388 - acc: 0.8472
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3376 - acc: 0.8537
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3343 - acc: 0.8571
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3316 - acc: 0.8564
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3269 - acc: 0.8611
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3291 - acc: 0.8569
1280/1283 [============================>.] - ETA: 0s - loss: 0.3276 - acc: 0.8586
1283/1283 [==============================] - 1s 574us/step - loss: 0.3270 - acc: 0.8589 - val_loss: 0.9147 - val_acc: 0.5284

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2789 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2478 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2326 - acc: 0.8984
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2375 - acc: 0.8958
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2371 - acc: 0.9004
 640/1283 [=============>................] - ETA: 0s - loss: 0.2453 - acc: 0.8938
 768/1283 [================>.............] - ETA: 0s - loss: 0.2341 - acc: 0.8997
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2270 - acc: 0.9074
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2282 - acc: 0.9053
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2248 - acc: 0.9080
1280/1283 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9023
1283/1283 [==============================] - 1s 678us/step - loss: 0.2290 - acc: 0.9026 - val_loss: 1.2518 - val_acc: 0.5677

Epoch 00009: val_acc improved from 0.55895 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1315 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2183 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2194 - acc: 0.9094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2021 - acc: 0.9152
 576/1283 [============>.................] - ETA: 0s - loss: 0.2056 - acc: 0.9132
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2007 - acc: 0.9162
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1929 - acc: 0.9231
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2001 - acc: 0.9156
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1899 - acc: 0.9210
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1965 - acc: 0.9186
1283/1283 [==============================] - 1s 661us/step - loss: 0.1955 - acc: 0.9166 - val_loss: 1.1676 - val_acc: 0.5459

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2433 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2135 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1892 - acc: 0.9250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2155 - acc: 0.9129
 576/1283 [============>.................] - ETA: 0s - loss: 0.2077 - acc: 0.9115
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2163 - acc: 0.9006
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2025 - acc: 0.9075
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2037 - acc: 0.9042
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1936 - acc: 0.9118
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1949 - acc: 0.9120
1283/1283 [==============================] - 1s 661us/step - loss: 0.1927 - acc: 0.9119 - val_loss: 1.0718 - val_acc: 0.5764

Epoch 00011: val_acc improved from 0.56769 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1385 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1562 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2090 - acc: 0.9156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2117 - acc: 0.9062
 576/1283 [============>.................] - ETA: 0s - loss: 0.2205 - acc: 0.8993
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2086 - acc: 0.9034
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2115 - acc: 0.9002
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2124 - acc: 0.8958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2149 - acc: 0.9017
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2142 - acc: 0.8997
1283/1283 [==============================] - 1s 649us/step - loss: 0.2132 - acc: 0.9018 - val_loss: 1.2438 - val_acc: 0.5677

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1604 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2773 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2197 - acc: 0.8969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2078 - acc: 0.9089
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2004 - acc: 0.9102
 640/1283 [=============>................] - ETA: 0s - loss: 0.1957 - acc: 0.9094
 768/1283 [================>.............] - ETA: 0s - loss: 0.1925 - acc: 0.9076
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1848 - acc: 0.9141
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1791 - acc: 0.9170
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1766 - acc: 0.9167
1280/1283 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9203
1283/1283 [==============================] - 1s 674us/step - loss: 0.1721 - acc: 0.9197 - val_loss: 1.3958 - val_acc: 0.5328

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1632 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1837 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1782 - acc: 0.9187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1569 - acc: 0.9308
 576/1283 [============>.................] - ETA: 0s - loss: 0.1590 - acc: 0.9271
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1675 - acc: 0.9219
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1608 - acc: 0.9243
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1739 - acc: 0.9208
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1715 - acc: 0.9228
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1908 - acc: 0.9178
1280/1283 [============================>.] - ETA: 0s - loss: 0.1880 - acc: 0.9187
1283/1283 [==============================] - 1s 670us/step - loss: 0.1883 - acc: 0.9189 - val_loss: 1.5910 - val_acc: 0.5459

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2059 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1582 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1557 - acc: 0.9344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1800 - acc: 0.9196
 576/1283 [============>.................] - ETA: 0s - loss: 0.1892 - acc: 0.9132
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1850 - acc: 0.9148
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1902 - acc: 0.9147
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1785 - acc: 0.9229
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1902 - acc: 0.9118
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1882 - acc: 0.9128
1283/1283 [==============================] - 1s 665us/step - loss: 0.1868 - acc: 0.9150 - val_loss: 1.6180 - val_acc: 0.5590

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0942 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2590 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2529 - acc: 0.8875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2426 - acc: 0.8929
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2438 - acc: 0.8867
 640/1283 [=============>................] - ETA: 0s - loss: 0.2376 - acc: 0.8812
 768/1283 [================>.............] - ETA: 0s - loss: 0.2408 - acc: 0.8776
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2267 - acc: 0.8884
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2224 - acc: 0.8916
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2144 - acc: 0.8984
1280/1283 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9000
1283/1283 [==============================] - 1s 683us/step - loss: 0.2111 - acc: 0.9002 - val_loss: 1.2855 - val_acc: 0.5328

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0995 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0986 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0937 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1058 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.1068 - acc: 0.9653
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1065 - acc: 0.9631
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1135 - acc: 0.9567
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1121 - acc: 0.9552
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1089 - acc: 0.9550
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1075 - acc: 0.9564
1283/1283 [==============================] - 1s 666us/step - loss: 0.1109 - acc: 0.9548 - val_loss: 1.4611 - val_acc: 0.5502

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0934 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0897 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0863 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0826 - acc: 0.9621
 576/1283 [============>.................] - ETA: 0s - loss: 0.0853 - acc: 0.9566
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0833 - acc: 0.9588
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0841 - acc: 0.9615
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0832 - acc: 0.9635
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0783 - acc: 0.9660
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0788 - acc: 0.9679
1283/1283 [==============================] - 1s 668us/step - loss: 0.0784 - acc: 0.9673 - val_loss: 1.6174 - val_acc: 0.5328

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0555 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1177 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1257 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1187 - acc: 0.9420
 576/1283 [============>.................] - ETA: 0s - loss: 0.1189 - acc: 0.9392
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1245 - acc: 0.9361
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1182 - acc: 0.9411
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1242 - acc: 0.9408
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1189 - acc: 0.9434
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1143 - acc: 0.9470
1280/1283 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9492
1283/1283 [==============================] - 1s 661us/step - loss: 0.1110 - acc: 0.9493 - val_loss: 1.6166 - val_acc: 0.5764

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1008 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1060 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0884 - acc: 0.9563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0847 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.0800 - acc: 0.9583
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0800 - acc: 0.9588
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0787 - acc: 0.9627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0773 - acc: 0.9635
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0786 - acc: 0.9623
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0824 - acc: 0.9613
1283/1283 [==============================] - 1s 669us/step - loss: 0.0811 - acc: 0.9618 - val_loss: 1.6897 - val_acc: 0.5590

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0535 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0604 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0627 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0704 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.0710 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0659 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0687 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0706 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0690 - acc: 0.9697
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0674 - acc: 0.9696
1283/1283 [==============================] - 1s 670us/step - loss: 0.0658 - acc: 0.9704 - val_loss: 1.8137 - val_acc: 0.5328

Epoch 00021: val_acc did not improve
Epoch 00021: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=3
max_len=25
epochs=100
mode=A
accuracy=0.5087463556851312
best_valid_accuracy=0.5
