/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:08:12.150020: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 1.0312 - acc: 0.3906
 256/1283 [====>.........................] - ETA: 2s - loss: 0.8899 - acc: 0.4766 
 448/1283 [=========>....................] - ETA: 1s - loss: 0.8194 - acc: 0.5134
 640/1283 [=============>................] - ETA: 0s - loss: 0.7955 - acc: 0.5266
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7855 - acc: 0.5252
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7830 - acc: 0.5260
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7774 - acc: 0.5312
1280/1283 [============================>.] - ETA: 0s - loss: 0.7652 - acc: 0.5359
1283/1283 [==============================] - 1s 927us/step - loss: 0.7648 - acc: 0.5362 - val_loss: 0.7222 - val_acc: 0.5153

Epoch 00001: val_acc improved from -inf to 0.51528, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6294 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6584 - acc: 0.6062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6418 - acc: 0.6228
 640/1283 [=============>................] - ETA: 0s - loss: 0.6323 - acc: 0.6359
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6292 - acc: 0.6382
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6305 - acc: 0.6338
1280/1283 [============================>.] - ETA: 0s - loss: 0.6303 - acc: 0.6398
1283/1283 [==============================] - 0s 314us/step - loss: 0.6306 - acc: 0.6391 - val_loss: 0.7232 - val_acc: 0.5109

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5955 - acc: 0.5938
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5958 - acc: 0.6469
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5933 - acc: 0.6621
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5833 - acc: 0.6861
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5798 - acc: 0.6920
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5826 - acc: 0.6847
1280/1283 [============================>.] - ETA: 0s - loss: 0.5757 - acc: 0.6922
1283/1283 [==============================] - 0s 374us/step - loss: 0.5757 - acc: 0.6921 - val_loss: 0.7275 - val_acc: 0.5502

Epoch 00003: val_acc improved from 0.51528 to 0.55022, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4343 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5027 - acc: 0.7875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5058 - acc: 0.7871
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5140 - acc: 0.7699
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5136 - acc: 0.7740
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5097 - acc: 0.7706
1283/1283 [==============================] - 0s 331us/step - loss: 0.5070 - acc: 0.7732 - val_loss: 0.7161 - val_acc: 0.5546

Epoch 00004: val_acc improved from 0.55022 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4304 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4248 - acc: 0.8516
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4352 - acc: 0.8415
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4366 - acc: 0.8366
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4394 - acc: 0.8198
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4437 - acc: 0.8142
1283/1283 [==============================] - 0s 297us/step - loss: 0.4483 - acc: 0.8137 - val_loss: 0.7409 - val_acc: 0.5939

Epoch 00005: val_acc improved from 0.55459 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4167 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4126 - acc: 0.8242
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3962 - acc: 0.8571
 576/1283 [============>.................] - ETA: 0s - loss: 0.4056 - acc: 0.8420
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4027 - acc: 0.8395
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3973 - acc: 0.8371
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4042 - acc: 0.8318
1283/1283 [==============================] - 0s 369us/step - loss: 0.4054 - acc: 0.8270 - val_loss: 0.8112 - val_acc: 0.5546

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3455 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3179 - acc: 0.8828
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3517 - acc: 0.8661
 640/1283 [=============>................] - ETA: 0s - loss: 0.3604 - acc: 0.8609
 768/1283 [================>.............] - ETA: 0s - loss: 0.3679 - acc: 0.8581
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3559 - acc: 0.8672
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3577 - acc: 0.8676
1280/1283 [============================>.] - ETA: 0s - loss: 0.3485 - acc: 0.8750
1283/1283 [==============================] - 0s 367us/step - loss: 0.3480 - acc: 0.8753 - val_loss: 0.8772 - val_acc: 0.5415

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2699 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2779 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2889 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2859 - acc: 0.8906
 576/1283 [============>.................] - ETA: 0s - loss: 0.2821 - acc: 0.8958
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2837 - acc: 0.8963
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2856 - acc: 0.8962
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2799 - acc: 0.8984
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2794 - acc: 0.9002
1280/1283 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.8984
1283/1283 [==============================] - 1s 483us/step - loss: 0.2811 - acc: 0.8987 - val_loss: 0.9814 - val_acc: 0.5590

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1958 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2430 - acc: 0.9167
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2520 - acc: 0.9219
 576/1283 [============>.................] - ETA: 0s - loss: 0.2781 - acc: 0.9010
 768/1283 [================>.............] - ETA: 0s - loss: 0.2603 - acc: 0.9154
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2633 - acc: 0.9118
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2591 - acc: 0.9173
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2606 - acc: 0.9128
1283/1283 [==============================] - 1s 422us/step - loss: 0.2620 - acc: 0.9111 - val_loss: 0.9285 - val_acc: 0.5808

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1413 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3025 - acc: 0.8359
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2874 - acc: 0.8542
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2769 - acc: 0.8730
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2789 - acc: 0.8707
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2698 - acc: 0.8834
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2702 - acc: 0.8844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2645 - acc: 0.8906
1280/1283 [============================>.] - ETA: 0s - loss: 0.2615 - acc: 0.8961
1283/1283 [==============================] - 1s 450us/step - loss: 0.2614 - acc: 0.8963 - val_loss: 0.9107 - val_acc: 0.5459

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1633 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1775 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1655 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1621 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.1654 - acc: 0.9740
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1712 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1737 - acc: 0.9675
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1713 - acc: 0.9667
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1697 - acc: 0.9651
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1690 - acc: 0.9630
1283/1283 [==============================] - 1s 569us/step - loss: 0.1677 - acc: 0.9634 - val_loss: 1.0011 - val_acc: 0.5721

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1438 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1465 - acc: 0.9563
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1281 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1274 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1256 - acc: 0.9736
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1227 - acc: 0.9750
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1212 - acc: 0.9752
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1248 - acc: 0.9712
1283/1283 [==============================] - 1s 449us/step - loss: 0.1233 - acc: 0.9719 - val_loss: 1.0036 - val_acc: 0.5721

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1136 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0955 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1003 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0946 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0947 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0955 - acc: 0.9929
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0964 - acc: 0.9916
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0957 - acc: 0.9927
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0968 - acc: 0.9917
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0970 - acc: 0.9893
1283/1283 [==============================] - 1s 511us/step - loss: 0.0963 - acc: 0.9891 - val_loss: 1.2664 - val_acc: 0.5502

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0641 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0731 - acc: 0.9948
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0995 - acc: 0.9661
 576/1283 [============>.................] - ETA: 0s - loss: 0.0952 - acc: 0.9740
 768/1283 [================>.............] - ETA: 0s - loss: 0.0930 - acc: 0.9779
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0884 - acc: 0.9814
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0874 - acc: 0.9819
1283/1283 [==============================] - 0s 366us/step - loss: 0.0872 - acc: 0.9821 - val_loss: 1.1738 - val_acc: 0.5677

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0622 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1531 - acc: 0.9297
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1730 - acc: 0.9308
 640/1283 [=============>................] - ETA: 0s - loss: 0.1718 - acc: 0.9375
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1730 - acc: 0.9351
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1686 - acc: 0.9375
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1647 - acc: 0.9416
1283/1283 [==============================] - 0s 349us/step - loss: 0.1665 - acc: 0.9415 - val_loss: 1.3039 - val_acc: 0.5197

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
epochs=100
mode=A
accuracy=0.5087463556851312
best_valid_accuracy=0.5
