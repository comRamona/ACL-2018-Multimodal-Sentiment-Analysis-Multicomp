/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:08:13.306359: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.7608 - acc: 0.4531
 128/1283 [=>............................] - ETA: 5s - loss: 0.7929 - acc: 0.4609 
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7696 - acc: 0.4844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7369 - acc: 0.5234
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7420 - acc: 0.5156
 576/1283 [============>.................] - ETA: 1s - loss: 0.7396 - acc: 0.5017
 640/1283 [=============>................] - ETA: 1s - loss: 0.7373 - acc: 0.4984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7371 - acc: 0.5000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7276 - acc: 0.5180
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7288 - acc: 0.5156
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7251 - acc: 0.5198
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7220 - acc: 0.5225
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7198 - acc: 0.5248
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7165 - acc: 0.5339
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7153 - acc: 0.5321
1280/1283 [============================>.] - ETA: 0s - loss: 0.7149 - acc: 0.5312
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7147 - acc: 0.5316 - val_loss: 0.7028 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6101 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6437 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6447 - acc: 0.6156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6528 - acc: 0.6068
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6487 - acc: 0.6183
 576/1283 [============>.................] - ETA: 0s - loss: 0.6503 - acc: 0.6094
 640/1283 [=============>................] - ETA: 0s - loss: 0.6534 - acc: 0.6047
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6532 - acc: 0.6051
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6473 - acc: 0.6154
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6450 - acc: 0.6250
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6443 - acc: 0.6250
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6413 - acc: 0.6302
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6385 - acc: 0.6382
1280/1283 [============================>.] - ETA: 0s - loss: 0.6366 - acc: 0.6406
1283/1283 [==============================] - 1s 978us/step - loss: 0.6366 - acc: 0.6399 - val_loss: 0.6913 - val_acc: 0.5677

Epoch 00002: val_acc improved from 0.53712 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6150 - acc: 0.6562
 128/1283 [=>............................] - ETA: 0s - loss: 0.5764 - acc: 0.7109
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5935 - acc: 0.6615
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5831 - acc: 0.6719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5735 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5681 - acc: 0.7090
 640/1283 [=============>................] - ETA: 0s - loss: 0.5687 - acc: 0.7109
 768/1283 [================>.............] - ETA: 0s - loss: 0.5698 - acc: 0.7174
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5685 - acc: 0.7132
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5705 - acc: 0.7109
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5688 - acc: 0.7132
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5715 - acc: 0.7089
1283/1283 [==============================] - 1s 789us/step - loss: 0.5732 - acc: 0.7054 - val_loss: 0.7506 - val_acc: 0.5066

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5255 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.5507 - acc: 0.6797
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5441 - acc: 0.6927
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5096 - acc: 0.7406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5110 - acc: 0.7448
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5197 - acc: 0.7388
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5334 - acc: 0.7266
 576/1283 [============>.................] - ETA: 0s - loss: 0.5383 - acc: 0.7240
 640/1283 [=============>................] - ETA: 0s - loss: 0.5409 - acc: 0.7234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5434 - acc: 0.7244
 768/1283 [================>.............] - ETA: 0s - loss: 0.5385 - acc: 0.7305
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5372 - acc: 0.7356
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5403 - acc: 0.7355
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5412 - acc: 0.7333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5453 - acc: 0.7305
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5444 - acc: 0.7307
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5444 - acc: 0.7318
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5463 - acc: 0.7327
1280/1283 [============================>.] - ETA: 0s - loss: 0.5445 - acc: 0.7328
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5445 - acc: 0.7327 - val_loss: 0.8053 - val_acc: 0.5240

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5672 - acc: 0.6094
 128/1283 [=>............................] - ETA: 1s - loss: 0.6197 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5769 - acc: 0.6042
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5834 - acc: 0.5898
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5683 - acc: 0.6188
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5422 - acc: 0.6641
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5581 - acc: 0.6607
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5575 - acc: 0.6758
 576/1283 [============>.................] - ETA: 0s - loss: 0.5633 - acc: 0.6701
 640/1283 [=============>................] - ETA: 0s - loss: 0.5570 - acc: 0.6766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5458 - acc: 0.6918
 768/1283 [================>.............] - ETA: 0s - loss: 0.5382 - acc: 0.7044
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5294 - acc: 0.7143
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5274 - acc: 0.7198
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5268 - acc: 0.7206
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5243 - acc: 0.7266
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5205 - acc: 0.7327
1283/1283 [==============================] - 1s 994us/step - loss: 0.5225 - acc: 0.7295 - val_loss: 0.7362 - val_acc: 0.5459

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4564 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4384 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4328 - acc: 0.8073
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4380 - acc: 0.8086
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4481 - acc: 0.7943
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4440 - acc: 0.7946
 576/1283 [============>.................] - ETA: 0s - loss: 0.4394 - acc: 0.8003
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4251 - acc: 0.8196
 768/1283 [================>.............] - ETA: 0s - loss: 0.4215 - acc: 0.8203
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4252 - acc: 0.8137
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4250 - acc: 0.8125
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4244 - acc: 0.8115
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4216 - acc: 0.8115
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4218 - acc: 0.8134
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4151 - acc: 0.8207
1280/1283 [============================>.] - ETA: 0s - loss: 0.4157 - acc: 0.8211
1283/1283 [==============================] - 1s 961us/step - loss: 0.4154 - acc: 0.8215 - val_loss: 0.7909 - val_acc: 0.5721

Epoch 00006: val_acc improved from 0.56769 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3596 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3528 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3713 - acc: 0.8320
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3579 - acc: 0.8307
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3499 - acc: 0.8348
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3479 - acc: 0.8418
 576/1283 [============>.................] - ETA: 0s - loss: 0.3479 - acc: 0.8472
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3441 - acc: 0.8509
 768/1283 [================>.............] - ETA: 0s - loss: 0.3408 - acc: 0.8529
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3447 - acc: 0.8522
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3373 - acc: 0.8571
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3502 - acc: 0.8457
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3469 - acc: 0.8464
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3488 - acc: 0.8462
1283/1283 [==============================] - 1s 902us/step - loss: 0.3497 - acc: 0.8472 - val_loss: 0.8663 - val_acc: 0.5459

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3040 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.2913 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3117 - acc: 0.8516
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2916 - acc: 0.8672
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2948 - acc: 0.8691
 576/1283 [============>.................] - ETA: 0s - loss: 0.2979 - acc: 0.8646
 640/1283 [=============>................] - ETA: 0s - loss: 0.2938 - acc: 0.8656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2979 - acc: 0.8636
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2913 - acc: 0.8726
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2942 - acc: 0.8683
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2851 - acc: 0.8740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2832 - acc: 0.8759
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2816 - acc: 0.8767
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2879 - acc: 0.8709
1283/1283 [==============================] - 1s 870us/step - loss: 0.2873 - acc: 0.8730 - val_loss: 1.1389 - val_acc: 0.5415

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3124 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.2775 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2762 - acc: 0.8438
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2717 - acc: 0.8568
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2807 - acc: 0.8594
 640/1283 [=============>................] - ETA: 0s - loss: 0.2767 - acc: 0.8656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2725 - acc: 0.8679
 768/1283 [================>.............] - ETA: 0s - loss: 0.2688 - acc: 0.8698
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2678 - acc: 0.8714
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2628 - acc: 0.8772
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2573 - acc: 0.8833
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2552 - acc: 0.8888
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2508 - acc: 0.8915
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2503 - acc: 0.8914
1283/1283 [==============================] - 1s 914us/step - loss: 0.2507 - acc: 0.8901 - val_loss: 1.0827 - val_acc: 0.5633

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1404 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2103 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1954 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1939 - acc: 0.9219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1880 - acc: 0.9271
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1882 - acc: 0.9263
 576/1283 [============>.................] - ETA: 0s - loss: 0.1900 - acc: 0.9253
 640/1283 [=============>................] - ETA: 0s - loss: 0.1925 - acc: 0.9234
 768/1283 [================>.............] - ETA: 0s - loss: 0.1877 - acc: 0.9284
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1863 - acc: 0.9291
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1922 - acc: 0.9252
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1932 - acc: 0.9240
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1867 - acc: 0.9274
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1879 - acc: 0.9253
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1866 - acc: 0.9260
1283/1283 [==============================] - 1s 958us/step - loss: 0.1869 - acc: 0.9236 - val_loss: 1.0512 - val_acc: 0.5764

Epoch 00010: val_acc improved from 0.57205 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1683 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1559 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1612 - acc: 0.9336
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1580 - acc: 0.9406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1583 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1591 - acc: 0.9353
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1637 - acc: 0.9297
 640/1283 [=============>................] - ETA: 0s - loss: 0.1547 - acc: 0.9391
 768/1283 [================>.............] - ETA: 0s - loss: 0.1583 - acc: 0.9349
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1562 - acc: 0.9363
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1535 - acc: 0.9386
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1502 - acc: 0.9424
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1463 - acc: 0.9458
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1464 - acc: 0.9444
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1435 - acc: 0.9465
1283/1283 [==============================] - 1s 857us/step - loss: 0.1421 - acc: 0.9462 - val_loss: 1.2134 - val_acc: 0.5852

Epoch 00011: val_acc improved from 0.57642 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1316 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1404 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1963 - acc: 0.9336
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2008 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2146 - acc: 0.9167
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2167 - acc: 0.9085
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2116 - acc: 0.9102
 576/1283 [============>.................] - ETA: 0s - loss: 0.2033 - acc: 0.9167
 640/1283 [=============>................] - ETA: 0s - loss: 0.1976 - acc: 0.9172
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1927 - acc: 0.9190
 768/1283 [================>.............] - ETA: 0s - loss: 0.1915 - acc: 0.9193
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1915 - acc: 0.9219
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1964 - acc: 0.9177
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1943 - acc: 0.9209
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1943 - acc: 0.9200
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1973 - acc: 0.9167
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1979 - acc: 0.9145
1280/1283 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9172
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1964 - acc: 0.9166 - val_loss: 1.2420 - val_acc: 0.5983

Epoch 00012: val_acc improved from 0.58515 to 0.59825, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1165 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2032 - acc: 0.8958
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1830 - acc: 0.9062
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1606 - acc: 0.9297
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1620 - acc: 0.9316
 640/1283 [=============>................] - ETA: 0s - loss: 0.1686 - acc: 0.9219
 768/1283 [================>.............] - ETA: 0s - loss: 0.1752 - acc: 0.9180
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1688 - acc: 0.9231
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1629 - acc: 0.9286
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1642 - acc: 0.9268
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1634 - acc: 0.9253
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1648 - acc: 0.9252
1283/1283 [==============================] - 1s 851us/step - loss: 0.1663 - acc: 0.9244 - val_loss: 1.4384 - val_acc: 0.5328

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0772 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1089 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1290 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1160 - acc: 0.9621
 576/1283 [============>.................] - ETA: 0s - loss: 0.1183 - acc: 0.9566
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1297 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1261 - acc: 0.9544
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1243 - acc: 0.9543
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1221 - acc: 0.9552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1242 - acc: 0.9541
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1218 - acc: 0.9550
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1276 - acc: 0.9497
1280/1283 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9508
1283/1283 [==============================] - 1s 893us/step - loss: 0.1273 - acc: 0.9509 - val_loss: 1.4269 - val_acc: 0.5459

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1032 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1378 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1564 - acc: 0.9297
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1579 - acc: 0.9323
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1521 - acc: 0.9355
 640/1283 [=============>................] - ETA: 0s - loss: 0.1597 - acc: 0.9281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1591 - acc: 0.9290
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1536 - acc: 0.9303
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1477 - acc: 0.9342
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1473 - acc: 0.9354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1445 - acc: 0.9355
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1438 - acc: 0.9347
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1446 - acc: 0.9340
1280/1283 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9367
1283/1283 [==============================] - 1s 866us/step - loss: 0.1417 - acc: 0.9369 - val_loss: 1.5140 - val_acc: 0.5808

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0824 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1280 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1191 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1115 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1039 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1001 - acc: 0.9635
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1011 - acc: 0.9629
 576/1283 [============>.................] - ETA: 0s - loss: 0.1065 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.1035 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1054 - acc: 0.9616
 768/1283 [================>.............] - ETA: 0s - loss: 0.1086 - acc: 0.9596
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1055 - acc: 0.9621
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1092 - acc: 0.9583
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1086 - acc: 0.9580
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1042 - acc: 0.9609
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1027 - acc: 0.9613
1283/1283 [==============================] - 1s 980us/step - loss: 0.1011 - acc: 0.9618 - val_loss: 1.5161 - val_acc: 0.5415

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0491 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0598 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0573 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0581 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0632 - acc: 0.9792
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0701 - acc: 0.9727
 640/1283 [=============>................] - ETA: 0s - loss: 0.0686 - acc: 0.9734
 768/1283 [================>.............] - ETA: 0s - loss: 0.0691 - acc: 0.9727
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0695 - acc: 0.9732
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0703 - acc: 0.9729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0726 - acc: 0.9715
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0742 - acc: 0.9714
1280/1283 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9719
1283/1283 [==============================] - 1s 822us/step - loss: 0.0750 - acc: 0.9719 - val_loss: 1.6070 - val_acc: 0.5502

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0622 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0695 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0667 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0733 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0688 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0759 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.0732 - acc: 0.9719
 768/1283 [================>.............] - ETA: 0s - loss: 0.0746 - acc: 0.9701
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0700 - acc: 0.9721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0704 - acc: 0.9708
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0657 - acc: 0.9733
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0656 - acc: 0.9748
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0659 - acc: 0.9753
1283/1283 [==============================] - 1s 821us/step - loss: 0.0655 - acc: 0.9743 - val_loss: 1.7337 - val_acc: 0.5502

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0538 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0771 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0621 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0669 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0647 - acc: 0.9727
 640/1283 [=============>................] - ETA: 0s - loss: 0.0647 - acc: 0.9734
 768/1283 [================>.............] - ETA: 0s - loss: 0.0667 - acc: 0.9740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0672 - acc: 0.9699
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0647 - acc: 0.9707
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0631 - acc: 0.9722
1280/1283 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9727
1283/1283 [==============================] - 1s 720us/step - loss: 0.0610 - acc: 0.9727 - val_loss: 1.7340 - val_acc: 0.5546

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0852 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0710 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0726 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0686 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0682 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.0656 - acc: 0.9757
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0673 - acc: 0.9730
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0670 - acc: 0.9724
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0696 - acc: 0.9699
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0678 - acc: 0.9717
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0655 - acc: 0.9731
1280/1283 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9711
1283/1283 [==============================] - 1s 726us/step - loss: 0.0686 - acc: 0.9712 - val_loss: 1.8046 - val_acc: 0.5764

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0548 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0696 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0603 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0647 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0681 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0641 - acc: 0.9716
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0647 - acc: 0.9724
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0643 - acc: 0.9740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0629 - acc: 0.9743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0628 - acc: 0.9737
1283/1283 [==============================] - 1s 628us/step - loss: 0.0620 - acc: 0.9735 - val_loss: 2.3257 - val_acc: 0.5328

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1155 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1373 - acc: 0.9271
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1910 - acc: 0.9281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1855 - acc: 0.9286
 576/1283 [============>.................] - ETA: 0s - loss: 0.1673 - acc: 0.9410
 768/1283 [================>.............] - ETA: 0s - loss: 0.1651 - acc: 0.9375
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1646 - acc: 0.9354
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1666 - acc: 0.9338
1280/1283 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9328
1283/1283 [==============================] - 1s 439us/step - loss: 0.1691 - acc: 0.9330 - val_loss: 2.7668 - val_acc: 0.5721

Epoch 00022: val_acc did not improve
Epoch 00022: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
epochs=100
mode=A
accuracy=0.44752186588921283
best_valid_accuracy=0.5131195335276968
