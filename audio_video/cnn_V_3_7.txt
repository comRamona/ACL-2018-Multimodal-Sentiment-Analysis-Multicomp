/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:20:51.038737: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.7078 - acc: 0.5156
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6923 - acc: 0.4727
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6906 - acc: 0.4911
 640/1283 [=============>................] - ETA: 0s - loss: 0.6934 - acc: 0.5234
 768/1283 [================>.............] - ETA: 0s - loss: 0.6889 - acc: 0.5326
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6893 - acc: 0.5271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6883 - acc: 0.5386
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6861 - acc: 0.5428
1283/1283 [==============================] - 1s 641us/step - loss: 0.6854 - acc: 0.5417 - val_loss: 0.6974 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6460 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6825 - acc: 0.5469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6822 - acc: 0.5495
 576/1283 [============>.................] - ETA: 0s - loss: 0.6770 - acc: 0.5556
 768/1283 [================>.............] - ETA: 0s - loss: 0.6731 - acc: 0.5742
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6716 - acc: 0.5703
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6738 - acc: 0.5726
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6738 - acc: 0.5715
1283/1283 [==============================] - 1s 442us/step - loss: 0.6724 - acc: 0.5744 - val_loss: 0.6890 - val_acc: 0.5371

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6634 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6693 - acc: 0.5521
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6494 - acc: 0.5938
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6522 - acc: 0.5840
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6517 - acc: 0.5923
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6530 - acc: 0.5950
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6533 - acc: 0.5938
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6591 - acc: 0.5956
1280/1283 [============================>.] - ETA: 0s - loss: 0.6605 - acc: 0.5914
1283/1283 [==============================] - 1s 426us/step - loss: 0.6606 - acc: 0.5916 - val_loss: 0.7098 - val_acc: 0.5022

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.7174 - acc: 0.5156
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6745 - acc: 0.5977
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6583 - acc: 0.6198
 576/1283 [============>.................] - ETA: 0s - loss: 0.6549 - acc: 0.6094
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6555 - acc: 0.6051
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6528 - acc: 0.6070
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6484 - acc: 0.6143
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6483 - acc: 0.6189
1283/1283 [==============================] - 1s 400us/step - loss: 0.6505 - acc: 0.6142 - val_loss: 0.6983 - val_acc: 0.5240

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6245 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6521 - acc: 0.5977
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6714 - acc: 0.5651
 576/1283 [============>.................] - ETA: 0s - loss: 0.6615 - acc: 0.5677
 768/1283 [================>.............] - ETA: 0s - loss: 0.6555 - acc: 0.5977
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6516 - acc: 0.6071
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6485 - acc: 0.6066
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6480 - acc: 0.6069
1283/1283 [==============================] - 0s 377us/step - loss: 0.6474 - acc: 0.6072 - val_loss: 0.7063 - val_acc: 0.5502

Epoch 00005: val_acc improved from 0.54148 to 0.55022, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6107 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6225 - acc: 0.6211
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6281 - acc: 0.6198
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6255 - acc: 0.6289
 640/1283 [=============>................] - ETA: 0s - loss: 0.6235 - acc: 0.6344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6224 - acc: 0.6382
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6259 - acc: 0.6333
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6286 - acc: 0.6314
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6300 - acc: 0.6324
1283/1283 [==============================] - 1s 553us/step - loss: 0.6305 - acc: 0.6306 - val_loss: 0.6963 - val_acc: 0.5415

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6197 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6317 - acc: 0.5938
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6241 - acc: 0.6219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6231 - acc: 0.6138
 576/1283 [============>.................] - ETA: 0s - loss: 0.6250 - acc: 0.6163
 640/1283 [=============>................] - ETA: 0s - loss: 0.6217 - acc: 0.6297
 768/1283 [================>.............] - ETA: 0s - loss: 0.6172 - acc: 0.6432
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6179 - acc: 0.6473
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6183 - acc: 0.6406
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6145 - acc: 0.6415
1280/1283 [============================>.] - ETA: 0s - loss: 0.6110 - acc: 0.6445
1283/1283 [==============================] - 1s 602us/step - loss: 0.6111 - acc: 0.6446 - val_loss: 0.7484 - val_acc: 0.4978

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6612 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6096 - acc: 0.6667
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6052 - acc: 0.6625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6044 - acc: 0.6585
 576/1283 [============>.................] - ETA: 0s - loss: 0.6143 - acc: 0.6476
 768/1283 [================>.............] - ETA: 0s - loss: 0.6096 - acc: 0.6510
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6054 - acc: 0.6510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6032 - acc: 0.6590
1280/1283 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.6609
1283/1283 [==============================] - 1s 465us/step - loss: 0.6021 - acc: 0.6602 - val_loss: 0.7219 - val_acc: 0.5415

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6029 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5772 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5752 - acc: 0.6849
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5722 - acc: 0.6875
 640/1283 [=============>................] - ETA: 0s - loss: 0.5747 - acc: 0.6906
 768/1283 [================>.............] - ETA: 0s - loss: 0.5861 - acc: 0.6758
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6026 - acc: 0.6740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6024 - acc: 0.6719
1280/1283 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.6719
1283/1283 [==============================] - 1s 436us/step - loss: 0.6018 - acc: 0.6726 - val_loss: 0.7130 - val_acc: 0.5459

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6675 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5940 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5787 - acc: 0.6813
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5808 - acc: 0.6696
 576/1283 [============>.................] - ETA: 0s - loss: 0.5880 - acc: 0.6788
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5861 - acc: 0.6761
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5892 - acc: 0.6695
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5887 - acc: 0.6667
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5791 - acc: 0.6719
1280/1283 [============================>.] - ETA: 0s - loss: 0.5742 - acc: 0.6773
1283/1283 [==============================] - 1s 522us/step - loss: 0.5749 - acc: 0.6765 - val_loss: 0.7950 - val_acc: 0.5197

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5343 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5283 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5283 - acc: 0.7469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5406 - acc: 0.7254
 640/1283 [=============>................] - ETA: 0s - loss: 0.5379 - acc: 0.7312
 768/1283 [================>.............] - ETA: 0s - loss: 0.5685 - acc: 0.7214
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5619 - acc: 0.7266
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5667 - acc: 0.7217
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5781 - acc: 0.7161
1280/1283 [============================>.] - ETA: 0s - loss: 0.5743 - acc: 0.7141
1283/1283 [==============================] - 1s 458us/step - loss: 0.5748 - acc: 0.7140 - val_loss: 0.8198 - val_acc: 0.5153

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5499 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6494 - acc: 0.6771
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6723 - acc: 0.6719
 576/1283 [============>.................] - ETA: 0s - loss: 0.6482 - acc: 0.6684
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6621 - acc: 0.6406
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6472 - acc: 0.6440
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6344 - acc: 0.6592
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6252 - acc: 0.6645
1283/1283 [==============================] - 1s 464us/step - loss: 0.6232 - acc: 0.6656 - val_loss: 0.7447 - val_acc: 0.5502

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.7867 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6659 - acc: 0.6562
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6147 - acc: 0.7031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6020 - acc: 0.7009
 576/1283 [============>.................] - ETA: 0s - loss: 0.5941 - acc: 0.7066
 768/1283 [================>.............] - ETA: 0s - loss: 0.5774 - acc: 0.7122
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5729 - acc: 0.7210
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5780 - acc: 0.7119
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5733 - acc: 0.7118
1280/1283 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7172
1283/1283 [==============================] - 1s 514us/step - loss: 0.5651 - acc: 0.7171 - val_loss: 0.7718 - val_acc: 0.4978

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4032 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4778 - acc: 0.7552
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5033 - acc: 0.7281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5062 - acc: 0.7321
 576/1283 [============>.................] - ETA: 0s - loss: 0.5074 - acc: 0.7274
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5155 - acc: 0.7202
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5106 - acc: 0.7344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5048 - acc: 0.7412
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5022 - acc: 0.7431
1283/1283 [==============================] - 1s 571us/step - loss: 0.5125 - acc: 0.7475 - val_loss: 0.8551 - val_acc: 0.5197

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5342 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5236 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4891 - acc: 0.7594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5096 - acc: 0.7746
 576/1283 [============>.................] - ETA: 0s - loss: 0.5310 - acc: 0.7535
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5131 - acc: 0.7571
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5141 - acc: 0.7596
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5107 - acc: 0.7594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5108 - acc: 0.7500
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5113 - acc: 0.7533
1283/1283 [==============================] - 1s 594us/step - loss: 0.5080 - acc: 0.7537 - val_loss: 0.8604 - val_acc: 0.5109

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=3
max_len=25
epochs=100
mode=V
accuracy=0.46355685131195334
best_valid_accuracy=0.5306122448979592
