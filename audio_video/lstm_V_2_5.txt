/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 09:42:27.791005: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.6954 - acc: 0.5156
 128/1283 [=>............................] - ETA: 5s - loss: 0.6926 - acc: 0.5469 
 192/1283 [===>..........................] - ETA: 3s - loss: 0.6958 - acc: 0.5052
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6958 - acc: 0.4969
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6935 - acc: 0.5268
 576/1283 [============>.................] - ETA: 1s - loss: 0.6922 - acc: 0.5382
 640/1283 [=============>................] - ETA: 0s - loss: 0.6914 - acc: 0.5437
 768/1283 [================>.............] - ETA: 0s - loss: 0.6891 - acc: 0.5482
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6891 - acc: 0.5433
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6895 - acc: 0.5391
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6880 - acc: 0.5518
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6874 - acc: 0.5542
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6852 - acc: 0.5608
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6852 - acc: 0.5600
1280/1283 [============================>.] - ETA: 0s - loss: 0.6863 - acc: 0.5531
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6863 - acc: 0.5534 - val_loss: 0.6947 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6770 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6656 - acc: 0.5990
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6652 - acc: 0.5977
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6703 - acc: 0.5833
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6724 - acc: 0.5670
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6715 - acc: 0.5684
 640/1283 [=============>................] - ETA: 0s - loss: 0.6725 - acc: 0.5687
 768/1283 [================>.............] - ETA: 0s - loss: 0.6690 - acc: 0.5755
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6675 - acc: 0.5829
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6662 - acc: 0.5882
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6643 - acc: 0.5917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6645 - acc: 0.5928
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6648 - acc: 0.5910
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6646 - acc: 0.5851
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6654 - acc: 0.5847
1283/1283 [==============================] - 1s 985us/step - loss: 0.6637 - acc: 0.5861 - val_loss: 0.7027 - val_acc: 0.5022

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6349 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6235 - acc: 0.6667
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6363 - acc: 0.6562
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6407 - acc: 0.6438
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6423 - acc: 0.6328
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6454 - acc: 0.6272
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6536 - acc: 0.6230
 576/1283 [============>.................] - ETA: 0s - loss: 0.6563 - acc: 0.6128
 640/1283 [=============>................] - ETA: 0s - loss: 0.6581 - acc: 0.6094
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6573 - acc: 0.6108
 768/1283 [================>.............] - ETA: 0s - loss: 0.6577 - acc: 0.6042
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6565 - acc: 0.6034
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6557 - acc: 0.6016
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6579 - acc: 0.5958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6584 - acc: 0.5947
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6578 - acc: 0.5956
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6555 - acc: 0.6016
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6547 - acc: 0.6020
1280/1283 [============================>.] - ETA: 0s - loss: 0.6530 - acc: 0.6055
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6527 - acc: 0.6056 - val_loss: 0.7013 - val_acc: 0.5022

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6779 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6508 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6569 - acc: 0.6172
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6453 - acc: 0.6281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6441 - acc: 0.6384
 576/1283 [============>.................] - ETA: 0s - loss: 0.6387 - acc: 0.6458
 640/1283 [=============>................] - ETA: 0s - loss: 0.6370 - acc: 0.6516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6407 - acc: 0.6378
 768/1283 [================>.............] - ETA: 0s - loss: 0.6396 - acc: 0.6380
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6440 - acc: 0.6310
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6408 - acc: 0.6283
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6430 - acc: 0.6271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6443 - acc: 0.6211
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6457 - acc: 0.6167
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6478 - acc: 0.6111
1280/1283 [============================>.] - ETA: 0s - loss: 0.6510 - acc: 0.6070
1283/1283 [==============================] - 1s 903us/step - loss: 0.6505 - acc: 0.6072 - val_loss: 0.7106 - val_acc: 0.5284

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6096 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.6163 - acc: 0.6172
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6178 - acc: 0.5990
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6170 - acc: 0.6250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6317 - acc: 0.6016
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6261 - acc: 0.6094
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6270 - acc: 0.6035
 576/1283 [============>.................] - ETA: 0s - loss: 0.6416 - acc: 0.5868
 640/1283 [=============>................] - ETA: 0s - loss: 0.6394 - acc: 0.5891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6368 - acc: 0.5980
 768/1283 [================>.............] - ETA: 0s - loss: 0.6384 - acc: 0.6029
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6346 - acc: 0.6142
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6381 - acc: 0.6127
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6408 - acc: 0.6052
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6345 - acc: 0.6123
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6359 - acc: 0.6094
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6382 - acc: 0.6094
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6362 - acc: 0.6118
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6338 - acc: 0.6142 - val_loss: 0.7348 - val_acc: 0.5153

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6787 - acc: 0.5625
 128/1283 [=>............................] - ETA: 1s - loss: 0.6461 - acc: 0.6016
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6378 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6450 - acc: 0.6016
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6375 - acc: 0.6250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6342 - acc: 0.6198
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6250 - acc: 0.6295
 576/1283 [============>.................] - ETA: 0s - loss: 0.6234 - acc: 0.6285
 640/1283 [=============>................] - ETA: 0s - loss: 0.6265 - acc: 0.6266
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6277 - acc: 0.6207
 768/1283 [================>.............] - ETA: 0s - loss: 0.6291 - acc: 0.6185
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6269 - acc: 0.6214
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6312 - acc: 0.6183
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6309 - acc: 0.6188
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6305 - acc: 0.6230
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6326 - acc: 0.6259
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6381 - acc: 0.6215
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6389 - acc: 0.6201
1280/1283 [============================>.] - ETA: 0s - loss: 0.6386 - acc: 0.6203
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6388 - acc: 0.6204 - val_loss: 0.7403 - val_acc: 0.5109

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6121 - acc: 0.6094
 128/1283 [=>............................] - ETA: 1s - loss: 0.6307 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6343 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6354 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6280 - acc: 0.6156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6231 - acc: 0.6432
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6244 - acc: 0.6348
 576/1283 [============>.................] - ETA: 0s - loss: 0.6270 - acc: 0.6267
 640/1283 [=============>................] - ETA: 0s - loss: 0.6296 - acc: 0.6219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6302 - acc: 0.6193
 768/1283 [================>.............] - ETA: 0s - loss: 0.6277 - acc: 0.6250
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6343 - acc: 0.6238
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6349 - acc: 0.6228
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6342 - acc: 0.6198
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6370 - acc: 0.6152
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6383 - acc: 0.6103
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6346 - acc: 0.6172
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6336 - acc: 0.6192
1280/1283 [============================>.] - ETA: 0s - loss: 0.6314 - acc: 0.6234
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6314 - acc: 0.6235 - val_loss: 0.7114 - val_acc: 0.4760

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6026 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.5929 - acc: 0.6641
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5952 - acc: 0.6823
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5987 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6092 - acc: 0.6625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6088 - acc: 0.6615
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6122 - acc: 0.6540
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6082 - acc: 0.6680
 576/1283 [============>.................] - ETA: 0s - loss: 0.6095 - acc: 0.6701
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6209 - acc: 0.6548
 768/1283 [================>.............] - ETA: 0s - loss: 0.6254 - acc: 0.6497
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6248 - acc: 0.6454
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6322 - acc: 0.6323
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6339 - acc: 0.6299
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6337 - acc: 0.6287
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6355 - acc: 0.6293
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6318 - acc: 0.6365
1280/1283 [============================>.] - ETA: 0s - loss: 0.6281 - acc: 0.6414
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6282 - acc: 0.6415 - val_loss: 0.7742 - val_acc: 0.4629

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5783 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6337 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6354 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6487 - acc: 0.6062
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6442 - acc: 0.6120
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6346 - acc: 0.6295
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6289 - acc: 0.6406
 576/1283 [============>.................] - ETA: 0s - loss: 0.6342 - acc: 0.6372
 640/1283 [=============>................] - ETA: 0s - loss: 0.6288 - acc: 0.6453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6275 - acc: 0.6463
 768/1283 [================>.............] - ETA: 0s - loss: 0.6309 - acc: 0.6354
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6309 - acc: 0.6358
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6288 - acc: 0.6395
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6290 - acc: 0.6385
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6280 - acc: 0.6377
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6279 - acc: 0.6369
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6275 - acc: 0.6363
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6263 - acc: 0.6357
1280/1283 [============================>.] - ETA: 0s - loss: 0.6271 - acc: 0.6352
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6270 - acc: 0.6352 - val_loss: 0.7827 - val_acc: 0.4672

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5626 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.6455 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6314 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6332 - acc: 0.6289
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6260 - acc: 0.6250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6306 - acc: 0.6250
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6233 - acc: 0.6339
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6208 - acc: 0.6367
 576/1283 [============>.................] - ETA: 0s - loss: 0.6209 - acc: 0.6354
 640/1283 [=============>................] - ETA: 0s - loss: 0.6159 - acc: 0.6406
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6122 - acc: 0.6491
 768/1283 [================>.............] - ETA: 0s - loss: 0.6177 - acc: 0.6393
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6199 - acc: 0.6322
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6169 - acc: 0.6373
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6189 - acc: 0.6312
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6177 - acc: 0.6318
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6164 - acc: 0.6268
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6179 - acc: 0.6241
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6177 - acc: 0.6209
1280/1283 [============================>.] - ETA: 0s - loss: 0.6185 - acc: 0.6211
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6182 - acc: 0.6212 - val_loss: 0.7892 - val_acc: 0.4716

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5696 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.5842 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6075 - acc: 0.6458
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6081 - acc: 0.6523
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6128 - acc: 0.6375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6138 - acc: 0.6432
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6018 - acc: 0.6652
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5981 - acc: 0.6680
 576/1283 [============>.................] - ETA: 0s - loss: 0.6077 - acc: 0.6545
 640/1283 [=============>................] - ETA: 0s - loss: 0.6053 - acc: 0.6562
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6041 - acc: 0.6619
 768/1283 [================>.............] - ETA: 0s - loss: 0.6099 - acc: 0.6576
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6087 - acc: 0.6647
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6077 - acc: 0.6652
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6071 - acc: 0.6667
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6090 - acc: 0.6621
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6098 - acc: 0.6608
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6138 - acc: 0.6510
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6131 - acc: 0.6505
1280/1283 [============================>.] - ETA: 0s - loss: 0.6130 - acc: 0.6477
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6129 - acc: 0.6477 - val_loss: 0.7767 - val_acc: 0.4498

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=15
mode=V
accuracy=0.5145772594752187
best_valid_accuracy=0.4839650145772595
