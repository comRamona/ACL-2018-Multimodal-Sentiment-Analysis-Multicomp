/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:20:53.439971: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.7078 - acc: 0.5156
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6928 - acc: 0.4805
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6913 - acc: 0.5000
 576/1283 [============>.................] - ETA: 0s - loss: 0.6985 - acc: 0.5191
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6928 - acc: 0.5341
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6922 - acc: 0.5279
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6888 - acc: 0.5441
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6865 - acc: 0.5485
1283/1283 [==============================] - 1s 623us/step - loss: 0.6859 - acc: 0.5472 - val_loss: 0.6986 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6479 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6741 - acc: 0.5625
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6853 - acc: 0.5469
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6799 - acc: 0.5508
 640/1283 [=============>................] - ETA: 0s - loss: 0.6792 - acc: 0.5594
 768/1283 [================>.............] - ETA: 0s - loss: 0.6744 - acc: 0.5729
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6729 - acc: 0.5703
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6766 - acc: 0.5654
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6753 - acc: 0.5703
1280/1283 [============================>.] - ETA: 0s - loss: 0.6741 - acc: 0.5711
1283/1283 [==============================] - 1s 597us/step - loss: 0.6739 - acc: 0.5721 - val_loss: 0.6894 - val_acc: 0.5371

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6612 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6669 - acc: 0.5625
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6574 - acc: 0.5969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6562 - acc: 0.5893
 576/1283 [============>.................] - ETA: 0s - loss: 0.6523 - acc: 0.6059
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6532 - acc: 0.6023
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6554 - acc: 0.5986
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6555 - acc: 0.5969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6613 - acc: 0.5983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6633 - acc: 0.5946
1283/1283 [==============================] - 1s 583us/step - loss: 0.6627 - acc: 0.5924 - val_loss: 0.7131 - val_acc: 0.5109

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.7249 - acc: 0.4844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6734 - acc: 0.6094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6557 - acc: 0.6451
 640/1283 [=============>................] - ETA: 0s - loss: 0.6525 - acc: 0.6375
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6513 - acc: 0.6262
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6470 - acc: 0.6260
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6458 - acc: 0.6293
1280/1283 [============================>.] - ETA: 0s - loss: 0.6477 - acc: 0.6266
1283/1283 [==============================] - 0s 385us/step - loss: 0.6486 - acc: 0.6251 - val_loss: 0.7010 - val_acc: 0.5371

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6369 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6462 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6677 - acc: 0.5656
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6672 - acc: 0.5566
 640/1283 [=============>................] - ETA: 0s - loss: 0.6628 - acc: 0.5687
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6589 - acc: 0.5913
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6547 - acc: 0.5977
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6523 - acc: 0.6036
1283/1283 [==============================] - 1s 433us/step - loss: 0.6509 - acc: 0.6064 - val_loss: 0.7083 - val_acc: 0.5328

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6064 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6209 - acc: 0.6302
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6303 - acc: 0.6156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6293 - acc: 0.6362
 576/1283 [============>.................] - ETA: 0s - loss: 0.6271 - acc: 0.6337
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6260 - acc: 0.6420
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6245 - acc: 0.6430
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6287 - acc: 0.6385
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6321 - acc: 0.6333
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6328 - acc: 0.6332
1283/1283 [==============================] - 1s 501us/step - loss: 0.6333 - acc: 0.6329 - val_loss: 0.7160 - val_acc: 0.5328

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6287 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6392 - acc: 0.6042
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6294 - acc: 0.6281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6243 - acc: 0.6429
 576/1283 [============>.................] - ETA: 0s - loss: 0.6233 - acc: 0.6510
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6196 - acc: 0.6634
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6196 - acc: 0.6623
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6170 - acc: 0.6615
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6128 - acc: 0.6597
1280/1283 [============================>.] - ETA: 0s - loss: 0.6095 - acc: 0.6602
1283/1283 [==============================] - 1s 537us/step - loss: 0.6096 - acc: 0.6602 - val_loss: 0.7789 - val_acc: 0.4978

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6715 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6117 - acc: 0.6562
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6048 - acc: 0.6500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6040 - acc: 0.6518
 576/1283 [============>.................] - ETA: 0s - loss: 0.6179 - acc: 0.6406
 640/1283 [=============>................] - ETA: 0s - loss: 0.6200 - acc: 0.6328
 768/1283 [================>.............] - ETA: 0s - loss: 0.6152 - acc: 0.6393
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6124 - acc: 0.6417
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6079 - acc: 0.6475
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6074 - acc: 0.6493
1280/1283 [============================>.] - ETA: 0s - loss: 0.6074 - acc: 0.6516
1283/1283 [==============================] - 1s 580us/step - loss: 0.6073 - acc: 0.6516 - val_loss: 0.7187 - val_acc: 0.5022

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6081 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5818 - acc: 0.6719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5838 - acc: 0.6719
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5807 - acc: 0.6660
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6229 - acc: 0.6705
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6159 - acc: 0.6719
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6211 - acc: 0.6719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6177 - acc: 0.6748
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6124 - acc: 0.6780
1280/1283 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.6766
1283/1283 [==============================] - 1s 490us/step - loss: 0.6106 - acc: 0.6773 - val_loss: 0.7146 - val_acc: 0.5284

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6462 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6034 - acc: 0.6562
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5828 - acc: 0.6781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5803 - acc: 0.6808
 576/1283 [============>.................] - ETA: 0s - loss: 0.5630 - acc: 0.6892
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5711 - acc: 0.6832
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5776 - acc: 0.6767
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5747 - acc: 0.6771
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5682 - acc: 0.6838
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5659 - acc: 0.6826
1283/1283 [==============================] - 1s 524us/step - loss: 0.5648 - acc: 0.6843 - val_loss: 0.7942 - val_acc: 0.5022

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5328 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5371 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5327 - acc: 0.7375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5436 - acc: 0.7254
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5525 - acc: 0.7129
 640/1283 [=============>................] - ETA: 0s - loss: 0.5443 - acc: 0.7203
 768/1283 [================>.............] - ETA: 0s - loss: 0.5495 - acc: 0.7148
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5460 - acc: 0.7143
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5509 - acc: 0.7090
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5490 - acc: 0.7135
1280/1283 [============================>.] - ETA: 0s - loss: 0.5474 - acc: 0.7086
1283/1283 [==============================] - 1s 600us/step - loss: 0.5480 - acc: 0.7085 - val_loss: 0.8264 - val_acc: 0.5240

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=3
max_len=25
epochs=100
mode=V
accuracy=0.46355685131195334
best_valid_accuracy=0.41545189504373176
