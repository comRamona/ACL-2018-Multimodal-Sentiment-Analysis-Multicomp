/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:15:24.703622: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.6709 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6736 - acc: 0.6000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6771 - acc: 0.5859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6763 - acc: 0.5739
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6802 - acc: 0.5558
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6891 - acc: 0.5747
1283/1283 [==============================] - 1s 526us/step - loss: 0.6848 - acc: 0.5799 - val_loss: 0.7089 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6243 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6319 - acc: 0.6250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6322 - acc: 0.6146
 576/1283 [============>.................] - ETA: 0s - loss: 0.6707 - acc: 0.6042
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6637 - acc: 0.6165
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6651 - acc: 0.6142
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6571 - acc: 0.6198
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6518 - acc: 0.6201
1283/1283 [==============================] - 1s 423us/step - loss: 0.6481 - acc: 0.6251 - val_loss: 0.7422 - val_acc: 0.5328

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6115 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6324 - acc: 0.5833
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6247 - acc: 0.6188
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6271 - acc: 0.6161
 640/1283 [=============>................] - ETA: 0s - loss: 0.6458 - acc: 0.6359
 768/1283 [================>.............] - ETA: 0s - loss: 0.6378 - acc: 0.6380
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6277 - acc: 0.6438
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6292 - acc: 0.6484
1280/1283 [============================>.] - ETA: 0s - loss: 0.6309 - acc: 0.6422
1283/1283 [==============================] - 1s 433us/step - loss: 0.6301 - acc: 0.6422 - val_loss: 0.7545 - val_acc: 0.5197

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5573 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5950 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6123 - acc: 0.6693
 576/1283 [============>.................] - ETA: 0s - loss: 0.6187 - acc: 0.6632
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6070 - acc: 0.6671
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6058 - acc: 0.6699
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6304 - acc: 0.6530
1283/1283 [==============================] - 0s 361us/step - loss: 0.6299 - acc: 0.6508 - val_loss: 0.7807 - val_acc: 0.4891

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5779 - acc: 0.6719
 128/1283 [=>............................] - ETA: 0s - loss: 0.5898 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5936 - acc: 0.6484
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6016 - acc: 0.6536
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6007 - acc: 0.6621
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5935 - acc: 0.6705
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5895 - acc: 0.6791
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5876 - acc: 0.6802
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5831 - acc: 0.6847
1280/1283 [============================>.] - ETA: 0s - loss: 0.5989 - acc: 0.6805
1283/1283 [==============================] - 1s 525us/step - loss: 0.5990 - acc: 0.6804 - val_loss: 0.8212 - val_acc: 0.4672

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5465 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5685 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5615 - acc: 0.6953
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5714 - acc: 0.6836
 640/1283 [=============>................] - ETA: 0s - loss: 0.5808 - acc: 0.6750
 768/1283 [================>.............] - ETA: 0s - loss: 0.5744 - acc: 0.6875
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5812 - acc: 0.7076
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5767 - acc: 0.7090
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5791 - acc: 0.7049
1280/1283 [============================>.] - ETA: 0s - loss: 0.5787 - acc: 0.7023
1283/1283 [==============================] - 1s 502us/step - loss: 0.5782 - acc: 0.7030 - val_loss: 0.8371 - val_acc: 0.4847

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5471 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5058 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5153 - acc: 0.7406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5185 - acc: 0.7500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5084 - acc: 0.7539
 640/1283 [=============>................] - ETA: 0s - loss: 0.5353 - acc: 0.7562
 768/1283 [================>.............] - ETA: 0s - loss: 0.5557 - acc: 0.7409
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5679 - acc: 0.7232
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5728 - acc: 0.7109
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5760 - acc: 0.7049
1280/1283 [============================>.] - ETA: 0s - loss: 0.5736 - acc: 0.7063
1283/1283 [==============================] - 1s 585us/step - loss: 0.5735 - acc: 0.7062 - val_loss: 0.7626 - val_acc: 0.5459

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5390 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6534 - acc: 0.7083
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5956 - acc: 0.7161
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5822 - acc: 0.7188
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5684 - acc: 0.7330
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5666 - acc: 0.7266
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5594 - acc: 0.7270
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5604 - acc: 0.7212
1283/1283 [==============================] - 1s 407us/step - loss: 0.5566 - acc: 0.7225 - val_loss: 0.7554 - val_acc: 0.5371

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5482 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5478 - acc: 0.7240
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5444 - acc: 0.7000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5266 - acc: 0.7227
 640/1283 [=============>................] - ETA: 0s - loss: 0.5269 - acc: 0.7156
 768/1283 [================>.............] - ETA: 0s - loss: 0.5124 - acc: 0.7357
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5219 - acc: 0.7232
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5169 - acc: 0.7275
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5188 - acc: 0.7283
1283/1283 [==============================] - 1s 506us/step - loss: 0.5285 - acc: 0.7311 - val_loss: 0.7938 - val_acc: 0.4891

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4973 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5628 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5433 - acc: 0.7562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5374 - acc: 0.7522
 576/1283 [============>.................] - ETA: 0s - loss: 0.5491 - acc: 0.7344
 768/1283 [================>.............] - ETA: 0s - loss: 0.5315 - acc: 0.7435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5228 - acc: 0.7377
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5195 - acc: 0.7402
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5167 - acc: 0.7378
1280/1283 [============================>.] - ETA: 0s - loss: 0.5134 - acc: 0.7414
1283/1283 [==============================] - 1s 553us/step - loss: 0.5149 - acc: 0.7405 - val_loss: 0.8558 - val_acc: 0.4978

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4622 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4944 - acc: 0.7292
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5257 - acc: 0.7562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5141 - acc: 0.7589
 576/1283 [============>.................] - ETA: 0s - loss: 0.5138 - acc: 0.7500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5104 - acc: 0.7528
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5197 - acc: 0.7416
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5207 - acc: 0.7406
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5292 - acc: 0.7500
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5245 - acc: 0.7500
1283/1283 [==============================] - 1s 590us/step - loss: 0.5237 - acc: 0.7482 - val_loss: 0.7754 - val_acc: 0.5284

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
epochs=100
mode=V
accuracy=0.5160349854227405
best_valid_accuracy=0.48104956268221577
