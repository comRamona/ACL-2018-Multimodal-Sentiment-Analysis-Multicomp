/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_blstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_blstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 15:53:59.718790: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 28s - loss: 0.8390 - acc: 0.4531
 192/1283 [===>..........................] - ETA: 8s - loss: 0.7811 - acc: 0.4688 
 256/1283 [====>.........................] - ETA: 6s - loss: 0.7548 - acc: 0.4961
 320/1283 [======>.......................] - ETA: 5s - loss: 0.7475 - acc: 0.5062
 448/1283 [=========>....................] - ETA: 3s - loss: 0.7348 - acc: 0.5067
 576/1283 [============>.................] - ETA: 2s - loss: 0.7209 - acc: 0.5243
 640/1283 [=============>................] - ETA: 1s - loss: 0.7147 - acc: 0.5344
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7100 - acc: 0.5455
 768/1283 [================>.............] - ETA: 1s - loss: 0.7134 - acc: 0.5391
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7121 - acc: 0.5397
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7058 - acc: 0.5469
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7070 - acc: 0.5404
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7062 - acc: 0.5408
1280/1283 [============================>.] - ETA: 0s - loss: 0.7041 - acc: 0.5430
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7045 - acc: 0.5417 - val_loss: 0.7065 - val_acc: 0.4934

Epoch 00001: val_acc improved from -inf to 0.49345, saving model to classification_logs//blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.7049 - acc: 0.5000
 128/1283 [=>............................] - ETA: 0s - loss: 0.6893 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6951 - acc: 0.5312
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6863 - acc: 0.5547
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6860 - acc: 0.5469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6823 - acc: 0.5625
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6774 - acc: 0.5762
 640/1283 [=============>................] - ETA: 0s - loss: 0.6756 - acc: 0.5813
 768/1283 [================>.............] - ETA: 0s - loss: 0.6735 - acc: 0.5885
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6666 - acc: 0.6004
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6652 - acc: 0.6055
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6647 - acc: 0.6057
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6662 - acc: 0.6016
1280/1283 [============================>.] - ETA: 0s - loss: 0.6677 - acc: 0.5977
1283/1283 [==============================] - 1s 879us/step - loss: 0.6679 - acc: 0.5970 - val_loss: 0.7084 - val_acc: 0.4760

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.7387 - acc: 0.4844
 128/1283 [=>............................] - ETA: 0s - loss: 0.7003 - acc: 0.5234
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6690 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6564 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6469 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6425 - acc: 0.6484
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6466 - acc: 0.6384
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6475 - acc: 0.6348
 576/1283 [============>.................] - ETA: 0s - loss: 0.6415 - acc: 0.6424
 640/1283 [=============>................] - ETA: 0s - loss: 0.6413 - acc: 0.6469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6393 - acc: 0.6463
 768/1283 [================>.............] - ETA: 0s - loss: 0.6397 - acc: 0.6432
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6339 - acc: 0.6502
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6364 - acc: 0.6427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6350 - acc: 0.6436
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6367 - acc: 0.6406
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6371 - acc: 0.6431
1283/1283 [==============================] - 1s 907us/step - loss: 0.6389 - acc: 0.6422 - val_loss: 0.6997 - val_acc: 0.5197

Epoch 00003: val_acc improved from 0.49345 to 0.51965, saving model to classification_logs//blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5949 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6225 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6130 - acc: 0.6906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6237 - acc: 0.6786
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6252 - acc: 0.6699
 576/1283 [============>.................] - ETA: 0s - loss: 0.6257 - acc: 0.6684
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6211 - acc: 0.6662
 768/1283 [================>.............] - ETA: 0s - loss: 0.6149 - acc: 0.6758
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6144 - acc: 0.6779
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6184 - acc: 0.6708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6158 - acc: 0.6729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6135 - acc: 0.6756
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6150 - acc: 0.6762
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6190 - acc: 0.6702
1280/1283 [============================>.] - ETA: 0s - loss: 0.6185 - acc: 0.6734
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6183 - acc: 0.6734 - val_loss: 0.7116 - val_acc: 0.5240

Epoch 00004: val_acc improved from 0.51965 to 0.52402, saving model to classification_logs//blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6525 - acc: 0.6250
 128/1283 [=>............................] - ETA: 1s - loss: 0.6069 - acc: 0.6797
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5932 - acc: 0.7031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5852 - acc: 0.7083
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5737 - acc: 0.7168
 576/1283 [============>.................] - ETA: 0s - loss: 0.5813 - acc: 0.7153
 640/1283 [=============>................] - ETA: 0s - loss: 0.5796 - acc: 0.7219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5833 - acc: 0.7173
 768/1283 [================>.............] - ETA: 0s - loss: 0.5885 - acc: 0.7070
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5853 - acc: 0.7091
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5833 - acc: 0.7052
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5842 - acc: 0.7041
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5906 - acc: 0.6962
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5910 - acc: 0.6957
1280/1283 [============================>.] - ETA: 0s - loss: 0.5921 - acc: 0.6945
1283/1283 [==============================] - 1s 989us/step - loss: 0.5921 - acc: 0.6952 - val_loss: 0.7154 - val_acc: 0.5197

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5390 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5495 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5458 - acc: 0.7461
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5406 - acc: 0.7469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5350 - acc: 0.7500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5392 - acc: 0.7388
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5443 - acc: 0.7266
 576/1283 [============>.................] - ETA: 0s - loss: 0.5541 - acc: 0.7257
 640/1283 [=============>................] - ETA: 0s - loss: 0.5568 - acc: 0.7234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5615 - acc: 0.7244
 768/1283 [================>.............] - ETA: 0s - loss: 0.5628 - acc: 0.7214
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5661 - acc: 0.7163
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5674 - acc: 0.7143
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5697 - acc: 0.7156
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5671 - acc: 0.7168
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5684 - acc: 0.7123
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5700 - acc: 0.7109
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5710 - acc: 0.7064
1280/1283 [============================>.] - ETA: 0s - loss: 0.5719 - acc: 0.7047
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5713 - acc: 0.7054 - val_loss: 0.7270 - val_acc: 0.5240

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5415 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5430 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5612 - acc: 0.7240
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5345 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5307 - acc: 0.7469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5323 - acc: 0.7321
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5381 - acc: 0.7207
 576/1283 [============>.................] - ETA: 0s - loss: 0.5376 - acc: 0.7205
 640/1283 [=============>................] - ETA: 0s - loss: 0.5366 - acc: 0.7219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5382 - acc: 0.7244
 768/1283 [================>.............] - ETA: 0s - loss: 0.5389 - acc: 0.7240
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5388 - acc: 0.7272
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5366 - acc: 0.7254
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5370 - acc: 0.7240
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5396 - acc: 0.7217
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5416 - acc: 0.7188
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5453 - acc: 0.7144
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5442 - acc: 0.7179
1280/1283 [============================>.] - ETA: 0s - loss: 0.5413 - acc: 0.7219
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5414 - acc: 0.7217 - val_loss: 0.7303 - val_acc: 0.5677

Epoch 00007: val_acc improved from 0.52402 to 0.56769, saving model to classification_logs//blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5609 - acc: 0.7344
 128/1283 [=>............................] - ETA: 1s - loss: 0.5238 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5314 - acc: 0.7305
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5416 - acc: 0.7125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5327 - acc: 0.7240
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5246 - acc: 0.7344
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5247 - acc: 0.7324
 576/1283 [============>.................] - ETA: 0s - loss: 0.5256 - acc: 0.7274
 640/1283 [=============>................] - ETA: 0s - loss: 0.5278 - acc: 0.7297
 768/1283 [================>.............] - ETA: 0s - loss: 0.5279 - acc: 0.7318
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5288 - acc: 0.7320
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5264 - acc: 0.7355
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5310 - acc: 0.7312
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5285 - acc: 0.7334
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5294 - acc: 0.7325
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5317 - acc: 0.7309
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5256 - acc: 0.7368
1280/1283 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.7359
1283/1283 [==============================] - 1s 977us/step - loss: 0.5250 - acc: 0.7350 - val_loss: 0.7347 - val_acc: 0.5895

Epoch 00008: val_acc improved from 0.56769 to 0.58952, saving model to classification_logs//blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5021 - acc: 0.7500
 128/1283 [=>............................] - ETA: 0s - loss: 0.5048 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4867 - acc: 0.7865
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4826 - acc: 0.7852
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4718 - acc: 0.7906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4698 - acc: 0.7865
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4651 - acc: 0.8013
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4733 - acc: 0.8047
 576/1283 [============>.................] - ETA: 0s - loss: 0.4677 - acc: 0.8090
 640/1283 [=============>................] - ETA: 0s - loss: 0.4741 - acc: 0.8063
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4790 - acc: 0.7969
 768/1283 [================>.............] - ETA: 0s - loss: 0.4804 - acc: 0.7956
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4794 - acc: 0.7957
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4832 - acc: 0.7924
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4843 - acc: 0.7896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4881 - acc: 0.7881
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4876 - acc: 0.7886
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4898 - acc: 0.7865
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4891 - acc: 0.7878
1280/1283 [============================>.] - ETA: 0s - loss: 0.4881 - acc: 0.7875
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4880 - acc: 0.7880 - val_loss: 0.7609 - val_acc: 0.5502

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4646 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4681 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4547 - acc: 0.8073
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4516 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4715 - acc: 0.7969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4901 - acc: 0.7839
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5001 - acc: 0.7723
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4959 - acc: 0.7734
 576/1283 [============>.................] - ETA: 1s - loss: 0.4918 - acc: 0.7743
 640/1283 [=============>................] - ETA: 0s - loss: 0.4859 - acc: 0.7750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4884 - acc: 0.7685
 768/1283 [================>.............] - ETA: 0s - loss: 0.4805 - acc: 0.7721
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4826 - acc: 0.7704
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4803 - acc: 0.7701
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4766 - acc: 0.7719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4766 - acc: 0.7725
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4710 - acc: 0.7794
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4680 - acc: 0.7795
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4656 - acc: 0.7812
1280/1283 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.7789
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4660 - acc: 0.7794 - val_loss: 0.7766 - val_acc: 0.5633

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.3677 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.3994 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4145 - acc: 0.8229
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4106 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3938 - acc: 0.8250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4078 - acc: 0.8151
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4177 - acc: 0.8147
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4157 - acc: 0.8184
 576/1283 [============>.................] - ETA: 1s - loss: 0.4080 - acc: 0.8264
 640/1283 [=============>................] - ETA: 1s - loss: 0.4167 - acc: 0.8219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4307 - acc: 0.8111
 768/1283 [================>.............] - ETA: 0s - loss: 0.4312 - acc: 0.8099
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4273 - acc: 0.8101
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4245 - acc: 0.8058
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4222 - acc: 0.8073
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4236 - acc: 0.8096
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4188 - acc: 0.8134
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4262 - acc: 0.8064
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4249 - acc: 0.8067
1280/1283 [============================>.] - ETA: 0s - loss: 0.4245 - acc: 0.8063
1283/1283 [==============================] - 2s 2ms/step - loss: 0.4250 - acc: 0.8059 - val_loss: 0.7999 - val_acc: 0.6114

Epoch 00011: val_acc improved from 0.58952 to 0.61135, saving model to classification_logs//blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3959 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.3589 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3430 - acc: 0.8646
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3347 - acc: 0.8672
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3487 - acc: 0.8719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3414 - acc: 0.8802
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3599 - acc: 0.8616
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3730 - acc: 0.8496
 576/1283 [============>.................] - ETA: 1s - loss: 0.3849 - acc: 0.8333
 640/1283 [=============>................] - ETA: 0s - loss: 0.3854 - acc: 0.8328
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3807 - acc: 0.8324
 768/1283 [================>.............] - ETA: 0s - loss: 0.3861 - acc: 0.8294
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3840 - acc: 0.8329
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3889 - acc: 0.8326
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3915 - acc: 0.8292
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3871 - acc: 0.8320
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3918 - acc: 0.8290
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3885 - acc: 0.8325
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3908 - acc: 0.8298
1280/1283 [============================>.] - ETA: 0s - loss: 0.3924 - acc: 0.8305
1283/1283 [==============================] - 2s 2ms/step - loss: 0.3924 - acc: 0.8301 - val_loss: 0.8258 - val_acc: 0.6245

Epoch 00012: val_acc improved from 0.61135 to 0.62445, saving model to classification_logs//blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3474 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.3057 - acc: 0.8828
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3060 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3146 - acc: 0.8789
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3168 - acc: 0.8750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3294 - acc: 0.8568
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3442 - acc: 0.8482
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3622 - acc: 0.8418
 576/1283 [============>.................] - ETA: 0s - loss: 0.3664 - acc: 0.8351
 640/1283 [=============>................] - ETA: 0s - loss: 0.3715 - acc: 0.8328
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3756 - acc: 0.8295
 768/1283 [================>.............] - ETA: 0s - loss: 0.3732 - acc: 0.8320
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3705 - acc: 0.8341
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3680 - acc: 0.8348
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3717 - acc: 0.8313
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3682 - acc: 0.8330
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3651 - acc: 0.8355
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3660 - acc: 0.8359
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3652 - acc: 0.8363
1280/1283 [============================>.] - ETA: 0s - loss: 0.3664 - acc: 0.8344
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3660 - acc: 0.8348 - val_loss: 0.7946 - val_acc: 0.6114

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3405 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.3138 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3257 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3318 - acc: 0.8555
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3305 - acc: 0.8562
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3263 - acc: 0.8620
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3258 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3304 - acc: 0.8594
 576/1283 [============>.................] - ETA: 0s - loss: 0.3274 - acc: 0.8628
 640/1283 [=============>................] - ETA: 1s - loss: 0.3210 - acc: 0.8672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3228 - acc: 0.8651
 768/1283 [================>.............] - ETA: 0s - loss: 0.3158 - acc: 0.8685
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3284 - acc: 0.8558
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3278 - acc: 0.8571
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3391 - acc: 0.8531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3385 - acc: 0.8535
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3330 - acc: 0.8585
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3303 - acc: 0.8602
1280/1283 [============================>.] - ETA: 0s - loss: 0.3280 - acc: 0.8625
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3281 - acc: 0.8628 - val_loss: 0.8183 - val_acc: 0.6026

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2958 - acc: 0.8750
 128/1283 [=>............................] - ETA: 2s - loss: 0.3271 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3383 - acc: 0.8490
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3228 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3322 - acc: 0.8594
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3125 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3119 - acc: 0.8795
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3126 - acc: 0.8789
 576/1283 [============>.................] - ETA: 1s - loss: 0.3190 - acc: 0.8767
 640/1283 [=============>................] - ETA: 1s - loss: 0.3246 - acc: 0.8734
 704/1283 [===============>..............] - ETA: 1s - loss: 0.3173 - acc: 0.8736
 768/1283 [================>.............] - ETA: 0s - loss: 0.3143 - acc: 0.8763
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3184 - acc: 0.8714
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3141 - acc: 0.8739
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3117 - acc: 0.8740
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3187 - acc: 0.8672
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3152 - acc: 0.8722
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3150 - acc: 0.8698
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3103 - acc: 0.8709
1280/1283 [============================>.] - ETA: 0s - loss: 0.3119 - acc: 0.8703
1283/1283 [==============================] - 2s 2ms/step - loss: 0.3116 - acc: 0.8706 - val_loss: 0.8474 - val_acc: 0.5983

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2672 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.2956 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2808 - acc: 0.8542
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2721 - acc: 0.8711
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2557 - acc: 0.8812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2667 - acc: 0.8802
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2674 - acc: 0.8817
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2636 - acc: 0.8867
 576/1283 [============>.................] - ETA: 1s - loss: 0.2607 - acc: 0.8906
 640/1283 [=============>................] - ETA: 0s - loss: 0.2616 - acc: 0.8875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2620 - acc: 0.8878
 768/1283 [================>.............] - ETA: 0s - loss: 0.2648 - acc: 0.8854
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2621 - acc: 0.8870
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2617 - acc: 0.8839
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2627 - acc: 0.8823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2604 - acc: 0.8848
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2629 - acc: 0.8833
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2626 - acc: 0.8828
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2612 - acc: 0.8849
1280/1283 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.8828
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2645 - acc: 0.8831 - val_loss: 1.0095 - val_acc: 0.6026

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1797 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.2167 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2238 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2587 - acc: 0.8875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2584 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2473 - acc: 0.8973
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2432 - acc: 0.9004
 576/1283 [============>.................] - ETA: 0s - loss: 0.2482 - acc: 0.8941
 640/1283 [=============>................] - ETA: 0s - loss: 0.2535 - acc: 0.8953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2497 - acc: 0.8963
 768/1283 [================>.............] - ETA: 0s - loss: 0.2451 - acc: 0.8984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2466 - acc: 0.8978
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2515 - acc: 0.8940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2527 - acc: 0.8927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2529 - acc: 0.8936
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2543 - acc: 0.8925
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2552 - acc: 0.8906
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2519 - acc: 0.8923
1280/1283 [============================>.] - ETA: 0s - loss: 0.2514 - acc: 0.8930
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2510 - acc: 0.8932 - val_loss: 0.9699 - val_acc: 0.6245

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1728 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1957 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2264 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2309 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2320 - acc: 0.9062
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2319 - acc: 0.9036
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2238 - acc: 0.9085
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2263 - acc: 0.9062
 576/1283 [============>.................] - ETA: 0s - loss: 0.2219 - acc: 0.9080
 640/1283 [=============>................] - ETA: 0s - loss: 0.2246 - acc: 0.9078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2257 - acc: 0.9077
 768/1283 [================>.............] - ETA: 0s - loss: 0.2210 - acc: 0.9115
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2206 - acc: 0.9111
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2174 - acc: 0.9118
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2187 - acc: 0.9115
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2210 - acc: 0.9102
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2184 - acc: 0.9108
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2164 - acc: 0.9115
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2176 - acc: 0.9120
1280/1283 [============================>.] - ETA: 0s - loss: 0.2209 - acc: 0.9117
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2207 - acc: 0.9119 - val_loss: 0.9760 - val_acc: 0.6114

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1977 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.1723 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1609 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1804 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1989 - acc: 0.9281
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1942 - acc: 0.9349
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1837 - acc: 0.9397
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1908 - acc: 0.9316
 576/1283 [============>.................] - ETA: 1s - loss: 0.1907 - acc: 0.9288
 640/1283 [=============>................] - ETA: 1s - loss: 0.1942 - acc: 0.9266
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1938 - acc: 0.9261
 768/1283 [================>.............] - ETA: 0s - loss: 0.1916 - acc: 0.9271
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1968 - acc: 0.9243
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1978 - acc: 0.9230
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2007 - acc: 0.9229
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1962 - acc: 0.9258
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1924 - acc: 0.9274
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1945 - acc: 0.9253
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1960 - acc: 0.9227
1280/1283 [============================>.] - ETA: 0s - loss: 0.1992 - acc: 0.9227
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2017 - acc: 0.9213 - val_loss: 0.9683 - val_acc: 0.6070

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2775 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.2822 - acc: 0.8672
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2517 - acc: 0.8802
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2542 - acc: 0.8945
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2661 - acc: 0.8844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2643 - acc: 0.8854
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2591 - acc: 0.8884
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2594 - acc: 0.8926
 576/1283 [============>.................] - ETA: 1s - loss: 0.2618 - acc: 0.8941
 640/1283 [=============>................] - ETA: 1s - loss: 0.2651 - acc: 0.8938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2621 - acc: 0.8963
 768/1283 [================>.............] - ETA: 0s - loss: 0.2580 - acc: 0.8984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2566 - acc: 0.8990
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2610 - acc: 0.8962
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2572 - acc: 0.8979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2559 - acc: 0.8994
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2582 - acc: 0.8989
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2522 - acc: 0.9010
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2505 - acc: 0.9013
1280/1283 [============================>.] - ETA: 0s - loss: 0.2490 - acc: 0.9031
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2485 - acc: 0.9034 - val_loss: 1.0274 - val_acc: 0.6114

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1337 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1489 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1560 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1590 - acc: 0.9414
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1567 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1577 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1909 - acc: 0.9241
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1847 - acc: 0.9277
 576/1283 [============>.................] - ETA: 1s - loss: 0.1871 - acc: 0.9236
 640/1283 [=============>................] - ETA: 1s - loss: 0.1863 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1828 - acc: 0.9247
 768/1283 [================>.............] - ETA: 0s - loss: 0.1802 - acc: 0.9271
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1792 - acc: 0.9267
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1748 - acc: 0.9308
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1708 - acc: 0.9333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1703 - acc: 0.9336
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1675 - acc: 0.9357
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1631 - acc: 0.9392
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1635 - acc: 0.9400
1280/1283 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9375
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1657 - acc: 0.9376 - val_loss: 1.0424 - val_acc: 0.5939

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0878 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1053 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1156 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1287 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1375 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1357 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1333 - acc: 0.9531
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1293 - acc: 0.9551
 576/1283 [============>.................] - ETA: 1s - loss: 0.1278 - acc: 0.9549
 640/1283 [=============>................] - ETA: 1s - loss: 0.1356 - acc: 0.9516
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1338 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1322 - acc: 0.9544
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1324 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1333 - acc: 0.9520
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1355 - acc: 0.9500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1357 - acc: 0.9512
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1387 - acc: 0.9467
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1378 - acc: 0.9479
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1420 - acc: 0.9465
1280/1283 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9477
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1417 - acc: 0.9478 - val_loss: 1.1589 - val_acc: 0.5852

Epoch 00022: val_acc did not improve
Epoch 00022: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
mode=A
accuracy=0.4650145772594752
best_valid_accuracy=0.46938775510204084
