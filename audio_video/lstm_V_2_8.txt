/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 09:42:45.645627: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 33s - loss: 0.7000 - acc: 0.4062
 128/1283 [=>............................] - ETA: 16s - loss: 0.6970 - acc: 0.4531
 192/1283 [===>..........................] - ETA: 11s - loss: 0.6949 - acc: 0.4844
 256/1283 [====>.........................] - ETA: 8s - loss: 0.6946 - acc: 0.4805 
 320/1283 [======>.......................] - ETA: 6s - loss: 0.6941 - acc: 0.4938
 384/1283 [=======>......................] - ETA: 5s - loss: 0.6943 - acc: 0.4844
 448/1283 [=========>....................] - ETA: 4s - loss: 0.6939 - acc: 0.4799
 512/1283 [==========>...................] - ETA: 3s - loss: 0.6937 - acc: 0.4805
 576/1283 [============>.................] - ETA: 3s - loss: 0.6938 - acc: 0.4809
 640/1283 [=============>................] - ETA: 2s - loss: 0.6940 - acc: 0.4844
 704/1283 [===============>..............] - ETA: 2s - loss: 0.6935 - acc: 0.4886
 768/1283 [================>.............] - ETA: 1s - loss: 0.6925 - acc: 0.4961
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6921 - acc: 0.4940
 896/1283 [===================>..........] - ETA: 1s - loss: 0.6911 - acc: 0.5000
 960/1283 [=====================>........] - ETA: 1s - loss: 0.6899 - acc: 0.5010
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6893 - acc: 0.5068
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6896 - acc: 0.5074
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6892 - acc: 0.5148
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6888 - acc: 0.5189
1280/1283 [============================>.] - ETA: 0s - loss: 0.6882 - acc: 0.5234
1283/1283 [==============================] - 4s 3ms/step - loss: 0.6882 - acc: 0.5238 - val_loss: 0.6972 - val_acc: 0.5022

Epoch 00001: val_acc improved from -inf to 0.50218, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.6739 - acc: 0.5625
 128/1283 [=>............................] - ETA: 1s - loss: 0.6794 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6774 - acc: 0.5625
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6733 - acc: 0.5781
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6748 - acc: 0.5656
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6730 - acc: 0.5703
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6723 - acc: 0.5759
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6693 - acc: 0.5879
 576/1283 [============>.................] - ETA: 1s - loss: 0.6684 - acc: 0.5868
 640/1283 [=============>................] - ETA: 1s - loss: 0.6691 - acc: 0.5813
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6684 - acc: 0.5895
 768/1283 [================>.............] - ETA: 0s - loss: 0.6695 - acc: 0.5964
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6688 - acc: 0.5950
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6667 - acc: 0.5971
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6661 - acc: 0.5969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6658 - acc: 0.5986
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6635 - acc: 0.6002
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6626 - acc: 0.6016
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6633 - acc: 0.5979
1280/1283 [============================>.] - ETA: 0s - loss: 0.6636 - acc: 0.5922
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6636 - acc: 0.5924 - val_loss: 0.7171 - val_acc: 0.5153

Epoch 00002: val_acc improved from 0.50218 to 0.51528, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6536 - acc: 0.5781
 128/1283 [=>............................] - ETA: 1s - loss: 0.6477 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6525 - acc: 0.5990
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6554 - acc: 0.6133
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6523 - acc: 0.6031
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6504 - acc: 0.6042
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6429 - acc: 0.6228
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6393 - acc: 0.6289
 576/1283 [============>.................] - ETA: 0s - loss: 0.6430 - acc: 0.6198
 640/1283 [=============>................] - ETA: 0s - loss: 0.6430 - acc: 0.6266
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6463 - acc: 0.6193
 768/1283 [================>.............] - ETA: 0s - loss: 0.6457 - acc: 0.6146
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6462 - acc: 0.6094
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6497 - acc: 0.6071
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6470 - acc: 0.6156
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6468 - acc: 0.6133
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6472 - acc: 0.6085
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6479 - acc: 0.6050
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6475 - acc: 0.6061
1280/1283 [============================>.] - ETA: 0s - loss: 0.6503 - acc: 0.6023
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6505 - acc: 0.6017 - val_loss: 0.7125 - val_acc: 0.4978

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6102 - acc: 0.6719
 128/1283 [=>............................] - ETA: 1s - loss: 0.6141 - acc: 0.6328
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6133 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6191 - acc: 0.6445
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6186 - acc: 0.6469
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6247 - acc: 0.6458
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6261 - acc: 0.6496
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6229 - acc: 0.6543
 576/1283 [============>.................] - ETA: 0s - loss: 0.6258 - acc: 0.6406
 640/1283 [=============>................] - ETA: 0s - loss: 0.6245 - acc: 0.6375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6215 - acc: 0.6420
 768/1283 [================>.............] - ETA: 0s - loss: 0.6221 - acc: 0.6432
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6254 - acc: 0.6418
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6291 - acc: 0.6328
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6274 - acc: 0.6354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6278 - acc: 0.6396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6283 - acc: 0.6369
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6308 - acc: 0.6380
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6312 - acc: 0.6340
1280/1283 [============================>.] - ETA: 0s - loss: 0.6317 - acc: 0.6305
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6322 - acc: 0.6298 - val_loss: 0.7219 - val_acc: 0.5197

Epoch 00004: val_acc improved from 0.51528 to 0.51965, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6103 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6486 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6303 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6235 - acc: 0.6484
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6181 - acc: 0.6719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6105 - acc: 0.6849
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6144 - acc: 0.6808
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6264 - acc: 0.6562
 576/1283 [============>.................] - ETA: 0s - loss: 0.6283 - acc: 0.6510
 640/1283 [=============>................] - ETA: 0s - loss: 0.6248 - acc: 0.6500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6225 - acc: 0.6591
 768/1283 [================>.............] - ETA: 0s - loss: 0.6195 - acc: 0.6602
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6180 - acc: 0.6587
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6159 - acc: 0.6607
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6173 - acc: 0.6510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6216 - acc: 0.6475
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6255 - acc: 0.6397
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6284 - acc: 0.6337
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6294 - acc: 0.6316
1280/1283 [============================>.] - ETA: 0s - loss: 0.6296 - acc: 0.6328
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6293 - acc: 0.6337 - val_loss: 0.7319 - val_acc: 0.5328

Epoch 00005: val_acc improved from 0.51965 to 0.53275, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6144 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.6205 - acc: 0.6328
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6230 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6327 - acc: 0.6367
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6146 - acc: 0.6500
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6127 - acc: 0.6536
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6180 - acc: 0.6362
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6130 - acc: 0.6426
 576/1283 [============>.................] - ETA: 0s - loss: 0.6121 - acc: 0.6458
 640/1283 [=============>................] - ETA: 0s - loss: 0.6042 - acc: 0.6562
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6075 - acc: 0.6506
 768/1283 [================>.............] - ETA: 0s - loss: 0.6159 - acc: 0.6484
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6141 - acc: 0.6466
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6147 - acc: 0.6496
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6191 - acc: 0.6490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6196 - acc: 0.6484
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6210 - acc: 0.6480
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6221 - acc: 0.6424
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6238 - acc: 0.6414
1280/1283 [============================>.] - ETA: 0s - loss: 0.6237 - acc: 0.6430
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6236 - acc: 0.6430 - val_loss: 0.7391 - val_acc: 0.4847

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6916 - acc: 0.5469
 128/1283 [=>............................] - ETA: 1s - loss: 0.6374 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6350 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6120 - acc: 0.6523
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6108 - acc: 0.6562
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6090 - acc: 0.6562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6063 - acc: 0.6629
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6227 - acc: 0.6367
 576/1283 [============>.................] - ETA: 0s - loss: 0.6165 - acc: 0.6424
 640/1283 [=============>................] - ETA: 0s - loss: 0.6116 - acc: 0.6500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6096 - acc: 0.6520
 768/1283 [================>.............] - ETA: 0s - loss: 0.6095 - acc: 0.6523
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6079 - acc: 0.6550
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6068 - acc: 0.6574
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6078 - acc: 0.6500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6080 - acc: 0.6465
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6080 - acc: 0.6471
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6122 - acc: 0.6398
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6129 - acc: 0.6406
1280/1283 [============================>.] - ETA: 0s - loss: 0.6166 - acc: 0.6406
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6175 - acc: 0.6399 - val_loss: 0.7329 - val_acc: 0.5546

Epoch 00007: val_acc improved from 0.53275 to 0.55459, saving model to classification_logs//lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_lstm_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6232 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.5959 - acc: 0.6641
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5960 - acc: 0.6510
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6026 - acc: 0.6484
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5961 - acc: 0.6750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5943 - acc: 0.6849
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5991 - acc: 0.6719
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5964 - acc: 0.6797
 576/1283 [============>.................] - ETA: 0s - loss: 0.5961 - acc: 0.6806
 640/1283 [=============>................] - ETA: 0s - loss: 0.6110 - acc: 0.6656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6143 - acc: 0.6506
 768/1283 [================>.............] - ETA: 0s - loss: 0.6149 - acc: 0.6471
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6217 - acc: 0.6370
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6193 - acc: 0.6362
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6183 - acc: 0.6375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6140 - acc: 0.6416
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6171 - acc: 0.6369
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6199 - acc: 0.6372
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6219 - acc: 0.6382
1283/1283 [==============================] - 1s 913us/step - loss: 0.6215 - acc: 0.6383 - val_loss: 0.7241 - val_acc: 0.5153

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6103 - acc: 0.6719
 128/1283 [=>............................] - ETA: 0s - loss: 0.6131 - acc: 0.6328
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6009 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6014 - acc: 0.6380
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5957 - acc: 0.6473
 576/1283 [============>.................] - ETA: 0s - loss: 0.6011 - acc: 0.6424
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6073 - acc: 0.6463
 768/1283 [================>.............] - ETA: 0s - loss: 0.6102 - acc: 0.6406
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6102 - acc: 0.6429
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6147 - acc: 0.6365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6175 - acc: 0.6348
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6174 - acc: 0.6333
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6183 - acc: 0.6283
1280/1283 [============================>.] - ETA: 0s - loss: 0.6137 - acc: 0.6359
1283/1283 [==============================] - 1s 852us/step - loss: 0.6134 - acc: 0.6368 - val_loss: 0.7412 - val_acc: 0.5284

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5970 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.6082 - acc: 0.6484
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6119 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5971 - acc: 0.6641
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5983 - acc: 0.6562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6021 - acc: 0.6680
 640/1283 [=============>................] - ETA: 0s - loss: 0.6040 - acc: 0.6641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6015 - acc: 0.6648
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6027 - acc: 0.6695
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6038 - acc: 0.6641
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6083 - acc: 0.6562
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6067 - acc: 0.6544
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6070 - acc: 0.6546
1280/1283 [============================>.] - ETA: 0s - loss: 0.6050 - acc: 0.6555
1283/1283 [==============================] - 1s 795us/step - loss: 0.6054 - acc: 0.6555 - val_loss: 0.7529 - val_acc: 0.5066

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6386 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6003 - acc: 0.6823
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5931 - acc: 0.6594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5952 - acc: 0.6607
 576/1283 [============>.................] - ETA: 0s - loss: 0.6010 - acc: 0.6649
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6007 - acc: 0.6591
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5981 - acc: 0.6587
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6035 - acc: 0.6573
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6056 - acc: 0.6535
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6098 - acc: 0.6521
1283/1283 [==============================] - 1s 613us/step - loss: 0.6133 - acc: 0.6485 - val_loss: 0.7615 - val_acc: 0.4803

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6160 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6299 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6134 - acc: 0.6438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6093 - acc: 0.6406
 576/1283 [============>.................] - ETA: 0s - loss: 0.6192 - acc: 0.6285
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6199 - acc: 0.6307
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6158 - acc: 0.6322
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6125 - acc: 0.6396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6096 - acc: 0.6379
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6062 - acc: 0.6431
1283/1283 [==============================] - 1s 545us/step - loss: 0.6031 - acc: 0.6477 - val_loss: 0.7627 - val_acc: 0.4760

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5716 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5771 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6093 - acc: 0.6531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6037 - acc: 0.6518
 576/1283 [============>.................] - ETA: 0s - loss: 0.6000 - acc: 0.6493
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5973 - acc: 0.6619
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5959 - acc: 0.6647
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5959 - acc: 0.6604
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5989 - acc: 0.6581
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6002 - acc: 0.6571
1283/1283 [==============================] - 1s 536us/step - loss: 0.5984 - acc: 0.6571 - val_loss: 0.7776 - val_acc: 0.4672

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5618 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5761 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5901 - acc: 0.6844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5858 - acc: 0.6830
 576/1283 [============>.................] - ETA: 0s - loss: 0.5962 - acc: 0.6615
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5947 - acc: 0.6520
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5956 - acc: 0.6562
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5940 - acc: 0.6625
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5996 - acc: 0.6572
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6026 - acc: 0.6554
1283/1283 [==============================] - 1s 536us/step - loss: 0.6015 - acc: 0.6578 - val_loss: 0.8063 - val_acc: 0.4192

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5131 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5355 - acc: 0.6927
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5460 - acc: 0.6781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5615 - acc: 0.6763
 576/1283 [============>.................] - ETA: 0s - loss: 0.5690 - acc: 0.6771
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5841 - acc: 0.6648
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5833 - acc: 0.6647
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5817 - acc: 0.6656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5814 - acc: 0.6627
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5841 - acc: 0.6612
1283/1283 [==============================] - 1s 540us/step - loss: 0.5839 - acc: 0.6664 - val_loss: 0.7821 - val_acc: 0.4760

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5831 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5932 - acc: 0.6823
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5767 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5886 - acc: 0.6830
 576/1283 [============>.................] - ETA: 0s - loss: 0.5747 - acc: 0.6944
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5740 - acc: 0.7060
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5679 - acc: 0.7115
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5604 - acc: 0.7115
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5632 - acc: 0.7050
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5761 - acc: 0.6974
1283/1283 [==============================] - 1s 543us/step - loss: 0.5847 - acc: 0.6882 - val_loss: 0.8169 - val_acc: 0.4934

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5951 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6005 - acc: 0.6667
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5774 - acc: 0.6813
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5833 - acc: 0.6652
 576/1283 [============>.................] - ETA: 0s - loss: 0.5775 - acc: 0.6667
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5768 - acc: 0.6591
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5742 - acc: 0.6695
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5778 - acc: 0.6667
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5786 - acc: 0.6590
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5818 - acc: 0.6579
1283/1283 [==============================] - 1s 539us/step - loss: 0.5846 - acc: 0.6586 - val_loss: 0.8056 - val_acc: 0.4847

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=30
mode=V
accuracy=0.4839650145772595
best_valid_accuracy=0.5247813411078717
