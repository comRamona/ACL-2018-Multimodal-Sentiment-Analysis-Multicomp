/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:08:00.519167: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.9096 - acc: 0.4844
 128/1283 [=>............................] - ETA: 6s - loss: 0.9103 - acc: 0.4688 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.8330 - acc: 0.5104
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7808 - acc: 0.5375
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7678 - acc: 0.5443
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7542 - acc: 0.5513
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7458 - acc: 0.5586
 576/1283 [============>.................] - ETA: 1s - loss: 0.7356 - acc: 0.5660
 640/1283 [=============>................] - ETA: 1s - loss: 0.7290 - acc: 0.5687
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7340 - acc: 0.5597
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7314 - acc: 0.5505
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7284 - acc: 0.5536
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7247 - acc: 0.5604
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7229 - acc: 0.5615
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7217 - acc: 0.5607
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7221 - acc: 0.5538
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7184 - acc: 0.5576
1280/1283 [============================>.] - ETA: 0s - loss: 0.7185 - acc: 0.5492
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7185 - acc: 0.5495 - val_loss: 0.6928 - val_acc: 0.5459

Epoch 00001: val_acc improved from -inf to 0.54585, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6412 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6498 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6542 - acc: 0.6094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6698 - acc: 0.5781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6650 - acc: 0.5871
 576/1283 [============>.................] - ETA: 0s - loss: 0.6654 - acc: 0.5833
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6602 - acc: 0.5952
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6590 - acc: 0.6010
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6546 - acc: 0.6062
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6506 - acc: 0.6140
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6502 - acc: 0.6127
1283/1283 [==============================] - 1s 756us/step - loss: 0.6481 - acc: 0.6150 - val_loss: 0.7154 - val_acc: 0.5153

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6172 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6421 - acc: 0.5938
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6205 - acc: 0.6156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6075 - acc: 0.6384
 576/1283 [============>.................] - ETA: 0s - loss: 0.5955 - acc: 0.6528
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6005 - acc: 0.6506
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5901 - acc: 0.6779
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5918 - acc: 0.6771
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5895 - acc: 0.6820
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5909 - acc: 0.6801
1283/1283 [==============================] - 1s 684us/step - loss: 0.5899 - acc: 0.6812 - val_loss: 0.6910 - val_acc: 0.6026

Epoch 00003: val_acc improved from 0.54585 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5464 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5320 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5020 - acc: 0.7383
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5188 - acc: 0.7370
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5186 - acc: 0.7411
 576/1283 [============>.................] - ETA: 0s - loss: 0.5260 - acc: 0.7326
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5232 - acc: 0.7244
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5239 - acc: 0.7356
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5242 - acc: 0.7396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5224 - acc: 0.7408
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5215 - acc: 0.7434
1283/1283 [==============================] - 1s 788us/step - loss: 0.5239 - acc: 0.7381 - val_loss: 0.7672 - val_acc: 0.5109

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4570 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4721 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4799 - acc: 0.7531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4858 - acc: 0.7634
 576/1283 [============>.................] - ETA: 0s - loss: 0.4964 - acc: 0.7517
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4906 - acc: 0.7543
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4847 - acc: 0.7620
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4821 - acc: 0.7698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4799 - acc: 0.7739
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4728 - acc: 0.7763
1283/1283 [==============================] - 1s 555us/step - loss: 0.4741 - acc: 0.7763 - val_loss: 0.7549 - val_acc: 0.5546

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3353 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3738 - acc: 0.8698
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3807 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3896 - acc: 0.8482
 576/1283 [============>.................] - ETA: 0s - loss: 0.3813 - acc: 0.8559
 768/1283 [================>.............] - ETA: 0s - loss: 0.3770 - acc: 0.8555
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3729 - acc: 0.8538
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3746 - acc: 0.8506
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3706 - acc: 0.8516
1280/1283 [============================>.] - ETA: 0s - loss: 0.3719 - acc: 0.8477
1283/1283 [==============================] - 1s 520us/step - loss: 0.3716 - acc: 0.8480 - val_loss: 0.9327 - val_acc: 0.5633

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3140 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3591 - acc: 0.8281
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3350 - acc: 0.8490
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3220 - acc: 0.8613
 640/1283 [=============>................] - ETA: 0s - loss: 0.3117 - acc: 0.8719
 768/1283 [================>.............] - ETA: 0s - loss: 0.3145 - acc: 0.8698
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3076 - acc: 0.8740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3051 - acc: 0.8759
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3015 - acc: 0.8758
1283/1283 [==============================] - 1s 491us/step - loss: 0.2988 - acc: 0.8745 - val_loss: 0.8611 - val_acc: 0.5808

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1784 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2577 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2625 - acc: 0.9094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2568 - acc: 0.9018
 576/1283 [============>.................] - ETA: 0s - loss: 0.2453 - acc: 0.9149
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2437 - acc: 0.9176
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2486 - acc: 0.9123
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2514 - acc: 0.9094
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2467 - acc: 0.9118
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2439 - acc: 0.9149
1280/1283 [============================>.] - ETA: 0s - loss: 0.2430 - acc: 0.9172
1283/1283 [==============================] - 1s 655us/step - loss: 0.2428 - acc: 0.9174 - val_loss: 0.9997 - val_acc: 0.5546

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1943 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2220 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1926 - acc: 0.9156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1964 - acc: 0.9174
 576/1283 [============>.................] - ETA: 0s - loss: 0.1882 - acc: 0.9236
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1830 - acc: 0.9276
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1782 - acc: 0.9303
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1737 - acc: 0.9365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1758 - acc: 0.9365
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1740 - acc: 0.9410
1280/1283 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9453
1283/1283 [==============================] - 1s 737us/step - loss: 0.1719 - acc: 0.9447 - val_loss: 0.9826 - val_acc: 0.5939

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1373 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.1527 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1696 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1810 - acc: 0.9245
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2025 - acc: 0.9121
 640/1283 [=============>................] - ETA: 0s - loss: 0.1986 - acc: 0.9125
 768/1283 [================>.............] - ETA: 0s - loss: 0.1919 - acc: 0.9193
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1961 - acc: 0.9183
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2051 - acc: 0.9167
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2005 - acc: 0.9189
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1953 - acc: 0.9219
1280/1283 [============================>.] - ETA: 0s - loss: 0.1909 - acc: 0.9258
1283/1283 [==============================] - 1s 752us/step - loss: 0.1905 - acc: 0.9260 - val_loss: 1.2090 - val_acc: 0.5502

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1359 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1141 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1277 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1211 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1261 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1220 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1222 - acc: 0.9629
 576/1283 [============>.................] - ETA: 0s - loss: 0.1183 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1177 - acc: 0.9645
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1191 - acc: 0.9651
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1189 - acc: 0.9656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1184 - acc: 0.9660
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1186 - acc: 0.9655
1280/1283 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9672
1283/1283 [==============================] - 1s 886us/step - loss: 0.1161 - acc: 0.9673 - val_loss: 1.2589 - val_acc: 0.5546

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0515 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1033 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0966 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0945 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0867 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.0930 - acc: 0.9705
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0885 - acc: 0.9730
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0893 - acc: 0.9748
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0871 - acc: 0.9750
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0870 - acc: 0.9743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0827 - acc: 0.9762
1283/1283 [==============================] - 1s 796us/step - loss: 0.0813 - acc: 0.9766 - val_loss: 1.3325 - val_acc: 0.5546

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0403 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0372 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0406 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0402 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0431 - acc: 0.9941
 640/1283 [=============>................] - ETA: 0s - loss: 0.0425 - acc: 0.9953
 768/1283 [================>.............] - ETA: 0s - loss: 0.0385 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0394 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0383 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0380 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0390 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0390 - acc: 0.9967
1283/1283 [==============================] - 1s 831us/step - loss: 0.0381 - acc: 0.9969 - val_loss: 1.5974 - val_acc: 0.5764

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
epochs=100
mode=A
accuracy=0.47667638483965014
best_valid_accuracy=0.4868804664723032
