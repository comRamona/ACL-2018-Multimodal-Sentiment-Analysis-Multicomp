/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:20:39.259839: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.6895 - acc: 0.4688
 192/1283 [===>..........................] - ETA: 2s - loss: 0.6840 - acc: 0.5052
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6779 - acc: 0.5188
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6959 - acc: 0.5000
 576/1283 [============>.................] - ETA: 0s - loss: 0.6909 - acc: 0.5174
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6866 - acc: 0.5270
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6878 - acc: 0.5228
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6866 - acc: 0.5260
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6871 - acc: 0.5257
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6855 - acc: 0.5321
1280/1283 [============================>.] - ETA: 0s - loss: 0.6825 - acc: 0.5445
1283/1283 [==============================] - 1s 856us/step - loss: 0.6826 - acc: 0.5448 - val_loss: 0.6893 - val_acc: 0.5066

Epoch 00001: val_acc improved from -inf to 0.50655, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6147 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6437 - acc: 0.6458
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6480 - acc: 0.6594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6604 - acc: 0.6518
 576/1283 [============>.................] - ETA: 0s - loss: 0.6637 - acc: 0.6267
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6621 - acc: 0.6278
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6620 - acc: 0.6334
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6605 - acc: 0.6312
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6579 - acc: 0.6314
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6573 - acc: 0.6308
1283/1283 [==============================] - 1s 639us/step - loss: 0.6555 - acc: 0.6290 - val_loss: 0.6992 - val_acc: 0.5153

Epoch 00002: val_acc improved from 0.50655 to 0.51528, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6111 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6213 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6368 - acc: 0.5969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6301 - acc: 0.6250
 576/1283 [============>.................] - ETA: 0s - loss: 0.6242 - acc: 0.6354
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6282 - acc: 0.6307
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6268 - acc: 0.6334
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6227 - acc: 0.6309
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6295 - acc: 0.6250
1280/1283 [============================>.] - ETA: 0s - loss: 0.6288 - acc: 0.6281
1283/1283 [==============================] - 1s 557us/step - loss: 0.6284 - acc: 0.6282 - val_loss: 0.7119 - val_acc: 0.5240

Epoch 00003: val_acc improved from 0.51528 to 0.52402, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6338 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6236 - acc: 0.6458
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5885 - acc: 0.6844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5751 - acc: 0.7098
 576/1283 [============>.................] - ETA: 0s - loss: 0.5877 - acc: 0.6910
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5950 - acc: 0.6790
 768/1283 [================>.............] - ETA: 0s - loss: 0.5996 - acc: 0.6771
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6000 - acc: 0.6708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6067 - acc: 0.6650
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6147 - acc: 0.6719
1280/1283 [============================>.] - ETA: 0s - loss: 0.6157 - acc: 0.6641
1283/1283 [==============================] - 1s 604us/step - loss: 0.6163 - acc: 0.6633 - val_loss: 0.7318 - val_acc: 0.5328

Epoch 00004: val_acc improved from 0.52402 to 0.53275, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6169 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5836 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5947 - acc: 0.6906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6146 - acc: 0.6607
 576/1283 [============>.................] - ETA: 0s - loss: 0.6471 - acc: 0.6493
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6378 - acc: 0.6520
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6261 - acc: 0.6683
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6218 - acc: 0.6656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6216 - acc: 0.6572
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6189 - acc: 0.6530
1283/1283 [==============================] - 1s 510us/step - loss: 0.6178 - acc: 0.6524 - val_loss: 0.7351 - val_acc: 0.5415

Epoch 00005: val_acc improved from 0.53275 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5329 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5641 - acc: 0.7240
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5696 - acc: 0.7031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5764 - acc: 0.6942
 576/1283 [============>.................] - ETA: 0s - loss: 0.5747 - acc: 0.6962
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5683 - acc: 0.7116
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5775 - acc: 0.7055
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5791 - acc: 0.6969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5984 - acc: 0.6866
1280/1283 [============================>.] - ETA: 0s - loss: 0.5961 - acc: 0.6852
1283/1283 [==============================] - 1s 537us/step - loss: 0.5955 - acc: 0.6859 - val_loss: 0.7688 - val_acc: 0.5284

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5341 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5907 - acc: 0.7448
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6155 - acc: 0.7188
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6000 - acc: 0.7031
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5915 - acc: 0.7045
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5870 - acc: 0.7031
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5766 - acc: 0.7080
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5641 - acc: 0.7113
1283/1283 [==============================] - 1s 451us/step - loss: 0.5654 - acc: 0.7085 - val_loss: 0.8051 - val_acc: 0.5022

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5796 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5236 - acc: 0.7227
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5240 - acc: 0.7214
 576/1283 [============>.................] - ETA: 0s - loss: 0.5193 - acc: 0.7326
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5262 - acc: 0.7287
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5325 - acc: 0.7224
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5341 - acc: 0.7167
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5352 - acc: 0.7096
1280/1283 [============================>.] - ETA: 0s - loss: 0.5441 - acc: 0.7172
1283/1283 [==============================] - 1s 427us/step - loss: 0.5442 - acc: 0.7171 - val_loss: 0.8414 - val_acc: 0.4934

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4974 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5286 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5466 - acc: 0.7250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5339 - acc: 0.7388
 640/1283 [=============>................] - ETA: 0s - loss: 0.5265 - acc: 0.7438
 768/1283 [================>.............] - ETA: 0s - loss: 0.5176 - acc: 0.7500
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5048 - acc: 0.7556
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5063 - acc: 0.7559
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5237 - acc: 0.7467
1283/1283 [==============================] - 1s 435us/step - loss: 0.5204 - acc: 0.7475 - val_loss: 0.8336 - val_acc: 0.4891

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6324 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5405 - acc: 0.7070
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5380 - acc: 0.7054
 640/1283 [=============>................] - ETA: 0s - loss: 0.5224 - acc: 0.7359
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5083 - acc: 0.7536
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5078 - acc: 0.7520
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5257 - acc: 0.7457
1283/1283 [==============================] - 1s 400us/step - loss: 0.5169 - acc: 0.7537 - val_loss: 0.8660 - val_acc: 0.4978

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6499 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5780 - acc: 0.6823
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5450 - acc: 0.7135
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5491 - acc: 0.7070
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5438 - acc: 0.7159
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5348 - acc: 0.7260
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5260 - acc: 0.7365
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5186 - acc: 0.7436
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5215 - acc: 0.7401
1283/1283 [==============================] - 1s 470us/step - loss: 0.5159 - acc: 0.7443 - val_loss: 0.8013 - val_acc: 0.4760

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3945 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4447 - acc: 0.7695
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4627 - acc: 0.7604
 576/1283 [============>.................] - ETA: 0s - loss: 0.4728 - acc: 0.7622
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4721 - acc: 0.7727
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4721 - acc: 0.7656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4648 - acc: 0.7705
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5061 - acc: 0.7734
1280/1283 [============================>.] - ETA: 0s - loss: 0.5112 - acc: 0.7773
1283/1283 [==============================] - 1s 447us/step - loss: 0.5111 - acc: 0.7779 - val_loss: 0.9378 - val_acc: 0.4803

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3883 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4786 - acc: 0.7461
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5102 - acc: 0.7526
 576/1283 [============>.................] - ETA: 0s - loss: 0.4800 - acc: 0.7656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5088 - acc: 0.7429
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5032 - acc: 0.7416
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4912 - acc: 0.7448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4926 - acc: 0.7417
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4963 - acc: 0.7418
1283/1283 [==============================] - 1s 444us/step - loss: 0.4961 - acc: 0.7405 - val_loss: 0.8648 - val_acc: 0.4891

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4321 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5040 - acc: 0.8073
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4815 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4373 - acc: 0.8281
 640/1283 [=============>................] - ETA: 0s - loss: 0.4217 - acc: 0.8328
 768/1283 [================>.............] - ETA: 0s - loss: 0.4430 - acc: 0.8047
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4302 - acc: 0.8170
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4247 - acc: 0.8244
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4247 - acc: 0.8240
1283/1283 [==============================] - 1s 474us/step - loss: 0.4231 - acc: 0.8239 - val_loss: 0.9196 - val_acc: 0.4891

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3195 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3508 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3823 - acc: 0.8375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3846 - acc: 0.8393
 640/1283 [=============>................] - ETA: 0s - loss: 0.3736 - acc: 0.8391
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3851 - acc: 0.8401
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3834 - acc: 0.8428
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3825 - acc: 0.8420
1283/1283 [==============================] - 1s 424us/step - loss: 0.3875 - acc: 0.8379 - val_loss: 1.0323 - val_acc: 0.4585

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=30
epochs=100
mode=V
accuracy=0.4839650145772595
best_valid_accuracy=0.5379008746355685
