/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 23:15:25.764543: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.7024 - acc: 0.4062
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7149 - acc: 0.4813
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6990 - acc: 0.5000
 768/1283 [================>.............] - ETA: 0s - loss: 0.6963 - acc: 0.4831
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6912 - acc: 0.4979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6891 - acc: 0.5110
1280/1283 [============================>.] - ETA: 0s - loss: 0.6851 - acc: 0.5133
1283/1283 [==============================] - 1s 529us/step - loss: 0.6850 - acc: 0.5144 - val_loss: 0.6836 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6453 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6438 - acc: 0.6156
 576/1283 [============>.................] - ETA: 0s - loss: 0.6446 - acc: 0.6076
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6648 - acc: 0.6118
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6588 - acc: 0.6143
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6545 - acc: 0.6184
1283/1283 [==============================] - 0s 277us/step - loss: 0.6544 - acc: 0.6126 - val_loss: 0.7255 - val_acc: 0.5240

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6402 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6700 - acc: 0.6289
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6582 - acc: 0.6183
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6424 - acc: 0.6364
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6552 - acc: 0.6344
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6513 - acc: 0.6293
1283/1283 [==============================] - 0s 281us/step - loss: 0.6492 - acc: 0.6329 - val_loss: 0.6934 - val_acc: 0.5633

Epoch 00003: val_acc improved from 0.54148 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_V_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5965 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6772 - acc: 0.6500
 576/1283 [============>.................] - ETA: 0s - loss: 0.6571 - acc: 0.6389
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6434 - acc: 0.6442
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6342 - acc: 0.6455
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6347 - acc: 0.6456
1283/1283 [==============================] - 0s 294us/step - loss: 0.6312 - acc: 0.6477 - val_loss: 0.7090 - val_acc: 0.5066

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5395 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5816 - acc: 0.6953
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6001 - acc: 0.6696
 640/1283 [=============>................] - ETA: 0s - loss: 0.6183 - acc: 0.6719
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6188 - acc: 0.6767
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6157 - acc: 0.6682
1280/1283 [============================>.] - ETA: 0s - loss: 0.6212 - acc: 0.6594
1283/1283 [==============================] - 0s 323us/step - loss: 0.6210 - acc: 0.6594 - val_loss: 0.7387 - val_acc: 0.5240

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6025 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6575 - acc: 0.6042
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6070 - acc: 0.6615
 576/1283 [============>.................] - ETA: 0s - loss: 0.6373 - acc: 0.6476
 768/1283 [================>.............] - ETA: 0s - loss: 0.6141 - acc: 0.6615
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6115 - acc: 0.6604
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6076 - acc: 0.6627
1283/1283 [==============================] - 0s 337us/step - loss: 0.6090 - acc: 0.6633 - val_loss: 0.7384 - val_acc: 0.5197

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6022 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5799 - acc: 0.6750
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5765 - acc: 0.6855
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5797 - acc: 0.6847
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5856 - acc: 0.6775
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5827 - acc: 0.6829
1280/1283 [============================>.] - ETA: 0s - loss: 0.5899 - acc: 0.6867
1283/1283 [==============================] - 0s 318us/step - loss: 0.5901 - acc: 0.6867 - val_loss: 0.7530 - val_acc: 0.4760

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5825 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6085 - acc: 0.7188
 576/1283 [============>.................] - ETA: 0s - loss: 0.5995 - acc: 0.7031
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6049 - acc: 0.6839
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5938 - acc: 0.6982
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5899 - acc: 0.6957
1283/1283 [==============================] - 0s 317us/step - loss: 0.5899 - acc: 0.6952 - val_loss: 0.7350 - val_acc: 0.5459

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5363 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6517 - acc: 0.6914
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6511 - acc: 0.6652
 640/1283 [=============>................] - ETA: 0s - loss: 0.6512 - acc: 0.6500
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6431 - acc: 0.6526
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6342 - acc: 0.6475
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6365 - acc: 0.6431
1283/1283 [==============================] - 0s 324us/step - loss: 0.6318 - acc: 0.6469 - val_loss: 0.7310 - val_acc: 0.5371

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5534 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6244 - acc: 0.6781
 576/1283 [============>.................] - ETA: 0s - loss: 0.6127 - acc: 0.6806
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6066 - acc: 0.6804
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6007 - acc: 0.6897
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6053 - acc: 0.6756
1280/1283 [============================>.] - ETA: 0s - loss: 0.5954 - acc: 0.6891
1283/1283 [==============================] - 0s 306us/step - loss: 0.5953 - acc: 0.6890 - val_loss: 0.7654 - val_acc: 0.5109

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.8606 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6084 - acc: 0.7266
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5761 - acc: 0.7478
 640/1283 [=============>................] - ETA: 0s - loss: 0.5783 - acc: 0.7156
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5808 - acc: 0.6995
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5716 - acc: 0.7129
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5683 - acc: 0.7196
1283/1283 [==============================] - 0s 351us/step - loss: 0.5660 - acc: 0.7249 - val_loss: 0.7453 - val_acc: 0.5371

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5947 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5447 - acc: 0.7094
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5364 - acc: 0.7188
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5352 - acc: 0.7273
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5359 - acc: 0.7219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5505 - acc: 0.7248
1283/1283 [==============================] - 0s 318us/step - loss: 0.5539 - acc: 0.7194 - val_loss: 0.7723 - val_acc: 0.5459

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4564 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4901 - acc: 0.7865
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5372 - acc: 0.7188
 576/1283 [============>.................] - ETA: 0s - loss: 0.5373 - acc: 0.7257
 768/1283 [================>.............] - ETA: 0s - loss: 0.5426 - acc: 0.7188
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5314 - acc: 0.7221
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5414 - acc: 0.7151
1280/1283 [============================>.] - ETA: 0s - loss: 0.5517 - acc: 0.7188
1283/1283 [==============================] - 0s 379us/step - loss: 0.5509 - acc: 0.7194 - val_loss: 0.7832 - val_acc: 0.5022

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
epochs=100
mode=V
accuracy=0.4970845481049563
best_valid_accuracy=0.5233236151603499
