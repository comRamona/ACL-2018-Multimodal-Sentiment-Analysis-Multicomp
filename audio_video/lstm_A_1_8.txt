/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 08:38:48.176243: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 14s - loss: 0.7126 - acc: 0.4688
 128/1283 [=>............................] - ETA: 7s - loss: 0.6950 - acc: 0.4844 
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7002 - acc: 0.4635
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6906 - acc: 0.5117
 320/1283 [======>.......................] - ETA: 3s - loss: 0.6935 - acc: 0.5000
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6958 - acc: 0.5000
 448/1283 [=========>....................] - ETA: 2s - loss: 0.6976 - acc: 0.5045
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7023 - acc: 0.5020
 576/1283 [============>.................] - ETA: 1s - loss: 0.6991 - acc: 0.5104
 640/1283 [=============>................] - ETA: 1s - loss: 0.6958 - acc: 0.5250
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6961 - acc: 0.5213
 768/1283 [================>.............] - ETA: 1s - loss: 0.6975 - acc: 0.5221
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6980 - acc: 0.5216
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6978 - acc: 0.5246
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6952 - acc: 0.5333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6939 - acc: 0.5391
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6934 - acc: 0.5423
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6948 - acc: 0.5399
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6945 - acc: 0.5378
1280/1283 [============================>.] - ETA: 0s - loss: 0.6937 - acc: 0.5398
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6937 - acc: 0.5394 - val_loss: 0.6857 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6496 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6866 - acc: 0.5547
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6723 - acc: 0.5781
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6689 - acc: 0.5859
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6713 - acc: 0.5750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6649 - acc: 0.5911
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6646 - acc: 0.6004
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6647 - acc: 0.6016
 576/1283 [============>.................] - ETA: 0s - loss: 0.6657 - acc: 0.6007
 640/1283 [=============>................] - ETA: 0s - loss: 0.6648 - acc: 0.5969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6635 - acc: 0.5952
 768/1283 [================>.............] - ETA: 0s - loss: 0.6600 - acc: 0.6055
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6562 - acc: 0.6106
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6548 - acc: 0.6127
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6551 - acc: 0.6062
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6532 - acc: 0.6143
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6562 - acc: 0.6048
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6529 - acc: 0.6094
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6521 - acc: 0.6118
1280/1283 [============================>.] - ETA: 0s - loss: 0.6525 - acc: 0.6133
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6527 - acc: 0.6126 - val_loss: 0.6809 - val_acc: 0.5371

Epoch 00002: val_acc improved from 0.52838 to 0.53712, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6249 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.6302 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6188 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6164 - acc: 0.7109
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6151 - acc: 0.7219
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6192 - acc: 0.7005
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6205 - acc: 0.6897
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6240 - acc: 0.6758
 576/1283 [============>.................] - ETA: 0s - loss: 0.6266 - acc: 0.6701
 640/1283 [=============>................] - ETA: 0s - loss: 0.6317 - acc: 0.6594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6317 - acc: 0.6577
 768/1283 [================>.............] - ETA: 0s - loss: 0.6284 - acc: 0.6615
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6283 - acc: 0.6575
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6303 - acc: 0.6574
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6314 - acc: 0.6510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6338 - acc: 0.6465
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6340 - acc: 0.6443
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6340 - acc: 0.6432
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6331 - acc: 0.6439
1280/1283 [============================>.] - ETA: 0s - loss: 0.6332 - acc: 0.6453
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6330 - acc: 0.6454 - val_loss: 0.6902 - val_acc: 0.5633

Epoch 00003: val_acc improved from 0.53712 to 0.56332, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6659 - acc: 0.6250
 128/1283 [=>............................] - ETA: 1s - loss: 0.6442 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6201 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6246 - acc: 0.6289
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6211 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6231 - acc: 0.6432
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6237 - acc: 0.6362
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6281 - acc: 0.6289
 576/1283 [============>.................] - ETA: 0s - loss: 0.6257 - acc: 0.6337
 640/1283 [=============>................] - ETA: 0s - loss: 0.6259 - acc: 0.6312
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6229 - acc: 0.6335
 768/1283 [================>.............] - ETA: 0s - loss: 0.6219 - acc: 0.6367
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6235 - acc: 0.6346
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6218 - acc: 0.6384
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6220 - acc: 0.6406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6204 - acc: 0.6436
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6216 - acc: 0.6406
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6231 - acc: 0.6398
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6209 - acc: 0.6414
1280/1283 [============================>.] - ETA: 0s - loss: 0.6198 - acc: 0.6445
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6197 - acc: 0.6446 - val_loss: 0.7047 - val_acc: 0.5546

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6195 - acc: 0.6250
 128/1283 [=>............................] - ETA: 1s - loss: 0.6352 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6233 - acc: 0.6042
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6422 - acc: 0.5859
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6224 - acc: 0.6156
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6140 - acc: 0.6302
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6086 - acc: 0.6384
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6078 - acc: 0.6406
 576/1283 [============>.................] - ETA: 0s - loss: 0.6101 - acc: 0.6441
 640/1283 [=============>................] - ETA: 0s - loss: 0.6078 - acc: 0.6422
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6024 - acc: 0.6520
 768/1283 [================>.............] - ETA: 0s - loss: 0.6016 - acc: 0.6549
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6029 - acc: 0.6526
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6056 - acc: 0.6518
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6065 - acc: 0.6552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6053 - acc: 0.6582
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6068 - acc: 0.6581
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6072 - acc: 0.6580
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6093 - acc: 0.6554
1280/1283 [============================>.] - ETA: 0s - loss: 0.6103 - acc: 0.6547
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6105 - acc: 0.6547 - val_loss: 0.7109 - val_acc: 0.5590

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5850 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5794 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5706 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5779 - acc: 0.7266
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5782 - acc: 0.7250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5745 - acc: 0.7188
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5664 - acc: 0.7232
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5610 - acc: 0.7305
 576/1283 [============>.................] - ETA: 0s - loss: 0.5627 - acc: 0.7240
 640/1283 [=============>................] - ETA: 0s - loss: 0.5684 - acc: 0.7172
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5645 - acc: 0.7216
 768/1283 [================>.............] - ETA: 0s - loss: 0.5647 - acc: 0.7201
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5678 - acc: 0.7163
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5685 - acc: 0.7199
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5695 - acc: 0.7219
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5720 - acc: 0.7178
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5707 - acc: 0.7178
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5693 - acc: 0.7214
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5772 - acc: 0.7138
1280/1283 [============================>.] - ETA: 0s - loss: 0.5787 - acc: 0.7078
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5782 - acc: 0.7085 - val_loss: 0.7173 - val_acc: 0.5895

Epoch 00006: val_acc improved from 0.56332 to 0.58952, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6579 - acc: 0.5781
 128/1283 [=>............................] - ETA: 1s - loss: 0.6201 - acc: 0.6328
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5976 - acc: 0.6510
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5816 - acc: 0.6797
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5585 - acc: 0.7188
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5670 - acc: 0.7109
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5551 - acc: 0.7210
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5525 - acc: 0.7207
 576/1283 [============>.................] - ETA: 1s - loss: 0.5468 - acc: 0.7257
 640/1283 [=============>................] - ETA: 0s - loss: 0.5513 - acc: 0.7172
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5544 - acc: 0.7145
 768/1283 [================>.............] - ETA: 0s - loss: 0.5576 - acc: 0.7083
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5546 - acc: 0.7091
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5533 - acc: 0.7132
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5528 - acc: 0.7198
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5573 - acc: 0.7188
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5566 - acc: 0.7178
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5581 - acc: 0.7161
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5574 - acc: 0.7146
1280/1283 [============================>.] - ETA: 0s - loss: 0.5588 - acc: 0.7094
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5586 - acc: 0.7101 - val_loss: 0.7180 - val_acc: 0.5852

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5329 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.5321 - acc: 0.7578
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5198 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5264 - acc: 0.7461
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5262 - acc: 0.7406
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5231 - acc: 0.7422
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5189 - acc: 0.7433
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5284 - acc: 0.7363
 576/1283 [============>.................] - ETA: 1s - loss: 0.5322 - acc: 0.7309
 640/1283 [=============>................] - ETA: 0s - loss: 0.5343 - acc: 0.7281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5375 - acc: 0.7259
 768/1283 [================>.............] - ETA: 0s - loss: 0.5421 - acc: 0.7214
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5334 - acc: 0.7344
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5268 - acc: 0.7377
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5210 - acc: 0.7438
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5256 - acc: 0.7402
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5280 - acc: 0.7362
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5237 - acc: 0.7413
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5229 - acc: 0.7434
1280/1283 [============================>.] - ETA: 0s - loss: 0.5229 - acc: 0.7422
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5231 - acc: 0.7428 - val_loss: 0.7133 - val_acc: 0.5721

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4105 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.4340 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4732 - acc: 0.7865
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4628 - acc: 0.7937
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4567 - acc: 0.8047
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4626 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4748 - acc: 0.7891
 576/1283 [============>.................] - ETA: 0s - loss: 0.4851 - acc: 0.7830
 640/1283 [=============>................] - ETA: 0s - loss: 0.4824 - acc: 0.7812
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4893 - acc: 0.7727
 768/1283 [================>.............] - ETA: 0s - loss: 0.4894 - acc: 0.7721
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4919 - acc: 0.7680
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4991 - acc: 0.7634
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5007 - acc: 0.7646
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5008 - acc: 0.7666
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4979 - acc: 0.7684
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4954 - acc: 0.7691
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4923 - acc: 0.7714
1280/1283 [============================>.] - ETA: 0s - loss: 0.4946 - acc: 0.7688
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4946 - acc: 0.7685 - val_loss: 0.7503 - val_acc: 0.6114

Epoch 00009: val_acc improved from 0.58952 to 0.61135, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4669 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.4826 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5065 - acc: 0.7292
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5494 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5187 - acc: 0.7312
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5086 - acc: 0.7344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5063 - acc: 0.7344
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5169 - acc: 0.7207
 576/1283 [============>.................] - ETA: 0s - loss: 0.5044 - acc: 0.7274
 640/1283 [=============>................] - ETA: 0s - loss: 0.4981 - acc: 0.7344
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4983 - acc: 0.7358
 768/1283 [================>.............] - ETA: 0s - loss: 0.4967 - acc: 0.7383
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4910 - acc: 0.7476
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4943 - acc: 0.7478
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4924 - acc: 0.7510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4937 - acc: 0.7500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4957 - acc: 0.7491
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4979 - acc: 0.7491
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5008 - acc: 0.7492
1280/1283 [============================>.] - ETA: 0s - loss: 0.5002 - acc: 0.7484
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4999 - acc: 0.7490 - val_loss: 0.7344 - val_acc: 0.5983

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5078 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.4926 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4579 - acc: 0.7917
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4498 - acc: 0.7852
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4406 - acc: 0.7875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4509 - acc: 0.7812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4617 - acc: 0.7812
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4678 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4636 - acc: 0.7778
 640/1283 [=============>................] - ETA: 0s - loss: 0.4627 - acc: 0.7828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4655 - acc: 0.7827
 768/1283 [================>.............] - ETA: 0s - loss: 0.4588 - acc: 0.7891
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4613 - acc: 0.7837
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4650 - acc: 0.7835
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4642 - acc: 0.7854
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4652 - acc: 0.7842
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4635 - acc: 0.7831
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4597 - acc: 0.7847
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4576 - acc: 0.7878
1280/1283 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.7922
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4548 - acc: 0.7919 - val_loss: 0.7456 - val_acc: 0.5633

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3861 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.4450 - acc: 0.7734
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4221 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4063 - acc: 0.8242
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4056 - acc: 0.8187
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4032 - acc: 0.8177
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4022 - acc: 0.8170
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4335 - acc: 0.8008
 576/1283 [============>.................] - ETA: 0s - loss: 0.4414 - acc: 0.7899
 640/1283 [=============>................] - ETA: 0s - loss: 0.4530 - acc: 0.7812
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4546 - acc: 0.7798
 768/1283 [================>.............] - ETA: 0s - loss: 0.4542 - acc: 0.7812
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4537 - acc: 0.7812
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4501 - acc: 0.7835
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4531 - acc: 0.7823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4533 - acc: 0.7852
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4419 - acc: 0.7960
1280/1283 [============================>.] - ETA: 0s - loss: 0.4387 - acc: 0.8000
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4389 - acc: 0.8005 - val_loss: 0.7559 - val_acc: 0.5590

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3970 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.3806 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3703 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3850 - acc: 0.8477
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4182 - acc: 0.8344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4104 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4085 - acc: 0.8326
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4057 - acc: 0.8320
 576/1283 [============>.................] - ETA: 0s - loss: 0.4115 - acc: 0.8264
 640/1283 [=============>................] - ETA: 0s - loss: 0.4121 - acc: 0.8250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4069 - acc: 0.8281
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4076 - acc: 0.8245
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3994 - acc: 0.8271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4002 - acc: 0.8271
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3991 - acc: 0.8281
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3955 - acc: 0.8289
1280/1283 [============================>.] - ETA: 0s - loss: 0.3941 - acc: 0.8297
1283/1283 [==============================] - 1s 969us/step - loss: 0.3937 - acc: 0.8301 - val_loss: 0.7979 - val_acc: 0.5590

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3618 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.3378 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3777 - acc: 0.8320
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3686 - acc: 0.8333
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3732 - acc: 0.8237
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3635 - acc: 0.8320
 576/1283 [============>.................] - ETA: 0s - loss: 0.3624 - acc: 0.8333
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3537 - acc: 0.8409
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3676 - acc: 0.8317
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3607 - acc: 0.8382
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3607 - acc: 0.8354
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3751 - acc: 0.8254
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3757 - acc: 0.8281
1280/1283 [============================>.] - ETA: 0s - loss: 0.3741 - acc: 0.8297
1283/1283 [==============================] - 1s 857us/step - loss: 0.3736 - acc: 0.8301 - val_loss: 0.8440 - val_acc: 0.5502

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3619 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3186 - acc: 0.8333
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3263 - acc: 0.8344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3222 - acc: 0.8482
 576/1283 [============>.................] - ETA: 0s - loss: 0.3218 - acc: 0.8576
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3160 - acc: 0.8608
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3197 - acc: 0.8630
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3240 - acc: 0.8627
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3264 - acc: 0.8643
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3305 - acc: 0.8628
1280/1283 [============================>.] - ETA: 0s - loss: 0.3298 - acc: 0.8609
1283/1283 [==============================] - 1s 775us/step - loss: 0.3316 - acc: 0.8605 - val_loss: 0.8230 - val_acc: 0.5764

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3019 - acc: 0.8906
 128/1283 [=>............................] - ETA: 0s - loss: 0.3168 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2977 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2866 - acc: 0.8781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2831 - acc: 0.8906
 576/1283 [============>.................] - ETA: 0s - loss: 0.2811 - acc: 0.8889
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2886 - acc: 0.8906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2907 - acc: 0.8846
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2881 - acc: 0.8875
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2872 - acc: 0.8906
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2918 - acc: 0.8837
1280/1283 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.8820
1283/1283 [==============================] - 1s 776us/step - loss: 0.2921 - acc: 0.8823 - val_loss: 0.8567 - val_acc: 0.5677

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2465 - acc: 0.9219
 128/1283 [=>............................] - ETA: 0s - loss: 0.2485 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2857 - acc: 0.8984
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2844 - acc: 0.8958
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2826 - acc: 0.8984
 640/1283 [=============>................] - ETA: 0s - loss: 0.2862 - acc: 0.8969
 768/1283 [================>.............] - ETA: 0s - loss: 0.2830 - acc: 0.8997
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2853 - acc: 0.8951
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2982 - acc: 0.8887
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3052 - acc: 0.8819
1280/1283 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.8836
1283/1283 [==============================] - 1s 793us/step - loss: 0.3028 - acc: 0.8839 - val_loss: 0.8501 - val_acc: 0.5459

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2404 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.2653 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2814 - acc: 0.8802
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2665 - acc: 0.8938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2519 - acc: 0.9062
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2489 - acc: 0.9062
 640/1283 [=============>................] - ETA: 0s - loss: 0.2550 - acc: 0.8969
 768/1283 [================>.............] - ETA: 0s - loss: 0.2586 - acc: 0.8945
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2607 - acc: 0.8917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2692 - acc: 0.8877
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2766 - acc: 0.8889
1280/1283 [============================>.] - ETA: 0s - loss: 0.2739 - acc: 0.8891
1283/1283 [==============================] - 1s 753us/step - loss: 0.2736 - acc: 0.8893 - val_loss: 0.9013 - val_acc: 0.5808

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2857 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2273 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2136 - acc: 0.9250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2181 - acc: 0.9152
 576/1283 [============>.................] - ETA: 0s - loss: 0.2193 - acc: 0.9149
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2171 - acc: 0.9176
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2243 - acc: 0.9147
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2283 - acc: 0.9146
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2246 - acc: 0.9164
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2306 - acc: 0.9112
1283/1283 [==============================] - 1s 663us/step - loss: 0.2310 - acc: 0.9096 - val_loss: 1.0466 - val_acc: 0.5852

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
mode=A
accuracy=0.48250728862973763
best_valid_accuracy=0.4897959183673469
