/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 08:38:48.176294: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.6951 - acc: 0.5625
 128/1283 [=>............................] - ETA: 7s - loss: 0.6908 - acc: 0.5312 
 192/1283 [===>..........................] - ETA: 5s - loss: 0.6919 - acc: 0.5260
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6883 - acc: 0.5352
 320/1283 [======>.......................] - ETA: 3s - loss: 0.6921 - acc: 0.5156
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6950 - acc: 0.5182
 448/1283 [=========>....................] - ETA: 2s - loss: 0.6958 - acc: 0.5201
 512/1283 [==========>...................] - ETA: 2s - loss: 0.6983 - acc: 0.5137
 576/1283 [============>.................] - ETA: 1s - loss: 0.6977 - acc: 0.5052
 640/1283 [=============>................] - ETA: 1s - loss: 0.6951 - acc: 0.5094
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6954 - acc: 0.5114
 768/1283 [================>.............] - ETA: 1s - loss: 0.6962 - acc: 0.5078
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6955 - acc: 0.5108
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6962 - acc: 0.5078
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6936 - acc: 0.5208
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6926 - acc: 0.5234
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6920 - acc: 0.5260
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6916 - acc: 0.5288
1280/1283 [============================>.] - ETA: 0s - loss: 0.6910 - acc: 0.5320
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6911 - acc: 0.5316 - val_loss: 0.6876 - val_acc: 0.4978

Epoch 00001: val_acc improved from -inf to 0.49782, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6449 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.6735 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6620 - acc: 0.6042
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6578 - acc: 0.6328
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6603 - acc: 0.6219
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6581 - acc: 0.6302
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6585 - acc: 0.6339
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6605 - acc: 0.6309
 576/1283 [============>.................] - ETA: 0s - loss: 0.6607 - acc: 0.6354
 640/1283 [=============>................] - ETA: 0s - loss: 0.6585 - acc: 0.6391
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6578 - acc: 0.6378
 768/1283 [================>.............] - ETA: 0s - loss: 0.6551 - acc: 0.6393
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6509 - acc: 0.6442
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6494 - acc: 0.6484
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6496 - acc: 0.6438
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6470 - acc: 0.6514
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6499 - acc: 0.6471
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6475 - acc: 0.6476
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6474 - acc: 0.6480
1280/1283 [============================>.] - ETA: 0s - loss: 0.6482 - acc: 0.6461
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6483 - acc: 0.6461 - val_loss: 0.6886 - val_acc: 0.5284

Epoch 00002: val_acc improved from 0.49782 to 0.52838, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6055 - acc: 0.7344
 128/1283 [=>............................] - ETA: 1s - loss: 0.6100 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6017 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6025 - acc: 0.7227
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6036 - acc: 0.7250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6070 - acc: 0.7161
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6091 - acc: 0.7098
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6127 - acc: 0.6953
 576/1283 [============>.................] - ETA: 0s - loss: 0.6169 - acc: 0.6910
 640/1283 [=============>................] - ETA: 0s - loss: 0.6198 - acc: 0.6844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6196 - acc: 0.6818
 768/1283 [================>.............] - ETA: 0s - loss: 0.6158 - acc: 0.6849
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6189 - acc: 0.6752
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6195 - acc: 0.6750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6212 - acc: 0.6709
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6216 - acc: 0.6710
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6204 - acc: 0.6727
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6198 - acc: 0.6735
1280/1283 [============================>.] - ETA: 0s - loss: 0.6181 - acc: 0.6734
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6179 - acc: 0.6734 - val_loss: 0.6992 - val_acc: 0.5371

Epoch 00003: val_acc improved from 0.52838 to 0.53712, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6284 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.6098 - acc: 0.6953
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5919 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5956 - acc: 0.6797
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5894 - acc: 0.6844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5874 - acc: 0.6849
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5906 - acc: 0.6786
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5955 - acc: 0.6719
 576/1283 [============>.................] - ETA: 0s - loss: 0.5948 - acc: 0.6771
 640/1283 [=============>................] - ETA: 0s - loss: 0.5989 - acc: 0.6797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5960 - acc: 0.6790
 768/1283 [================>.............] - ETA: 0s - loss: 0.5960 - acc: 0.6758
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5964 - acc: 0.6767
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5947 - acc: 0.6797
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5945 - acc: 0.6792
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5935 - acc: 0.6768
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5952 - acc: 0.6737
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5983 - acc: 0.6710
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5984 - acc: 0.6711
1280/1283 [============================>.] - ETA: 0s - loss: 0.5979 - acc: 0.6742
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5978 - acc: 0.6750 - val_loss: 0.7162 - val_acc: 0.5633

Epoch 00004: val_acc improved from 0.53712 to 0.56332, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5624 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.5961 - acc: 0.6016
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5815 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5993 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5837 - acc: 0.6531
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5727 - acc: 0.6719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5688 - acc: 0.6808
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5726 - acc: 0.6758
 576/1283 [============>.................] - ETA: 0s - loss: 0.5738 - acc: 0.6736
 640/1283 [=============>................] - ETA: 0s - loss: 0.5698 - acc: 0.6781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5687 - acc: 0.6832
 768/1283 [================>.............] - ETA: 0s - loss: 0.5693 - acc: 0.6849
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5714 - acc: 0.6839
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5754 - acc: 0.6797
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5753 - acc: 0.6823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5737 - acc: 0.6895
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5768 - acc: 0.6857
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5766 - acc: 0.6858
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5784 - acc: 0.6850
1280/1283 [============================>.] - ETA: 0s - loss: 0.5785 - acc: 0.6852
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5785 - acc: 0.6851 - val_loss: 0.7324 - val_acc: 0.5153

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5621 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5391 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5360 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5399 - acc: 0.7734
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5470 - acc: 0.7625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5485 - acc: 0.7500
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5412 - acc: 0.7545
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5337 - acc: 0.7598
 576/1283 [============>.................] - ETA: 0s - loss: 0.5326 - acc: 0.7604
 640/1283 [=============>................] - ETA: 0s - loss: 0.5374 - acc: 0.7547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5331 - acc: 0.7571
 768/1283 [================>.............] - ETA: 0s - loss: 0.5321 - acc: 0.7565
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5372 - acc: 0.7488
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5392 - acc: 0.7500
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5420 - acc: 0.7448
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5441 - acc: 0.7412
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5420 - acc: 0.7463
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5405 - acc: 0.7465
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5475 - acc: 0.7401
1280/1283 [============================>.] - ETA: 0s - loss: 0.5490 - acc: 0.7352
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5483 - acc: 0.7358 - val_loss: 0.7364 - val_acc: 0.5983

Epoch 00006: val_acc improved from 0.56332 to 0.59825, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6194 - acc: 0.6250
 128/1283 [=>............................] - ETA: 1s - loss: 0.5844 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5704 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5617 - acc: 0.6680
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5381 - acc: 0.7094
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5406 - acc: 0.7083
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5292 - acc: 0.7210
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5261 - acc: 0.7246
 576/1283 [============>.................] - ETA: 0s - loss: 0.5175 - acc: 0.7309
 640/1283 [=============>................] - ETA: 0s - loss: 0.5213 - acc: 0.7297
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5204 - acc: 0.7301
 768/1283 [================>.............] - ETA: 0s - loss: 0.5208 - acc: 0.7318
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5163 - acc: 0.7356
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5162 - acc: 0.7422
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5163 - acc: 0.7490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5222 - acc: 0.7461
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5210 - acc: 0.7463
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5226 - acc: 0.7431
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5202 - acc: 0.7418
1280/1283 [============================>.] - ETA: 0s - loss: 0.5215 - acc: 0.7375
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5217 - acc: 0.7366 - val_loss: 0.7256 - val_acc: 0.6070

Epoch 00007: val_acc improved from 0.59825 to 0.60699, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4896 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4738 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4772 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4890 - acc: 0.7852
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4855 - acc: 0.7906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4831 - acc: 0.7917
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4787 - acc: 0.7902
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4956 - acc: 0.7734
 576/1283 [============>.................] - ETA: 0s - loss: 0.4985 - acc: 0.7691
 640/1283 [=============>................] - ETA: 0s - loss: 0.4963 - acc: 0.7656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4991 - acc: 0.7628
 768/1283 [================>.............] - ETA: 0s - loss: 0.5001 - acc: 0.7604
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4909 - acc: 0.7704
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4865 - acc: 0.7723
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4823 - acc: 0.7792
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4858 - acc: 0.7744
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4863 - acc: 0.7711
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4822 - acc: 0.7760
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4832 - acc: 0.7738
1280/1283 [============================>.] - ETA: 0s - loss: 0.4802 - acc: 0.7758
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4805 - acc: 0.7755 - val_loss: 0.7251 - val_acc: 0.5677

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3767 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.4061 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4486 - acc: 0.7865
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4373 - acc: 0.8008
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4247 - acc: 0.8094
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4198 - acc: 0.8177
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4238 - acc: 0.8214
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4396 - acc: 0.8086
 576/1283 [============>.................] - ETA: 0s - loss: 0.4490 - acc: 0.8021
 640/1283 [=============>................] - ETA: 0s - loss: 0.4476 - acc: 0.8000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4498 - acc: 0.7969
 768/1283 [================>.............] - ETA: 0s - loss: 0.4473 - acc: 0.7982
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4477 - acc: 0.7981
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4577 - acc: 0.7913
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4577 - acc: 0.7896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4565 - acc: 0.7891
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4537 - acc: 0.7895
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4507 - acc: 0.7934
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4474 - acc: 0.7952
1280/1283 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.7930
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4505 - acc: 0.7935 - val_loss: 0.7509 - val_acc: 0.6157

Epoch 00009: val_acc improved from 0.60699 to 0.61572, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3979 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4301 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4410 - acc: 0.7865
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4728 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4412 - acc: 0.7875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4289 - acc: 0.7917
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4268 - acc: 0.7946
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4409 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4298 - acc: 0.7899
 640/1283 [=============>................] - ETA: 0s - loss: 0.4257 - acc: 0.7953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4259 - acc: 0.7940
 768/1283 [================>.............] - ETA: 0s - loss: 0.4298 - acc: 0.7930
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4276 - acc: 0.7957
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4298 - acc: 0.7980
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4258 - acc: 0.8042
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4271 - acc: 0.8057
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4281 - acc: 0.8061
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4313 - acc: 0.8051
1280/1283 [============================>.] - ETA: 0s - loss: 0.4315 - acc: 0.8047
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4312 - acc: 0.8051 - val_loss: 0.7301 - val_acc: 0.5983

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3980 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.3991 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3776 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3803 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3650 - acc: 0.8438
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3791 - acc: 0.8307
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3814 - acc: 0.8304
 576/1283 [============>.................] - ETA: 0s - loss: 0.3889 - acc: 0.8247
 640/1283 [=============>................] - ETA: 0s - loss: 0.3862 - acc: 0.8328
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3926 - acc: 0.8338
 768/1283 [================>.............] - ETA: 0s - loss: 0.3888 - acc: 0.8385
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3931 - acc: 0.8365
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3942 - acc: 0.8337
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3926 - acc: 0.8344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3926 - acc: 0.8369
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3907 - acc: 0.8392
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3831 - acc: 0.8446
1280/1283 [============================>.] - ETA: 0s - loss: 0.3810 - acc: 0.8453
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3813 - acc: 0.8449 - val_loss: 0.7479 - val_acc: 0.5808

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3223 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.3616 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3443 - acc: 0.8646
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3312 - acc: 0.8789
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3313 - acc: 0.8781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3314 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3400 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3589 - acc: 0.8477
 576/1283 [============>.................] - ETA: 0s - loss: 0.3610 - acc: 0.8455
 640/1283 [=============>................] - ETA: 0s - loss: 0.3723 - acc: 0.8375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3742 - acc: 0.8352
 768/1283 [================>.............] - ETA: 0s - loss: 0.3760 - acc: 0.8372
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3742 - acc: 0.8353
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3704 - acc: 0.8393
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3737 - acc: 0.8406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3741 - acc: 0.8398
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3646 - acc: 0.8474
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3651 - acc: 0.8472
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3641 - acc: 0.8479
1280/1283 [============================>.] - ETA: 0s - loss: 0.3649 - acc: 0.8477
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3652 - acc: 0.8472 - val_loss: 0.7389 - val_acc: 0.5939

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3186 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.3146 - acc: 0.8672
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3156 - acc: 0.8646
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3263 - acc: 0.8633
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3508 - acc: 0.8562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3453 - acc: 0.8549
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3377 - acc: 0.8594
 576/1283 [============>.................] - ETA: 0s - loss: 0.3474 - acc: 0.8559
 640/1283 [=============>................] - ETA: 0s - loss: 0.3451 - acc: 0.8594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3432 - acc: 0.8622
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3406 - acc: 0.8642
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3362 - acc: 0.8656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3344 - acc: 0.8662
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3366 - acc: 0.8637
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3320 - acc: 0.8676
1280/1283 [============================>.] - ETA: 0s - loss: 0.3315 - acc: 0.8664
1283/1283 [==============================] - 1s 954us/step - loss: 0.3310 - acc: 0.8667 - val_loss: 0.7715 - val_acc: 0.5939

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2955 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3056 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3035 - acc: 0.8688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2945 - acc: 0.8772
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2858 - acc: 0.8809
 576/1283 [============>.................] - ETA: 0s - loss: 0.2826 - acc: 0.8837
 640/1283 [=============>................] - ETA: 0s - loss: 0.2795 - acc: 0.8875
 768/1283 [================>.............] - ETA: 0s - loss: 0.2803 - acc: 0.8867
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2794 - acc: 0.8882
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2726 - acc: 0.8940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2704 - acc: 0.8958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2826 - acc: 0.8888
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2841 - acc: 0.8873
1283/1283 [==============================] - 1s 818us/step - loss: 0.2817 - acc: 0.8909 - val_loss: 0.8184 - val_acc: 0.5983

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2544 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2455 - acc: 0.9115
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2451 - acc: 0.9031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2498 - acc: 0.8996
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2521 - acc: 0.8965
 640/1283 [=============>................] - ETA: 0s - loss: 0.2452 - acc: 0.9031
 768/1283 [================>.............] - ETA: 0s - loss: 0.2407 - acc: 0.9062
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2418 - acc: 0.9074
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2409 - acc: 0.9062
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2474 - acc: 0.9019
1280/1283 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.9055
1283/1283 [==============================] - 1s 772us/step - loss: 0.2442 - acc: 0.9049 - val_loss: 0.7941 - val_acc: 0.6026

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2398 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2236 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2368 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2291 - acc: 0.9152
 576/1283 [============>.................] - ETA: 0s - loss: 0.2241 - acc: 0.9167
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2299 - acc: 0.9105
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2262 - acc: 0.9159
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2207 - acc: 0.9219
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2181 - acc: 0.9219
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2215 - acc: 0.9235
1283/1283 [==============================] - 1s 780us/step - loss: 0.2187 - acc: 0.9252 - val_loss: 0.8500 - val_acc: 0.6288

Epoch 00016: val_acc improved from 0.61572 to 0.62882, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1572 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1769 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1985 - acc: 0.9281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1888 - acc: 0.9353
 576/1283 [============>.................] - ETA: 0s - loss: 0.1937 - acc: 0.9306
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1827 - acc: 0.9403
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1864 - acc: 0.9411
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1973 - acc: 0.9354
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2027 - acc: 0.9338
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2029 - acc: 0.9342
1280/1283 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9352
1283/1283 [==============================] - 1s 783us/step - loss: 0.1996 - acc: 0.9353 - val_loss: 0.8983 - val_acc: 0.6157

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1841 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1876 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1693 - acc: 0.9414
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1651 - acc: 0.9453
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1597 - acc: 0.9531
 640/1283 [=============>................] - ETA: 0s - loss: 0.1589 - acc: 0.9516
 768/1283 [================>.............] - ETA: 0s - loss: 0.1627 - acc: 0.9453
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1637 - acc: 0.9453
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1701 - acc: 0.9404
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1717 - acc: 0.9418
1280/1283 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9430
1283/1283 [==============================] - 1s 747us/step - loss: 0.1717 - acc: 0.9431 - val_loss: 0.9702 - val_acc: 0.5983

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1509 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1333 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1347 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1337 - acc: 0.9643
 576/1283 [============>.................] - ETA: 0s - loss: 0.1325 - acc: 0.9601
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1345 - acc: 0.9602
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1357 - acc: 0.9591
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1351 - acc: 0.9583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1316 - acc: 0.9605
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1348 - acc: 0.9589
1283/1283 [==============================] - 1s 638us/step - loss: 0.1370 - acc: 0.9579 - val_loss: 1.0105 - val_acc: 0.6201

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1856 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1253 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1234 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1377 - acc: 0.9621
 576/1283 [============>.................] - ETA: 0s - loss: 0.1359 - acc: 0.9601
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1305 - acc: 0.9631
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1284 - acc: 0.9591
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1278 - acc: 0.9604
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1257 - acc: 0.9632
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1313 - acc: 0.9605
1283/1283 [==============================] - 1s 615us/step - loss: 0.1301 - acc: 0.9610 - val_loss: 1.1114 - val_acc: 0.6070

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1049 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1285 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1329 - acc: 0.9500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1265 - acc: 0.9554
 576/1283 [============>.................] - ETA: 0s - loss: 0.1263 - acc: 0.9583
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1274 - acc: 0.9616
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1220 - acc: 0.9639
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1251 - acc: 0.9625
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1210 - acc: 0.9642
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1208 - acc: 0.9638
1283/1283 [==============================] - 1s 535us/step - loss: 0.1188 - acc: 0.9641 - val_loss: 1.0792 - val_acc: 0.5895

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0887 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1055 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0899 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0935 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0957 - acc: 0.9757
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0986 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0981 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0983 - acc: 0.9698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0995 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0995 - acc: 0.9696
1283/1283 [==============================] - 1s 496us/step - loss: 0.0987 - acc: 0.9704 - val_loss: 1.1820 - val_acc: 0.6201

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1072 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0956 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0863 - acc: 0.9812
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0863 - acc: 0.9805
 640/1283 [=============>................] - ETA: 0s - loss: 0.0814 - acc: 0.9812
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0774 - acc: 0.9832
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0800 - acc: 0.9805
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0826 - acc: 0.9786
1283/1283 [==============================] - 1s 431us/step - loss: 0.0830 - acc: 0.9774 - val_loss: 1.3747 - val_acc: 0.6288

Epoch 00023: val_acc did not improve
Epoch 24/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0542 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0990 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0935 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0957 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0975 - acc: 0.9675
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0964 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0984 - acc: 0.9663
1283/1283 [==============================] - 0s 368us/step - loss: 0.0973 - acc: 0.9665 - val_loss: 1.2178 - val_acc: 0.5983

Epoch 00024: val_acc did not improve
Epoch 25/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0511 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1223 - acc: 0.9414
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1236 - acc: 0.9420
 640/1283 [=============>................] - ETA: 0s - loss: 0.1128 - acc: 0.9469
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1116 - acc: 0.9507
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1133 - acc: 0.9512
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1061 - acc: 0.9564
1283/1283 [==============================] - 0s 311us/step - loss: 0.1056 - acc: 0.9571 - val_loss: 1.1477 - val_acc: 0.5983

Epoch 00025: val_acc did not improve
Epoch 26/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0694 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1038 - acc: 0.9805
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1087 - acc: 0.9710
 640/1283 [=============>................] - ETA: 0s - loss: 0.1196 - acc: 0.9641
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1104 - acc: 0.9651
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1060 - acc: 0.9668
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1033 - acc: 0.9671
1283/1283 [==============================] - 0s 311us/step - loss: 0.1011 - acc: 0.9688 - val_loss: 1.3065 - val_acc: 0.5852

Epoch 00026: val_acc did not improve
Epoch 00026: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=30
mode=A
accuracy=0.4868804664723032
best_valid_accuracy=0.4620991253644315
