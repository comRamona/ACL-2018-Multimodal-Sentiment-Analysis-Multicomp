/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 00:05:41.160685: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 25s - loss: 0.6903 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 8s - loss: 0.6898 - acc: 0.5312 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.6942 - acc: 0.5281
 448/1283 [=========>....................] - ETA: 2s - loss: 0.6930 - acc: 0.5290
 576/1283 [============>.................] - ETA: 2s - loss: 0.6932 - acc: 0.5260
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6881 - acc: 0.5426
 768/1283 [================>.............] - ETA: 1s - loss: 0.6895 - acc: 0.5365
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6882 - acc: 0.5433
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6859 - acc: 0.5500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6870 - acc: 0.5450
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6866 - acc: 0.5502
1280/1283 [============================>.] - ETA: 0s - loss: 0.6875 - acc: 0.5477
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6875 - acc: 0.5479 - val_loss: 0.6626 - val_acc: 0.5677

Epoch 00001: val_acc improved from -inf to 0.56769, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6750 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6462 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6503 - acc: 0.6641
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6466 - acc: 0.6719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6455 - acc: 0.6641
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6398 - acc: 0.6719
 576/1283 [============>.................] - ETA: 0s - loss: 0.6397 - acc: 0.6753
 640/1283 [=============>................] - ETA: 0s - loss: 0.6376 - acc: 0.6719
 768/1283 [================>.............] - ETA: 0s - loss: 0.6378 - acc: 0.6641
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6380 - acc: 0.6629
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6354 - acc: 0.6656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6342 - acc: 0.6654
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6325 - acc: 0.6719
1283/1283 [==============================] - 1s 780us/step - loss: 0.6313 - acc: 0.6719 - val_loss: 0.6296 - val_acc: 0.6812

Epoch 00002: val_acc improved from 0.56769 to 0.68122, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6248 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5898 - acc: 0.7135
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5781 - acc: 0.7461
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5895 - acc: 0.7109
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5900 - acc: 0.7031
 640/1283 [=============>................] - ETA: 0s - loss: 0.5915 - acc: 0.7125
 768/1283 [================>.............] - ETA: 0s - loss: 0.5866 - acc: 0.7188
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5844 - acc: 0.7232
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5769 - acc: 0.7285
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5768 - acc: 0.7233
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5749 - acc: 0.7262
1283/1283 [==============================] - 1s 749us/step - loss: 0.5748 - acc: 0.7233 - val_loss: 0.5866 - val_acc: 0.7293

Epoch 00003: val_acc improved from 0.68122 to 0.72926, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5135 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5092 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5215 - acc: 0.7781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5267 - acc: 0.7682
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5377 - acc: 0.7637
 640/1283 [=============>................] - ETA: 0s - loss: 0.5310 - acc: 0.7688
 768/1283 [================>.............] - ETA: 0s - loss: 0.5281 - acc: 0.7734
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5179 - acc: 0.7757
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5126 - acc: 0.7803
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5124 - acc: 0.7769
1280/1283 [============================>.] - ETA: 0s - loss: 0.5087 - acc: 0.7812
1283/1283 [==============================] - 1s 680us/step - loss: 0.5083 - acc: 0.7818 - val_loss: 0.5459 - val_acc: 0.7555

Epoch 00004: val_acc improved from 0.72926 to 0.75546, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4093 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4274 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4302 - acc: 0.8313
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4513 - acc: 0.8013
 576/1283 [============>.................] - ETA: 0s - loss: 0.4424 - acc: 0.8125
 640/1283 [=============>................] - ETA: 0s - loss: 0.4429 - acc: 0.8078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4493 - acc: 0.7955
 768/1283 [================>.............] - ETA: 0s - loss: 0.4468 - acc: 0.8034
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4496 - acc: 0.8053
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4495 - acc: 0.8052
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4446 - acc: 0.8042
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4417 - acc: 0.8084
1283/1283 [==============================] - 1s 844us/step - loss: 0.4374 - acc: 0.8114 - val_loss: 0.5288 - val_acc: 0.7467

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3407 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.3886 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3953 - acc: 0.8542
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4010 - acc: 0.8477
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3836 - acc: 0.8625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3831 - acc: 0.8620
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3684 - acc: 0.8728
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3718 - acc: 0.8672
 576/1283 [============>.................] - ETA: 0s - loss: 0.3770 - acc: 0.8646
 640/1283 [=============>................] - ETA: 0s - loss: 0.3844 - acc: 0.8562
 768/1283 [================>.............] - ETA: 0s - loss: 0.3847 - acc: 0.8516
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3854 - acc: 0.8462
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3854 - acc: 0.8482
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3816 - acc: 0.8490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3810 - acc: 0.8457
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3775 - acc: 0.8493
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3776 - acc: 0.8455
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3728 - acc: 0.8470
1280/1283 [============================>.] - ETA: 0s - loss: 0.3702 - acc: 0.8484
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3710 - acc: 0.8472 - val_loss: 0.5179 - val_acc: 0.7598

Epoch 00006: val_acc improved from 0.75546 to 0.75983, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3514 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3007 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3034 - acc: 0.8867
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3084 - acc: 0.8844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3013 - acc: 0.8929
 576/1283 [============>.................] - ETA: 0s - loss: 0.2905 - acc: 0.9028
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3070 - acc: 0.8920
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3069 - acc: 0.8942
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3066 - acc: 0.8958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3024 - acc: 0.8943
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3008 - acc: 0.8939
1283/1283 [==============================] - 1s 690us/step - loss: 0.3106 - acc: 0.8893 - val_loss: 0.5481 - val_acc: 0.7424

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2947 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2395 - acc: 0.9271
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2344 - acc: 0.9187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2333 - acc: 0.9241
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2406 - acc: 0.9238
 576/1283 [============>.................] - ETA: 0s - loss: 0.2440 - acc: 0.9253
 640/1283 [=============>................] - ETA: 0s - loss: 0.2493 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2510 - acc: 0.9233
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2466 - acc: 0.9243
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2435 - acc: 0.9252
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2407 - acc: 0.9268
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2369 - acc: 0.9256
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2337 - acc: 0.9276
1280/1283 [============================>.] - ETA: 0s - loss: 0.2377 - acc: 0.9250
1283/1283 [==============================] - 1s 799us/step - loss: 0.2372 - acc: 0.9252 - val_loss: 0.5706 - val_acc: 0.7249

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1983 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1898 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1844 - acc: 0.9406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1848 - acc: 0.9420
 576/1283 [============>.................] - ETA: 0s - loss: 0.1750 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1768 - acc: 0.9403
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1846 - acc: 0.9339
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1925 - acc: 0.9286
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1931 - acc: 0.9307
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1896 - acc: 0.9306
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1865 - acc: 0.9334
1283/1283 [==============================] - 1s 779us/step - loss: 0.1849 - acc: 0.9361 - val_loss: 0.6679 - val_acc: 0.6900

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1161 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.1157 - acc: 0.9766
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1425 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1448 - acc: 0.9563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1433 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.1401 - acc: 0.9601
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1473 - acc: 0.9560
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1456 - acc: 0.9567
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1477 - acc: 0.9531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1458 - acc: 0.9531
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1382 - acc: 0.9575
1280/1283 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9563
1283/1283 [==============================] - 1s 806us/step - loss: 0.1413 - acc: 0.9556 - val_loss: 0.6849 - val_acc: 0.7336

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1082 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1206 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1017 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1015 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.0981 - acc: 0.9757
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0962 - acc: 0.9759
 768/1283 [================>.............] - ETA: 0s - loss: 0.1016 - acc: 0.9753
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1061 - acc: 0.9721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1089 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1117 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1109 - acc: 0.9679
1280/1283 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9680
1283/1283 [==============================] - 1s 743us/step - loss: 0.1098 - acc: 0.9680 - val_loss: 0.8060 - val_acc: 0.6769

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0575 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.1157 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0964 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0885 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0900 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0933 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0898 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1031 - acc: 0.9727
 576/1283 [============>.................] - ETA: 0s - loss: 0.0966 - acc: 0.9757
 640/1283 [=============>................] - ETA: 0s - loss: 0.0982 - acc: 0.9750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1002 - acc: 0.9730
 768/1283 [================>.............] - ETA: 0s - loss: 0.0996 - acc: 0.9740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0961 - acc: 0.9743
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0914 - acc: 0.9766
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0888 - acc: 0.9783
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0862 - acc: 0.9794
1280/1283 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9781
1283/1283 [==============================] - 1s 947us/step - loss: 0.0891 - acc: 0.9774 - val_loss: 0.7628 - val_acc: 0.7205

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0874 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0700 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0643 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0691 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0615 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0627 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0593 - acc: 0.9883
 640/1283 [=============>................] - ETA: 0s - loss: 0.0628 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0584 - acc: 0.9870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0572 - acc: 0.9880
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0582 - acc: 0.9875
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0651 - acc: 0.9835
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0652 - acc: 0.9835
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0649 - acc: 0.9827
1280/1283 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9828
1283/1283 [==============================] - 1s 884us/step - loss: 0.0647 - acc: 0.9829 - val_loss: 0.8214 - val_acc: 0.6856

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0648 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0627 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0459 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0425 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0428 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0433 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0487 - acc: 0.9878
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0496 - acc: 0.9872
 768/1283 [================>.............] - ETA: 0s - loss: 0.0476 - acc: 0.9883
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0484 - acc: 0.9877
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0513 - acc: 0.9873
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0542 - acc: 0.9870
1280/1283 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9875
1283/1283 [==============================] - 1s 797us/step - loss: 0.0536 - acc: 0.9875 - val_loss: 0.8683 - val_acc: 0.6987

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0255 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0332 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0346 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0351 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0355 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0348 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0355 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0349 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0347 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0369 - acc: 0.9951
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0360 - acc: 0.9939
1280/1283 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9945
1283/1283 [==============================] - 1s 816us/step - loss: 0.0344 - acc: 0.9945 - val_loss: 0.9350 - val_acc: 0.6812

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0435 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0312 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0287 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0289 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0254 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0270 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0283 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0273 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0279 - acc: 0.9952
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0288 - acc: 0.9938
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0267 - acc: 0.9945
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0281 - acc: 0.9939
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0275 - acc: 0.9942
1283/1283 [==============================] - 1s 900us/step - loss: 0.0288 - acc: 0.9938 - val_loss: 0.9616 - val_acc: 0.6900

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
mode=AT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.7113702623906706
best_valid_accuracy=0.6938775510204082
