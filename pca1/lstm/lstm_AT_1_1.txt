/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 00:05:41.137210: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 28s - loss: 0.6953 - acc: 0.5312
 128/1283 [=>............................] - ETA: 13s - loss: 0.6908 - acc: 0.5469
 256/1283 [====>.........................] - ETA: 6s - loss: 0.6876 - acc: 0.5391 
 384/1283 [=======>......................] - ETA: 3s - loss: 0.6909 - acc: 0.5156
 448/1283 [=========>....................] - ETA: 3s - loss: 0.6880 - acc: 0.5246
 576/1283 [============>.................] - ETA: 2s - loss: 0.6886 - acc: 0.5278
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6838 - acc: 0.5426
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6841 - acc: 0.5409
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6821 - acc: 0.5448
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6818 - acc: 0.5459
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6830 - acc: 0.5399
1280/1283 [============================>.] - ETA: 0s - loss: 0.6833 - acc: 0.5414
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6833 - acc: 0.5417 - val_loss: 0.6578 - val_acc: 0.5764

Epoch 00001: val_acc improved from -inf to 0.57642, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6606 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6377 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6386 - acc: 0.6992
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6361 - acc: 0.6745
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6341 - acc: 0.6786
 576/1283 [============>.................] - ETA: 0s - loss: 0.6291 - acc: 0.6927
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6254 - acc: 0.6932
 768/1283 [================>.............] - ETA: 0s - loss: 0.6264 - acc: 0.6875
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6272 - acc: 0.6863
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6277 - acc: 0.6830
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6247 - acc: 0.6885
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6244 - acc: 0.6857
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6229 - acc: 0.6891
1283/1283 [==============================] - 1s 845us/step - loss: 0.6214 - acc: 0.6890 - val_loss: 0.6197 - val_acc: 0.6856

Epoch 00002: val_acc improved from 0.57642 to 0.68559, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6046 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5619 - acc: 0.7292
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5526 - acc: 0.7578
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5578 - acc: 0.7531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5619 - acc: 0.7396
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5709 - acc: 0.7299
 576/1283 [============>.................] - ETA: 0s - loss: 0.5686 - acc: 0.7292
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5654 - acc: 0.7330
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5674 - acc: 0.7296
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5583 - acc: 0.7396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5540 - acc: 0.7454
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5548 - acc: 0.7434
1283/1283 [==============================] - 1s 784us/step - loss: 0.5546 - acc: 0.7420 - val_loss: 0.5722 - val_acc: 0.7162

Epoch 00003: val_acc improved from 0.68559 to 0.71616, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4934 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4809 - acc: 0.8333
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4916 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4946 - acc: 0.8021
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5104 - acc: 0.7902
 576/1283 [============>.................] - ETA: 0s - loss: 0.5070 - acc: 0.7934
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4979 - acc: 0.7983
 768/1283 [================>.............] - ETA: 0s - loss: 0.5001 - acc: 0.7956
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4973 - acc: 0.7933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4852 - acc: 0.8021
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4825 - acc: 0.8015
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4818 - acc: 0.7995
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4764 - acc: 0.8051
1280/1283 [============================>.] - ETA: 0s - loss: 0.4776 - acc: 0.8047
1283/1283 [==============================] - 1s 812us/step - loss: 0.4773 - acc: 0.8051 - val_loss: 0.5321 - val_acc: 0.7424

Epoch 00004: val_acc improved from 0.71616 to 0.74236, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3571 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3936 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3958 - acc: 0.8438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4104 - acc: 0.8348
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4006 - acc: 0.8418
 640/1283 [=============>................] - ETA: 0s - loss: 0.4005 - acc: 0.8359
 768/1283 [================>.............] - ETA: 0s - loss: 0.4026 - acc: 0.8372
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4105 - acc: 0.8315
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4046 - acc: 0.8330
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4018 - acc: 0.8373
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4028 - acc: 0.8342
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3993 - acc: 0.8380
1283/1283 [==============================] - 1s 766us/step - loss: 0.3952 - acc: 0.8394 - val_loss: 0.5264 - val_acc: 0.7380

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2758 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3513 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3588 - acc: 0.8555
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3425 - acc: 0.8646
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3294 - acc: 0.8728
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3303 - acc: 0.8730
 640/1283 [=============>................] - ETA: 0s - loss: 0.3392 - acc: 0.8656
 768/1283 [================>.............] - ETA: 0s - loss: 0.3391 - acc: 0.8672
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3406 - acc: 0.8654
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3358 - acc: 0.8688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3324 - acc: 0.8695
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3276 - acc: 0.8701
1283/1283 [==============================] - 1s 874us/step - loss: 0.3265 - acc: 0.8691 - val_loss: 0.5235 - val_acc: 0.7380

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2785 - acc: 0.8906
 128/1283 [=>............................] - ETA: 0s - loss: 0.2631 - acc: 0.9141
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2527 - acc: 0.9141
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2497 - acc: 0.9141
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2416 - acc: 0.9219
 640/1283 [=============>................] - ETA: 0s - loss: 0.2561 - acc: 0.9172
 768/1283 [================>.............] - ETA: 0s - loss: 0.2574 - acc: 0.9180
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2612 - acc: 0.9163
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2604 - acc: 0.9170
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2552 - acc: 0.9184
1280/1283 [============================>.] - ETA: 0s - loss: 0.2653 - acc: 0.9141
1283/1283 [==============================] - 1s 726us/step - loss: 0.2648 - acc: 0.9143 - val_loss: 0.5766 - val_acc: 0.7380

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2539 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2045 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2004 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2044 - acc: 0.9401
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2050 - acc: 0.9453
 576/1283 [============>.................] - ETA: 0s - loss: 0.2066 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2111 - acc: 0.9460
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2058 - acc: 0.9471
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2014 - acc: 0.9479
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1966 - acc: 0.9485
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1931 - acc: 0.9507
1283/1283 [==============================] - 1s 767us/step - loss: 0.1974 - acc: 0.9470 - val_loss: 0.5940 - val_acc: 0.7293

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1520 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1456 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1400 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1440 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.1361 - acc: 0.9722
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1376 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1424 - acc: 0.9627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1529 - acc: 0.9563
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1483 - acc: 0.9577
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1433 - acc: 0.9605
1283/1283 [==============================] - 1s 687us/step - loss: 0.1410 - acc: 0.9626 - val_loss: 0.7081 - val_acc: 0.6943

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0820 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1044 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1070 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1075 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1038 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.1007 - acc: 0.9722
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1042 - acc: 0.9659
 768/1283 [================>.............] - ETA: 0s - loss: 0.1041 - acc: 0.9661
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1007 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1021 - acc: 0.9697
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0975 - acc: 0.9731
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0960 - acc: 0.9745
1283/1283 [==============================] - 1s 734us/step - loss: 0.0990 - acc: 0.9719 - val_loss: 0.7269 - val_acc: 0.7249

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0721 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0794 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0738 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0759 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0771 - acc: 0.9746
 640/1283 [=============>................] - ETA: 0s - loss: 0.0753 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0735 - acc: 0.9787
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0753 - acc: 0.9796
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0802 - acc: 0.9777
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0824 - acc: 0.9775
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0851 - acc: 0.9761
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0829 - acc: 0.9762
1283/1283 [==============================] - 1s 802us/step - loss: 0.0839 - acc: 0.9751 - val_loss: 0.8893 - val_acc: 0.6725

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0407 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0890 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0779 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0676 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0722 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0786 - acc: 0.9707
 640/1283 [=============>................] - ETA: 0s - loss: 0.0725 - acc: 0.9750
 768/1283 [================>.............] - ETA: 0s - loss: 0.0693 - acc: 0.9779
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0705 - acc: 0.9772
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0672 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0654 - acc: 0.9802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0634 - acc: 0.9814
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0638 - acc: 0.9807
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0624 - acc: 0.9818
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0612 - acc: 0.9819
1280/1283 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9812
1283/1283 [==============================] - 1s 940us/step - loss: 0.0635 - acc: 0.9805 - val_loss: 0.8114 - val_acc: 0.6943

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0471 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0530 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0450 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0469 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0411 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0396 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0390 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0363 - acc: 0.9964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0355 - acc: 0.9969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0405 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0399 - acc: 0.9957
1280/1283 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9945
1283/1283 [==============================] - 1s 775us/step - loss: 0.0401 - acc: 0.9945 - val_loss: 0.8707 - val_acc: 0.6856

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0346 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0370 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0268 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0246 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0311 - acc: 0.9941
 640/1283 [=============>................] - ETA: 0s - loss: 0.0318 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0324 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0308 - acc: 0.9961
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0289 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0295 - acc: 0.9969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0288 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0314 - acc: 0.9965
1280/1283 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9969
1283/1283 [==============================] - 1s 783us/step - loss: 0.0303 - acc: 0.9969 - val_loss: 0.9155 - val_acc: 0.6900

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
mode=AT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6909620991253644
best_valid_accuracy=0.6836734693877551
