/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:34:39.654798: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.6884 - acc: 0.5469
 128/1283 [=>............................] - ETA: 4s - loss: 0.7112 - acc: 0.5547
 192/1283 [===>..........................] - ETA: 3s - loss: 0.7416 - acc: 0.5260
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7359 - acc: 0.5430
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7340 - acc: 0.5563
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7299 - acc: 0.5547
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7329 - acc: 0.5491
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7490 - acc: 0.5410
 576/1283 [============>.................] - ETA: 1s - loss: 0.7383 - acc: 0.5469
 640/1283 [=============>................] - ETA: 1s - loss: 0.7468 - acc: 0.5422
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7539 - acc: 0.5412
 768/1283 [================>.............] - ETA: 0s - loss: 0.7547 - acc: 0.5365
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7523 - acc: 0.5337
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7466 - acc: 0.5346
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7453 - acc: 0.5365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7447 - acc: 0.5391
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7398 - acc: 0.5423
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7383 - acc: 0.5382
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7360 - acc: 0.5395
1280/1283 [============================>.] - ETA: 0s - loss: 0.7344 - acc: 0.5391
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7342 - acc: 0.5394 - val_loss: 0.7024 - val_acc: 0.5197

Epoch 00001: val_acc improved from -inf to 0.51965, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6371 - acc: 0.5938
 128/1283 [=>............................] - ETA: 1s - loss: 0.6074 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5918 - acc: 0.7083
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5996 - acc: 0.6953
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5869 - acc: 0.7250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5829 - acc: 0.7318
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5802 - acc: 0.7277
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5755 - acc: 0.7285
 576/1283 [============>.................] - ETA: 0s - loss: 0.5728 - acc: 0.7257
 640/1283 [=============>................] - ETA: 0s - loss: 0.5696 - acc: 0.7297
 768/1283 [================>.............] - ETA: 0s - loss: 0.5613 - acc: 0.7396
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5588 - acc: 0.7404
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5552 - acc: 0.7400
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5549 - acc: 0.7354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5543 - acc: 0.7324
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5511 - acc: 0.7353
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5476 - acc: 0.7368
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5434 - acc: 0.7412 - val_loss: 0.7729 - val_acc: 0.5852

Epoch 00002: val_acc improved from 0.51965 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4997 - acc: 0.7344
 128/1283 [=>............................] - ETA: 0s - loss: 0.4557 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4510 - acc: 0.8021
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4340 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4413 - acc: 0.8094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4472 - acc: 0.8047
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4388 - acc: 0.8103
 576/1283 [============>.................] - ETA: 0s - loss: 0.4342 - acc: 0.8125
 640/1283 [=============>................] - ETA: 0s - loss: 0.4274 - acc: 0.8187
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4250 - acc: 0.8168
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4230 - acc: 0.8173
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4207 - acc: 0.8225
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4166 - acc: 0.8252
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4140 - acc: 0.8229
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4153 - acc: 0.8232
1283/1283 [==============================] - 1s 892us/step - loss: 0.4109 - acc: 0.8270 - val_loss: 0.7005 - val_acc: 0.6114

Epoch 00003: val_acc improved from 0.58515 to 0.61135, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2410 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2704 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2761 - acc: 0.9094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2785 - acc: 0.9040
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2784 - acc: 0.9082
 576/1283 [============>.................] - ETA: 0s - loss: 0.2869 - acc: 0.8941
 640/1283 [=============>................] - ETA: 0s - loss: 0.2913 - acc: 0.8891
 768/1283 [================>.............] - ETA: 0s - loss: 0.3007 - acc: 0.8724
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3015 - acc: 0.8750
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3003 - acc: 0.8761
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2969 - acc: 0.8760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3010 - acc: 0.8721
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2941 - acc: 0.8767
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2944 - acc: 0.8758
1280/1283 [============================>.] - ETA: 0s - loss: 0.2967 - acc: 0.8734
1283/1283 [==============================] - 1s 949us/step - loss: 0.2971 - acc: 0.8730 - val_loss: 0.8001 - val_acc: 0.6070

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2114 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.2434 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2356 - acc: 0.8854
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2841 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2808 - acc: 0.8625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2737 - acc: 0.8646
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2712 - acc: 0.8809
 576/1283 [============>.................] - ETA: 0s - loss: 0.2660 - acc: 0.8819
 640/1283 [=============>................] - ETA: 0s - loss: 0.2635 - acc: 0.8828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2522 - acc: 0.8892
 768/1283 [================>.............] - ETA: 0s - loss: 0.2508 - acc: 0.8906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2527 - acc: 0.8906
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2507 - acc: 0.8895
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2517 - acc: 0.8854
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2474 - acc: 0.8867
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2441 - acc: 0.8897
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2474 - acc: 0.8880
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2478 - acc: 0.8898
1283/1283 [==============================] - 1s 941us/step - loss: 0.2455 - acc: 0.8917 - val_loss: 0.8364 - val_acc: 0.5983

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1397 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1576 - acc: 0.9271
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1644 - acc: 0.9297
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1824 - acc: 0.9094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1859 - acc: 0.9010
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1780 - acc: 0.9102
 640/1283 [=============>................] - ETA: 0s - loss: 0.1688 - acc: 0.9219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1663 - acc: 0.9247
 768/1283 [================>.............] - ETA: 0s - loss: 0.1714 - acc: 0.9232
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1751 - acc: 0.9219
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1745 - acc: 0.9238
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1738 - acc: 0.9227
1280/1283 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9242
1283/1283 [==============================] - 1s 857us/step - loss: 0.1732 - acc: 0.9244 - val_loss: 0.8692 - val_acc: 0.6245

Epoch 00006: val_acc improved from 0.61135 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1305 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1409 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1479 - acc: 0.9414
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1359 - acc: 0.9505
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1310 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1260 - acc: 0.9514
 640/1283 [=============>................] - ETA: 0s - loss: 0.1272 - acc: 0.9516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1290 - acc: 0.9503
 768/1283 [================>.............] - ETA: 0s - loss: 0.1301 - acc: 0.9492
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1313 - acc: 0.9471
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1333 - acc: 0.9464
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1338 - acc: 0.9448
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1341 - acc: 0.9443
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1307 - acc: 0.9458
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1315 - acc: 0.9436
1280/1283 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9430
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1366 - acc: 0.9423 - val_loss: 1.1069 - val_acc: 0.6550

Epoch 00007: val_acc improved from 0.62445 to 0.65502, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1426 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1992 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1810 - acc: 0.9180
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1671 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1574 - acc: 0.9401
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1624 - acc: 0.9375
 576/1283 [============>.................] - ETA: 0s - loss: 0.1645 - acc: 0.9340
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1596 - acc: 0.9318
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1554 - acc: 0.9315
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1535 - acc: 0.9323
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1640 - acc: 0.9297
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1620 - acc: 0.9311
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1600 - acc: 0.9314
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1594 - acc: 0.9309
1283/1283 [==============================] - 1s 981us/step - loss: 0.1603 - acc: 0.9306 - val_loss: 1.0247 - val_acc: 0.6026

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0756 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0838 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1111 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1273 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1463 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1513 - acc: 0.9375
 576/1283 [============>.................] - ETA: 0s - loss: 0.1607 - acc: 0.9340
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1714 - acc: 0.9261
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1642 - acc: 0.9303
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1631 - acc: 0.9308
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1693 - acc: 0.9287
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1666 - acc: 0.9301
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1626 - acc: 0.9326
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1692 - acc: 0.9299 - val_loss: 1.1316 - val_acc: 0.6070

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1357 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.1141 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1241 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1137 - acc: 0.9563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1203 - acc: 0.9464
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1151 - acc: 0.9492
 640/1283 [=============>................] - ETA: 0s - loss: 0.1124 - acc: 0.9547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1086 - acc: 0.9574
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1120 - acc: 0.9555
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1129 - acc: 0.9565
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1096 - acc: 0.9594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1087 - acc: 0.9600
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1108 - acc: 0.9577
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1092 - acc: 0.9592
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1119 - acc: 0.9572
1283/1283 [==============================] - 1s 913us/step - loss: 0.1101 - acc: 0.9579 - val_loss: 1.2503 - val_acc: 0.5808

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1279 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1188 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1060 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1094 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0992 - acc: 0.9576
 576/1283 [============>.................] - ETA: 0s - loss: 0.0919 - acc: 0.9618
 640/1283 [=============>................] - ETA: 0s - loss: 0.0886 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0870 - acc: 0.9659
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0880 - acc: 0.9663
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0864 - acc: 0.9677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0894 - acc: 0.9642
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0867 - acc: 0.9661
1280/1283 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9680
1283/1283 [==============================] - 1s 843us/step - loss: 0.0834 - acc: 0.9680 - val_loss: 1.2677 - val_acc: 0.6114

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0875 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0620 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0675 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0622 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.0688 - acc: 0.9722
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0685 - acc: 0.9716
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0684 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0697 - acc: 0.9699
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0706 - acc: 0.9717
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0713 - acc: 0.9706
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0715 - acc: 0.9712
1283/1283 [==============================] - 1s 751us/step - loss: 0.0714 - acc: 0.9704 - val_loss: 1.3975 - val_acc: 0.6157

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0508 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0628 - acc: 0.9766
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0666 - acc: 0.9727
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0756 - acc: 0.9714
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0777 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0732 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0725 - acc: 0.9688
 768/1283 [================>.............] - ETA: 0s - loss: 0.0709 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0711 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0715 - acc: 0.9667
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0742 - acc: 0.9648
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0774 - acc: 0.9642
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0741 - acc: 0.9663
1283/1283 [==============================] - 1s 826us/step - loss: 0.0744 - acc: 0.9673 - val_loss: 1.5543 - val_acc: 0.6201

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0339 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0564 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0547 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0594 - acc: 0.9792
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0533 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0590 - acc: 0.9774
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0587 - acc: 0.9773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0557 - acc: 0.9784
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0617 - acc: 0.9740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0627 - acc: 0.9724
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0644 - acc: 0.9712
1283/1283 [==============================] - 1s 703us/step - loss: 0.0650 - acc: 0.9704 - val_loss: 1.5834 - val_acc: 0.6114

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0565 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0724 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0716 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0610 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0606 - acc: 0.9727
 576/1283 [============>.................] - ETA: 0s - loss: 0.0625 - acc: 0.9705
 640/1283 [=============>................] - ETA: 0s - loss: 0.0626 - acc: 0.9719
 768/1283 [================>.............] - ETA: 0s - loss: 0.0592 - acc: 0.9740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0610 - acc: 0.9710
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0597 - acc: 0.9727
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0578 - acc: 0.9743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0582 - acc: 0.9737
1283/1283 [==============================] - 1s 772us/step - loss: 0.0574 - acc: 0.9743 - val_loss: 1.6329 - val_acc: 0.5895

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0747 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0641 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0564 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0591 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.0596 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0544 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0536 - acc: 0.9724
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0520 - acc: 0.9740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0532 - acc: 0.9752
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0563 - acc: 0.9745
1283/1283 [==============================] - 1s 714us/step - loss: 0.0549 - acc: 0.9751 - val_loss: 1.6665 - val_acc: 0.6070

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0705 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0646 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0572 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0573 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0561 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.0521 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0510 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0562 - acc: 0.9663
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0576 - acc: 0.9665
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0555 - acc: 0.9688
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0552 - acc: 0.9705
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0538 - acc: 0.9720
1280/1283 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9734
1283/1283 [==============================] - 1s 756us/step - loss: 0.0520 - acc: 0.9735 - val_loss: 1.7652 - val_acc: 0.5808

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
nodes=100
mode=AT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5583090379008746
best_valid_accuracy=0.6064139941690962
