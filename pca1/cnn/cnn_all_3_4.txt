/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:06:01.695537: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.7497 - acc: 0.5938
 128/1283 [=>............................] - ETA: 5s - loss: 0.7278 - acc: 0.5625 
 192/1283 [===>..........................] - ETA: 3s - loss: 0.7630 - acc: 0.5260
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7415 - acc: 0.5352
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7282 - acc: 0.5437
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7251 - acc: 0.5339
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7169 - acc: 0.5513
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7100 - acc: 0.5605
 576/1283 [============>.................] - ETA: 1s - loss: 0.7046 - acc: 0.5712
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7038 - acc: 0.5625
 768/1283 [================>.............] - ETA: 0s - loss: 0.6993 - acc: 0.5625
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6927 - acc: 0.5681
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6952 - acc: 0.5594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6943 - acc: 0.5596
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6927 - acc: 0.5625
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6914 - acc: 0.5633
1280/1283 [============================>.] - ETA: 0s - loss: 0.6913 - acc: 0.5641
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6914 - acc: 0.5635 - val_loss: 0.6898 - val_acc: 0.5459

Epoch 00001: val_acc improved from -inf to 0.54585, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6379 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.6162 - acc: 0.7266
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6129 - acc: 0.7292
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6072 - acc: 0.7344
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6031 - acc: 0.7188
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6008 - acc: 0.7135
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5876 - acc: 0.7188
 576/1283 [============>.................] - ETA: 0s - loss: 0.5843 - acc: 0.7222
 640/1283 [=============>................] - ETA: 0s - loss: 0.5840 - acc: 0.7156
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5807 - acc: 0.7131
 768/1283 [================>.............] - ETA: 0s - loss: 0.5746 - acc: 0.7214
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5733 - acc: 0.7224
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5677 - acc: 0.7299
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5661 - acc: 0.7302
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5664 - acc: 0.7285
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5597 - acc: 0.7344
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5576 - acc: 0.7378
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5580 - acc: 0.7393
1280/1283 [============================>.] - ETA: 0s - loss: 0.5569 - acc: 0.7398
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5573 - acc: 0.7389 - val_loss: 0.7382 - val_acc: 0.6201

Epoch 00002: val_acc improved from 0.54585 to 0.62009, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4517 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4249 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4759 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4686 - acc: 0.7539
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4609 - acc: 0.7594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4545 - acc: 0.7634
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4590 - acc: 0.7617
 576/1283 [============>.................] - ETA: 0s - loss: 0.4624 - acc: 0.7569
 640/1283 [=============>................] - ETA: 0s - loss: 0.4573 - acc: 0.7609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4484 - acc: 0.7699
 768/1283 [================>.............] - ETA: 0s - loss: 0.4414 - acc: 0.7773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4371 - acc: 0.7800
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4339 - acc: 0.7857
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4313 - acc: 0.7896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4290 - acc: 0.7959
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4298 - acc: 0.7914
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4324 - acc: 0.7865
1280/1283 [============================>.] - ETA: 0s - loss: 0.4314 - acc: 0.7937
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4309 - acc: 0.7942 - val_loss: 0.8629 - val_acc: 0.6245

Epoch 00003: val_acc improved from 0.62009 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3609 - acc: 0.7969
 128/1283 [=>............................] - ETA: 0s - loss: 0.4134 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3746 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3443 - acc: 0.8500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3273 - acc: 0.8549
 576/1283 [============>.................] - ETA: 0s - loss: 0.3271 - acc: 0.8594
 640/1283 [=============>................] - ETA: 0s - loss: 0.3136 - acc: 0.8672
 768/1283 [================>.............] - ETA: 0s - loss: 0.3028 - acc: 0.8750
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2938 - acc: 0.8795
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2907 - acc: 0.8833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2843 - acc: 0.8867
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2810 - acc: 0.8906
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2761 - acc: 0.8932
1280/1283 [============================>.] - ETA: 0s - loss: 0.2763 - acc: 0.8930
1283/1283 [==============================] - 1s 887us/step - loss: 0.2763 - acc: 0.8932 - val_loss: 0.7865 - val_acc: 0.6245

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2076 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.2236 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2018 - acc: 0.9336
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1865 - acc: 0.9406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1783 - acc: 0.9330
 576/1283 [============>.................] - ETA: 0s - loss: 0.1756 - acc: 0.9340
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1749 - acc: 0.9304
 768/1283 [================>.............] - ETA: 0s - loss: 0.1895 - acc: 0.9232
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1814 - acc: 0.9263
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1777 - acc: 0.9292
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1735 - acc: 0.9320
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1711 - acc: 0.9349
1280/1283 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9344
1283/1283 [==============================] - 1s 855us/step - loss: 0.1703 - acc: 0.9345 - val_loss: 1.1623 - val_acc: 0.6070

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2136 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.1824 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1640 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1387 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1218 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1074 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1101 - acc: 0.9629
 576/1283 [============>.................] - ETA: 0s - loss: 0.1090 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.1110 - acc: 0.9625
 768/1283 [================>.............] - ETA: 0s - loss: 0.1083 - acc: 0.9622
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1071 - acc: 0.9627
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1049 - acc: 0.9643
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1037 - acc: 0.9629
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0966 - acc: 0.9670
1280/1283 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9703
1283/1283 [==============================] - 1s 852us/step - loss: 0.0946 - acc: 0.9704 - val_loss: 0.9844 - val_acc: 0.6376

Epoch 00006: val_acc improved from 0.62445 to 0.63755, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0381 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0464 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0535 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0607 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0585 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0520 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0514 - acc: 0.9861
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0596 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0584 - acc: 0.9844
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0560 - acc: 0.9854
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0602 - acc: 0.9824
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0613 - acc: 0.9825
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0608 - acc: 0.9818
1280/1283 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9805
1283/1283 [==============================] - 1s 904us/step - loss: 0.0626 - acc: 0.9805 - val_loss: 1.3053 - val_acc: 0.6288

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0435 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0466 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0363 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0323 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0351 - acc: 0.9931
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0370 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0349 - acc: 0.9935
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0324 - acc: 0.9944
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0327 - acc: 0.9941
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0325 - acc: 0.9931
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0314 - acc: 0.9934
1283/1283 [==============================] - 1s 778us/step - loss: 0.0317 - acc: 0.9930 - val_loss: 1.3450 - val_acc: 0.6288

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0132 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0125 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0222 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0189 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0171 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0165 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0179 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0171 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0162 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0148 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0136 - acc: 0.9992
1280/1283 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9992
1283/1283 [==============================] - 1s 768us/step - loss: 0.0131 - acc: 0.9992 - val_loss: 1.3964 - val_acc: 0.6507

Epoch 00009: val_acc improved from 0.63755 to 0.65066, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0050 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0050 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0054 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0043 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0042 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0042 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0047 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 1.0000
1283/1283 [==============================] - 1s 834us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.4423 - val_acc: 0.6463

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0021 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0024 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0025 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0027 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0025 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0024 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0024 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 1.0000
1283/1283 [==============================] - 1s 905us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.5242 - val_acc: 0.6419

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0019 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0012 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0012 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0012 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0013 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0014 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0014 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0013 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0013 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0013 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0016 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 1.0000
1283/1283 [==============================] - 1s 774us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.5772 - val_acc: 0.6419

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0015 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0011 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 9.5005e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 9.0701e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 8.8261e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 8.9161e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0010 - acc: 1.0000    
1280/1283 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000
1283/1283 [==============================] - 1s 742us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.6418 - val_acc: 0.6376

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 3.7112e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 6.2717e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0011 - acc: 1.0000    
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 8.7753e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 8.0715e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 7.7061e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 8.9456e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 9.0340e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 9.1088e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 8.8511e-04 - acc: 1.0000
1283/1283 [==============================] - 1s 701us/step - loss: 8.8654e-04 - acc: 1.0000 - val_loss: 1.7033 - val_acc: 0.6463

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 3.7958e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0012 - acc: 1.0000    
 320/1283 [======>.......................] - ETA: 0s - loss: 8.9828e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 7.3511e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 9.6094e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 8.7140e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 8.4938e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 7.8142e-04 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 7.6048e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 7.2362e-04 - acc: 1.0000
1283/1283 [==============================] - 1s 698us/step - loss: 7.3011e-04 - acc: 1.0000 - val_loss: 1.7433 - val_acc: 0.6288

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 2.9913e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 8.9957e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 6.6128e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 5.6550e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 5.0780e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 7.0800e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 6.9170e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 6.6744e-04 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 6.2273e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 5.9573e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 5.9347e-04 - acc: 1.0000
1283/1283 [==============================] - 1s 664us/step - loss: 5.9253e-04 - acc: 1.0000 - val_loss: 1.7988 - val_acc: 0.6463

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 4.0259e-04 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 2.7690e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 4.9724e-04 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 4.5239e-04 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 4.8994e-04 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 5.8708e-04 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 5.2011e-04 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 5.5974e-04 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 5.5786e-04 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 5.6830e-04 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 5.3303e-04 - acc: 1.0000
1283/1283 [==============================] - 1s 566us/step - loss: 5.3181e-04 - acc: 1.0000 - val_loss: 1.8336 - val_acc: 0.6463

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0014 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 5.7529e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 5.3012e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 5.1870e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 4.5063e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 3.9406e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 3.7917e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 4.5639e-04 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 4.3844e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 4.1505e-04 - acc: 1.0000
1283/1283 [==============================] - 1s 488us/step - loss: 4.1190e-04 - acc: 1.0000 - val_loss: 1.8717 - val_acc: 0.6463

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 1.4657e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 2.4325e-04 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 2.9564e-04 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 2.6876e-04 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 2.5356e-04 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 2.3799e-04 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 2.3993e-04 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 3.6147e-04 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 3.5151e-04 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 4.5805e-04 - acc: 1.0000
1283/1283 [==============================] - 1s 488us/step - loss: 4.6122e-04 - acc: 1.0000 - val_loss: 2.0069 - val_acc: 0.6463

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=3
max_len=30
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.7113702623906706
best_valid_accuracy=0.7186588921282799
