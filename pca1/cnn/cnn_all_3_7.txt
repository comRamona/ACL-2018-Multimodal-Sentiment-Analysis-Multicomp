/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:06:15.143123: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.6627 - acc: 0.4375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6856 - acc: 0.5312
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6744 - acc: 0.5625
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6783 - acc: 0.5563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6838 - acc: 0.5692
 576/1283 [============>.................] - ETA: 0s - loss: 0.6837 - acc: 0.5677
 640/1283 [=============>................] - ETA: 0s - loss: 0.6955 - acc: 0.5563
 768/1283 [================>.............] - ETA: 0s - loss: 0.7012 - acc: 0.5417
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6983 - acc: 0.5402
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7002 - acc: 0.5361
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6982 - acc: 0.5373
1280/1283 [============================>.] - ETA: 0s - loss: 0.6973 - acc: 0.5375
1283/1283 [==============================] - 1s 832us/step - loss: 0.6972 - acc: 0.5378 - val_loss: 0.6837 - val_acc: 0.6026

Epoch 00001: val_acc improved from -inf to 0.60262, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6448 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6483 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6454 - acc: 0.7188
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6421 - acc: 0.6745
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6355 - acc: 0.6836
 576/1283 [============>.................] - ETA: 0s - loss: 0.6290 - acc: 0.6910
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6206 - acc: 0.7045
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6211 - acc: 0.6875
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6116 - acc: 0.6937
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6107 - acc: 0.6895
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6070 - acc: 0.6866
1280/1283 [============================>.] - ETA: 0s - loss: 0.6048 - acc: 0.6875
1283/1283 [==============================] - 1s 736us/step - loss: 0.6051 - acc: 0.6867 - val_loss: 0.6767 - val_acc: 0.5808

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5532 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5147 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5314 - acc: 0.7312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5093 - acc: 0.7656
 576/1283 [============>.................] - ETA: 0s - loss: 0.5150 - acc: 0.7483
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5006 - acc: 0.7699
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4945 - acc: 0.7680
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4937 - acc: 0.7656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4894 - acc: 0.7647
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4842 - acc: 0.7673
1283/1283 [==============================] - 1s 679us/step - loss: 0.4823 - acc: 0.7693 - val_loss: 0.6814 - val_acc: 0.6245

Epoch 00003: val_acc improved from 0.60262 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3709 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3317 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3218 - acc: 0.8625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3110 - acc: 0.8638
 576/1283 [============>.................] - ETA: 0s - loss: 0.3239 - acc: 0.8628
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3315 - acc: 0.8537
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3274 - acc: 0.8594
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3236 - acc: 0.8583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3194 - acc: 0.8612
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3128 - acc: 0.8676
1283/1283 [==============================] - 1s 615us/step - loss: 0.3151 - acc: 0.8636 - val_loss: 0.8255 - val_acc: 0.5895

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2344 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2078 - acc: 0.9115
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1839 - acc: 0.9281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1898 - acc: 0.9196
 576/1283 [============>.................] - ETA: 0s - loss: 0.1904 - acc: 0.9167
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1930 - acc: 0.9162
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1818 - acc: 0.9255
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1878 - acc: 0.9229
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1874 - acc: 0.9228
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1838 - acc: 0.9252
1283/1283 [==============================] - 1s 567us/step - loss: 0.1815 - acc: 0.9260 - val_loss: 1.3970 - val_acc: 0.5852

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2561 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1841 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1679 - acc: 0.9187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1708 - acc: 0.9196
 576/1283 [============>.................] - ETA: 0s - loss: 0.1636 - acc: 0.9271
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1610 - acc: 0.9304
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1623 - acc: 0.9303
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1624 - acc: 0.9302
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1626 - acc: 0.9283
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1620 - acc: 0.9276
1283/1283 [==============================] - 1s 567us/step - loss: 0.1732 - acc: 0.9244 - val_loss: 1.1771 - val_acc: 0.6288

Epoch 00006: val_acc improved from 0.62445 to 0.62882, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0976 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0994 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1409 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1874 - acc: 0.9152
 576/1283 [============>.................] - ETA: 0s - loss: 0.1826 - acc: 0.9149
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1775 - acc: 0.9176
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1782 - acc: 0.9147
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1688 - acc: 0.9229
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1750 - acc: 0.9154
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1685 - acc: 0.9211
1283/1283 [==============================] - 1s 578us/step - loss: 0.1698 - acc: 0.9221 - val_loss: 1.4491 - val_acc: 0.5939

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1566 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3897 - acc: 0.8698
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4206 - acc: 0.8719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3563 - acc: 0.8795
 576/1283 [============>.................] - ETA: 0s - loss: 0.3595 - acc: 0.8594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3310 - acc: 0.8693
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3058 - acc: 0.8810
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3037 - acc: 0.8781
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2838 - acc: 0.8869
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2776 - acc: 0.8890
1283/1283 [==============================] - 1s 563us/step - loss: 0.2773 - acc: 0.8893 - val_loss: 1.0968 - val_acc: 0.6070

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0707 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0916 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1138 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1285 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.1219 - acc: 0.9601
 768/1283 [================>.............] - ETA: 0s - loss: 0.1179 - acc: 0.9609
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1221 - acc: 0.9576
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1218 - acc: 0.9580
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1269 - acc: 0.9575
1280/1283 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9555
1283/1283 [==============================] - 1s 452us/step - loss: 0.1261 - acc: 0.9556 - val_loss: 1.3052 - val_acc: 0.5983

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1076 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1004 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0920 - acc: 0.9563
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0860 - acc: 0.9590
 640/1283 [=============>................] - ETA: 0s - loss: 0.0842 - acc: 0.9625
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0828 - acc: 0.9651
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0829 - acc: 0.9648
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0814 - acc: 0.9661
1283/1283 [==============================] - 1s 430us/step - loss: 0.0815 - acc: 0.9665 - val_loss: 1.5704 - val_acc: 0.5895

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0641 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0684 - acc: 0.9635
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0568 - acc: 0.9766
 576/1283 [============>.................] - ETA: 0s - loss: 0.0631 - acc: 0.9705
 768/1283 [================>.............] - ETA: 0s - loss: 0.0616 - acc: 0.9714
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0692 - acc: 0.9667
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0677 - acc: 0.9669
1280/1283 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9695
1283/1283 [==============================] - 1s 402us/step - loss: 0.0661 - acc: 0.9696 - val_loss: 1.7494 - val_acc: 0.5852

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0371 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0601 - acc: 0.9727
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0651 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.0689 - acc: 0.9653
 768/1283 [================>.............] - ETA: 0s - loss: 0.0656 - acc: 0.9648
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0615 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0600 - acc: 0.9706
1280/1283 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9695
1283/1283 [==============================] - 0s 380us/step - loss: 0.0588 - acc: 0.9696 - val_loss: 1.9078 - val_acc: 0.5983

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0709 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0529 - acc: 0.9883
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0554 - acc: 0.9799
 640/1283 [=============>................] - ETA: 0s - loss: 0.0581 - acc: 0.9734
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0615 - acc: 0.9676
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0581 - acc: 0.9688
1283/1283 [==============================] - 0s 306us/step - loss: 0.0586 - acc: 0.9696 - val_loss: 2.0315 - val_acc: 0.5895

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0524 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0604 - acc: 0.9719
 576/1283 [============>.................] - ETA: 0s - loss: 0.0732 - acc: 0.9670
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0684 - acc: 0.9675
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0665 - acc: 0.9688
1283/1283 [==============================] - 0s 272us/step - loss: 0.0662 - acc: 0.9680 - val_loss: 2.0000 - val_acc: 0.5895

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0566 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0635 - acc: 0.9719
 576/1283 [============>.................] - ETA: 0s - loss: 0.0722 - acc: 0.9670
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0637 - acc: 0.9700
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0690 - acc: 0.9669
1283/1283 [==============================] - 0s 259us/step - loss: 0.0678 - acc: 0.9665 - val_loss: 2.1669 - val_acc: 0.5895

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0578 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0698 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0578 - acc: 0.9670
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0709 - acc: 0.9567
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0652 - acc: 0.9605
1283/1283 [==============================] - 0s 248us/step - loss: 0.0662 - acc: 0.9602 - val_loss: 2.0603 - val_acc: 0.5895

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=3
max_len=25
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6005830903790087
best_valid_accuracy=0.5991253644314869
