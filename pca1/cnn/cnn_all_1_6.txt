/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 07:58:19.455382: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 15s - loss: 0.7096 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7480 - acc: 0.5052 
 320/1283 [======>.......................] - ETA: 3s - loss: 0.8070 - acc: 0.4938
 384/1283 [=======>......................] - ETA: 2s - loss: 0.8113 - acc: 0.5000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7993 - acc: 0.5059
 640/1283 [=============>................] - ETA: 1s - loss: 0.7779 - acc: 0.5266
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7761 - acc: 0.5256
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7575 - acc: 0.5312
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7553 - acc: 0.5437
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7514 - acc: 0.5449
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7468 - acc: 0.5478
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7360 - acc: 0.5535
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7305 - acc: 0.5573 - val_loss: 0.6583 - val_acc: 0.5983

Epoch 00001: val_acc improved from -inf to 0.59825, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4564 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4637 - acc: 0.8073
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4547 - acc: 0.8242
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4450 - acc: 0.8385
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4454 - acc: 0.8348
 576/1283 [============>.................] - ETA: 0s - loss: 0.4439 - acc: 0.8333
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4427 - acc: 0.8324
 768/1283 [================>.............] - ETA: 0s - loss: 0.4404 - acc: 0.8320
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4354 - acc: 0.8326
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4292 - acc: 0.8359
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4234 - acc: 0.8351
1280/1283 [============================>.] - ETA: 0s - loss: 0.4159 - acc: 0.8383
1283/1283 [==============================] - 1s 753us/step - loss: 0.4156 - acc: 0.8387 - val_loss: 0.7084 - val_acc: 0.6288

Epoch 00002: val_acc improved from 0.59825 to 0.62882, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3540 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3560 - acc: 0.8229
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3317 - acc: 0.8438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3107 - acc: 0.8683
 576/1283 [============>.................] - ETA: 0s - loss: 0.3143 - acc: 0.8733
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3041 - acc: 0.8807
 768/1283 [================>.............] - ETA: 0s - loss: 0.3004 - acc: 0.8789
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3073 - acc: 0.8772
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3036 - acc: 0.8812
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3067 - acc: 0.8759
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3067 - acc: 0.8766
1280/1283 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.8797
1283/1283 [==============================] - 1s 741us/step - loss: 0.3041 - acc: 0.8800 - val_loss: 0.6782 - val_acc: 0.6332

Epoch 00003: val_acc improved from 0.62882 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1651 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2246 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2062 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2031 - acc: 0.9349
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2021 - acc: 0.9355
 640/1283 [=============>................] - ETA: 0s - loss: 0.2033 - acc: 0.9344
 768/1283 [================>.............] - ETA: 0s - loss: 0.2001 - acc: 0.9375
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2003 - acc: 0.9399
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1957 - acc: 0.9431
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1945 - acc: 0.9424
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1950 - acc: 0.9412
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1897 - acc: 0.9449
1280/1283 [============================>.] - ETA: 0s - loss: 0.1873 - acc: 0.9469
1283/1283 [==============================] - 1s 911us/step - loss: 0.1872 - acc: 0.9470 - val_loss: 0.7211 - val_acc: 0.6463

Epoch 00004: val_acc improved from 0.63319 to 0.64629, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1017 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1068 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1149 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1174 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1231 - acc: 0.9727
 640/1283 [=============>................] - ETA: 0s - loss: 0.1208 - acc: 0.9719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1204 - acc: 0.9716
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1195 - acc: 0.9724
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1197 - acc: 0.9721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1179 - acc: 0.9729
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1166 - acc: 0.9736
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1172 - acc: 0.9724
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1169 - acc: 0.9722
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1166 - acc: 0.9720
1280/1283 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9727
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1147 - acc: 0.9727 - val_loss: 0.8007 - val_acc: 0.6594

Epoch 00005: val_acc improved from 0.64629 to 0.65939, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1218 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1109 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1025 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0931 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0879 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0833 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0809 - acc: 0.9883
 576/1283 [============>.................] - ETA: 0s - loss: 0.0783 - acc: 0.9896
 640/1283 [=============>................] - ETA: 0s - loss: 0.0766 - acc: 0.9906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0746 - acc: 0.9901
 768/1283 [================>.............] - ETA: 0s - loss: 0.0731 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0719 - acc: 0.9916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0707 - acc: 0.9922
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0710 - acc: 0.9917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0695 - acc: 0.9912
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0696 - acc: 0.9905
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0686 - acc: 0.9910
1283/1283 [==============================] - 1s 916us/step - loss: 0.0688 - acc: 0.9906 - val_loss: 0.8570 - val_acc: 0.6288

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0456 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0405 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0408 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0467 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0464 - acc: 0.9941
 640/1283 [=============>................] - ETA: 0s - loss: 0.0420 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0420 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0413 - acc: 0.9961
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0425 - acc: 0.9955
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0418 - acc: 0.9951
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0407 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0402 - acc: 0.9951
1280/1283 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9945
1283/1283 [==============================] - 1s 811us/step - loss: 0.0408 - acc: 0.9945 - val_loss: 0.9210 - val_acc: 0.6332

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0195 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0215 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0216 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0222 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0250 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0243 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0247 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0271 - acc: 0.9978
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0259 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0259 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0259 - acc: 0.9983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0257 - acc: 0.9984
1283/1283 [==============================] - 1s 824us/step - loss: 0.0254 - acc: 0.9984 - val_loss: 0.9921 - val_acc: 0.6245

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0229 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0191 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0169 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0169 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0162 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0164 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0179 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0166 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0176 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0169 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0162 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0157 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0154 - acc: 0.9992
1280/1283 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9992
1283/1283 [==============================] - 1s 953us/step - loss: 0.0152 - acc: 0.9992 - val_loss: 1.0671 - val_acc: 0.6332

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0119 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0108 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0108 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0109 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0113 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0122 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0120 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0116 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0111 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0107 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0105 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0107 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0115 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0113 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0111 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0108 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0105 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 1.0000
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 1.1235 - val_acc: 0.6419

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0080 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0065 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0096 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0098 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0105 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0100 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0100 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0092 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0089 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0087 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0089 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0090 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0090 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0090 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0091 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0090 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 1.0000
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.1699 - val_acc: 0.6376

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0062 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0065 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0066 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0062 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0060 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0062 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0065 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0062 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0063 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0062 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 1.0000
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.2218 - val_acc: 0.6332

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0041 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0042 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0046 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0048 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0046 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0044 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0044 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0044 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0044 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0043 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0042 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 1.0000
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 1.3557 - val_acc: 0.6376

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0097 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0252 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0308 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0281 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0340 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0337 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0304 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0286 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0435 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0423 - acc: 0.9901
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0387 - acc: 0.9916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0370 - acc: 0.9922
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0407 - acc: 0.9893
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0414 - acc: 0.9890
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0416 - acc: 0.9885
1280/1283 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9891
1283/1283 [==============================] - 1s 911us/step - loss: 0.0420 - acc: 0.9883 - val_loss: 1.2055 - val_acc: 0.6114

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0176 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0975 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1027 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0882 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0853 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0900 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.0887 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.0820 - acc: 0.9750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0773 - acc: 0.9773
 768/1283 [================>.............] - ETA: 0s - loss: 0.0744 - acc: 0.9779
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0784 - acc: 0.9772
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0739 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0786 - acc: 0.9771
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0750 - acc: 0.9785
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0704 - acc: 0.9809
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0684 - acc: 0.9811
1280/1283 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9805
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0682 - acc: 0.9805 - val_loss: 1.2968 - val_acc: 0.6332

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=20
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6603498542274052
best_valid_accuracy=0.6822157434402333
