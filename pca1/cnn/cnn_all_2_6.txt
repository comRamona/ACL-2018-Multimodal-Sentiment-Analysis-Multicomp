/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 07:58:29.275831: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 11s - loss: 0.8852 - acc: 0.5312
 128/1283 [=>............................] - ETA: 5s - loss: 0.8608 - acc: 0.4922 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.8027 - acc: 0.5312
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7690 - acc: 0.5031
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7549 - acc: 0.5156
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7466 - acc: 0.5112
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7360 - acc: 0.5312
 576/1283 [============>.................] - ETA: 1s - loss: 0.7365 - acc: 0.5191
 640/1283 [=============>................] - ETA: 1s - loss: 0.7356 - acc: 0.5141
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7299 - acc: 0.5270
 768/1283 [================>.............] - ETA: 0s - loss: 0.7290 - acc: 0.5260
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7224 - acc: 0.5413
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7176 - acc: 0.5510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7150 - acc: 0.5488
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7142 - acc: 0.5450
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7082 - acc: 0.5510
1280/1283 [============================>.] - ETA: 0s - loss: 0.7080 - acc: 0.5461
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7077 - acc: 0.5464 - val_loss: 0.6998 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5831 - acc: 0.7344
 128/1283 [=>............................] - ETA: 0s - loss: 0.5811 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5646 - acc: 0.8047
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5665 - acc: 0.8000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5645 - acc: 0.7891
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5570 - acc: 0.7930
 576/1283 [============>.................] - ETA: 0s - loss: 0.5542 - acc: 0.7951
 640/1283 [=============>................] - ETA: 0s - loss: 0.5535 - acc: 0.7859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5521 - acc: 0.7884
 768/1283 [================>.............] - ETA: 0s - loss: 0.5485 - acc: 0.7930
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5439 - acc: 0.7924
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5453 - acc: 0.7854
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5397 - acc: 0.7891
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5368 - acc: 0.7877
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5338 - acc: 0.7873
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5361 - acc: 0.7862
1280/1283 [============================>.] - ETA: 0s - loss: 0.5352 - acc: 0.7820
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5350 - acc: 0.7818 - val_loss: 0.7075 - val_acc: 0.5983

Epoch 00002: val_acc improved from 0.52838 to 0.59825, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3726 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.4051 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4107 - acc: 0.8490
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4120 - acc: 0.8359
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3995 - acc: 0.8594
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3955 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3961 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3899 - acc: 0.8691
 576/1283 [============>.................] - ETA: 1s - loss: 0.3917 - acc: 0.8663
 640/1283 [=============>................] - ETA: 0s - loss: 0.3935 - acc: 0.8641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3837 - acc: 0.8736
 768/1283 [================>.............] - ETA: 0s - loss: 0.3792 - acc: 0.8763
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3798 - acc: 0.8738
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3827 - acc: 0.8694
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3807 - acc: 0.8688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3772 - acc: 0.8730
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3756 - acc: 0.8713
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3718 - acc: 0.8724
1280/1283 [============================>.] - ETA: 0s - loss: 0.3692 - acc: 0.8703
1283/1283 [==============================] - 2s 2ms/step - loss: 0.3689 - acc: 0.8706 - val_loss: 0.7318 - val_acc: 0.6245

Epoch 00003: val_acc improved from 0.59825 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2717 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.2411 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2404 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2308 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2258 - acc: 0.9344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2295 - acc: 0.9323
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2227 - acc: 0.9375
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2291 - acc: 0.9277
 576/1283 [============>.................] - ETA: 0s - loss: 0.2358 - acc: 0.9236
 640/1283 [=============>................] - ETA: 0s - loss: 0.2334 - acc: 0.9219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2366 - acc: 0.9162
 768/1283 [================>.............] - ETA: 0s - loss: 0.2357 - acc: 0.9141
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2350 - acc: 0.9123
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2317 - acc: 0.9141
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2337 - acc: 0.9104
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2328 - acc: 0.9102
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2314 - acc: 0.9081
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2303 - acc: 0.9071
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2275 - acc: 0.9087
1280/1283 [============================>.] - ETA: 0s - loss: 0.2237 - acc: 0.9102
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2238 - acc: 0.9096 - val_loss: 0.8715 - val_acc: 0.6201

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0997 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1166 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1305 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1452 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1432 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1409 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1360 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1314 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.1281 - acc: 0.9670
 640/1283 [=============>................] - ETA: 0s - loss: 0.1329 - acc: 0.9656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1365 - acc: 0.9602
 768/1283 [================>.............] - ETA: 0s - loss: 0.1395 - acc: 0.9557
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1422 - acc: 0.9507
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1391 - acc: 0.9542
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1350 - acc: 0.9573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1355 - acc: 0.9551
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1343 - acc: 0.9559
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1334 - acc: 0.9549
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1316 - acc: 0.9548
1280/1283 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9555
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1302 - acc: 0.9548 - val_loss: 1.0067 - val_acc: 0.5808

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0953 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0672 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0606 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0685 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0642 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0746 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0774 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0835 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.0849 - acc: 0.9774
 640/1283 [=============>................] - ETA: 0s - loss: 0.0849 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0868 - acc: 0.9773
 768/1283 [================>.............] - ETA: 0s - loss: 0.0891 - acc: 0.9753
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0885 - acc: 0.9748
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0894 - acc: 0.9729
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0919 - acc: 0.9707
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0931 - acc: 0.9697
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0938 - acc: 0.9688
1280/1283 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9719
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0888 - acc: 0.9719 - val_loss: 1.1878 - val_acc: 0.5852

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0706 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0585 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0488 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0478 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0514 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0633 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0597 - acc: 0.9805
 576/1283 [============>.................] - ETA: 0s - loss: 0.0614 - acc: 0.9792
 640/1283 [=============>................] - ETA: 0s - loss: 0.0581 - acc: 0.9812
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0579 - acc: 0.9801
 768/1283 [================>.............] - ETA: 0s - loss: 0.0578 - acc: 0.9805
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0600 - acc: 0.9796
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0591 - acc: 0.9799
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0581 - acc: 0.9802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0592 - acc: 0.9785
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0590 - acc: 0.9798
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0585 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0572 - acc: 0.9803
1280/1283 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9805
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0565 - acc: 0.9805 - val_loss: 1.3228 - val_acc: 0.6245

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0614 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0434 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0357 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0381 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0368 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0394 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0380 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0374 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0369 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0349 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0368 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0358 - acc: 0.9948
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0347 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0448 - acc: 0.9922
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0425 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0449 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0456 - acc: 0.9936
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0464 - acc: 0.9913
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0461 - acc: 0.9901
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0488 - acc: 0.9875 - val_loss: 2.3803 - val_acc: 0.5633

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3251 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.4207 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3205 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2510 - acc: 0.8984
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2247 - acc: 0.9094
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2059 - acc: 0.9167
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2100 - acc: 0.9107
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2195 - acc: 0.9062
 576/1283 [============>.................] - ETA: 1s - loss: 0.2001 - acc: 0.9149
 640/1283 [=============>................] - ETA: 1s - loss: 0.1842 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1824 - acc: 0.9247
 768/1283 [================>.............] - ETA: 0s - loss: 0.2051 - acc: 0.9167
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1960 - acc: 0.9207
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1870 - acc: 0.9230
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1800 - acc: 0.9240
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1960 - acc: 0.9209
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1888 - acc: 0.9246
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1820 - acc: 0.9280
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1900 - acc: 0.9276
1280/1283 [============================>.] - ETA: 0s - loss: 0.1871 - acc: 0.9281
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1869 - acc: 0.9283 - val_loss: 1.4682 - val_acc: 0.5721

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0637 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1118 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1134 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1100 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0957 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0895 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0806 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0771 - acc: 0.9824
 640/1283 [=============>................] - ETA: 0s - loss: 0.0734 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0716 - acc: 0.9815
 768/1283 [================>.............] - ETA: 0s - loss: 0.0715 - acc: 0.9805
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0690 - acc: 0.9820
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0675 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0660 - acc: 0.9823
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0667 - acc: 0.9807
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0677 - acc: 0.9786
1280/1283 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9789
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0686 - acc: 0.9790 - val_loss: 1.3365 - val_acc: 0.6026

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0242 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0277 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0491 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0543 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0514 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0453 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0437 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0408 - acc: 0.9941
 576/1283 [============>.................] - ETA: 1s - loss: 0.0419 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0416 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0451 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0435 - acc: 0.9948
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0412 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0408 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0396 - acc: 0.9938
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0385 - acc: 0.9936
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0387 - acc: 0.9922
1280/1283 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9891
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0398 - acc: 0.9891 - val_loss: 1.4558 - val_acc: 0.6070

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0339 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0342 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0290 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0278 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0266 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0263 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0288 - acc: 0.9922
 576/1283 [============>.................] - ETA: 1s - loss: 0.0268 - acc: 0.9931
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0274 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0270 - acc: 0.9922
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0267 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0281 - acc: 0.9900
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0263 - acc: 0.9912
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0281 - acc: 0.9890
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0312 - acc: 0.9887
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0316 - acc: 0.9885
1280/1283 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9891
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0303 - acc: 0.9891 - val_loss: 1.5127 - val_acc: 0.6026

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0348 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0474 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0365 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0301 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0280 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0256 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0257 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0277 - acc: 0.9883
 576/1283 [============>.................] - ETA: 1s - loss: 0.0301 - acc: 0.9861
 640/1283 [=============>................] - ETA: 0s - loss: 0.0315 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0295 - acc: 0.9858
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0276 - acc: 0.9868
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0265 - acc: 0.9877
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0267 - acc: 0.9885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0264 - acc: 0.9883
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0256 - acc: 0.9890
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0256 - acc: 0.9887
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0277 - acc: 0.9885
1280/1283 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9891
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0270 - acc: 0.9891 - val_loss: 1.5989 - val_acc: 0.6157

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=20
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6209912536443148
best_valid_accuracy=0.5947521865889213
