/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:34:16.354095: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 18s - loss: 0.9548 - acc: 0.5625
 128/1283 [=>............................] - ETA: 9s - loss: 0.9622 - acc: 0.5391 
 192/1283 [===>..........................] - ETA: 6s - loss: 0.8644 - acc: 0.5729
 256/1283 [====>.........................] - ETA: 5s - loss: 0.8437 - acc: 0.5625
 320/1283 [======>.......................] - ETA: 4s - loss: 0.8442 - acc: 0.5469
 384/1283 [=======>......................] - ETA: 3s - loss: 0.8406 - acc: 0.5495
 448/1283 [=========>....................] - ETA: 2s - loss: 0.8313 - acc: 0.5536
 512/1283 [==========>...................] - ETA: 2s - loss: 0.8192 - acc: 0.5625
 640/1283 [=============>................] - ETA: 1s - loss: 0.8044 - acc: 0.5656
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7927 - acc: 0.5696
 768/1283 [================>.............] - ETA: 1s - loss: 0.7860 - acc: 0.5690
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7887 - acc: 0.5647
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7884 - acc: 0.5656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7820 - acc: 0.5703
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7788 - acc: 0.5616
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7745 - acc: 0.5625
1280/1283 [============================>.] - ETA: 0s - loss: 0.7681 - acc: 0.5648
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7679 - acc: 0.5651 - val_loss: 0.6970 - val_acc: 0.6026

Epoch 00001: val_acc improved from -inf to 0.60262, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4999 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.4841 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5166 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5087 - acc: 0.7734
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5065 - acc: 0.7793
 640/1283 [=============>................] - ETA: 0s - loss: 0.5001 - acc: 0.7906
 768/1283 [================>.............] - ETA: 0s - loss: 0.4925 - acc: 0.7995
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4905 - acc: 0.8029
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4836 - acc: 0.8052
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4800 - acc: 0.8097
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4771 - acc: 0.8142
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4779 - acc: 0.8109
1280/1283 [============================>.] - ETA: 0s - loss: 0.4730 - acc: 0.8156
1283/1283 [==============================] - 1s 957us/step - loss: 0.4728 - acc: 0.8161 - val_loss: 0.6853 - val_acc: 0.6157

Epoch 00002: val_acc improved from 0.60262 to 0.61572, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3216 - acc: 0.8594
 128/1283 [=>............................] - ETA: 0s - loss: 0.3552 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3425 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3438 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3484 - acc: 0.8375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3554 - acc: 0.8385
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3421 - acc: 0.8549
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3409 - acc: 0.8555
 640/1283 [=============>................] - ETA: 0s - loss: 0.3477 - acc: 0.8516
 768/1283 [================>.............] - ETA: 0s - loss: 0.3472 - acc: 0.8503
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3557 - acc: 0.8438
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3519 - acc: 0.8493
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3513 - acc: 0.8510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3497 - acc: 0.8535
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3527 - acc: 0.8498
1280/1283 [============================>.] - ETA: 0s - loss: 0.3477 - acc: 0.8523
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3478 - acc: 0.8519 - val_loss: 0.6951 - val_acc: 0.6943

Epoch 00003: val_acc improved from 0.61572 to 0.69432, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2456 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2470 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2419 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2403 - acc: 0.9281
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2335 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2336 - acc: 0.9330
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2353 - acc: 0.9336
 576/1283 [============>.................] - ETA: 0s - loss: 0.2389 - acc: 0.9323
 640/1283 [=============>................] - ETA: 0s - loss: 0.2436 - acc: 0.9250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2510 - acc: 0.9205
 768/1283 [================>.............] - ETA: 0s - loss: 0.2519 - acc: 0.9180
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2509 - acc: 0.9183
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2482 - acc: 0.9196
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2507 - acc: 0.9150
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2476 - acc: 0.9173
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2454 - acc: 0.9161
1280/1283 [============================>.] - ETA: 0s - loss: 0.2413 - acc: 0.9195
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2426 - acc: 0.9182 - val_loss: 0.6969 - val_acc: 0.6943

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1529 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1721 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2064 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2068 - acc: 0.9250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2119 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2096 - acc: 0.9241
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2130 - acc: 0.9219
 576/1283 [============>.................] - ETA: 0s - loss: 0.2074 - acc: 0.9288
 640/1283 [=============>................] - ETA: 0s - loss: 0.2045 - acc: 0.9328
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2005 - acc: 0.9361
 768/1283 [================>.............] - ETA: 0s - loss: 0.2038 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2024 - acc: 0.9315
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2017 - acc: 0.9330
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1995 - acc: 0.9333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1987 - acc: 0.9346
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1951 - acc: 0.9375
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1951 - acc: 0.9384
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1944 - acc: 0.9383
1280/1283 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9406
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1916 - acc: 0.9408 - val_loss: 0.7191 - val_acc: 0.6812

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0972 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1068 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1169 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1254 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1297 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1267 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1224 - acc: 0.9668
 576/1283 [============>.................] - ETA: 0s - loss: 0.1263 - acc: 0.9618
 640/1283 [=============>................] - ETA: 0s - loss: 0.1246 - acc: 0.9625
 768/1283 [================>.............] - ETA: 0s - loss: 0.1304 - acc: 0.9596
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1289 - acc: 0.9615
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1310 - acc: 0.9609
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1301 - acc: 0.9629
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1305 - acc: 0.9632
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1287 - acc: 0.9635
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1288 - acc: 0.9638
1280/1283 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9641
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1279 - acc: 0.9641 - val_loss: 0.7703 - val_acc: 0.6900

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1150 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1041 - acc: 0.9609
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1025 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0923 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0892 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0857 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.0856 - acc: 0.9792
 640/1283 [=============>................] - ETA: 0s - loss: 0.0839 - acc: 0.9812
 768/1283 [================>.............] - ETA: 0s - loss: 0.0870 - acc: 0.9805
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0840 - acc: 0.9820
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0864 - acc: 0.9812
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0870 - acc: 0.9795
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0868 - acc: 0.9807
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0868 - acc: 0.9800
1280/1283 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9797
1283/1283 [==============================] - 1s 979us/step - loss: 0.0873 - acc: 0.9797 - val_loss: 0.8329 - val_acc: 0.6681

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0833 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0879 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0837 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0771 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0716 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0625 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0656 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0624 - acc: 0.9859
 768/1283 [================>.............] - ETA: 0s - loss: 0.0595 - acc: 0.9870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0609 - acc: 0.9868
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0618 - acc: 0.9866
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0619 - acc: 0.9875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0618 - acc: 0.9873
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0617 - acc: 0.9871
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0632 - acc: 0.9860
1280/1283 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9859
1283/1283 [==============================] - 1s 989us/step - loss: 0.0646 - acc: 0.9860 - val_loss: 0.8889 - val_acc: 0.6725

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0439 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0540 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0526 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0507 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0479 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0464 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0527 - acc: 0.9906
 768/1283 [================>.............] - ETA: 0s - loss: 0.0515 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0509 - acc: 0.9916
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0495 - acc: 0.9917
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0483 - acc: 0.9917
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0488 - acc: 0.9910
1280/1283 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9914
1283/1283 [==============================] - 1s 889us/step - loss: 0.0482 - acc: 0.9914 - val_loss: 1.0125 - val_acc: 0.6550

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0232 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0239 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0340 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0376 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0353 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0380 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0381 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0375 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0382 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0366 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0354 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0350 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0380 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0376 - acc: 0.9951
1280/1283 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9945
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0373 - acc: 0.9945 - val_loss: 1.0333 - val_acc: 0.6812

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0324 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0343 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0392 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0366 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0334 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0278 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0276 - acc: 0.9941
 576/1283 [============>.................] - ETA: 1s - loss: 0.0300 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0285 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0281 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0285 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0312 - acc: 0.9922
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0298 - acc: 0.9922
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0297 - acc: 0.9926
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0293 - acc: 0.9931
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0295 - acc: 0.9926
1280/1283 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9922
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0295 - acc: 0.9922 - val_loss: 1.0863 - val_acc: 0.6681

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0214 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0159 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0130 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0219 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0243 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0225 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0218 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0234 - acc: 0.9883
 576/1283 [============>.................] - ETA: 0s - loss: 0.0226 - acc: 0.9896
 640/1283 [=============>................] - ETA: 0s - loss: 0.0218 - acc: 0.9906
 768/1283 [================>.............] - ETA: 0s - loss: 0.0203 - acc: 0.9922
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0196 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0199 - acc: 0.9933
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0204 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0212 - acc: 0.9926
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0219 - acc: 0.9931
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0220 - acc: 0.9934
1280/1283 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9938
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0215 - acc: 0.9938 - val_loss: 1.1263 - val_acc: 0.6725

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0185 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0124 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0151 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0142 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0184 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0174 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0162 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0153 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0175 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0162 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0159 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0163 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0168 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0181 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0174 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0171 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0177 - acc: 0.9945
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0179 - acc: 0.9948
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0179 - acc: 0.9951
1280/1283 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9945
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0184 - acc: 0.9945 - val_loss: 1.1558 - val_acc: 0.6638

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=25
nodes=100
mode=AT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6253644314868805
best_valid_accuracy=0.5830903790087464
