/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:47:33.293205: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 1.0265 - acc: 0.4219
 192/1283 [===>..........................] - ETA: 2s - loss: 0.9552 - acc: 0.4740
 320/1283 [======>.......................] - ETA: 1s - loss: 0.9138 - acc: 0.4781
 448/1283 [=========>....................] - ETA: 1s - loss: 0.8600 - acc: 0.4777
 576/1283 [============>.................] - ETA: 0s - loss: 0.8338 - acc: 0.5052
 640/1283 [=============>................] - ETA: 0s - loss: 0.8204 - acc: 0.5156
 768/1283 [================>.............] - ETA: 0s - loss: 0.8071 - acc: 0.5208
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7924 - acc: 0.5223
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7782 - acc: 0.5244
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7743 - acc: 0.5303
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7701 - acc: 0.5304
1283/1283 [==============================] - 1s 988us/step - loss: 0.7687 - acc: 0.5261 - val_loss: 0.7002 - val_acc: 0.5022

Epoch 00001: val_acc improved from -inf to 0.50218, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6712 - acc: 0.5000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6470 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6284 - acc: 0.6937
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6347 - acc: 0.6362
 576/1283 [============>.................] - ETA: 0s - loss: 0.6426 - acc: 0.6111
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6401 - acc: 0.6094
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6318 - acc: 0.6274
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6291 - acc: 0.6406
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6247 - acc: 0.6507
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6219 - acc: 0.6612
1283/1283 [==============================] - 1s 544us/step - loss: 0.6189 - acc: 0.6680 - val_loss: 0.6833 - val_acc: 0.5633

Epoch 00002: val_acc improved from 0.50218 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5110 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5141 - acc: 0.8177
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5285 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5118 - acc: 0.8170
 576/1283 [============>.................] - ETA: 0s - loss: 0.5024 - acc: 0.8142
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4941 - acc: 0.8168
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4845 - acc: 0.8257
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4797 - acc: 0.8271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4785 - acc: 0.8189
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4763 - acc: 0.8158
1283/1283 [==============================] - 1s 599us/step - loss: 0.4720 - acc: 0.8168 - val_loss: 0.6941 - val_acc: 0.6201

Epoch 00003: val_acc improved from 0.56332 to 0.62009, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3467 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3366 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3200 - acc: 0.9000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3233 - acc: 0.8951
 576/1283 [============>.................] - ETA: 0s - loss: 0.3197 - acc: 0.8941
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3123 - acc: 0.8935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3054 - acc: 0.8978
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3035 - acc: 0.8958
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3052 - acc: 0.8872
1280/1283 [============================>.] - ETA: 0s - loss: 0.3032 - acc: 0.8891
1283/1283 [==============================] - 1s 525us/step - loss: 0.3032 - acc: 0.8893 - val_loss: 0.7796 - val_acc: 0.6245

Epoch 00004: val_acc improved from 0.62009 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1653 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2141 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1992 - acc: 0.9250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2021 - acc: 0.9219
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1981 - acc: 0.9277
 640/1283 [=============>................] - ETA: 0s - loss: 0.1993 - acc: 0.9234
 768/1283 [================>.............] - ETA: 0s - loss: 0.2009 - acc: 0.9167
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1992 - acc: 0.9196
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1958 - acc: 0.9199
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1992 - acc: 0.9201
1280/1283 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9187
1283/1283 [==============================] - 1s 670us/step - loss: 0.2045 - acc: 0.9182 - val_loss: 0.8533 - val_acc: 0.6550

Epoch 00005: val_acc improved from 0.62445 to 0.65502, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1890 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1589 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1436 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1293 - acc: 0.9554
 576/1283 [============>.................] - ETA: 0s - loss: 0.1386 - acc: 0.9497
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1321 - acc: 0.9517
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1309 - acc: 0.9507
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1307 - acc: 0.9510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1289 - acc: 0.9531
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1263 - acc: 0.9556
1283/1283 [==============================] - 1s 522us/step - loss: 0.1303 - acc: 0.9532 - val_loss: 0.9472 - val_acc: 0.6114

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0833 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1134 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1357 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1261 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.1384 - acc: 0.9601
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1376 - acc: 0.9602
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1305 - acc: 0.9603
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1285 - acc: 0.9604
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1249 - acc: 0.9614
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1200 - acc: 0.9630
1283/1283 [==============================] - 1s 530us/step - loss: 0.1208 - acc: 0.9626 - val_loss: 1.0728 - val_acc: 0.6288

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0481 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0524 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0639 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0691 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.0727 - acc: 0.9740
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0728 - acc: 0.9744
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0716 - acc: 0.9748
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0706 - acc: 0.9760
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0683 - acc: 0.9779
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0664 - acc: 0.9794
1283/1283 [==============================] - 1s 534us/step - loss: 0.0651 - acc: 0.9797 - val_loss: 1.0976 - val_acc: 0.5983

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0339 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0370 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0392 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0357 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0399 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0402 - acc: 0.9915
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0381 - acc: 0.9916
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0404 - acc: 0.9896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0396 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0391 - acc: 0.9901
1283/1283 [==============================] - 1s 552us/step - loss: 0.0393 - acc: 0.9899 - val_loss: 1.2223 - val_acc: 0.6201

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0138 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0266 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0309 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0304 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0334 - acc: 0.9931
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0360 - acc: 0.9901
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0353 - acc: 0.9904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0346 - acc: 0.9896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0324 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0315 - acc: 0.9901
1283/1283 [==============================] - 1s 549us/step - loss: 0.0319 - acc: 0.9891 - val_loss: 1.3465 - val_acc: 0.6201

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0105 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0188 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0187 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0190 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0194 - acc: 0.9961
 640/1283 [=============>................] - ETA: 0s - loss: 0.0211 - acc: 0.9953
 768/1283 [================>.............] - ETA: 0s - loss: 0.0228 - acc: 0.9948
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0211 - acc: 0.9955
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0223 - acc: 0.9932
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0223 - acc: 0.9931
1280/1283 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9930
1283/1283 [==============================] - 1s 643us/step - loss: 0.0221 - acc: 0.9930 - val_loss: 1.4503 - val_acc: 0.6288

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0228 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0117 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0147 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0169 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0167 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0159 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0153 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0179 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0165 - acc: 0.9963
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0176 - acc: 0.9959
1283/1283 [==============================] - 1s 584us/step - loss: 0.0188 - acc: 0.9953 - val_loss: 1.4970 - val_acc: 0.6288

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0075 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0093 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0153 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0158 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0145 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0144 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0156 - acc: 0.9964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0169 - acc: 0.9948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0164 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0158 - acc: 0.9959
1283/1283 [==============================] - 1s 647us/step - loss: 0.0164 - acc: 0.9953 - val_loss: 1.5625 - val_acc: 0.6332

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0105 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0107 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0086 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0078 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0105 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0122 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0135 - acc: 0.9940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0133 - acc: 0.9938
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0129 - acc: 0.9945
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0123 - acc: 0.9951
1280/1283 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9953
1283/1283 [==============================] - 1s 589us/step - loss: 0.0118 - acc: 0.9953 - val_loss: 1.5945 - val_acc: 0.6114

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0064 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0059 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0059 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0066 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0074 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0099 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0109 - acc: 0.9963
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0104 - acc: 0.9967
1283/1283 [==============================] - 1s 626us/step - loss: 0.0107 - acc: 0.9961 - val_loss: 1.6934 - val_acc: 0.6419

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=15
nodes=100
mode=VT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6632653061224489
best_valid_accuracy=0.6180758017492711
