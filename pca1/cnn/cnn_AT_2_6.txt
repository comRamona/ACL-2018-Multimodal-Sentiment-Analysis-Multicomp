/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:34:28.808367: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 26s - loss: 0.8082 - acc: 0.5469
 128/1283 [=>............................] - ETA: 13s - loss: 0.8277 - acc: 0.4844
 192/1283 [===>..........................] - ETA: 8s - loss: 0.7733 - acc: 0.5260 
 320/1283 [======>.......................] - ETA: 5s - loss: 0.7502 - acc: 0.5156
 384/1283 [=======>......................] - ETA: 4s - loss: 0.7464 - acc: 0.5156
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7359 - acc: 0.5176
 576/1283 [============>.................] - ETA: 2s - loss: 0.7406 - acc: 0.5104
 640/1283 [=============>................] - ETA: 2s - loss: 0.7469 - acc: 0.5031
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7401 - acc: 0.5142
 768/1283 [================>.............] - ETA: 1s - loss: 0.7375 - acc: 0.5182
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7324 - acc: 0.5252
 896/1283 [===================>..........] - ETA: 1s - loss: 0.7329 - acc: 0.5246
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7277 - acc: 0.5344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7253 - acc: 0.5400
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7228 - acc: 0.5414
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7192 - acc: 0.5469
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7165 - acc: 0.5526
1280/1283 [============================>.] - ETA: 0s - loss: 0.7166 - acc: 0.5469
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7166 - acc: 0.5472 - val_loss: 0.6873 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6087 - acc: 0.6562
 128/1283 [=>............................] - ETA: 0s - loss: 0.5822 - acc: 0.7266
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5783 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5757 - acc: 0.7734
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5803 - acc: 0.7594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5816 - acc: 0.7552
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5762 - acc: 0.7567
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5765 - acc: 0.7617
 576/1283 [============>.................] - ETA: 0s - loss: 0.5735 - acc: 0.7622
 640/1283 [=============>................] - ETA: 0s - loss: 0.5765 - acc: 0.7484
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5715 - acc: 0.7642
 768/1283 [================>.............] - ETA: 0s - loss: 0.5718 - acc: 0.7643
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5658 - acc: 0.7679
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5643 - acc: 0.7698
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5616 - acc: 0.7734
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5609 - acc: 0.7702
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5589 - acc: 0.7708
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5611 - acc: 0.7623
1280/1283 [============================>.] - ETA: 0s - loss: 0.5586 - acc: 0.7641
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5587 - acc: 0.7638 - val_loss: 0.7099 - val_acc: 0.5983

Epoch 00002: val_acc improved from 0.54148 to 0.59825, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4467 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.4773 - acc: 0.7422
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4732 - acc: 0.7708
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4644 - acc: 0.7891
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4462 - acc: 0.8219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4450 - acc: 0.8203
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4466 - acc: 0.8192
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4407 - acc: 0.8223
 576/1283 [============>.................] - ETA: 0s - loss: 0.4379 - acc: 0.8247
 640/1283 [=============>................] - ETA: 0s - loss: 0.4306 - acc: 0.8281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4219 - acc: 0.8395
 768/1283 [================>.............] - ETA: 0s - loss: 0.4201 - acc: 0.8359
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4214 - acc: 0.8337
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4180 - acc: 0.8344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4172 - acc: 0.8320
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4154 - acc: 0.8299
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4132 - acc: 0.8306
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4134 - acc: 0.8293 - val_loss: 0.6918 - val_acc: 0.6070

Epoch 00003: val_acc improved from 0.59825 to 0.60699, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3155 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2894 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2787 - acc: 0.9102
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2735 - acc: 0.9156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2731 - acc: 0.9152
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2781 - acc: 0.9043
 640/1283 [=============>................] - ETA: 0s - loss: 0.2853 - acc: 0.8906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2846 - acc: 0.8906
 768/1283 [================>.............] - ETA: 0s - loss: 0.2818 - acc: 0.8971
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2783 - acc: 0.8990
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2779 - acc: 0.8996
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2803 - acc: 0.8990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2814 - acc: 0.8955
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2795 - acc: 0.8934
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2761 - acc: 0.8958
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2755 - acc: 0.8956
1280/1283 [============================>.] - ETA: 0s - loss: 0.2728 - acc: 0.8969
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2729 - acc: 0.8963 - val_loss: 0.7824 - val_acc: 0.6201

Epoch 00004: val_acc improved from 0.60699 to 0.62009, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1527 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1729 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1870 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1905 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1894 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1867 - acc: 0.9531
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1826 - acc: 0.9570
 576/1283 [============>.................] - ETA: 0s - loss: 0.1771 - acc: 0.9583
 640/1283 [=============>................] - ETA: 0s - loss: 0.1797 - acc: 0.9516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1848 - acc: 0.9474
 768/1283 [================>.............] - ETA: 0s - loss: 0.1877 - acc: 0.9440
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1909 - acc: 0.9375
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1860 - acc: 0.9408
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1821 - acc: 0.9406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1804 - acc: 0.9424
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1796 - acc: 0.9430
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1792 - acc: 0.9418
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1778 - acc: 0.9416
1280/1283 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9430
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1746 - acc: 0.9431 - val_loss: 0.8762 - val_acc: 0.5895

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1159 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0942 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0981 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0914 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1024 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1051 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1053 - acc: 0.9766
 576/1283 [============>.................] - ETA: 0s - loss: 0.1076 - acc: 0.9757
 640/1283 [=============>................] - ETA: 0s - loss: 0.1073 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1087 - acc: 0.9744
 768/1283 [================>.............] - ETA: 0s - loss: 0.1093 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1090 - acc: 0.9724
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1123 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1118 - acc: 0.9698
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1110 - acc: 0.9697
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1123 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1138 - acc: 0.9653
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1124 - acc: 0.9655
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1094 - acc: 0.9673 - val_loss: 1.0449 - val_acc: 0.6026

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0858 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0732 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0683 - acc: 0.9883
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0825 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0826 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0800 - acc: 0.9785
 576/1283 [============>.................] - ETA: 0s - loss: 0.0820 - acc: 0.9774
 640/1283 [=============>................] - ETA: 0s - loss: 0.0783 - acc: 0.9797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0767 - acc: 0.9801
 768/1283 [================>.............] - ETA: 0s - loss: 0.0762 - acc: 0.9792
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0780 - acc: 0.9784
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0769 - acc: 0.9771
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0764 - acc: 0.9770
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0745 - acc: 0.9770
1283/1283 [==============================] - 1s 991us/step - loss: 0.0743 - acc: 0.9774 - val_loss: 1.2577 - val_acc: 0.6026

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1028 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0545 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0658 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0690 - acc: 0.9766
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0716 - acc: 0.9766
 576/1283 [============>.................] - ETA: 0s - loss: 0.0711 - acc: 0.9757
 640/1283 [=============>................] - ETA: 0s - loss: 0.0683 - acc: 0.9781
 768/1283 [================>.............] - ETA: 0s - loss: 0.0663 - acc: 0.9779
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0634 - acc: 0.9796
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0784 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0758 - acc: 0.9802
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0760 - acc: 0.9807
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0759 - acc: 0.9803
1280/1283 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9797
1283/1283 [==============================] - 1s 828us/step - loss: 0.0771 - acc: 0.9797 - val_loss: 1.2157 - val_acc: 0.6507

Epoch 00008: val_acc improved from 0.62009 to 0.65066, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0373 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0571 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0591 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0568 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0557 - acc: 0.9785
 640/1283 [=============>................] - ETA: 0s - loss: 0.0526 - acc: 0.9781
 768/1283 [================>.............] - ETA: 0s - loss: 0.0500 - acc: 0.9805
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0506 - acc: 0.9808
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0495 - acc: 0.9823
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0482 - acc: 0.9825
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0574 - acc: 0.9836
1283/1283 [==============================] - 1s 777us/step - loss: 0.0581 - acc: 0.9829 - val_loss: 1.2528 - val_acc: 0.6070

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0542 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1605 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1118 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0974 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0905 - acc: 0.9805
 640/1283 [=============>................] - ETA: 0s - loss: 0.0790 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0750 - acc: 0.9830
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0707 - acc: 0.9832
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0679 - acc: 0.9823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0670 - acc: 0.9814
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0636 - acc: 0.9818
1280/1283 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9812
1283/1283 [==============================] - 1s 829us/step - loss: 0.0621 - acc: 0.9813 - val_loss: 1.5298 - val_acc: 0.5852

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0216 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0772 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0670 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0580 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0552 - acc: 0.9866
 576/1283 [============>.................] - ETA: 0s - loss: 0.0500 - acc: 0.9861
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0511 - acc: 0.9858
 768/1283 [================>.............] - ETA: 0s - loss: 0.0490 - acc: 0.9857
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0463 - acc: 0.9868
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0429 - acc: 0.9885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0409 - acc: 0.9893
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0412 - acc: 0.9870
1280/1283 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9867
1283/1283 [==============================] - 1s 848us/step - loss: 0.0414 - acc: 0.9867 - val_loss: 1.3914 - val_acc: 0.6638

Epoch 00011: val_acc improved from 0.65066 to 0.66376, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0264 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0256 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0268 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0238 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0260 - acc: 0.9902
 640/1283 [=============>................] - ETA: 0s - loss: 0.0251 - acc: 0.9891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0247 - acc: 0.9886
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0244 - acc: 0.9892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0263 - acc: 0.9865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0272 - acc: 0.9862
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0353 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9852
1283/1283 [==============================] - 1s 900us/step - loss: 0.0332 - acc: 0.9852 - val_loss: 1.5296 - val_acc: 0.6376

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0347 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0591 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0411 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0341 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0359 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0337 - acc: 0.9886
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0309 - acc: 0.9904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0297 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0279 - acc: 0.9917
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0300 - acc: 0.9901
1283/1283 [==============================] - 1s 649us/step - loss: 0.0293 - acc: 0.9899 - val_loss: 1.5882 - val_acc: 0.6288

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0185 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0270 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0237 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0201 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0196 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0216 - acc: 0.9891
 768/1283 [================>.............] - ETA: 0s - loss: 0.0231 - acc: 0.9909
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0262 - acc: 0.9911
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0260 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0249 - acc: 0.9899
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0258 - acc: 0.9893
1283/1283 [==============================] - 1s 671us/step - loss: 0.0254 - acc: 0.9891 - val_loss: 1.6374 - val_acc: 0.6463

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0028 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0182 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0133 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0167 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0150 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0166 - acc: 0.9906
 768/1283 [================>.............] - ETA: 0s - loss: 0.0154 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0152 - acc: 0.9916
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0161 - acc: 0.9917
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0181 - acc: 0.9917
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0206 - acc: 0.9901
1283/1283 [==============================] - 1s 701us/step - loss: 0.0207 - acc: 0.9899 - val_loss: 1.7106 - val_acc: 0.6419

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0024 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0083 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0177 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0187 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0194 - acc: 0.9902
 640/1283 [=============>................] - ETA: 0s - loss: 0.0171 - acc: 0.9922
 768/1283 [================>.............] - ETA: 0s - loss: 0.0187 - acc: 0.9896
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0189 - acc: 0.9888
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0184 - acc: 0.9893
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0184 - acc: 0.9905
1280/1283 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9914
1283/1283 [==============================] - 1s 762us/step - loss: 0.0190 - acc: 0.9906 - val_loss: 1.8157 - val_acc: 0.6201

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0145 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0080 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0100 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0185 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0206 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0199 - acc: 0.9883
 640/1283 [=============>................] - ETA: 0s - loss: 0.0181 - acc: 0.9906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0169 - acc: 0.9915
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0181 - acc: 0.9904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0170 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0158 - acc: 0.9917
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0168 - acc: 0.9910
1283/1283 [==============================] - 1s 860us/step - loss: 0.0181 - acc: 0.9899 - val_loss: 1.9711 - val_acc: 0.6376

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0173 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0146 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0185 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0205 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0199 - acc: 0.9883
 640/1283 [=============>................] - ETA: 0s - loss: 0.0196 - acc: 0.9906
 768/1283 [================>.............] - ETA: 0s - loss: 0.0212 - acc: 0.9870
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0191 - acc: 0.9888
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0175 - acc: 0.9902
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0162 - acc: 0.9913
1280/1283 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9914
1283/1283 [==============================] - 1s 725us/step - loss: 0.0171 - acc: 0.9914 - val_loss: 1.8595 - val_acc: 0.6201

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0200 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0236 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0150 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0154 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0164 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0158 - acc: 0.9943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0155 - acc: 0.9940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0189 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0182 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0172 - acc: 0.9918
1283/1283 [==============================] - 1s 630us/step - loss: 0.0175 - acc: 0.9914 - val_loss: 1.9411 - val_acc: 0.6245

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0084 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0145 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0109 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0124 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0134 - acc: 0.9915
 768/1283 [================>.............] - ETA: 0s - loss: 0.0164 - acc: 0.9883
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0168 - acc: 0.9888
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0165 - acc: 0.9893
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0168 - acc: 0.9887
1280/1283 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9898
1283/1283 [==============================] - 1s 680us/step - loss: 0.0162 - acc: 0.9899 - val_loss: 2.1200 - val_acc: 0.6201

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0163 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0076 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0092 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0139 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0214 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0212 - acc: 0.9886
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0191 - acc: 0.9892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0172 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0166 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0162 - acc: 0.9910
1283/1283 [==============================] - 1s 635us/step - loss: 0.0160 - acc: 0.9914 - val_loss: 2.0357 - val_acc: 0.6245

Epoch 00021: val_acc did not improve
Epoch 00021: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=20
nodes=100
mode=AT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6180758017492711
best_valid_accuracy=0.60932944606414
