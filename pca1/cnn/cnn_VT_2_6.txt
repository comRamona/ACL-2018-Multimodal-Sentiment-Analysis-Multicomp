/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:47:49.928169: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.8334 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7587 - acc: 0.4948
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7432 - acc: 0.5125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7318 - acc: 0.5246
 576/1283 [============>.................] - ETA: 0s - loss: 0.7272 - acc: 0.5243
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7167 - acc: 0.5469
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7113 - acc: 0.5493
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7115 - acc: 0.5500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7079 - acc: 0.5515
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7041 - acc: 0.5559
1283/1283 [==============================] - 1s 704us/step - loss: 0.7053 - acc: 0.5503 - val_loss: 0.6878 - val_acc: 0.5546

Epoch 00001: val_acc improved from -inf to 0.55459, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5870 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5689 - acc: 0.7292
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5600 - acc: 0.7562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5546 - acc: 0.7567
 576/1283 [============>.................] - ETA: 0s - loss: 0.5501 - acc: 0.7622
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5510 - acc: 0.7599
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5473 - acc: 0.7704
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5392 - acc: 0.7764
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5312 - acc: 0.7795
1280/1283 [============================>.] - ETA: 0s - loss: 0.5319 - acc: 0.7727
1283/1283 [==============================] - 1s 471us/step - loss: 0.5323 - acc: 0.7724 - val_loss: 0.7216 - val_acc: 0.5895

Epoch 00002: val_acc improved from 0.55459 to 0.58952, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3825 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4389 - acc: 0.7852
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4161 - acc: 0.8170
 640/1283 [=============>................] - ETA: 0s - loss: 0.4068 - acc: 0.8250
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3943 - acc: 0.8425
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3932 - acc: 0.8418
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3855 - acc: 0.8470
1283/1283 [==============================] - 0s 343us/step - loss: 0.3866 - acc: 0.8441 - val_loss: 0.7359 - val_acc: 0.6245

Epoch 00003: val_acc improved from 0.58952 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2889 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2561 - acc: 0.9141
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2466 - acc: 0.9196
 640/1283 [=============>................] - ETA: 0s - loss: 0.2568 - acc: 0.9047
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2519 - acc: 0.9014
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2473 - acc: 0.9033
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2429 - acc: 0.9030
1283/1283 [==============================] - 0s 300us/step - loss: 0.2428 - acc: 0.9034 - val_loss: 0.8759 - val_acc: 0.6332

Epoch 00004: val_acc improved from 0.62445 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1104 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1568 - acc: 0.9297
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1559 - acc: 0.9397
 640/1283 [=============>................] - ETA: 0s - loss: 0.1516 - acc: 0.9469
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1615 - acc: 0.9363
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1561 - acc: 0.9384
1283/1283 [==============================] - 0s 297us/step - loss: 0.1528 - acc: 0.9400 - val_loss: 1.0116 - val_acc: 0.5895

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1140 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0826 - acc: 0.9727
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0914 - acc: 0.9710
 640/1283 [=============>................] - ETA: 0s - loss: 0.0970 - acc: 0.9703
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0999 - acc: 0.9675
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1044 - acc: 0.9648
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1073 - acc: 0.9613
1283/1283 [==============================] - 0s 308us/step - loss: 0.1045 - acc: 0.9634 - val_loss: 1.1889 - val_acc: 0.5895

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0733 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0623 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0870 - acc: 0.9710
 640/1283 [=============>................] - ETA: 0s - loss: 0.0826 - acc: 0.9750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0824 - acc: 0.9724
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0806 - acc: 0.9707
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0768 - acc: 0.9745
1283/1283 [==============================] - 0s 321us/step - loss: 0.0764 - acc: 0.9735 - val_loss: 1.3777 - val_acc: 0.5983

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1318 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0680 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0598 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0571 - acc: 0.9875
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0541 - acc: 0.9856
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0655 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0648 - acc: 0.9819
1283/1283 [==============================] - 0s 306us/step - loss: 0.0665 - acc: 0.9813 - val_loss: 1.3954 - val_acc: 0.5633

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0514 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0552 - acc: 0.9805
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0609 - acc: 0.9777
 640/1283 [=============>................] - ETA: 0s - loss: 0.0563 - acc: 0.9781
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0531 - acc: 0.9820
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0504 - acc: 0.9805
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0563 - acc: 0.9827
1283/1283 [==============================] - 0s 308us/step - loss: 0.0570 - acc: 0.9821 - val_loss: 1.4753 - val_acc: 0.5633

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0827 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1006 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0695 - acc: 0.9799
 640/1283 [=============>................] - ETA: 0s - loss: 0.0555 - acc: 0.9828
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0523 - acc: 0.9820
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0500 - acc: 0.9814
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0497 - acc: 0.9794
1283/1283 [==============================] - 0s 311us/step - loss: 0.0487 - acc: 0.9805 - val_loss: 1.8189 - val_acc: 0.5939

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0239 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1555 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1422 - acc: 0.9464
 640/1283 [=============>................] - ETA: 0s - loss: 0.1556 - acc: 0.9437
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1462 - acc: 0.9483
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1426 - acc: 0.9492
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1503 - acc: 0.9465
1283/1283 [==============================] - 0s 305us/step - loss: 0.1515 - acc: 0.9447 - val_loss: 1.3581 - val_acc: 0.6288

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0449 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1305 - acc: 0.9492
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1053 - acc: 0.9643
 640/1283 [=============>................] - ETA: 0s - loss: 0.1052 - acc: 0.9594
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1056 - acc: 0.9639
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0978 - acc: 0.9648
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1130 - acc: 0.9572
1283/1283 [==============================] - 0s 311us/step - loss: 0.1081 - acc: 0.9595 - val_loss: 1.5998 - val_acc: 0.6288

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0577 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1034 - acc: 0.9648
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0741 - acc: 0.9754
 640/1283 [=============>................] - ETA: 0s - loss: 0.0785 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0687 - acc: 0.9736
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0655 - acc: 0.9756
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0635 - acc: 0.9762
1283/1283 [==============================] - 0s 309us/step - loss: 0.0626 - acc: 0.9758 - val_loss: 1.4438 - val_acc: 0.6332

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0351 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0303 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0282 - acc: 0.9888
 640/1283 [=============>................] - ETA: 0s - loss: 0.0307 - acc: 0.9859
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0347 - acc: 0.9820
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0374 - acc: 0.9795
1280/1283 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9812
1283/1283 [==============================] - 0s 309us/step - loss: 0.0390 - acc: 0.9813 - val_loss: 1.5829 - val_acc: 0.6288

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=20
nodes=100
mode=VT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.565597667638484
best_valid_accuracy=0.5612244897959183
