/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 07:59:05.720312: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.8852 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 3s - loss: 0.8027 - acc: 0.5365 
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7838 - acc: 0.5273
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7690 - acc: 0.5062
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7549 - acc: 0.5182
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7467 - acc: 0.5134
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7360 - acc: 0.5332
 640/1283 [=============>................] - ETA: 1s - loss: 0.7355 - acc: 0.5156
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7299 - acc: 0.5284
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7240 - acc: 0.5385
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7224 - acc: 0.5402
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7176 - acc: 0.5500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7143 - acc: 0.5450
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7098 - acc: 0.5503
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7082 - acc: 0.5502
1280/1283 [============================>.] - ETA: 0s - loss: 0.7083 - acc: 0.5453
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7079 - acc: 0.5456 - val_loss: 0.7007 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5806 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5750 - acc: 0.7708
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5642 - acc: 0.8008
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5657 - acc: 0.7969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5630 - acc: 0.7917
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5551 - acc: 0.7988
 576/1283 [============>.................] - ETA: 0s - loss: 0.5526 - acc: 0.8021
 640/1283 [=============>................] - ETA: 0s - loss: 0.5520 - acc: 0.7906
 768/1283 [================>.............] - ETA: 0s - loss: 0.5476 - acc: 0.7969
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5446 - acc: 0.7969
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5431 - acc: 0.7958
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5448 - acc: 0.7885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5392 - acc: 0.7920
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5365 - acc: 0.7895
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5366 - acc: 0.7878
1283/1283 [==============================] - 1s 948us/step - loss: 0.5360 - acc: 0.7833 - val_loss: 0.7075 - val_acc: 0.6114

Epoch 00002: val_acc improved from 0.54148 to 0.61135, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3731 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4092 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3969 - acc: 0.8656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3944 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3882 - acc: 0.8652
 640/1283 [=============>................] - ETA: 0s - loss: 0.3918 - acc: 0.8625
 768/1283 [================>.............] - ETA: 0s - loss: 0.3774 - acc: 0.8750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3782 - acc: 0.8714
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3813 - acc: 0.8661
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3796 - acc: 0.8646
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3762 - acc: 0.8682
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3713 - acc: 0.8698
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3678 - acc: 0.8717
1280/1283 [============================>.] - ETA: 0s - loss: 0.3689 - acc: 0.8672
1283/1283 [==============================] - 1s 869us/step - loss: 0.3686 - acc: 0.8675 - val_loss: 0.7236 - val_acc: 0.6376

Epoch 00003: val_acc improved from 0.61135 to 0.63755, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2730 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2419 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2276 - acc: 0.9406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2253 - acc: 0.9397
 576/1283 [============>.................] - ETA: 0s - loss: 0.2375 - acc: 0.9253
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2378 - acc: 0.9176
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2345 - acc: 0.9159
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2311 - acc: 0.9185
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2310 - acc: 0.9170
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2296 - acc: 0.9154
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2261 - acc: 0.9145
1283/1283 [==============================] - 1s 825us/step - loss: 0.2229 - acc: 0.9143 - val_loss: 0.8669 - val_acc: 0.5939

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0970 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1259 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1399 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1337 - acc: 0.9643
 576/1283 [============>.................] - ETA: 0s - loss: 0.1264 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.1315 - acc: 0.9672
 768/1283 [================>.............] - ETA: 0s - loss: 0.1385 - acc: 0.9557
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1384 - acc: 0.9531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1351 - acc: 0.9541
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1326 - acc: 0.9549
1280/1283 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9570
1283/1283 [==============================] - 1s 703us/step - loss: 0.1293 - acc: 0.9564 - val_loss: 1.0329 - val_acc: 0.5939

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0962 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.0682 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0607 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0634 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0758 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0842 - acc: 0.9774
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0862 - acc: 0.9759
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0885 - acc: 0.9736
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0891 - acc: 0.9719
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0934 - acc: 0.9669
1280/1283 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9688
1283/1283 [==============================] - 1s 610us/step - loss: 0.0891 - acc: 0.9688 - val_loss: 1.1936 - val_acc: 0.5808

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0706 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0483 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0523 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0647 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.0624 - acc: 0.9809
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0586 - acc: 0.9815
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0601 - acc: 0.9808
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0582 - acc: 0.9812
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0589 - acc: 0.9807
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0574 - acc: 0.9811
1283/1283 [==============================] - 1s 620us/step - loss: 0.0565 - acc: 0.9821 - val_loss: 1.3258 - val_acc: 0.6245

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0604 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0343 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0355 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0363 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0353 - acc: 0.9931
 768/1283 [================>.............] - ETA: 0s - loss: 0.0345 - acc: 0.9909
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0404 - acc: 0.9906
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0446 - acc: 0.9878
1280/1283 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9875
1283/1283 [==============================] - 1s 466us/step - loss: 0.0465 - acc: 0.9867 - val_loss: 2.2433 - val_acc: 0.5590

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2678 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2358 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1693 - acc: 0.9187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1538 - acc: 0.9308
 576/1283 [============>.................] - ETA: 0s - loss: 0.1575 - acc: 0.9271
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1496 - acc: 0.9332
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1563 - acc: 0.9297
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1738 - acc: 0.9283
1280/1283 [============================>.] - ETA: 0s - loss: 0.1760 - acc: 0.9305
1283/1283 [==============================] - 1s 470us/step - loss: 0.1757 - acc: 0.9306 - val_loss: 1.6187 - val_acc: 0.5852

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0844 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1070 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0903 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0869 - acc: 0.9643
 640/1283 [=============>................] - ETA: 0s - loss: 0.0794 - acc: 0.9672
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0734 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0750 - acc: 0.9668
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0734 - acc: 0.9679
1283/1283 [==============================] - 1s 408us/step - loss: 0.0729 - acc: 0.9688 - val_loss: 1.3540 - val_acc: 0.6070

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0303 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0426 - acc: 0.9948
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0405 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0377 - acc: 0.9948
 768/1283 [================>.............] - ETA: 0s - loss: 0.0408 - acc: 0.9948
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0382 - acc: 0.9933
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0361 - acc: 0.9936
1280/1283 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9922
1283/1283 [==============================] - 1s 407us/step - loss: 0.0371 - acc: 0.9922 - val_loss: 1.4311 - val_acc: 0.6026

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0295 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0318 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0257 - acc: 0.9969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0268 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0252 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0248 - acc: 0.9922
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0252 - acc: 0.9906
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0277 - acc: 0.9887
1283/1283 [==============================] - 1s 423us/step - loss: 0.0270 - acc: 0.9891 - val_loss: 1.5474 - val_acc: 0.6026

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0324 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0245 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0209 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0204 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0258 - acc: 0.9861
 768/1283 [================>.............] - ETA: 0s - loss: 0.0251 - acc: 0.9870
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0234 - acc: 0.9877
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0234 - acc: 0.9883
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0230 - acc: 0.9896
1283/1283 [==============================] - 1s 506us/step - loss: 0.0244 - acc: 0.9899 - val_loss: 1.6101 - val_acc: 0.5895

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6180758017492711
best_valid_accuracy=0.5918367346938775
