/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:34:49.299392: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 11s - loss: 0.6884 - acc: 0.5469
 128/1283 [=>............................] - ETA: 6s - loss: 0.7113 - acc: 0.5547 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.7418 - acc: 0.5260
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7339 - acc: 0.5563
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7324 - acc: 0.5491
 576/1283 [============>.................] - ETA: 1s - loss: 0.7368 - acc: 0.5538
 640/1283 [=============>................] - ETA: 1s - loss: 0.7454 - acc: 0.5484
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7520 - acc: 0.5469
 768/1283 [================>.............] - ETA: 0s - loss: 0.7526 - acc: 0.5417
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7502 - acc: 0.5361
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7448 - acc: 0.5346
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7440 - acc: 0.5375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7436 - acc: 0.5400
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7386 - acc: 0.5432
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7374 - acc: 0.5391
1280/1283 [============================>.] - ETA: 0s - loss: 0.7339 - acc: 0.5414
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7336 - acc: 0.5417 - val_loss: 0.7023 - val_acc: 0.5197

Epoch 00001: val_acc improved from -inf to 0.51965, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6362 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.6063 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5984 - acc: 0.6953
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5856 - acc: 0.7250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5820 - acc: 0.7318
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5788 - acc: 0.7299
 576/1283 [============>.................] - ETA: 0s - loss: 0.5731 - acc: 0.7274
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5699 - acc: 0.7273
 768/1283 [================>.............] - ETA: 0s - loss: 0.5634 - acc: 0.7370
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5610 - acc: 0.7392
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5569 - acc: 0.7388
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5573 - acc: 0.7305
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5544 - acc: 0.7325
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5522 - acc: 0.7352
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5510 - acc: 0.7360
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5467 - acc: 0.7412 - val_loss: 0.7845 - val_acc: 0.5852

Epoch 00002: val_acc improved from 0.51965 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5204 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4689 - acc: 0.7969
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4477 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4535 - acc: 0.8073
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4476 - acc: 0.8125
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4438 - acc: 0.8164
 640/1283 [=============>................] - ETA: 0s - loss: 0.4321 - acc: 0.8234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4307 - acc: 0.8182
 768/1283 [================>.............] - ETA: 0s - loss: 0.4278 - acc: 0.8203
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4277 - acc: 0.8161
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4245 - acc: 0.8214
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4217 - acc: 0.8223
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4176 - acc: 0.8263
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4179 - acc: 0.8212
1280/1283 [============================>.] - ETA: 0s - loss: 0.4142 - acc: 0.8250
1283/1283 [==============================] - 1s 988us/step - loss: 0.4139 - acc: 0.8254 - val_loss: 0.7111 - val_acc: 0.6288

Epoch 00003: val_acc improved from 0.58515 to 0.62882, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2436 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2738 - acc: 0.8958
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2670 - acc: 0.9102
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2723 - acc: 0.9062
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2746 - acc: 0.9102
 640/1283 [=============>................] - ETA: 0s - loss: 0.2844 - acc: 0.8922
 768/1283 [================>.............] - ETA: 0s - loss: 0.2953 - acc: 0.8802
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2949 - acc: 0.8822
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2940 - acc: 0.8839
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2914 - acc: 0.8823
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2940 - acc: 0.8787
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2908 - acc: 0.8783
1283/1283 [==============================] - 1s 811us/step - loss: 0.2936 - acc: 0.8753 - val_loss: 0.8382 - val_acc: 0.5939

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2204 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2573 - acc: 0.8802
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2848 - acc: 0.8625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2816 - acc: 0.8772
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2822 - acc: 0.8809
 640/1283 [=============>................] - ETA: 0s - loss: 0.2688 - acc: 0.8891
 768/1283 [================>.............] - ETA: 0s - loss: 0.2560 - acc: 0.8958
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2555 - acc: 0.8940
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2503 - acc: 0.8916
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2513 - acc: 0.8915
1280/1283 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.8953
1283/1283 [==============================] - 1s 764us/step - loss: 0.2487 - acc: 0.8956 - val_loss: 0.8491 - val_acc: 0.5939

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1395 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.1323 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1587 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1663 - acc: 0.9180
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1879 - acc: 0.8932
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1858 - acc: 0.8973
 576/1283 [============>.................] - ETA: 0s - loss: 0.1755 - acc: 0.9132
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1670 - acc: 0.9219
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1729 - acc: 0.9207
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1734 - acc: 0.9219
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1746 - acc: 0.9219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1743 - acc: 0.9201
1280/1283 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9219
1283/1283 [==============================] - 1s 781us/step - loss: 0.1738 - acc: 0.9221 - val_loss: 0.8843 - val_acc: 0.6114

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1265 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1371 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1427 - acc: 0.9453
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1322 - acc: 0.9531
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1272 - acc: 0.9512
 576/1283 [============>.................] - ETA: 0s - loss: 0.1229 - acc: 0.9531
 640/1283 [=============>................] - ETA: 0s - loss: 0.1240 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1266 - acc: 0.9518
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1303 - acc: 0.9475
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1311 - acc: 0.9453
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1286 - acc: 0.9444
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1304 - acc: 0.9449
1283/1283 [==============================] - 1s 790us/step - loss: 0.1322 - acc: 0.9439 - val_loss: 1.0435 - val_acc: 0.6594

Epoch 00007: val_acc improved from 0.62882 to 0.65939, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1289 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1346 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1490 - acc: 0.9414
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1362 - acc: 0.9557
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1385 - acc: 0.9512
 640/1283 [=============>................] - ETA: 0s - loss: 0.1447 - acc: 0.9469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1428 - acc: 0.9460
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1409 - acc: 0.9447
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1370 - acc: 0.9469
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1453 - acc: 0.9421
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1438 - acc: 0.9408
1283/1283 [==============================] - 1s 711us/step - loss: 0.1431 - acc: 0.9423 - val_loss: 1.0483 - val_acc: 0.5852

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0647 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1100 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1223 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1287 - acc: 0.9464
 576/1283 [============>.................] - ETA: 0s - loss: 0.1340 - acc: 0.9444
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1493 - acc: 0.9332
 768/1283 [================>.............] - ETA: 0s - loss: 0.1471 - acc: 0.9336
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1433 - acc: 0.9363
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1445 - acc: 0.9385
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1439 - acc: 0.9395
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1380 - acc: 0.9427
1280/1283 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9422
1283/1283 [==============================] - 1s 763us/step - loss: 0.1450 - acc: 0.9423 - val_loss: 1.2875 - val_acc: 0.5983

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1355 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1229 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1271 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1264 - acc: 0.9464
 576/1283 [============>.................] - ETA: 0s - loss: 0.1186 - acc: 0.9531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1143 - acc: 0.9517
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1174 - acc: 0.9483
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1140 - acc: 0.9531
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1142 - acc: 0.9522
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1124 - acc: 0.9540
1280/1283 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9531
1283/1283 [==============================] - 1s 757us/step - loss: 0.1133 - acc: 0.9532 - val_loss: 1.3184 - val_acc: 0.5721

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1242 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1136 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1015 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0933 - acc: 0.9576
 576/1283 [============>.................] - ETA: 0s - loss: 0.0868 - acc: 0.9618
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0826 - acc: 0.9659
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0853 - acc: 0.9651
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0832 - acc: 0.9656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0865 - acc: 0.9632
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0839 - acc: 0.9653
1280/1283 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9672
1283/1283 [==============================] - 1s 756us/step - loss: 0.0812 - acc: 0.9673 - val_loss: 1.3256 - val_acc: 0.5721

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0815 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0582 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0645 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0596 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.0668 - acc: 0.9705
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0665 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0658 - acc: 0.9712
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0684 - acc: 0.9698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0690 - acc: 0.9706
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0694 - acc: 0.9704
1283/1283 [==============================] - 1s 677us/step - loss: 0.0692 - acc: 0.9696 - val_loss: 1.4967 - val_acc: 0.6026

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0481 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0644 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0645 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0747 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0762 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.0717 - acc: 0.9672
 768/1283 [================>.............] - ETA: 0s - loss: 0.0692 - acc: 0.9674
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0688 - acc: 0.9665
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0708 - acc: 0.9639
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0730 - acc: 0.9635
1280/1283 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9664
1283/1283 [==============================] - 1s 630us/step - loss: 0.0715 - acc: 0.9665 - val_loss: 1.5947 - val_acc: 0.5939

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0336 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0544 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0591 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0554 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.0586 - acc: 0.9774
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0585 - acc: 0.9773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0552 - acc: 0.9796
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0606 - acc: 0.9750
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0634 - acc: 0.9724
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0648 - acc: 0.9720
1283/1283 [==============================] - 1s 613us/step - loss: 0.0653 - acc: 0.9712 - val_loss: 1.6535 - val_acc: 0.5939

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0561 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0726 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0721 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0622 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.0634 - acc: 0.9705
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0588 - acc: 0.9744
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0582 - acc: 0.9748
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0596 - acc: 0.9729
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0595 - acc: 0.9727
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0566 - acc: 0.9748
1280/1283 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9742
1283/1283 [==============================] - 1s 647us/step - loss: 0.0569 - acc: 0.9743 - val_loss: 1.6666 - val_acc: 0.5852

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0775 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0642 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0556 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0581 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.0585 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0535 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0525 - acc: 0.9724
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0506 - acc: 0.9740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0517 - acc: 0.9752
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0548 - acc: 0.9745
1283/1283 [==============================] - 1s 636us/step - loss: 0.0534 - acc: 0.9758 - val_loss: 1.6904 - val_acc: 0.6070

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0669 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0610 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0545 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0582 - acc: 0.9643
 576/1283 [============>.................] - ETA: 0s - loss: 0.0516 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0495 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0548 - acc: 0.9663
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0559 - acc: 0.9677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0557 - acc: 0.9697
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0524 - acc: 0.9729
1283/1283 [==============================] - 1s 597us/step - loss: 0.0506 - acc: 0.9743 - val_loss: 1.7977 - val_acc: 0.5808

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=AT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5830903790087464
best_valid_accuracy=0.6049562682215743
