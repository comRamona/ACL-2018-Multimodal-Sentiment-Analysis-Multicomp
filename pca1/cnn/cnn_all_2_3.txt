/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 07:58:31.762534: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 21s - loss: 0.6787 - acc: 0.5156
 128/1283 [=>............................] - ETA: 10s - loss: 0.7430 - acc: 0.5078
 192/1283 [===>..........................] - ETA: 7s - loss: 0.7352 - acc: 0.5104 
 256/1283 [====>.........................] - ETA: 5s - loss: 0.7520 - acc: 0.5273
 320/1283 [======>.......................] - ETA: 4s - loss: 0.7606 - acc: 0.5437
 384/1283 [=======>......................] - ETA: 3s - loss: 0.7562 - acc: 0.5365
 448/1283 [=========>....................] - ETA: 3s - loss: 0.7450 - acc: 0.5424
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7653 - acc: 0.5312
 576/1283 [============>.................] - ETA: 2s - loss: 0.7592 - acc: 0.5417
 640/1283 [=============>................] - ETA: 2s - loss: 0.7537 - acc: 0.5375
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7529 - acc: 0.5384
 768/1283 [================>.............] - ETA: 1s - loss: 0.7506 - acc: 0.5339
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7445 - acc: 0.5373
 896/1283 [===================>..........] - ETA: 1s - loss: 0.7432 - acc: 0.5357
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7430 - acc: 0.5312
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7410 - acc: 0.5283
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7381 - acc: 0.5349
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7354 - acc: 0.5321
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7353 - acc: 0.5271
1280/1283 [============================>.] - ETA: 0s - loss: 0.7329 - acc: 0.5289
1283/1283 [==============================] - 4s 3ms/step - loss: 0.7335 - acc: 0.5284 - val_loss: 0.7128 - val_acc: 0.5066

Epoch 00001: val_acc improved from -inf to 0.50655, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5404 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.5441 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5447 - acc: 0.8229
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5604 - acc: 0.7969
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5618 - acc: 0.7781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5671 - acc: 0.7630
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5677 - acc: 0.7567
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5697 - acc: 0.7539
 576/1283 [============>.................] - ETA: 1s - loss: 0.5695 - acc: 0.7500
 640/1283 [=============>................] - ETA: 1s - loss: 0.5649 - acc: 0.7531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5635 - acc: 0.7514
 768/1283 [================>.............] - ETA: 0s - loss: 0.5622 - acc: 0.7526
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5594 - acc: 0.7548
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5577 - acc: 0.7545
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5573 - acc: 0.7521
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5581 - acc: 0.7480
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5576 - acc: 0.7454
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5572 - acc: 0.7422
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5569 - acc: 0.7377
1280/1283 [============================>.] - ETA: 0s - loss: 0.5546 - acc: 0.7375
1283/1283 [==============================] - 3s 2ms/step - loss: 0.5548 - acc: 0.7373 - val_loss: 0.7944 - val_acc: 0.5721

Epoch 00002: val_acc improved from 0.50655 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5315 - acc: 0.6719
 128/1283 [=>............................] - ETA: 2s - loss: 0.5052 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 2s - loss: 0.4934 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4686 - acc: 0.7773
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4692 - acc: 0.7844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4660 - acc: 0.7839
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4638 - acc: 0.7812
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4617 - acc: 0.7832
 576/1283 [============>.................] - ETA: 1s - loss: 0.4581 - acc: 0.7865
 640/1283 [=============>................] - ETA: 1s - loss: 0.4565 - acc: 0.7875
 704/1283 [===============>..............] - ETA: 1s - loss: 0.4512 - acc: 0.7898
 768/1283 [================>.............] - ETA: 1s - loss: 0.4497 - acc: 0.7917
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4525 - acc: 0.7861
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4498 - acc: 0.7891
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4456 - acc: 0.7958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4440 - acc: 0.7969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4389 - acc: 0.8015
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4375 - acc: 0.8030
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4365 - acc: 0.8043
1280/1283 [============================>.] - ETA: 0s - loss: 0.4336 - acc: 0.8086
1283/1283 [==============================] - 3s 2ms/step - loss: 0.4336 - acc: 0.8083 - val_loss: 0.8034 - val_acc: 0.5939

Epoch 00003: val_acc improved from 0.57205 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2860 - acc: 0.9219
 128/1283 [=>............................] - ETA: 3s - loss: 0.3158 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 2s - loss: 0.3299 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 2s - loss: 0.3178 - acc: 0.8945
 320/1283 [======>.......................] - ETA: 2s - loss: 0.3134 - acc: 0.8969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3128 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3104 - acc: 0.8906
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3121 - acc: 0.8867
 576/1283 [============>.................] - ETA: 1s - loss: 0.3218 - acc: 0.8733
 640/1283 [=============>................] - ETA: 1s - loss: 0.3263 - acc: 0.8641
 704/1283 [===============>..............] - ETA: 1s - loss: 0.3314 - acc: 0.8551
 768/1283 [================>.............] - ETA: 1s - loss: 0.3391 - acc: 0.8490
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3426 - acc: 0.8486
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3423 - acc: 0.8504
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3390 - acc: 0.8500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3439 - acc: 0.8457
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3426 - acc: 0.8456
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3369 - acc: 0.8498
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3362 - acc: 0.8479
1280/1283 [============================>.] - ETA: 0s - loss: 0.3369 - acc: 0.8477
1283/1283 [==============================] - 3s 2ms/step - loss: 0.3377 - acc: 0.8472 - val_loss: 0.8344 - val_acc: 0.5852

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2347 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.2608 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2545 - acc: 0.8802
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3104 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3146 - acc: 0.8281
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3024 - acc: 0.8490
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2991 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2938 - acc: 0.8652
 576/1283 [============>.................] - ETA: 1s - loss: 0.2880 - acc: 0.8698
 640/1283 [=============>................] - ETA: 0s - loss: 0.2841 - acc: 0.8719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2788 - acc: 0.8736
 768/1283 [================>.............] - ETA: 0s - loss: 0.2775 - acc: 0.8724
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2743 - acc: 0.8762
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2709 - acc: 0.8828
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2707 - acc: 0.8823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2698 - acc: 0.8857
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2660 - acc: 0.8906
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2666 - acc: 0.8889
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2662 - acc: 0.8898
1280/1283 [============================>.] - ETA: 0s - loss: 0.2646 - acc: 0.8891
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2642 - acc: 0.8893 - val_loss: 0.9062 - val_acc: 0.5983

Epoch 00005: val_acc improved from 0.59389 to 0.59825, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1782 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.1675 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1728 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1744 - acc: 0.9414
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1912 - acc: 0.9250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2020 - acc: 0.9141
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2000 - acc: 0.9152
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1975 - acc: 0.9180
 576/1283 [============>.................] - ETA: 1s - loss: 0.1931 - acc: 0.9236
 640/1283 [=============>................] - ETA: 1s - loss: 0.1873 - acc: 0.9266
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1845 - acc: 0.9290
 768/1283 [================>.............] - ETA: 0s - loss: 0.1846 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1841 - acc: 0.9291
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1847 - acc: 0.9286
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1860 - acc: 0.9292
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1868 - acc: 0.9287
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1862 - acc: 0.9292
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1850 - acc: 0.9280
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1862 - acc: 0.9268
1280/1283 [============================>.] - ETA: 0s - loss: 0.1879 - acc: 0.9266
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1875 - acc: 0.9267 - val_loss: 0.9609 - val_acc: 0.6245

Epoch 00006: val_acc improved from 0.59825 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1445 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1443 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1474 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1522 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1492 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1403 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1370 - acc: 0.9576
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1374 - acc: 0.9531
 576/1283 [============>.................] - ETA: 1s - loss: 0.1329 - acc: 0.9549
 640/1283 [=============>................] - ETA: 0s - loss: 0.1320 - acc: 0.9578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1328 - acc: 0.9560
 768/1283 [================>.............] - ETA: 0s - loss: 0.1329 - acc: 0.9570
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1355 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1370 - acc: 0.9531
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1368 - acc: 0.9531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1384 - acc: 0.9512
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1362 - acc: 0.9514
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1365 - acc: 0.9515
1280/1283 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9508
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1387 - acc: 0.9501 - val_loss: 1.1494 - val_acc: 0.6288

Epoch 00007: val_acc improved from 0.62445 to 0.62882, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1207 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1174 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1152 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1125 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1127 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1109 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1173 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1221 - acc: 0.9688
 576/1283 [============>.................] - ETA: 1s - loss: 0.1205 - acc: 0.9670
 640/1283 [=============>................] - ETA: 1s - loss: 0.1226 - acc: 0.9609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1254 - acc: 0.9560
 768/1283 [================>.............] - ETA: 0s - loss: 0.1251 - acc: 0.9544
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1247 - acc: 0.9543
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1233 - acc: 0.9542
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1231 - acc: 0.9542
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1295 - acc: 0.9502
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1290 - acc: 0.9504
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1281 - acc: 0.9514
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1287 - acc: 0.9498
1280/1283 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9508
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1293 - acc: 0.9501 - val_loss: 1.1585 - val_acc: 0.5852

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0732 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0790 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1055 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1037 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1051 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1021 - acc: 0.9505
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1035 - acc: 0.9509
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1081 - acc: 0.9492
 576/1283 [============>.................] - ETA: 1s - loss: 0.1104 - acc: 0.9462
 640/1283 [=============>................] - ETA: 0s - loss: 0.1173 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1167 - acc: 0.9460
 768/1283 [================>.............] - ETA: 0s - loss: 0.1151 - acc: 0.9479
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1100 - acc: 0.9531
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1095 - acc: 0.9542
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1067 - acc: 0.9561
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1054 - acc: 0.9568
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1034 - acc: 0.9575
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1053 - acc: 0.9572
1280/1283 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9570
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1083 - acc: 0.9571 - val_loss: 1.2388 - val_acc: 0.5764

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1130 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0969 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0945 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0995 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0921 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0968 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0976 - acc: 0.9576
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0930 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.0916 - acc: 0.9618
 640/1283 [=============>................] - ETA: 0s - loss: 0.0882 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0854 - acc: 0.9645
 768/1283 [================>.............] - ETA: 0s - loss: 0.0823 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0867 - acc: 0.9627
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0849 - acc: 0.9643
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0831 - acc: 0.9667
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0831 - acc: 0.9678
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0849 - acc: 0.9669
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0841 - acc: 0.9670
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0845 - acc: 0.9655
1280/1283 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9648
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0843 - acc: 0.9649 - val_loss: 1.4037 - val_acc: 0.5415

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1225 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.1122 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1057 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0911 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0939 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0916 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0813 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0791 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.0748 - acc: 0.9670
 640/1283 [=============>................] - ETA: 0s - loss: 0.0719 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0701 - acc: 0.9702
 768/1283 [================>.............] - ETA: 0s - loss: 0.0727 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0727 - acc: 0.9700
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0744 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0717 - acc: 0.9708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0741 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0747 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0724 - acc: 0.9696
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0711 - acc: 0.9712
1280/1283 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9719
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0701 - acc: 0.9719 - val_loss: 1.4720 - val_acc: 0.5459

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0691 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0442 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0480 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0603 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0553 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0537 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0506 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0552 - acc: 0.9766
 576/1283 [============>.................] - ETA: 0s - loss: 0.0582 - acc: 0.9740
 640/1283 [=============>................] - ETA: 0s - loss: 0.0589 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0573 - acc: 0.9744
 768/1283 [================>.............] - ETA: 0s - loss: 0.0587 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0568 - acc: 0.9748
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0587 - acc: 0.9721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0601 - acc: 0.9719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0590 - acc: 0.9736
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0600 - acc: 0.9724
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0622 - acc: 0.9714
1280/1283 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9719
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0601 - acc: 0.9719 - val_loss: 1.5996 - val_acc: 0.6114

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0451 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0616 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0662 - acc: 0.9766
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0685 - acc: 0.9740
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0699 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0698 - acc: 0.9727
 576/1283 [============>.................] - ETA: 0s - loss: 0.0689 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.0668 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0665 - acc: 0.9716
 768/1283 [================>.............] - ETA: 0s - loss: 0.0659 - acc: 0.9714
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0655 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0658 - acc: 0.9699
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0651 - acc: 0.9708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0664 - acc: 0.9697
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0697 - acc: 0.9697
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0687 - acc: 0.9696
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0663 - acc: 0.9712
1280/1283 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9719
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0672 - acc: 0.9719 - val_loss: 1.9165 - val_acc: 0.5677

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0337 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0527 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0526 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0519 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0556 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0553 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0512 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0493 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0538 - acc: 0.9792
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0541 - acc: 0.9787
 768/1283 [================>.............] - ETA: 0s - loss: 0.0521 - acc: 0.9805
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0497 - acc: 0.9808
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0552 - acc: 0.9760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0551 - acc: 0.9756
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0574 - acc: 0.9731
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0569 - acc: 0.9737
1280/1283 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9727
1283/1283 [==============================] - 1s 968us/step - loss: 0.0572 - acc: 0.9727 - val_loss: 1.7339 - val_acc: 0.6157

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0496 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0632 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0675 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0709 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0671 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0594 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0585 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0575 - acc: 0.9727
 576/1283 [============>.................] - ETA: 0s - loss: 0.0583 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.0584 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0545 - acc: 0.9759
 768/1283 [================>.............] - ETA: 0s - loss: 0.0551 - acc: 0.9753
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0557 - acc: 0.9721
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0536 - acc: 0.9746
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0515 - acc: 0.9761
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0517 - acc: 0.9753
1280/1283 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9758
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0509 - acc: 0.9758 - val_loss: 1.7760 - val_acc: 0.5721

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0707 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0536 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0597 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0614 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0517 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0572 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0552 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0563 - acc: 0.9668
 576/1283 [============>.................] - ETA: 0s - loss: 0.0542 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0494 - acc: 0.9716
 768/1283 [================>.............] - ETA: 0s - loss: 0.0482 - acc: 0.9740
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0493 - acc: 0.9736
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0479 - acc: 0.9754
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0468 - acc: 0.9760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0463 - acc: 0.9775
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0476 - acc: 0.9770
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0483 - acc: 0.9783
1280/1283 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9773
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0483 - acc: 0.9774 - val_loss: 1.8343 - val_acc: 0.6070

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0572 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0668 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0559 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0584 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0517 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0551 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0513 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0486 - acc: 0.9705
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0458 - acc: 0.9716
 768/1283 [================>.............] - ETA: 0s - loss: 0.0493 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0500 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0500 - acc: 0.9708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0486 - acc: 0.9727
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0505 - acc: 0.9724
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0488 - acc: 0.9740
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0476 - acc: 0.9753
1283/1283 [==============================] - 1s 938us/step - loss: 0.0460 - acc: 0.9766 - val_loss: 1.9101 - val_acc: 0.5677

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5379008746355685
best_valid_accuracy=0.5962099125364432
