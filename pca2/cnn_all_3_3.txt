/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 13:09:40.510936: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 19s - loss: 0.7355 - acc: 0.5469
 128/1283 [=>............................] - ETA: 10s - loss: 0.7177 - acc: 0.5703
 192/1283 [===>..........................] - ETA: 7s - loss: 0.7553 - acc: 0.5469 
 256/1283 [====>.........................] - ETA: 5s - loss: 0.7380 - acc: 0.5430
 320/1283 [======>.......................] - ETA: 4s - loss: 0.7234 - acc: 0.5500
 384/1283 [=======>......................] - ETA: 3s - loss: 0.7398 - acc: 0.5391
 448/1283 [=========>....................] - ETA: 3s - loss: 0.7351 - acc: 0.5268
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7284 - acc: 0.5371
 576/1283 [============>.................] - ETA: 2s - loss: 0.7243 - acc: 0.5365
 640/1283 [=============>................] - ETA: 2s - loss: 0.7219 - acc: 0.5391
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7188 - acc: 0.5426
 768/1283 [================>.............] - ETA: 1s - loss: 0.7172 - acc: 0.5417
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7154 - acc: 0.5445
 896/1283 [===================>..........] - ETA: 1s - loss: 0.7133 - acc: 0.5480
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7125 - acc: 0.5437
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7113 - acc: 0.5469
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7106 - acc: 0.5460
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7090 - acc: 0.5443
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7092 - acc: 0.5378
1280/1283 [============================>.] - ETA: 0s - loss: 0.7075 - acc: 0.5422
1283/1283 [==============================] - 4s 3ms/step - loss: 0.7074 - acc: 0.5425 - val_loss: 0.6917 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6360 - acc: 0.6719
 128/1283 [=>............................] - ETA: 1s - loss: 0.6271 - acc: 0.6797
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6299 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6310 - acc: 0.6680
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6256 - acc: 0.6656
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6256 - acc: 0.6667
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6223 - acc: 0.6741
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6249 - acc: 0.6680
 576/1283 [============>.................] - ETA: 1s - loss: 0.6209 - acc: 0.6736
 640/1283 [=============>................] - ETA: 1s - loss: 0.6246 - acc: 0.6672
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6273 - acc: 0.6591
 768/1283 [================>.............] - ETA: 0s - loss: 0.6258 - acc: 0.6562
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6226 - acc: 0.6599
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6187 - acc: 0.6607
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6169 - acc: 0.6615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6147 - acc: 0.6660
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6147 - acc: 0.6608
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6115 - acc: 0.6641
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6093 - acc: 0.6669
1280/1283 [============================>.] - ETA: 0s - loss: 0.6141 - acc: 0.6594
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6135 - acc: 0.6602 - val_loss: 0.7112 - val_acc: 0.5546

Epoch 00002: val_acc improved from 0.53712 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4830 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.5106 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 2s - loss: 0.5055 - acc: 0.7552
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4950 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 2s - loss: 0.4977 - acc: 0.7500
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5117 - acc: 0.7370
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4985 - acc: 0.7589
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4965 - acc: 0.7559
 576/1283 [============>.................] - ETA: 1s - loss: 0.4918 - acc: 0.7552
 640/1283 [=============>................] - ETA: 1s - loss: 0.4886 - acc: 0.7547
 704/1283 [===============>..............] - ETA: 1s - loss: 0.4816 - acc: 0.7628
 768/1283 [================>.............] - ETA: 1s - loss: 0.4749 - acc: 0.7695
 832/1283 [==================>...........] - ETA: 1s - loss: 0.4730 - acc: 0.7692
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4755 - acc: 0.7690
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4736 - acc: 0.7719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4706 - acc: 0.7764
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4713 - acc: 0.7748
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4698 - acc: 0.7778
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4694 - acc: 0.7788
1280/1283 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.7773
1283/1283 [==============================] - 4s 3ms/step - loss: 0.4689 - acc: 0.7771 - val_loss: 0.7823 - val_acc: 0.5721

Epoch 00003: val_acc improved from 0.55459 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4236 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.3944 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3683 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3497 - acc: 0.8516
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3543 - acc: 0.8469
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3579 - acc: 0.8385
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3527 - acc: 0.8438
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3549 - acc: 0.8398
 576/1283 [============>.................] - ETA: 1s - loss: 0.3494 - acc: 0.8403
 640/1283 [=============>................] - ETA: 1s - loss: 0.3440 - acc: 0.8453
 704/1283 [===============>..............] - ETA: 1s - loss: 0.3427 - acc: 0.8438
 768/1283 [================>.............] - ETA: 1s - loss: 0.3332 - acc: 0.8503
 832/1283 [==================>...........] - ETA: 1s - loss: 0.3319 - acc: 0.8534
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3286 - acc: 0.8560
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3281 - acc: 0.8573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3251 - acc: 0.8584
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3247 - acc: 0.8575
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3197 - acc: 0.8611
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3182 - acc: 0.8643
1280/1283 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.8664
1283/1283 [==============================] - 4s 3ms/step - loss: 0.3164 - acc: 0.8667 - val_loss: 0.8404 - val_acc: 0.6114

Epoch 00004: val_acc improved from 0.57205 to 0.61135, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1798 - acc: 0.9531
 128/1283 [=>............................] - ETA: 3s - loss: 0.1892 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 3s - loss: 0.1869 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1736 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 2s - loss: 0.1662 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 2s - loss: 0.1819 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 2s - loss: 0.1802 - acc: 0.9442
 512/1283 [==========>...................] - ETA: 2s - loss: 0.1777 - acc: 0.9414
 576/1283 [============>.................] - ETA: 1s - loss: 0.1824 - acc: 0.9340
 640/1283 [=============>................] - ETA: 1s - loss: 0.1871 - acc: 0.9344
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1827 - acc: 0.9361
 768/1283 [================>.............] - ETA: 1s - loss: 0.1832 - acc: 0.9336
 832/1283 [==================>...........] - ETA: 1s - loss: 0.1811 - acc: 0.9339
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1866 - acc: 0.9286
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1897 - acc: 0.9250
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1879 - acc: 0.9277
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1919 - acc: 0.9256
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1881 - acc: 0.9253
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1868 - acc: 0.9268
1280/1283 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9250
1283/1283 [==============================] - 3s 3ms/step - loss: 0.1871 - acc: 0.9252 - val_loss: 1.1084 - val_acc: 0.5677

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0997 - acc: 0.9531
 128/1283 [=>............................] - ETA: 2s - loss: 0.1194 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1036 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1116 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 2s - loss: 0.1020 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 2s - loss: 0.1062 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 2s - loss: 0.1011 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1024 - acc: 0.9609
 576/1283 [============>.................] - ETA: 1s - loss: 0.1085 - acc: 0.9566
 640/1283 [=============>................] - ETA: 1s - loss: 0.1104 - acc: 0.9547
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1140 - acc: 0.9517
 768/1283 [================>.............] - ETA: 1s - loss: 0.1120 - acc: 0.9544
 832/1283 [==================>...........] - ETA: 1s - loss: 0.1130 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1117 - acc: 0.9520
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1114 - acc: 0.9521
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1090 - acc: 0.9531
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1083 - acc: 0.9550
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1062 - acc: 0.9557
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1050 - acc: 0.9572
1280/1283 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9578
1283/1283 [==============================] - 3s 3ms/step - loss: 0.1041 - acc: 0.9579 - val_loss: 1.2932 - val_acc: 0.5764

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0506 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0478 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0659 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0696 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0778 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0794 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0764 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0753 - acc: 0.9648
 576/1283 [============>.................] - ETA: 1s - loss: 0.0743 - acc: 0.9653
 640/1283 [=============>................] - ETA: 1s - loss: 0.0749 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0755 - acc: 0.9631
 768/1283 [================>.............] - ETA: 0s - loss: 0.0739 - acc: 0.9661
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0734 - acc: 0.9675
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0740 - acc: 0.9676
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0725 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0728 - acc: 0.9668
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0722 - acc: 0.9688
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0709 - acc: 0.9696
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0719 - acc: 0.9671
1280/1283 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9664
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0738 - acc: 0.9665 - val_loss: 1.7327 - val_acc: 0.5895

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0478 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.1328 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1184 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0981 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1048 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1002 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0964 - acc: 0.9576
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0888 - acc: 0.9629
 576/1283 [============>.................] - ETA: 1s - loss: 0.0908 - acc: 0.9601
 640/1283 [=============>................] - ETA: 1s - loss: 0.0897 - acc: 0.9594
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0910 - acc: 0.9588
 768/1283 [================>.............] - ETA: 1s - loss: 0.0880 - acc: 0.9609
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0846 - acc: 0.9627
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0820 - acc: 0.9632
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0834 - acc: 0.9635
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0816 - acc: 0.9658
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0812 - acc: 0.9660
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0819 - acc: 0.9653
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0818 - acc: 0.9638
1280/1283 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9648
1283/1283 [==============================] - 3s 3ms/step - loss: 0.0808 - acc: 0.9649 - val_loss: 1.7129 - val_acc: 0.5983

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0299 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0510 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0444 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0513 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0610 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0623 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0606 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0574 - acc: 0.9688
 576/1283 [============>.................] - ETA: 1s - loss: 0.0556 - acc: 0.9705
 640/1283 [=============>................] - ETA: 1s - loss: 0.0577 - acc: 0.9703
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0632 - acc: 0.9659
 768/1283 [================>.............] - ETA: 1s - loss: 0.0607 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0628 - acc: 0.9688
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0619 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0608 - acc: 0.9719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0624 - acc: 0.9717
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0658 - acc: 0.9724
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0647 - acc: 0.9722
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0634 - acc: 0.9737
1280/1283 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9750
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0636 - acc: 0.9751 - val_loss: 2.5009 - val_acc: 0.5808

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.1560 - acc: 0.9531
 128/1283 [=>............................] - ETA: 3s - loss: 0.1247 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0950 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0806 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 2s - loss: 0.0751 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 2s - loss: 0.0747 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0683 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0681 - acc: 0.9746
 576/1283 [============>.................] - ETA: 1s - loss: 0.0733 - acc: 0.9722
 640/1283 [=============>................] - ETA: 1s - loss: 0.0695 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0670 - acc: 0.9744
 768/1283 [================>.............] - ETA: 1s - loss: 0.0668 - acc: 0.9753
 832/1283 [==================>...........] - ETA: 1s - loss: 0.0752 - acc: 0.9688
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0766 - acc: 0.9665
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0739 - acc: 0.9677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0749 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0793 - acc: 0.9660
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0842 - acc: 0.9627
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0858 - acc: 0.9613
1280/1283 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9633
1283/1283 [==============================] - 3s 3ms/step - loss: 0.0850 - acc: 0.9626 - val_loss: 1.9634 - val_acc: 0.5633

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0243 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.3158 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 2s - loss: 0.3887 - acc: 0.8958
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3706 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3610 - acc: 0.9125
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3476 - acc: 0.9115
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3335 - acc: 0.9152
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3229 - acc: 0.9180
 576/1283 [============>.................] - ETA: 1s - loss: 0.3392 - acc: 0.9132
 640/1283 [=============>................] - ETA: 1s - loss: 0.3139 - acc: 0.9141
 704/1283 [===============>..............] - ETA: 1s - loss: 0.3043 - acc: 0.9091
 768/1283 [================>.............] - ETA: 0s - loss: 0.2949 - acc: 0.9102
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2982 - acc: 0.9123
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2880 - acc: 0.9141
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2759 - acc: 0.9177
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2683 - acc: 0.9189
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2648 - acc: 0.9191
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2551 - acc: 0.9227
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2453 - acc: 0.9252
1280/1283 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.9234
1283/1283 [==============================] - 3s 2ms/step - loss: 0.2393 - acc: 0.9236 - val_loss: 1.8877 - val_acc: 0.5633

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.3210 - acc: 0.8750
 128/1283 [=>............................] - ETA: 2s - loss: 0.2444 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 2s - loss: 0.2095 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1744 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 2s - loss: 0.1621 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1506 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1420 - acc: 0.9509
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1319 - acc: 0.9551
 576/1283 [============>.................] - ETA: 1s - loss: 0.1263 - acc: 0.9549
 640/1283 [=============>................] - ETA: 1s - loss: 0.1191 - acc: 0.9594
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1152 - acc: 0.9602
 768/1283 [================>.............] - ETA: 1s - loss: 0.1120 - acc: 0.9596
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1128 - acc: 0.9567
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1129 - acc: 0.9565
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1091 - acc: 0.9573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1065 - acc: 0.9570
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1035 - acc: 0.9596
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1014 - acc: 0.9592
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0997 - acc: 0.9597
1280/1283 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9609
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0978 - acc: 0.9610 - val_loss: 1.6694 - val_acc: 0.5721

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0661 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0531 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0524 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0509 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0538 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0518 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0515 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0542 - acc: 0.9824
 576/1283 [============>.................] - ETA: 1s - loss: 0.0522 - acc: 0.9844
 640/1283 [=============>................] - ETA: 1s - loss: 0.0520 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0486 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0502 - acc: 0.9831
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0488 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0485 - acc: 0.9844
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0487 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0477 - acc: 0.9834
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0476 - acc: 0.9825
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0496 - acc: 0.9800
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0508 - acc: 0.9778
1280/1283 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9781
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0500 - acc: 0.9782 - val_loss: 2.0004 - val_acc: 0.5546

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0656 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0415 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0368 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0495 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0540 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0508 - acc: 0.9740
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0509 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0507 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.0491 - acc: 0.9774
 640/1283 [=============>................] - ETA: 0s - loss: 0.0485 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0457 - acc: 0.9787
 768/1283 [================>.............] - ETA: 0s - loss: 0.0449 - acc: 0.9792
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0455 - acc: 0.9784
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0449 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0439 - acc: 0.9792
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0467 - acc: 0.9785
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0461 - acc: 0.9789
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0449 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0444 - acc: 0.9794
1280/1283 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9789
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0441 - acc: 0.9790 - val_loss: 2.1323 - val_acc: 0.5415

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=3
max_len=25
nodes=100
mode=all
PCA audio=35
PCA visual=45
PCA text=130
accuracy=0.5889212827988338
best_valid_accuracy=0.597667638483965
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 14:03:41.286871: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.7355 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7565 - acc: 0.5469
 320/1283 [======>.......................] - ETA: 0s - loss: 0.7240 - acc: 0.5531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7355 - acc: 0.5290
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7285 - acc: 0.5371
 640/1283 [=============>................] - ETA: 0s - loss: 0.7220 - acc: 0.5344
 768/1283 [================>.............] - ETA: 0s - loss: 0.7173 - acc: 0.5378
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7128 - acc: 0.5469
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7114 - acc: 0.5439
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7094 - acc: 0.5399
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7094 - acc: 0.5345
1283/1283 [==============================] - 1s 812us/step - loss: 0.7080 - acc: 0.5378 - val_loss: 0.6918 - val_acc: 0.5328

Epoch 00001: val_loss improved from inf to 0.69184, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6321 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6242 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6174 - acc: 0.6969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6148 - acc: 0.6920
 576/1283 [============>.................] - ETA: 0s - loss: 0.6146 - acc: 0.6858
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6205 - acc: 0.6690
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6163 - acc: 0.6707
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6127 - acc: 0.6730
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6111 - acc: 0.6729
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6088 - acc: 0.6768
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6050 - acc: 0.6736
1280/1283 [============================>.] - ETA: 0s - loss: 0.6079 - acc: 0.6656
1283/1283 [==============================] - 1s 799us/step - loss: 0.6073 - acc: 0.6664 - val_loss: 0.6915 - val_acc: 0.5939

Epoch 00002: val_loss improved from 0.69184 to 0.69153, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4630 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.4807 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4810 - acc: 0.7917
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4751 - acc: 0.7930
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4759 - acc: 0.7906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4867 - acc: 0.7734
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4748 - acc: 0.7857
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4756 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4712 - acc: 0.7795
 640/1283 [=============>................] - ETA: 0s - loss: 0.4674 - acc: 0.7812
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4607 - acc: 0.7869
 768/1283 [================>.............] - ETA: 0s - loss: 0.4553 - acc: 0.7917
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4547 - acc: 0.7897
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4564 - acc: 0.7891
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4530 - acc: 0.7927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4510 - acc: 0.7949
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4514 - acc: 0.7950
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4508 - acc: 0.7969
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4501 - acc: 0.7969
1280/1283 [============================>.] - ETA: 0s - loss: 0.4486 - acc: 0.7953
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4494 - acc: 0.7942 - val_loss: 0.7678 - val_acc: 0.5764

Epoch 00003: val_loss did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4111 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.3581 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3383 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3253 - acc: 0.8516
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3357 - acc: 0.8438
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3391 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3307 - acc: 0.8482
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3309 - acc: 0.8496
 576/1283 [============>.................] - ETA: 0s - loss: 0.3301 - acc: 0.8490
 640/1283 [=============>................] - ETA: 0s - loss: 0.3285 - acc: 0.8500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3277 - acc: 0.8509
 768/1283 [================>.............] - ETA: 0s - loss: 0.3216 - acc: 0.8529
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3202 - acc: 0.8582
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3187 - acc: 0.8583
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3179 - acc: 0.8615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3148 - acc: 0.8613
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3153 - acc: 0.8603
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3118 - acc: 0.8628
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3104 - acc: 0.8643
1280/1283 [============================>.] - ETA: 0s - loss: 0.3106 - acc: 0.8641
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3103 - acc: 0.8644 - val_loss: 0.8232 - val_acc: 0.6026

Epoch 00004: val_loss did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1855 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.2019 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2031 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1888 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1799 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1909 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1891 - acc: 0.9442
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1891 - acc: 0.9414
 576/1283 [============>.................] - ETA: 0s - loss: 0.1946 - acc: 0.9323
 640/1283 [=============>................] - ETA: 0s - loss: 0.1937 - acc: 0.9328
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1903 - acc: 0.9347
 768/1283 [================>.............] - ETA: 0s - loss: 0.1923 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1893 - acc: 0.9327
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1936 - acc: 0.9275
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1963 - acc: 0.9260
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1955 - acc: 0.9277
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1982 - acc: 0.9246
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1943 - acc: 0.9253
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1923 - acc: 0.9268
1280/1283 [============================>.] - ETA: 0s - loss: 0.1924 - acc: 0.9258
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1920 - acc: 0.9260 - val_loss: 1.0317 - val_acc: 0.6070

Epoch 00005: val_loss did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1091 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1217 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1093 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1182 - acc: 0.9492
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1137 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1088 - acc: 0.9576
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1086 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.1149 - acc: 0.9566
 640/1283 [=============>................] - ETA: 0s - loss: 0.1154 - acc: 0.9563
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1195 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1165 - acc: 0.9557
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1181 - acc: 0.9519
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1156 - acc: 0.9531
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1150 - acc: 0.9542
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1139 - acc: 0.9551
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1127 - acc: 0.9568
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1108 - acc: 0.9575
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1097 - acc: 0.9581
1280/1283 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9586
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1087 - acc: 0.9587 - val_loss: 1.3154 - val_acc: 0.5983

Epoch 00006: val_loss did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0514 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0502 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0762 - acc: 0.9727
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0809 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0782 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0773 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0786 - acc: 0.9670
 640/1283 [=============>................] - ETA: 0s - loss: 0.0773 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0768 - acc: 0.9673
 768/1283 [================>.............] - ETA: 0s - loss: 0.0753 - acc: 0.9701
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0752 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0728 - acc: 0.9721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0742 - acc: 0.9719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0742 - acc: 0.9707
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0741 - acc: 0.9724
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0731 - acc: 0.9731
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0741 - acc: 0.9712
1280/1283 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9695
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0759 - acc: 0.9696 - val_loss: 2.1179 - val_acc: 0.5939

Epoch 00007: val_loss did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0635 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1805 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1512 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1861 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1651 - acc: 0.9344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1474 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1442 - acc: 0.9375
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1341 - acc: 0.9434
 576/1283 [============>.................] - ETA: 0s - loss: 0.1299 - acc: 0.9427
 640/1283 [=============>................] - ETA: 0s - loss: 0.1227 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1233 - acc: 0.9446
 768/1283 [================>.............] - ETA: 0s - loss: 0.1162 - acc: 0.9479
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1111 - acc: 0.9507
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1149 - acc: 0.9487
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1183 - acc: 0.9469
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1124 - acc: 0.9513
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1168 - acc: 0.9505
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1199 - acc: 0.9465
1280/1283 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9469
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1176 - acc: 0.9470 - val_loss: 1.9895 - val_acc: 0.5590

Epoch 00008: val_loss did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1951 - acc: 0.9219
 128/1283 [=>............................] - ETA: 0s - loss: 0.1420 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1064 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0956 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0824 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0883 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0889 - acc: 0.9576
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0839 - acc: 0.9629
 640/1283 [=============>................] - ETA: 0s - loss: 0.0822 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0851 - acc: 0.9602
 768/1283 [================>.............] - ETA: 0s - loss: 0.0809 - acc: 0.9635
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0810 - acc: 0.9639
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0783 - acc: 0.9665
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0765 - acc: 0.9677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0757 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0757 - acc: 0.9697
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0739 - acc: 0.9696
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0726 - acc: 0.9712
1280/1283 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9727
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0725 - acc: 0.9727 - val_loss: 1.7861 - val_acc: 0.5764

Epoch 00009: val_loss did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0310 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0594 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0544 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0510 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0487 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0518 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0490 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0465 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0476 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0461 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0452 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0454 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0468 - acc: 0.9820
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0490 - acc: 0.9799
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0481 - acc: 0.9802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0497 - acc: 0.9805
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0511 - acc: 0.9789
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0520 - acc: 0.9774
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0520 - acc: 0.9770
1280/1283 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9773
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0556 - acc: 0.9774 - val_loss: 1.9614 - val_acc: 0.5764

Epoch 00010: val_loss did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0202 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0761 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0666 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0649 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0586 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0551 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0530 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0517 - acc: 0.9805
 576/1283 [============>.................] - ETA: 0s - loss: 0.0526 - acc: 0.9792
 640/1283 [=============>................] - ETA: 0s - loss: 0.0541 - acc: 0.9750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0549 - acc: 0.9744
 768/1283 [================>.............] - ETA: 0s - loss: 0.0517 - acc: 0.9766
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0529 - acc: 0.9777
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0512 - acc: 0.9792
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0505 - acc: 0.9795
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0494 - acc: 0.9798
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0474 - acc: 0.9809
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0469 - acc: 0.9803
1280/1283 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9789
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0488 - acc: 0.9782 - val_loss: 2.1990 - val_acc: 0.5764

Epoch 00011: val_loss did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0744 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.2695 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3024 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2553 - acc: 0.9187
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3645 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3221 - acc: 0.9062
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2874 - acc: 0.9141
 576/1283 [============>.................] - ETA: 0s - loss: 0.3095 - acc: 0.9062
 640/1283 [=============>................] - ETA: 0s - loss: 0.3111 - acc: 0.9016
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2966 - acc: 0.9048
 768/1283 [================>.............] - ETA: 0s - loss: 0.2812 - acc: 0.9076
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2682 - acc: 0.9087
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2724 - acc: 0.9074
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2798 - acc: 0.9031
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2710 - acc: 0.9023
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2580 - acc: 0.9081
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2556 - acc: 0.9080
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2533 - acc: 0.9079
1280/1283 [============================>.] - ETA: 0s - loss: 0.2514 - acc: 0.9078
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2522 - acc: 0.9072 - val_loss: 1.7577 - val_acc: 0.5808

Epoch 00012: val_loss did not improve
Epoch 00012: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=3
max_len=25
nodes=100
mode=all
PCA audio=35
PCA visual=45
PCA text=130
accuracy=0.5903790087463557
best_valid_accuracy=0.48250728862973763
