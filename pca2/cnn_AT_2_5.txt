/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 13:40:01.805272: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 17s - loss: 0.7324 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7841 - acc: 0.5260 
 256/1283 [====>.........................] - ETA: 4s - loss: 0.7727 - acc: 0.5117
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7737 - acc: 0.5031
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7678 - acc: 0.5026
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7518 - acc: 0.5290
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7485 - acc: 0.5254
 576/1283 [============>.................] - ETA: 1s - loss: 0.7424 - acc: 0.5260
 640/1283 [=============>................] - ETA: 1s - loss: 0.7412 - acc: 0.5266
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7382 - acc: 0.5241
 768/1283 [================>.............] - ETA: 1s - loss: 0.7333 - acc: 0.5312
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7303 - acc: 0.5325
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7263 - acc: 0.5354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7201 - acc: 0.5439
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7244 - acc: 0.5423
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7228 - acc: 0.5425
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7190 - acc: 0.5461
1280/1283 [============================>.] - ETA: 0s - loss: 0.7159 - acc: 0.5453
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7154 - acc: 0.5456 - val_loss: 0.7672 - val_acc: 0.5328

Epoch 00001: val_acc improved from -inf to 0.53275, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5963 - acc: 0.6562
 128/1283 [=>............................] - ETA: 0s - loss: 0.5912 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5712 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5619 - acc: 0.6969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5577 - acc: 0.6927
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5527 - acc: 0.7009
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5505 - acc: 0.7051
 576/1283 [============>.................] - ETA: 0s - loss: 0.5378 - acc: 0.7222
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5384 - acc: 0.7088
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5250 - acc: 0.7272
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5164 - acc: 0.7458
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5115 - acc: 0.7480
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5043 - acc: 0.7595
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5029 - acc: 0.7582
1280/1283 [============================>.] - ETA: 0s - loss: 0.5012 - acc: 0.7578
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5010 - acc: 0.7576 - val_loss: 0.7031 - val_acc: 0.5895

Epoch 00002: val_acc improved from 0.53275 to 0.58952, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3832 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3528 - acc: 0.8958
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3351 - acc: 0.9102
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3167 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3178 - acc: 0.8996
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3215 - acc: 0.8965
 576/1283 [============>.................] - ETA: 0s - loss: 0.3215 - acc: 0.8924
 640/1283 [=============>................] - ETA: 0s - loss: 0.3157 - acc: 0.8969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3114 - acc: 0.8977
 768/1283 [================>.............] - ETA: 0s - loss: 0.3120 - acc: 0.8932
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3104 - acc: 0.8954
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3030 - acc: 0.8984
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3026 - acc: 0.9010
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2985 - acc: 0.9026
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2968 - acc: 0.9036
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2950 - acc: 0.9038
1280/1283 [============================>.] - ETA: 0s - loss: 0.2954 - acc: 0.9031
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2956 - acc: 0.9026 - val_loss: 0.7330 - val_acc: 0.6332

Epoch 00003: val_acc improved from 0.58952 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1420 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2080 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2092 - acc: 0.9297
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2043 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1931 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1912 - acc: 0.9442
 576/1283 [============>.................] - ETA: 0s - loss: 0.2105 - acc: 0.9288
 640/1283 [=============>................] - ETA: 0s - loss: 0.2082 - acc: 0.9313
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2026 - acc: 0.9361
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1998 - acc: 0.9363
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2005 - acc: 0.9353
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2025 - acc: 0.9336
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1998 - acc: 0.9347
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1937 - acc: 0.9375
1280/1283 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9367
1283/1283 [==============================] - 1s 938us/step - loss: 0.1944 - acc: 0.9369 - val_loss: 0.9724 - val_acc: 0.5939

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1520 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1222 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1142 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1039 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.1049 - acc: 0.9740
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1013 - acc: 0.9744
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1007 - acc: 0.9712
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0975 - acc: 0.9729
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1008 - acc: 0.9717
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1000 - acc: 0.9714
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0988 - acc: 0.9712
1283/1283 [==============================] - 1s 877us/step - loss: 0.0982 - acc: 0.9719 - val_loss: 0.9023 - val_acc: 0.6463

Epoch 00005: val_acc improved from 0.63319 to 0.64629, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0407 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0679 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0638 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0626 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0565 - acc: 0.9866
 576/1283 [============>.................] - ETA: 0s - loss: 0.0521 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0510 - acc: 0.9901
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0498 - acc: 0.9892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0477 - acc: 0.9906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0486 - acc: 0.9912
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0477 - acc: 0.9908
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0473 - acc: 0.9905
1280/1283 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9906
1283/1283 [==============================] - 1s 925us/step - loss: 0.0459 - acc: 0.9906 - val_loss: 1.0575 - val_acc: 0.6201

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0193 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0186 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0208 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0193 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0193 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0212 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0219 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0217 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0225 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0260 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0270 - acc: 0.9929
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0265 - acc: 0.9940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0253 - acc: 0.9948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0236 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0247 - acc: 0.9942
1283/1283 [==============================] - 1s 959us/step - loss: 0.0243 - acc: 0.9945 - val_loss: 1.1838 - val_acc: 0.6114

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0296 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0277 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0221 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0184 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0218 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0201 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0196 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0199 - acc: 0.9961
 640/1283 [=============>................] - ETA: 0s - loss: 0.0195 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0184 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0185 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0178 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0177 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0187 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0192 - acc: 0.9945
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0181 - acc: 0.9951
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0175 - acc: 0.9953 - val_loss: 1.2649 - val_acc: 0.6157

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0240 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0168 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0203 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0198 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0170 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0157 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0167 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0150 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0137 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0129 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0137 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0137 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0129 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0129 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0127 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0125 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0121 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0117 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0121 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9961
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0126 - acc: 0.9961 - val_loss: 1.3595 - val_acc: 0.6245

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0121 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0130 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0104 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0126 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0124 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0116 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0107 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0095 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0088 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0092 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0093 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0090 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0087 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9969
1283/1283 [==============================] - 1s 918us/step - loss: 0.0095 - acc: 0.9969 - val_loss: 1.4301 - val_acc: 0.6245

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0227 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0145 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0101 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0080 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0069 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0060 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0054 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0049 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0068 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0064 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0074 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0069 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0082 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0078 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0074 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0071 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0073 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0070 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9969
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0080 - acc: 0.9969 - val_loss: 1.8540 - val_acc: 0.6288

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0248 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1388 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1343 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0868 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1232 - acc: 0.9427
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1152 - acc: 0.9473
 576/1283 [============>.................] - ETA: 0s - loss: 0.1143 - acc: 0.9497
 640/1283 [=============>................] - ETA: 0s - loss: 0.1086 - acc: 0.9516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1013 - acc: 0.9560
 768/1283 [================>.............] - ETA: 0s - loss: 0.1107 - acc: 0.9531
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1055 - acc: 0.9555
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0991 - acc: 0.9587
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0999 - acc: 0.9594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0974 - acc: 0.9609
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0945 - acc: 0.9623
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0944 - acc: 0.9618
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0917 - acc: 0.9622
1280/1283 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9633
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0895 - acc: 0.9634 - val_loss: 1.2958 - val_acc: 0.6114

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0331 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0498 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0402 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0336 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0322 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0344 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0363 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0345 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0342 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0324 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0327 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0323 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0312 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0311 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0309 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0296 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0286 - acc: 0.9936
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0276 - acc: 0.9939
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0280 - acc: 0.9934
1280/1283 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9930
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0289 - acc: 0.9930 - val_loss: 1.3268 - val_acc: 0.6070

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0091 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0100 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0117 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0112 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0113 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0160 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0152 - acc: 0.9941
 576/1283 [============>.................] - ETA: 1s - loss: 0.0145 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0136 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0131 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0124 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0131 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0132 - acc: 0.9955
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0129 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0126 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0122 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0123 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9969
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0119 - acc: 0.9969 - val_loss: 1.3982 - val_acc: 0.6245

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0158 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0096 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0080 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0124 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0104 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0099 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0093 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0086 - acc: 0.9980
 576/1283 [============>.................] - ETA: 1s - loss: 0.0089 - acc: 0.9983
 640/1283 [=============>................] - ETA: 1s - loss: 0.0094 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0090 - acc: 0.9972
 768/1283 [================>.............] - ETA: 0s - loss: 0.0084 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0082 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0088 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0084 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0082 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0082 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0084 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0088 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9961
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0094 - acc: 0.9961 - val_loss: 1.5316 - val_acc: 0.6201

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=15
nodes=100
mode=AT
PCA audio=35
PCA visual=45
PCA text=130
accuracy=0.6107871720116618
best_valid_accuracy=0.5903790087463557
