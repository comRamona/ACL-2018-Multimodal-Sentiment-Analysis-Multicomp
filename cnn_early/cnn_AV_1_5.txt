/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 22:27:24.664453: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 1.0661 - acc: 0.3594
 320/1283 [======>.......................] - ETA: 1s - loss: 0.9124 - acc: 0.4844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.8471 - acc: 0.5059
 704/1283 [===============>..............] - ETA: 0s - loss: 0.8162 - acc: 0.5099
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8009 - acc: 0.5192
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7919 - acc: 0.5260
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7772 - acc: 0.5234
1280/1283 [============================>.] - ETA: 0s - loss: 0.7711 - acc: 0.5258
1283/1283 [==============================] - 1s 696us/step - loss: 0.7705 - acc: 0.5269 - val_loss: 0.7190 - val_acc: 0.5197

Epoch 00001: val_acc improved from -inf to 0.51965, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6227 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6630 - acc: 0.5469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6425 - acc: 0.5885
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6337 - acc: 0.6094
 576/1283 [============>.................] - ETA: 0s - loss: 0.6291 - acc: 0.6146
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6234 - acc: 0.6179
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6249 - acc: 0.6262
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6298 - acc: 0.6208
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6277 - acc: 0.6260
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6259 - acc: 0.6311
1283/1283 [==============================] - 1s 583us/step - loss: 0.6262 - acc: 0.6321 - val_loss: 0.7396 - val_acc: 0.4716

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6103 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6018 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5977 - acc: 0.6289
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5936 - acc: 0.6458
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5902 - acc: 0.6562
 640/1283 [=============>................] - ETA: 0s - loss: 0.5771 - acc: 0.6797
 768/1283 [================>.............] - ETA: 0s - loss: 0.5687 - acc: 0.6927
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5611 - acc: 0.7031
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5692 - acc: 0.6985
1280/1283 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7063
1283/1283 [==============================] - 1s 561us/step - loss: 0.5647 - acc: 0.7062 - val_loss: 0.7099 - val_acc: 0.5633

Epoch 00003: val_acc improved from 0.51965 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4404 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4651 - acc: 0.8021
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4953 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5083 - acc: 0.7612
 576/1283 [============>.................] - ETA: 0s - loss: 0.5041 - acc: 0.7569
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4991 - acc: 0.7614
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4964 - acc: 0.7692
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4941 - acc: 0.7698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4923 - acc: 0.7721
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4929 - acc: 0.7697
1283/1283 [==============================] - 1s 569us/step - loss: 0.4911 - acc: 0.7708 - val_loss: 0.7186 - val_acc: 0.5459

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4031 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4190 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4286 - acc: 0.8406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4316 - acc: 0.8393
 576/1283 [============>.................] - ETA: 0s - loss: 0.4411 - acc: 0.8351
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4401 - acc: 0.8324
 768/1283 [================>.............] - ETA: 0s - loss: 0.4440 - acc: 0.8268
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4361 - acc: 0.8250
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4390 - acc: 0.8203
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4400 - acc: 0.8160
1280/1283 [============================>.] - ETA: 0s - loss: 0.4429 - acc: 0.8125
1283/1283 [==============================] - 1s 646us/step - loss: 0.4428 - acc: 0.8122 - val_loss: 0.7575 - val_acc: 0.5677

Epoch 00005: val_acc improved from 0.56332 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4282 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4141 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4136 - acc: 0.8516
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4165 - acc: 0.8438
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4100 - acc: 0.8398
 640/1283 [=============>................] - ETA: 0s - loss: 0.4005 - acc: 0.8406
 768/1283 [================>.............] - ETA: 0s - loss: 0.4040 - acc: 0.8359
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4039 - acc: 0.8305
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4094 - acc: 0.8225
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4057 - acc: 0.8281
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4159 - acc: 0.8125
1280/1283 [============================>.] - ETA: 0s - loss: 0.4190 - acc: 0.8070
1283/1283 [==============================] - 1s 678us/step - loss: 0.4192 - acc: 0.8067 - val_loss: 0.7980 - val_acc: 0.5284

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3564 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.3515 - acc: 0.8672
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3307 - acc: 0.8984
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3355 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3466 - acc: 0.8854
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3536 - acc: 0.8770
 640/1283 [=============>................] - ETA: 0s - loss: 0.3501 - acc: 0.8766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3546 - acc: 0.8736
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3501 - acc: 0.8750
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3487 - acc: 0.8792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3493 - acc: 0.8787
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3479 - acc: 0.8793
1280/1283 [============================>.] - ETA: 0s - loss: 0.3400 - acc: 0.8852
1283/1283 [==============================] - 1s 815us/step - loss: 0.3396 - acc: 0.8854 - val_loss: 0.8377 - val_acc: 0.5415

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2944 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2830 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3163 - acc: 0.8500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3019 - acc: 0.8828
 640/1283 [=============>................] - ETA: 0s - loss: 0.2954 - acc: 0.8922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2954 - acc: 0.8920
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2960 - acc: 0.8942
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2877 - acc: 0.8979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2878 - acc: 0.8980
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2848 - acc: 0.9030
1280/1283 [============================>.] - ETA: 0s - loss: 0.2832 - acc: 0.9039
1283/1283 [==============================] - 1s 646us/step - loss: 0.2833 - acc: 0.9034 - val_loss: 1.0541 - val_acc: 0.5677

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2116 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3152 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2952 - acc: 0.8562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2962 - acc: 0.8616
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3095 - acc: 0.8555
 640/1283 [=============>................] - ETA: 0s - loss: 0.3126 - acc: 0.8578
 768/1283 [================>.............] - ETA: 0s - loss: 0.2992 - acc: 0.8685
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2997 - acc: 0.8683
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2997 - acc: 0.8667
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2972 - acc: 0.8741
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2975 - acc: 0.8725
1283/1283 [==============================] - 1s 646us/step - loss: 0.2989 - acc: 0.8683 - val_loss: 0.7982 - val_acc: 0.5415

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1716 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2404 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3217 - acc: 0.8750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3091 - acc: 0.8880
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2887 - acc: 0.9062
 640/1283 [=============>................] - ETA: 0s - loss: 0.3052 - acc: 0.8875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3137 - acc: 0.8821
 768/1283 [================>.............] - ETA: 0s - loss: 0.3098 - acc: 0.8828
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3004 - acc: 0.8917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3086 - acc: 0.8848
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3151 - acc: 0.8787
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3068 - acc: 0.8849
1280/1283 [============================>.] - ETA: 0s - loss: 0.3014 - acc: 0.8891
1283/1283 [==============================] - 1s 970us/step - loss: 0.3011 - acc: 0.8893 - val_loss: 0.8225 - val_acc: 0.5415

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4331 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.3214 - acc: 0.9609
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2511 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2267 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2222 - acc: 0.9598
 640/1283 [=============>................] - ETA: 0s - loss: 0.2127 - acc: 0.9594
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2208 - acc: 0.9459
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2172 - acc: 0.9473
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2155 - acc: 0.9453
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2132 - acc: 0.9465
1283/1283 [==============================] - 1s 743us/step - loss: 0.2113 - acc: 0.9470 - val_loss: 0.9469 - val_acc: 0.5590

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1776 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.1660 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1604 - acc: 0.9492
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1727 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1652 - acc: 0.9487
 576/1283 [============>.................] - ETA: 0s - loss: 0.1611 - acc: 0.9497
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1582 - acc: 0.9531
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1589 - acc: 0.9519
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1603 - acc: 0.9510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1663 - acc: 0.9531
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1663 - acc: 0.9531
1280/1283 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9531
1283/1283 [==============================] - 1s 757us/step - loss: 0.1636 - acc: 0.9532 - val_loss: 0.9736 - val_acc: 0.5284

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1559 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1435 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1477 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1398 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1280 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1227 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.1187 - acc: 0.9757
 640/1283 [=============>................] - ETA: 0s - loss: 0.1180 - acc: 0.9781
 768/1283 [================>.............] - ETA: 0s - loss: 0.1205 - acc: 0.9727
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1167 - acc: 0.9754
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1199 - acc: 0.9727
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1181 - acc: 0.9740
1280/1283 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9727
1283/1283 [==============================] - 1s 887us/step - loss: 0.1204 - acc: 0.9727 - val_loss: 1.1497 - val_acc: 0.5502

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0743 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0938 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1221 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1153 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1142 - acc: 0.9727
 576/1283 [============>.................] - ETA: 0s - loss: 0.1147 - acc: 0.9740
 640/1283 [=============>................] - ETA: 0s - loss: 0.1218 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1182 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1202 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1187 - acc: 0.9732
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1178 - acc: 0.9740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1132 - acc: 0.9770
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1149 - acc: 0.9766
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1125 - acc: 0.9778
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1129 - acc: 0.9766 - val_loss: 1.1681 - val_acc: 0.5328

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0797 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2408 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2071 - acc: 0.9156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2045 - acc: 0.9174
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2012 - acc: 0.9180
 640/1283 [=============>................] - ETA: 0s - loss: 0.2005 - acc: 0.9141
 768/1283 [================>.............] - ETA: 0s - loss: 0.1891 - acc: 0.9219
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1844 - acc: 0.9263
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1820 - acc: 0.9268
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1770 - acc: 0.9283
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1730 - acc: 0.9309
1283/1283 [==============================] - 1s 876us/step - loss: 0.1713 - acc: 0.9314 - val_loss: 1.2441 - val_acc: 0.5677

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
epochs=100
mode=AV
accuracy=0.48833819241982507
best_valid_accuracy=0.48542274052478135
