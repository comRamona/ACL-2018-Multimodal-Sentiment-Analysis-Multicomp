/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 22:39:17.303946: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.7315 - acc: 0.5156
 128/1283 [=>............................] - ETA: 2s - loss: 0.7243 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7279 - acc: 0.5000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.7066 - acc: 0.5273
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7216 - acc: 0.5156
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7261 - acc: 0.5052
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7299 - acc: 0.5045
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7239 - acc: 0.5137
 576/1283 [============>.................] - ETA: 0s - loss: 0.7150 - acc: 0.5208
 640/1283 [=============>................] - ETA: 0s - loss: 0.7115 - acc: 0.5312
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7222 - acc: 0.5256
 768/1283 [================>.............] - ETA: 0s - loss: 0.7252 - acc: 0.5182
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7235 - acc: 0.5192
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7191 - acc: 0.5212
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7162 - acc: 0.5240
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7151 - acc: 0.5205
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7137 - acc: 0.5230
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7100 - acc: 0.5296
1280/1283 [============================>.] - ETA: 0s - loss: 0.7110 - acc: 0.5258
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7110 - acc: 0.5261 - val_loss: 0.6955 - val_acc: 0.5153

Epoch 00001: val_acc improved from -inf to 0.51528, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6296 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6386 - acc: 0.6641
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6453 - acc: 0.6510
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6450 - acc: 0.6367
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6587 - acc: 0.6000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6545 - acc: 0.5990
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6599 - acc: 0.5982
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6651 - acc: 0.5781
 576/1283 [============>.................] - ETA: 0s - loss: 0.6652 - acc: 0.5799
 640/1283 [=============>................] - ETA: 0s - loss: 0.6657 - acc: 0.5828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6645 - acc: 0.5866
 768/1283 [================>.............] - ETA: 0s - loss: 0.6614 - acc: 0.5898
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6603 - acc: 0.5938
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6591 - acc: 0.5938
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6575 - acc: 0.5969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6568 - acc: 0.5967
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6559 - acc: 0.6002
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6573 - acc: 0.5972
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6567 - acc: 0.5987
1280/1283 [============================>.] - ETA: 0s - loss: 0.6544 - acc: 0.6000
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6542 - acc: 0.6009 - val_loss: 0.7057 - val_acc: 0.5197

Epoch 00002: val_acc improved from 0.51528 to 0.51965, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6278 - acc: 0.5938
 128/1283 [=>............................] - ETA: 1s - loss: 0.6280 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6392 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6303 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6302 - acc: 0.6281
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6276 - acc: 0.6328
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6228 - acc: 0.6384
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6165 - acc: 0.6445
 576/1283 [============>.................] - ETA: 0s - loss: 0.6107 - acc: 0.6545
 640/1283 [=============>................] - ETA: 0s - loss: 0.6085 - acc: 0.6547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6116 - acc: 0.6406
 768/1283 [================>.............] - ETA: 0s - loss: 0.6092 - acc: 0.6471
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6059 - acc: 0.6502
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6043 - acc: 0.6529
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6083 - acc: 0.6523
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6091 - acc: 0.6544
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6129 - acc: 0.6502
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6106 - acc: 0.6497
1280/1283 [============================>.] - ETA: 0s - loss: 0.6104 - acc: 0.6500
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6104 - acc: 0.6493 - val_loss: 0.7112 - val_acc: 0.5415

Epoch 00003: val_acc improved from 0.51965 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5973 - acc: 0.6719
 128/1283 [=>............................] - ETA: 1s - loss: 0.5970 - acc: 0.6641
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5770 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5478 - acc: 0.7305
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5471 - acc: 0.7240
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5407 - acc: 0.7411
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5428 - acc: 0.7324
 576/1283 [============>.................] - ETA: 0s - loss: 0.5496 - acc: 0.7257
 640/1283 [=============>................] - ETA: 0s - loss: 0.5464 - acc: 0.7234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5483 - acc: 0.7230
 768/1283 [================>.............] - ETA: 0s - loss: 0.5549 - acc: 0.7161
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5560 - acc: 0.7175
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5575 - acc: 0.7154
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5566 - acc: 0.7188
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5553 - acc: 0.7205
1280/1283 [============================>.] - ETA: 0s - loss: 0.5560 - acc: 0.7164
1283/1283 [==============================] - 1s 896us/step - loss: 0.5567 - acc: 0.7155 - val_loss: 0.8012 - val_acc: 0.4978

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5006 - acc: 0.6875
 128/1283 [=>............................] - ETA: 0s - loss: 0.5046 - acc: 0.7109
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4892 - acc: 0.7083
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4967 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5036 - acc: 0.7312
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5163 - acc: 0.7240
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5198 - acc: 0.7254
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5311 - acc: 0.7168
 576/1283 [============>.................] - ETA: 0s - loss: 0.5331 - acc: 0.7257
 640/1283 [=============>................] - ETA: 0s - loss: 0.5279 - acc: 0.7344
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5296 - acc: 0.7287
 768/1283 [================>.............] - ETA: 0s - loss: 0.5299 - acc: 0.7292
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5233 - acc: 0.7380
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5170 - acc: 0.7467
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5183 - acc: 0.7417
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5167 - acc: 0.7393
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5173 - acc: 0.7390
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5152 - acc: 0.7422
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5146 - acc: 0.7418
1280/1283 [============================>.] - ETA: 0s - loss: 0.5151 - acc: 0.7430
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5154 - acc: 0.7428 - val_loss: 0.7565 - val_acc: 0.5459

Epoch 00005: val_acc improved from 0.54148 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3604 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.3707 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4307 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4252 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4236 - acc: 0.8250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4215 - acc: 0.8255
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4234 - acc: 0.8259
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4172 - acc: 0.8340
 576/1283 [============>.................] - ETA: 0s - loss: 0.4103 - acc: 0.8368
 640/1283 [=============>................] - ETA: 0s - loss: 0.4136 - acc: 0.8313
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4176 - acc: 0.8295
 768/1283 [================>.............] - ETA: 0s - loss: 0.4094 - acc: 0.8333
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4103 - acc: 0.8341
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4091 - acc: 0.8304
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4088 - acc: 0.8271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4142 - acc: 0.8213
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4169 - acc: 0.8189
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4151 - acc: 0.8168
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4123 - acc: 0.8191
1280/1283 [============================>.] - ETA: 0s - loss: 0.4145 - acc: 0.8172
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4149 - acc: 0.8168 - val_loss: 1.4102 - val_acc: 0.5546

Epoch 00006: val_acc improved from 0.54585 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5855 - acc: 0.6250
 128/1283 [=>............................] - ETA: 1s - loss: 0.7345 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.7321 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6823 - acc: 0.6523
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6195 - acc: 0.6844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6039 - acc: 0.6901
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5899 - acc: 0.7031
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5811 - acc: 0.7090
 576/1283 [============>.................] - ETA: 0s - loss: 0.5729 - acc: 0.7101
 640/1283 [=============>................] - ETA: 0s - loss: 0.5546 - acc: 0.7219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5414 - acc: 0.7287
 768/1283 [================>.............] - ETA: 0s - loss: 0.5317 - acc: 0.7357
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5208 - acc: 0.7333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5073 - acc: 0.7422
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5026 - acc: 0.7445
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4905 - acc: 0.7543
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4864 - acc: 0.7590
1280/1283 [============================>.] - ETA: 0s - loss: 0.4793 - acc: 0.7672
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4796 - acc: 0.7662 - val_loss: 0.7445 - val_acc: 0.6070

Epoch 00007: val_acc improved from 0.55459 to 0.60699, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_30.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3515 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.3514 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3272 - acc: 0.9271
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3165 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3169 - acc: 0.9115
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3209 - acc: 0.9062
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3243 - acc: 0.9004
 576/1283 [============>.................] - ETA: 0s - loss: 0.3181 - acc: 0.9028
 640/1283 [=============>................] - ETA: 0s - loss: 0.3172 - acc: 0.9016
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3176 - acc: 0.9006
 768/1283 [================>.............] - ETA: 0s - loss: 0.3145 - acc: 0.8958
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3153 - acc: 0.8942
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3094 - acc: 0.8938
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3070 - acc: 0.8888
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3151 - acc: 0.8915
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3108 - acc: 0.8914
1280/1283 [============================>.] - ETA: 0s - loss: 0.3085 - acc: 0.8898
1283/1283 [==============================] - 1s 975us/step - loss: 0.3089 - acc: 0.8893 - val_loss: 1.0785 - val_acc: 0.5721

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2683 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.2953 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3690 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3622 - acc: 0.8406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3850 - acc: 0.8304
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3788 - acc: 0.8340
 576/1283 [============>.................] - ETA: 0s - loss: 0.3714 - acc: 0.8351
 640/1283 [=============>................] - ETA: 0s - loss: 0.3582 - acc: 0.8438
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3457 - acc: 0.8480
 768/1283 [================>.............] - ETA: 0s - loss: 0.3470 - acc: 0.8451
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3436 - acc: 0.8462
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3474 - acc: 0.8382
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3391 - acc: 0.8438
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3347 - acc: 0.8477
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3257 - acc: 0.8524
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3257 - acc: 0.8561
1280/1283 [============================>.] - ETA: 0s - loss: 0.3204 - acc: 0.8594
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3208 - acc: 0.8597 - val_loss: 0.9299 - val_acc: 0.5328

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2318 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2126 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2085 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2105 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2253 - acc: 0.9000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2419 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2370 - acc: 0.8929
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2272 - acc: 0.9023
 576/1283 [============>.................] - ETA: 0s - loss: 0.2235 - acc: 0.9080
 640/1283 [=============>................] - ETA: 0s - loss: 0.2246 - acc: 0.9109
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2213 - acc: 0.9148
 768/1283 [================>.............] - ETA: 0s - loss: 0.2106 - acc: 0.9219
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2089 - acc: 0.9231
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2187 - acc: 0.9174
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2194 - acc: 0.9146
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2148 - acc: 0.9160
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2115 - acc: 0.9164
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2084 - acc: 0.9184
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2098 - acc: 0.9186
1280/1283 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9219
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2043 - acc: 0.9221 - val_loss: 1.0458 - val_acc: 0.5459

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1512 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1366 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1255 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1159 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1197 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1261 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1212 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1188 - acc: 0.9707
 576/1283 [============>.................] - ETA: 0s - loss: 0.1220 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.1251 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1247 - acc: 0.9602
 768/1283 [================>.............] - ETA: 0s - loss: 0.1240 - acc: 0.9596
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1237 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1229 - acc: 0.9587
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1214 - acc: 0.9604
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1187 - acc: 0.9629
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1200 - acc: 0.9605
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1243 - acc: 0.9601
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1253 - acc: 0.9589
1280/1283 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9602
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1250 - acc: 0.9587 - val_loss: 1.8861 - val_acc: 0.5284

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2767 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.4273 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7195 - acc: 0.7760
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6822 - acc: 0.7773
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6156 - acc: 0.7844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5568 - acc: 0.8073
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5799 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6009 - acc: 0.7930
 576/1283 [============>.................] - ETA: 1s - loss: 0.6351 - acc: 0.7726
 640/1283 [=============>................] - ETA: 0s - loss: 0.6071 - acc: 0.7734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5944 - acc: 0.7827
 768/1283 [================>.............] - ETA: 0s - loss: 0.5776 - acc: 0.7852
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5635 - acc: 0.7861
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5627 - acc: 0.7835
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5648 - acc: 0.7802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5591 - acc: 0.7764
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5430 - acc: 0.7822
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5275 - acc: 0.7891
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5130 - acc: 0.7977
1280/1283 [============================>.] - ETA: 0s - loss: 0.5018 - acc: 0.8016
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5012 - acc: 0.8020 - val_loss: 0.8297 - val_acc: 0.5721

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.3934 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.3128 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 2s - loss: 0.2983 - acc: 0.8646
 256/1283 [====>.........................] - ETA: 2s - loss: 0.2900 - acc: 0.8711
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3243 - acc: 0.8844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3313 - acc: 0.8984
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3156 - acc: 0.9040
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3183 - acc: 0.8984
 576/1283 [============>.................] - ETA: 1s - loss: 0.3124 - acc: 0.8941
 640/1283 [=============>................] - ETA: 1s - loss: 0.3076 - acc: 0.8906
 704/1283 [===============>..............] - ETA: 1s - loss: 0.2925 - acc: 0.9006
 768/1283 [================>.............] - ETA: 1s - loss: 0.2784 - acc: 0.9089
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2751 - acc: 0.9099
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2697 - acc: 0.9118
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2667 - acc: 0.9135
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2648 - acc: 0.9121
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2599 - acc: 0.9164
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2556 - acc: 0.9184
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2527 - acc: 0.9202
1280/1283 [============================>.] - ETA: 0s - loss: 0.2463 - acc: 0.9242
1283/1283 [==============================] - 3s 2ms/step - loss: 0.2464 - acc: 0.9244 - val_loss: 1.0922 - val_acc: 0.5808

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1164 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1465 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2394 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2211 - acc: 0.9492
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1935 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1815 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1709 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1748 - acc: 0.9590
 576/1283 [============>.................] - ETA: 1s - loss: 0.1670 - acc: 0.9618
 640/1283 [=============>................] - ETA: 1s - loss: 0.1587 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1581 - acc: 0.9645
 768/1283 [================>.............] - ETA: 0s - loss: 0.1658 - acc: 0.9609
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1635 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1631 - acc: 0.9576
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1612 - acc: 0.9563
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1591 - acc: 0.9561
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1546 - acc: 0.9586
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1537 - acc: 0.9566
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1515 - acc: 0.9564
1280/1283 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9570
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1484 - acc: 0.9571 - val_loss: 1.2864 - val_acc: 0.5852

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0881 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0983 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1688 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1619 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1545 - acc: 0.9281
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1507 - acc: 0.9349
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1471 - acc: 0.9330
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1419 - acc: 0.9336
 576/1283 [============>.................] - ETA: 1s - loss: 0.1394 - acc: 0.9358
 640/1283 [=============>................] - ETA: 1s - loss: 0.1437 - acc: 0.9344
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1571 - acc: 0.9375
 768/1283 [================>.............] - ETA: 0s - loss: 0.1538 - acc: 0.9388
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1475 - acc: 0.9435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1423 - acc: 0.9464
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1452 - acc: 0.9437
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1420 - acc: 0.9453
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1387 - acc: 0.9476
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1343 - acc: 0.9497
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1335 - acc: 0.9515
1280/1283 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9523
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1330 - acc: 0.9525 - val_loss: 1.3119 - val_acc: 0.5371

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0590 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0725 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0736 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0691 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0777 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0714 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0689 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0659 - acc: 0.9805
 576/1283 [============>.................] - ETA: 1s - loss: 0.0642 - acc: 0.9809
 640/1283 [=============>................] - ETA: 1s - loss: 0.0620 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0620 - acc: 0.9830
 768/1283 [================>.............] - ETA: 0s - loss: 0.0637 - acc: 0.9805
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0630 - acc: 0.9820
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0622 - acc: 0.9833
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0626 - acc: 0.9823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0786 - acc: 0.9805
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0774 - acc: 0.9807
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0754 - acc: 0.9818
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0733 - acc: 0.9827
1280/1283 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9836
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0715 - acc: 0.9836 - val_loss: 1.6154 - val_acc: 0.5590

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0460 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0514 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0460 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0429 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0452 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0429 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0401 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0425 - acc: 0.9922
 576/1283 [============>.................] - ETA: 1s - loss: 0.0413 - acc: 0.9913
 640/1283 [=============>................] - ETA: 1s - loss: 0.0399 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0382 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0379 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0384 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0371 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0359 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0511 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0489 - acc: 0.9936
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0493 - acc: 0.9922
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0477 - acc: 0.9926
1280/1283 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9922
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0468 - acc: 0.9922 - val_loss: 1.6981 - val_acc: 0.5590

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=3
max_len=30
epochs=100
mode=AV
accuracy=0.5087463556851312
best_valid_accuracy=0.5481049562682215
