/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 22:47:41.009131: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.7404 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7205 - acc: 0.5625
 320/1283 [======>.......................] - ETA: 0s - loss: 0.7308 - acc: 0.5437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7224 - acc: 0.5402
 576/1283 [============>.................] - ETA: 0s - loss: 0.7111 - acc: 0.5469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7164 - acc: 0.5355
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7245 - acc: 0.5337
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7240 - acc: 0.5396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7187 - acc: 0.5478
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7106 - acc: 0.5559
1283/1283 [==============================] - 1s 788us/step - loss: 0.7108 - acc: 0.5565 - val_loss: 0.6913 - val_acc: 0.5852

Epoch 00001: val_acc improved from -inf to 0.58515, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5446 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5161 - acc: 0.7708
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5318 - acc: 0.7281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5324 - acc: 0.7098
 576/1283 [============>.................] - ETA: 0s - loss: 0.5272 - acc: 0.7257
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5185 - acc: 0.7415
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5120 - acc: 0.7536
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5047 - acc: 0.7646
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5014 - acc: 0.7676
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4933 - acc: 0.7717
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4890 - acc: 0.7738
1283/1283 [==============================] - 1s 688us/step - loss: 0.4869 - acc: 0.7747 - val_loss: 0.6743 - val_acc: 0.6900

Epoch 00002: val_acc improved from 0.58515 to 0.68996, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4197 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3369 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3633 - acc: 0.8406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3831 - acc: 0.8371
 576/1283 [============>.................] - ETA: 0s - loss: 0.3741 - acc: 0.8385
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3668 - acc: 0.8395
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3598 - acc: 0.8462
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3669 - acc: 0.8417
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3607 - acc: 0.8483
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3513 - acc: 0.8528
1280/1283 [============================>.] - ETA: 0s - loss: 0.3474 - acc: 0.8555
1283/1283 [==============================] - 1s 650us/step - loss: 0.3470 - acc: 0.8558 - val_loss: 0.6722 - val_acc: 0.6769

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1864 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2089 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2247 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2299 - acc: 0.9174
 576/1283 [============>.................] - ETA: 0s - loss: 0.2232 - acc: 0.9236
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2212 - acc: 0.9233
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2237 - acc: 0.9231
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2172 - acc: 0.9229
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2126 - acc: 0.9237
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2061 - acc: 0.9252
1283/1283 [==============================] - 1s 654us/step - loss: 0.2053 - acc: 0.9260 - val_loss: 0.8049 - val_acc: 0.6070

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1307 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1814 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1713 - acc: 0.9344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1651 - acc: 0.9397
 576/1283 [============>.................] - ETA: 0s - loss: 0.1625 - acc: 0.9410
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1539 - acc: 0.9460
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1521 - acc: 0.9495
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1497 - acc: 0.9510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1494 - acc: 0.9504
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1497 - acc: 0.9490
1283/1283 [==============================] - 1s 661us/step - loss: 0.1502 - acc: 0.9478 - val_loss: 0.8774 - val_acc: 0.6376

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1090 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0955 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1036 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1078 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.1034 - acc: 0.9635
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1068 - acc: 0.9602
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1062 - acc: 0.9603
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1083 - acc: 0.9583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1114 - acc: 0.9586
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1088 - acc: 0.9605
1283/1283 [==============================] - 1s 701us/step - loss: 0.1067 - acc: 0.9618 - val_loss: 1.1263 - val_acc: 0.6419

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0728 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0807 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0727 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0725 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.0751 - acc: 0.9826
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0746 - acc: 0.9815
 768/1283 [================>.............] - ETA: 0s - loss: 0.0762 - acc: 0.9792
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0744 - acc: 0.9777
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0682 - acc: 0.9805
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0665 - acc: 0.9809
1280/1283 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9812
1283/1283 [==============================] - 1s 801us/step - loss: 0.0649 - acc: 0.9813 - val_loss: 1.0976 - val_acc: 0.6550

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0569 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0357 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0351 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0345 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0409 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0451 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0447 - acc: 0.9859
 768/1283 [================>.............] - ETA: 0s - loss: 0.0441 - acc: 0.9870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0445 - acc: 0.9856
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0419 - acc: 0.9875
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0430 - acc: 0.9862
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0430 - acc: 0.9861
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0418 - acc: 0.9868
1283/1283 [==============================] - 1s 825us/step - loss: 0.0406 - acc: 0.9875 - val_loss: 1.2948 - val_acc: 0.6157

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0151 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0261 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0246 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0347 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0319 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0298 - acc: 0.9931
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0283 - acc: 0.9943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0292 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0282 - acc: 0.9955
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0292 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0305 - acc: 0.9936
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0309 - acc: 0.9931
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0305 - acc: 0.9934
1280/1283 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9914
1283/1283 [==============================] - 1s 921us/step - loss: 0.0323 - acc: 0.9914 - val_loss: 1.2649 - val_acc: 0.6463

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0282 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0274 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0209 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0218 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0193 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0169 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0153 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0149 - acc: 0.9941
 640/1283 [=============>................] - ETA: 0s - loss: 0.0186 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0202 - acc: 0.9901
 768/1283 [================>.............] - ETA: 0s - loss: 0.0190 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0191 - acc: 0.9916
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0196 - acc: 0.9917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0206 - acc: 0.9912
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0221 - acc: 0.9908
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0222 - acc: 0.9905
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0214 - acc: 0.9910
1283/1283 [==============================] - 1s 990us/step - loss: 0.0215 - acc: 0.9906 - val_loss: 1.2823 - val_acc: 0.6638

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0255 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0348 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0304 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0274 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0368 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0663 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0657 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0697 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0628 - acc: 0.9857
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0572 - acc: 0.9866
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0736 - acc: 0.9814
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0700 - acc: 0.9800
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0699 - acc: 0.9803
1280/1283 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9789
1283/1283 [==============================] - 1s 810us/step - loss: 0.0728 - acc: 0.9790 - val_loss: 1.3388 - val_acc: 0.6681

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0236 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0734 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0766 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0628 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0596 - acc: 0.9785
 576/1283 [============>.................] - ETA: 0s - loss: 0.0585 - acc: 0.9792
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0568 - acc: 0.9815
 768/1283 [================>.............] - ETA: 0s - loss: 0.0556 - acc: 0.9818
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0529 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0518 - acc: 0.9833
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0538 - acc: 0.9825
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0514 - acc: 0.9835
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0541 - acc: 0.9819
1280/1283 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9797
1283/1283 [==============================] - 1s 888us/step - loss: 0.0587 - acc: 0.9797 - val_loss: 1.3542 - val_acc: 0.6594

Epoch 00012: val_acc did not improve
Epoch 00012: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=15
epochs=100
mode=VT
accuracy=0.6049562682215743
best_valid_accuracy=0.6559766763848397
