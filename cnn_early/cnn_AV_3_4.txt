/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 22:39:16.259376: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.7315 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7317 - acc: 0.5052
 320/1283 [======>.......................] - ETA: 0s - loss: 0.7207 - acc: 0.5094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7294 - acc: 0.5156
 576/1283 [============>.................] - ETA: 0s - loss: 0.7147 - acc: 0.5312
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7245 - acc: 0.5327
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7264 - acc: 0.5252
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7216 - acc: 0.5324
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7182 - acc: 0.5344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7168 - acc: 0.5312
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7153 - acc: 0.5322
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7156 - acc: 0.5304
1280/1283 [============================>.] - ETA: 0s - loss: 0.7122 - acc: 0.5320
1283/1283 [==============================] - 1s 881us/step - loss: 0.7123 - acc: 0.5316 - val_loss: 0.6953 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6300 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6479 - acc: 0.6562
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6551 - acc: 0.6219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6507 - acc: 0.6276
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6536 - acc: 0.6272
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6594 - acc: 0.6055
 576/1283 [============>.................] - ETA: 0s - loss: 0.6591 - acc: 0.6042
 640/1283 [=============>................] - ETA: 0s - loss: 0.6604 - acc: 0.5984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6597 - acc: 0.6023
 768/1283 [================>.............] - ETA: 0s - loss: 0.6571 - acc: 0.6042
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6559 - acc: 0.5993
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6557 - acc: 0.6000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6559 - acc: 0.6006
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6543 - acc: 0.6066
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6559 - acc: 0.6033
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6546 - acc: 0.6061
1280/1283 [============================>.] - ETA: 0s - loss: 0.6528 - acc: 0.6086
1283/1283 [==============================] - 1s 922us/step - loss: 0.6526 - acc: 0.6095 - val_loss: 0.6986 - val_acc: 0.5371

Epoch 00002: val_acc improved from 0.53712 to 0.53712, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6223 - acc: 0.6562
 128/1283 [=>............................] - ETA: 0s - loss: 0.6210 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6296 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6218 - acc: 0.6094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6230 - acc: 0.6172
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6167 - acc: 0.6295
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6118 - acc: 0.6406
 576/1283 [============>.................] - ETA: 0s - loss: 0.6066 - acc: 0.6545
 640/1283 [=============>................] - ETA: 0s - loss: 0.6043 - acc: 0.6562
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6079 - acc: 0.6449
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6032 - acc: 0.6526
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6010 - acc: 0.6562
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6044 - acc: 0.6521
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6053 - acc: 0.6523
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6100 - acc: 0.6536
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6073 - acc: 0.6571
1280/1283 [============================>.] - ETA: 0s - loss: 0.6074 - acc: 0.6570
1283/1283 [==============================] - 1s 967us/step - loss: 0.6074 - acc: 0.6563 - val_loss: 0.7133 - val_acc: 0.4978

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6119 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.5913 - acc: 0.7109
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5714 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5400 - acc: 0.7578
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5606 - acc: 0.7281
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5440 - acc: 0.7422
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5405 - acc: 0.7522
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5410 - acc: 0.7461
 576/1283 [============>.................] - ETA: 0s - loss: 0.5446 - acc: 0.7431
 640/1283 [=============>................] - ETA: 0s - loss: 0.5433 - acc: 0.7391
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5460 - acc: 0.7386
 768/1283 [================>.............] - ETA: 0s - loss: 0.5499 - acc: 0.7318
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5501 - acc: 0.7332
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5549 - acc: 0.7271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5542 - acc: 0.7279
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5518 - acc: 0.7309
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5516 - acc: 0.7270
1280/1283 [============================>.] - ETA: 0s - loss: 0.5517 - acc: 0.7250
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5519 - acc: 0.7241 - val_loss: 0.7782 - val_acc: 0.4891

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4866 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.4742 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4563 - acc: 0.7552
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4757 - acc: 0.7344
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4761 - acc: 0.7469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4821 - acc: 0.7500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4855 - acc: 0.7567
 576/1283 [============>.................] - ETA: 0s - loss: 0.4982 - acc: 0.7622
 640/1283 [=============>................] - ETA: 0s - loss: 0.4938 - acc: 0.7672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4928 - acc: 0.7656
 768/1283 [================>.............] - ETA: 0s - loss: 0.4864 - acc: 0.7708
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4809 - acc: 0.7752
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4750 - acc: 0.7824
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4773 - acc: 0.7760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4744 - acc: 0.7783
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4718 - acc: 0.7812
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4712 - acc: 0.7771
1280/1283 [============================>.] - ETA: 0s - loss: 0.4711 - acc: 0.7766
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4713 - acc: 0.7763 - val_loss: 0.7988 - val_acc: 0.5852

Epoch 00005: val_acc improved from 0.53712 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3615 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.3719 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4276 - acc: 0.8021
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4140 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4044 - acc: 0.8094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3982 - acc: 0.8151
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3973 - acc: 0.8192
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3903 - acc: 0.8262
 576/1283 [============>.................] - ETA: 0s - loss: 0.3895 - acc: 0.8264
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3974 - acc: 0.8224
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3910 - acc: 0.8317
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3892 - acc: 0.8292
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3847 - acc: 0.8313
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3878 - acc: 0.8291
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3893 - acc: 0.8290
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3868 - acc: 0.8281
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3851 - acc: 0.8298
1280/1283 [============================>.] - ETA: 0s - loss: 0.3875 - acc: 0.8281
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3874 - acc: 0.8285 - val_loss: 1.1919 - val_acc: 0.5590

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3887 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.5428 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5477 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5230 - acc: 0.7266
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4903 - acc: 0.7562
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4832 - acc: 0.7604
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4718 - acc: 0.7723
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4679 - acc: 0.7754
 576/1283 [============>.................] - ETA: 0s - loss: 0.4514 - acc: 0.7865
 640/1283 [=============>................] - ETA: 0s - loss: 0.4380 - acc: 0.7969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4345 - acc: 0.7955
 768/1283 [================>.............] - ETA: 0s - loss: 0.4388 - acc: 0.7917
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4366 - acc: 0.7897
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4255 - acc: 0.7991
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4183 - acc: 0.8073
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4133 - acc: 0.8096
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4069 - acc: 0.8162
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4006 - acc: 0.8212
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4012 - acc: 0.8207
1280/1283 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8258
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3951 - acc: 0.8262 - val_loss: 0.8266 - val_acc: 0.5502

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2284 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.2408 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2366 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2463 - acc: 0.8984
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2495 - acc: 0.9000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2528 - acc: 0.8958
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2445 - acc: 0.9040
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2462 - acc: 0.9004
 576/1283 [============>.................] - ETA: 0s - loss: 0.2418 - acc: 0.9062
 640/1283 [=============>................] - ETA: 0s - loss: 0.2411 - acc: 0.9094
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2392 - acc: 0.9134
 768/1283 [================>.............] - ETA: 0s - loss: 0.2466 - acc: 0.9128
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2469 - acc: 0.9123
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2446 - acc: 0.9141
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2410 - acc: 0.9146
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2431 - acc: 0.9111
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2384 - acc: 0.9127
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2348 - acc: 0.9141
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2308 - acc: 0.9145
1280/1283 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.9141
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2307 - acc: 0.9135 - val_loss: 1.2118 - val_acc: 0.5371

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2098 - acc: 0.8906
 128/1283 [=>............................] - ETA: 0s - loss: 0.2837 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3897 - acc: 0.8073
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3273 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3097 - acc: 0.8562
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3352 - acc: 0.8333
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3865 - acc: 0.8103
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3754 - acc: 0.8125
 576/1283 [============>.................] - ETA: 0s - loss: 0.3608 - acc: 0.8177
 640/1283 [=============>................] - ETA: 0s - loss: 0.3415 - acc: 0.8313
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3392 - acc: 0.8352
 768/1283 [================>.............] - ETA: 0s - loss: 0.3432 - acc: 0.8281
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3427 - acc: 0.8281
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3477 - acc: 0.8270
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3349 - acc: 0.8375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3285 - acc: 0.8428
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3270 - acc: 0.8456
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3272 - acc: 0.8446
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3259 - acc: 0.8487
1280/1283 [============================>.] - ETA: 0s - loss: 0.3219 - acc: 0.8516
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3229 - acc: 0.8511 - val_loss: 0.8854 - val_acc: 0.5240

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1752 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1859 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1898 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1965 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2027 - acc: 0.9250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2068 - acc: 0.9271
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2052 - acc: 0.9330
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2029 - acc: 0.9355
 640/1283 [=============>................] - ETA: 0s - loss: 0.2115 - acc: 0.9250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2093 - acc: 0.9233
 768/1283 [================>.............] - ETA: 0s - loss: 0.1975 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1953 - acc: 0.9303
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2000 - acc: 0.9275
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1928 - acc: 0.9316
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1894 - acc: 0.9338
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1876 - acc: 0.9340
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1867 - acc: 0.9342
1280/1283 [============================>.] - ETA: 0s - loss: 0.1826 - acc: 0.9367
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1822 - acc: 0.9369 - val_loss: 1.0861 - val_acc: 0.5240

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1055 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0889 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0978 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1032 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1008 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1051 - acc: 0.9740
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1019 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1005 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.1018 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.1023 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1049 - acc: 0.9688
 768/1283 [================>.............] - ETA: 0s - loss: 0.1023 - acc: 0.9714
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1015 - acc: 0.9700
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1036 - acc: 0.9665
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1010 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0997 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0998 - acc: 0.9697
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1004 - acc: 0.9705
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1012 - acc: 0.9688
1280/1283 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9703
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1005 - acc: 0.9696 - val_loss: 1.4159 - val_acc: 0.5459

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1380 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.2541 - acc: 0.8672
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3773 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3292 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2890 - acc: 0.8719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2804 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3006 - acc: 0.8728
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3079 - acc: 0.8711
 576/1283 [============>.................] - ETA: 0s - loss: 0.2987 - acc: 0.8785
 640/1283 [=============>................] - ETA: 0s - loss: 0.2781 - acc: 0.8891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2857 - acc: 0.8878
 768/1283 [================>.............] - ETA: 0s - loss: 0.2884 - acc: 0.8867
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2832 - acc: 0.8882
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2783 - acc: 0.8906
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2690 - acc: 0.8969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2675 - acc: 0.8945
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2649 - acc: 0.8943
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2789 - acc: 0.8889
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2732 - acc: 0.8914
1280/1283 [============================>.] - ETA: 0s - loss: 0.2681 - acc: 0.8930
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2675 - acc: 0.8932 - val_loss: 1.1750 - val_acc: 0.5852

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1472 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1550 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1473 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1453 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1747 - acc: 0.9500
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1697 - acc: 0.9505
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1637 - acc: 0.9531
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1616 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1579 - acc: 0.9566
 640/1283 [=============>................] - ETA: 0s - loss: 0.1625 - acc: 0.9500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1699 - acc: 0.9474
 768/1283 [================>.............] - ETA: 0s - loss: 0.1648 - acc: 0.9492
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1609 - acc: 0.9519
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1574 - acc: 0.9531
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1524 - acc: 0.9552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1484 - acc: 0.9570
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1483 - acc: 0.9550
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1462 - acc: 0.9549
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1436 - acc: 0.9556
1280/1283 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9570
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1416 - acc: 0.9571 - val_loss: 1.1990 - val_acc: 0.5502

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0648 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0885 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0864 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0819 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0763 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0716 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0692 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0744 - acc: 0.9883
 576/1283 [============>.................] - ETA: 1s - loss: 0.0707 - acc: 0.9878
 640/1283 [=============>................] - ETA: 1s - loss: 0.0688 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0674 - acc: 0.9886
 768/1283 [================>.............] - ETA: 0s - loss: 0.0694 - acc: 0.9857
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0689 - acc: 0.9868
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0685 - acc: 0.9877
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0687 - acc: 0.9875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0678 - acc: 0.9883
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0658 - acc: 0.9890
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0655 - acc: 0.9896
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0639 - acc: 0.9901
1280/1283 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9891
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0663 - acc: 0.9891 - val_loss: 1.3127 - val_acc: 0.5415

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1361 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0920 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0712 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0619 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0584 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0562 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0578 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0539 - acc: 0.9883
 576/1283 [============>.................] - ETA: 0s - loss: 0.0502 - acc: 0.9896
 640/1283 [=============>................] - ETA: 0s - loss: 0.0476 - acc: 0.9906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0455 - acc: 0.9915
 768/1283 [================>.............] - ETA: 0s - loss: 0.0450 - acc: 0.9922
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0432 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0427 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0420 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0405 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0407 - acc: 0.9945
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0425 - acc: 0.9939
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0422 - acc: 0.9942
1280/1283 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9945
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0416 - acc: 0.9945 - val_loss: 1.4020 - val_acc: 0.5415

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=3
max_len=30
epochs=100
mode=AV
accuracy=0.5131195335276968
best_valid_accuracy=0.478134110787172
