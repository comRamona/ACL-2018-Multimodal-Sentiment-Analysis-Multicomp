/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-19 14:59:34.872758: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 9s - loss: 0.6888 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 3s - loss: 0.6796 - acc: 0.5677
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6742 - acc: 0.5813
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6801 - acc: 0.5737
 576/1283 [============>.................] - ETA: 0s - loss: 0.6855 - acc: 0.5625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6845 - acc: 0.5440
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6806 - acc: 0.5541
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6797 - acc: 0.5594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6778 - acc: 0.5680
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6788 - acc: 0.5641
1283/1283 [==============================] - 1s 970us/step - loss: 0.6780 - acc: 0.5635 - val_loss: 0.6884 - val_acc: 0.5153

Epoch 00001: val_acc improved from -inf to 0.51528, saving model to classification_logs//lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6411 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6455 - acc: 0.6667
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6455 - acc: 0.6500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6431 - acc: 0.6562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6402 - acc: 0.6680
 576/1283 [============>.................] - ETA: 0s - loss: 0.6407 - acc: 0.6667
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6438 - acc: 0.6463
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6441 - acc: 0.6418
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6415 - acc: 0.6507
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6410 - acc: 0.6494
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6397 - acc: 0.6510
1280/1283 [============================>.] - ETA: 0s - loss: 0.6423 - acc: 0.6414
1283/1283 [==============================] - 1s 773us/step - loss: 0.6423 - acc: 0.6415 - val_loss: 0.7006 - val_acc: 0.5240

Epoch 00002: val_acc improved from 0.51528 to 0.52402, saving model to classification_logs//lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6303 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6319 - acc: 0.6458
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6282 - acc: 0.6531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6263 - acc: 0.6589
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6252 - acc: 0.6582
 640/1283 [=============>................] - ETA: 0s - loss: 0.6154 - acc: 0.6687
 768/1283 [================>.............] - ETA: 0s - loss: 0.6113 - acc: 0.6667
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6101 - acc: 0.6674
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6098 - acc: 0.6656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6129 - acc: 0.6621
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6071 - acc: 0.6693
1280/1283 [============================>.] - ETA: 0s - loss: 0.6083 - acc: 0.6711
1283/1283 [==============================] - 1s 752us/step - loss: 0.6080 - acc: 0.6719 - val_loss: 0.7180 - val_acc: 0.5284

Epoch 00003: val_acc improved from 0.52402 to 0.52838, saving model to classification_logs//lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5629 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5799 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5835 - acc: 0.7109
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5894 - acc: 0.6937
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5902 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5970 - acc: 0.6797
 576/1283 [============>.................] - ETA: 0s - loss: 0.5837 - acc: 0.6944
 640/1283 [=============>................] - ETA: 0s - loss: 0.5791 - acc: 0.7000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5841 - acc: 0.6989
 768/1283 [================>.............] - ETA: 0s - loss: 0.5837 - acc: 0.7018
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5821 - acc: 0.7055
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5839 - acc: 0.7031
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5877 - acc: 0.6934
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5867 - acc: 0.6958
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5869 - acc: 0.6962
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5897 - acc: 0.6900
1280/1283 [============================>.] - ETA: 0s - loss: 0.5877 - acc: 0.6953
1283/1283 [==============================] - 1s 977us/step - loss: 0.5874 - acc: 0.6952 - val_loss: 0.7487 - val_acc: 0.5415

Epoch 00004: val_acc improved from 0.52838 to 0.54148, saving model to classification_logs//lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5188 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5348 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5299 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5473 - acc: 0.7344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5463 - acc: 0.7321
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5381 - acc: 0.7285
 576/1283 [============>.................] - ETA: 0s - loss: 0.5361 - acc: 0.7309
 640/1283 [=============>................] - ETA: 0s - loss: 0.5471 - acc: 0.7219
 768/1283 [================>.............] - ETA: 0s - loss: 0.5518 - acc: 0.7109
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5500 - acc: 0.7127
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5529 - acc: 0.7073
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5505 - acc: 0.7086
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5566 - acc: 0.7040
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5563 - acc: 0.7081
1280/1283 [============================>.] - ETA: 0s - loss: 0.5563 - acc: 0.7094
1283/1283 [==============================] - 1s 961us/step - loss: 0.5568 - acc: 0.7093 - val_loss: 0.7710 - val_acc: 0.4629

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4435 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4866 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4943 - acc: 0.7760
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5205 - acc: 0.7383
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5216 - acc: 0.7469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5263 - acc: 0.7370
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5335 - acc: 0.7299
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5432 - acc: 0.7148
 576/1283 [============>.................] - ETA: 0s - loss: 0.5433 - acc: 0.7205
 640/1283 [=============>................] - ETA: 0s - loss: 0.5404 - acc: 0.7203
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5393 - acc: 0.7216
 768/1283 [================>.............] - ETA: 0s - loss: 0.5416 - acc: 0.7227
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5439 - acc: 0.7212
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5400 - acc: 0.7277
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5397 - acc: 0.7271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5465 - acc: 0.7188
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5426 - acc: 0.7240
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5421 - acc: 0.7245
1280/1283 [============================>.] - ETA: 0s - loss: 0.5416 - acc: 0.7266
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5417 - acc: 0.7264 - val_loss: 0.7722 - val_acc: 0.5415

Epoch 00006: val_acc improved from 0.54148 to 0.54148, saving model to classification_logs//lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5221 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5156 - acc: 0.7135
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5211 - acc: 0.7109
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5211 - acc: 0.7125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5225 - acc: 0.7109
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5252 - acc: 0.7188
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5180 - acc: 0.7266
 576/1283 [============>.................] - ETA: 0s - loss: 0.5215 - acc: 0.7205
 640/1283 [=============>................] - ETA: 0s - loss: 0.5177 - acc: 0.7234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5202 - acc: 0.7315
 768/1283 [================>.............] - ETA: 0s - loss: 0.5191 - acc: 0.7331
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5202 - acc: 0.7296
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5196 - acc: 0.7277
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5207 - acc: 0.7302
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5233 - acc: 0.7285
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5205 - acc: 0.7335
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5211 - acc: 0.7344
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5171 - acc: 0.7368
1280/1283 [============================>.] - ETA: 0s - loss: 0.5183 - acc: 0.7359
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5185 - acc: 0.7358 - val_loss: 0.7696 - val_acc: 0.4629

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4588 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.4944 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5191 - acc: 0.7708
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4918 - acc: 0.7688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5088 - acc: 0.7604
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5112 - acc: 0.7634
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5084 - acc: 0.7637
 640/1283 [=============>................] - ETA: 0s - loss: 0.5069 - acc: 0.7625
 768/1283 [================>.............] - ETA: 0s - loss: 0.4977 - acc: 0.7643
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4971 - acc: 0.7620
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4978 - acc: 0.7656
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4917 - acc: 0.7708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4914 - acc: 0.7686
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4958 - acc: 0.7647
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4992 - acc: 0.7630
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5011 - acc: 0.7615
1280/1283 [============================>.] - ETA: 0s - loss: 0.4991 - acc: 0.7609
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4992 - acc: 0.7607 - val_loss: 0.8217 - val_acc: 0.4934

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4948 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4654 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4498 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4748 - acc: 0.7812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4700 - acc: 0.7865
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4702 - acc: 0.7891
 576/1283 [============>.................] - ETA: 0s - loss: 0.4628 - acc: 0.7899
 640/1283 [=============>................] - ETA: 0s - loss: 0.4641 - acc: 0.7875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4636 - acc: 0.7841
 768/1283 [================>.............] - ETA: 0s - loss: 0.4598 - acc: 0.7878
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4564 - acc: 0.7897
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4518 - acc: 0.7958
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4482 - acc: 0.7958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4483 - acc: 0.7949
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4518 - acc: 0.7914
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4536 - acc: 0.7917
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4547 - acc: 0.7911
1280/1283 [============================>.] - ETA: 0s - loss: 0.4569 - acc: 0.7906
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4565 - acc: 0.7911 - val_loss: 0.8773 - val_acc: 0.4323

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5040 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.4427 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4355 - acc: 0.7917
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4303 - acc: 0.7937
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4208 - acc: 0.8125
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4243 - acc: 0.8086
 576/1283 [============>.................] - ETA: 0s - loss: 0.4246 - acc: 0.8108
 640/1283 [=============>................] - ETA: 0s - loss: 0.4195 - acc: 0.8203
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4257 - acc: 0.8139
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4300 - acc: 0.8101
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4278 - acc: 0.8114
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4244 - acc: 0.8135
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4213 - acc: 0.8171
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4241 - acc: 0.8151
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4312 - acc: 0.8100
1280/1283 [============================>.] - ETA: 0s - loss: 0.4330 - acc: 0.8063
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4346 - acc: 0.8059 - val_loss: 0.8762 - val_acc: 0.4454

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3638 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.3861 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3525 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3418 - acc: 0.8945
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3469 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3585 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3629 - acc: 0.8683
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3586 - acc: 0.8691
 576/1283 [============>.................] - ETA: 0s - loss: 0.3813 - acc: 0.8524
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4011 - acc: 0.8310
 768/1283 [================>.............] - ETA: 0s - loss: 0.3984 - acc: 0.8320
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3929 - acc: 0.8377
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3921 - acc: 0.8393
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3925 - acc: 0.8365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3877 - acc: 0.8389
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3907 - acc: 0.8392
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3948 - acc: 0.8368
1280/1283 [============================>.] - ETA: 0s - loss: 0.4052 - acc: 0.8336
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4056 - acc: 0.8332 - val_loss: 0.9006 - val_acc: 0.4803

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3464 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.3245 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3455 - acc: 0.8750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3549 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3715 - acc: 0.8482
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3720 - acc: 0.8438
 576/1283 [============>.................] - ETA: 0s - loss: 0.3706 - acc: 0.8438
 640/1283 [=============>................] - ETA: 0s - loss: 0.3681 - acc: 0.8453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3671 - acc: 0.8480
 768/1283 [================>.............] - ETA: 0s - loss: 0.3663 - acc: 0.8477
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3674 - acc: 0.8486
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3684 - acc: 0.8493
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3708 - acc: 0.8448
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3666 - acc: 0.8486
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3688 - acc: 0.8456
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3655 - acc: 0.8498
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3696 - acc: 0.8479
1280/1283 [============================>.] - ETA: 0s - loss: 0.3708 - acc: 0.8461
1283/1283 [==============================] - 1s 972us/step - loss: 0.3711 - acc: 0.8457 - val_loss: 0.9338 - val_acc: 0.4803

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3032 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.3070 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3359 - acc: 0.8958
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3614 - acc: 0.8711
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3593 - acc: 0.8625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3627 - acc: 0.8620
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3619 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3597 - acc: 0.8574
 576/1283 [============>.................] - ETA: 0s - loss: 0.3576 - acc: 0.8524
 640/1283 [=============>................] - ETA: 0s - loss: 0.3591 - acc: 0.8484
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3531 - acc: 0.8537
 768/1283 [================>.............] - ETA: 0s - loss: 0.3488 - acc: 0.8542
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3516 - acc: 0.8460
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3521 - acc: 0.8427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3468 - acc: 0.8496
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3504 - acc: 0.8493
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3510 - acc: 0.8472
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3509 - acc: 0.8462
1280/1283 [============================>.] - ETA: 0s - loss: 0.3510 - acc: 0.8453
1283/1283 [==============================] - 1s 987us/step - loss: 0.3526 - acc: 0.8441 - val_loss: 0.9339 - val_acc: 0.4847

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2939 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.3420 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3027 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3224 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3409 - acc: 0.8776
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3470 - acc: 0.8795
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3623 - acc: 0.8770
 576/1283 [============>.................] - ETA: 0s - loss: 0.3607 - acc: 0.8715
 640/1283 [=============>................] - ETA: 0s - loss: 0.3580 - acc: 0.8703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3522 - acc: 0.8722
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3521 - acc: 0.8690
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3558 - acc: 0.8627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3498 - acc: 0.8646
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3528 - acc: 0.8652
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3495 - acc: 0.8658
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3483 - acc: 0.8672
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3447 - acc: 0.8692
1280/1283 [============================>.] - ETA: 0s - loss: 0.3430 - acc: 0.8703
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3429 - acc: 0.8706 - val_loss: 0.9304 - val_acc: 0.4803

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2779 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2839 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2778 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2923 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3134 - acc: 0.8625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3155 - acc: 0.8620
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3100 - acc: 0.8683
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3033 - acc: 0.8730
 576/1283 [============>.................] - ETA: 0s - loss: 0.3006 - acc: 0.8785
 640/1283 [=============>................] - ETA: 0s - loss: 0.2941 - acc: 0.8844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2910 - acc: 0.8849
 768/1283 [================>.............] - ETA: 0s - loss: 0.2936 - acc: 0.8841
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2941 - acc: 0.8846
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2897 - acc: 0.8862
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2900 - acc: 0.8875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2979 - acc: 0.8838
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3008 - acc: 0.8819
1280/1283 [============================>.] - ETA: 0s - loss: 0.2953 - acc: 0.8859
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2954 - acc: 0.8862 - val_loss: 1.0068 - val_acc: 0.4978

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2879 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2515 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2710 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2581 - acc: 0.9102
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2637 - acc: 0.9000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2628 - acc: 0.8984
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2712 - acc: 0.8887
 576/1283 [============>.................] - ETA: 0s - loss: 0.2692 - acc: 0.8906
 640/1283 [=============>................] - ETA: 0s - loss: 0.2708 - acc: 0.8875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2759 - acc: 0.8849
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2764 - acc: 0.8870
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2731 - acc: 0.8862
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2734 - acc: 0.8833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2736 - acc: 0.8848
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2701 - acc: 0.8879
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2667 - acc: 0.8882
1280/1283 [============================>.] - ETA: 0s - loss: 0.2680 - acc: 0.8875
1283/1283 [==============================] - 1s 972us/step - loss: 0.2682 - acc: 0.8870 - val_loss: 1.1525 - val_acc: 0.4410

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
mode=AV
accuracy=0.5087463556851312
best_valid_accuracy=0.47230320699708456
