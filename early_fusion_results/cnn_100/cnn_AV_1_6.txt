/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:140: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:142: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-27 13:51:13.974417: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.7023 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 2s - loss: 0.8789 - acc: 0.5260
 320/1283 [======>.......................] - ETA: 1s - loss: 0.9095 - acc: 0.5219
 384/1283 [=======>......................] - ETA: 1s - loss: 0.8905 - acc: 0.5234
 512/1283 [==========>...................] - ETA: 1s - loss: 0.8526 - acc: 0.5273
 640/1283 [=============>................] - ETA: 0s - loss: 0.8116 - acc: 0.5375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.8104 - acc: 0.5341
 768/1283 [================>.............] - ETA: 0s - loss: 0.8076 - acc: 0.5365
 896/1283 [===================>..........] - ETA: 0s - loss: 0.8094 - acc: 0.5301
1024/1283 [======================>.......] - ETA: 0s - loss: 0.8000 - acc: 0.5283
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7957 - acc: 0.5252
1280/1283 [============================>.] - ETA: 0s - loss: 0.7850 - acc: 0.5281
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7844 - acc: 0.5284 - val_loss: 0.7024 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6035 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6202 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6340 - acc: 0.6224
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6289 - acc: 0.6205
 576/1283 [============>.................] - ETA: 0s - loss: 0.6490 - acc: 0.6302
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6429 - acc: 0.6307
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6370 - acc: 0.6310
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6361 - acc: 0.6328
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6323 - acc: 0.6387
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6306 - acc: 0.6424
1280/1283 [============================>.] - ETA: 0s - loss: 0.6238 - acc: 0.6523
1283/1283 [==============================] - 1s 704us/step - loss: 0.6239 - acc: 0.6516 - val_loss: 0.7263 - val_acc: 0.5284

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5927 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.5467 - acc: 0.6953
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5661 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5626 - acc: 0.6901
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5677 - acc: 0.6953
 576/1283 [============>.................] - ETA: 0s - loss: 0.5679 - acc: 0.6927
 640/1283 [=============>................] - ETA: 0s - loss: 0.5674 - acc: 0.6922
 768/1283 [================>.............] - ETA: 0s - loss: 0.5691 - acc: 0.6940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5684 - acc: 0.7042
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5639 - acc: 0.7090
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5762 - acc: 0.7101
1280/1283 [============================>.] - ETA: 0s - loss: 0.5755 - acc: 0.7086
1283/1283 [==============================] - 1s 844us/step - loss: 0.5753 - acc: 0.7085 - val_loss: 0.7278 - val_acc: 0.5459

Epoch 00003: val_acc improved from 0.53712 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5071 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4911 - acc: 0.8021
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4953 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4921 - acc: 0.7723
 576/1283 [============>.................] - ETA: 0s - loss: 0.5035 - acc: 0.7674
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5091 - acc: 0.7585
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5035 - acc: 0.7632
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4972 - acc: 0.7698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4940 - acc: 0.7757
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4887 - acc: 0.7796
1283/1283 [==============================] - 1s 573us/step - loss: 0.4917 - acc: 0.7786 - val_loss: 0.7773 - val_acc: 0.5197

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4508 - acc: 0.7656
 128/1283 [=>............................] - ETA: 0s - loss: 0.4752 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4443 - acc: 0.7852
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4423 - acc: 0.7917
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4353 - acc: 0.7930
 576/1283 [============>.................] - ETA: 0s - loss: 0.4412 - acc: 0.7917
 640/1283 [=============>................] - ETA: 0s - loss: 0.4417 - acc: 0.7937
 768/1283 [================>.............] - ETA: 0s - loss: 0.4354 - acc: 0.8047
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4342 - acc: 0.8041
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4335 - acc: 0.8052
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4340 - acc: 0.8051
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4340 - acc: 0.8043
1280/1283 [============================>.] - ETA: 0s - loss: 0.4339 - acc: 0.8039
1283/1283 [==============================] - 1s 786us/step - loss: 0.4339 - acc: 0.8044 - val_loss: 0.7956 - val_acc: 0.5677

Epoch 00005: val_acc improved from 0.54585 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4016 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3429 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3830 - acc: 0.8250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3855 - acc: 0.8237
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3917 - acc: 0.8184
 640/1283 [=============>................] - ETA: 0s - loss: 0.3934 - acc: 0.8250
 768/1283 [================>.............] - ETA: 0s - loss: 0.3929 - acc: 0.8255
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3899 - acc: 0.8292
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3957 - acc: 0.8223
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3946 - acc: 0.8229
1280/1283 [============================>.] - ETA: 0s - loss: 0.3980 - acc: 0.8187
1283/1283 [==============================] - 1s 677us/step - loss: 0.3987 - acc: 0.8184 - val_loss: 0.7760 - val_acc: 0.5677

Epoch 00006: val_acc improved from 0.56769 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3327 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3475 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3506 - acc: 0.8594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3460 - acc: 0.8568
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3568 - acc: 0.8460
 576/1283 [============>.................] - ETA: 0s - loss: 0.3555 - acc: 0.8507
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3576 - acc: 0.8537
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3521 - acc: 0.8642
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3549 - acc: 0.8646
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3659 - acc: 0.8613
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3699 - acc: 0.8585
1280/1283 [============================>.] - ETA: 0s - loss: 0.3673 - acc: 0.8547
1283/1283 [==============================] - 1s 787us/step - loss: 0.3670 - acc: 0.8550 - val_loss: 0.7914 - val_acc: 0.5459

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2725 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.2963 - acc: 0.8828
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2792 - acc: 0.9180
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2886 - acc: 0.9125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2996 - acc: 0.8984
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2938 - acc: 0.9040
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2950 - acc: 0.9023
 640/1283 [=============>................] - ETA: 0s - loss: 0.2960 - acc: 0.9000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3030 - acc: 0.8920
 768/1283 [================>.............] - ETA: 0s - loss: 0.3010 - acc: 0.8932
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3039 - acc: 0.8884
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3025 - acc: 0.8906
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2996 - acc: 0.8941
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2961 - acc: 0.8956
1280/1283 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.8914
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2963 - acc: 0.8917 - val_loss: 0.8358 - val_acc: 0.5066

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2387 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.2936 - acc: 0.8828
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2631 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2651 - acc: 0.9000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2702 - acc: 0.8951
 576/1283 [============>.................] - ETA: 0s - loss: 0.2752 - acc: 0.8889
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2593 - acc: 0.9034
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2601 - acc: 0.9050
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2580 - acc: 0.9042
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2582 - acc: 0.9033
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2638 - acc: 0.9028
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2610 - acc: 0.9046
1283/1283 [==============================] - 1s 825us/step - loss: 0.2590 - acc: 0.9057 - val_loss: 0.8679 - val_acc: 0.5328

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1837 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2607 - acc: 0.9271
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2688 - acc: 0.9281
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2538 - acc: 0.9297
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2375 - acc: 0.9316
 640/1283 [=============>................] - ETA: 0s - loss: 0.2348 - acc: 0.9266
 768/1283 [================>.............] - ETA: 0s - loss: 0.2262 - acc: 0.9323
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2220 - acc: 0.9353
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2183 - acc: 0.9375
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2143 - acc: 0.9384
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2129 - acc: 0.9384
1280/1283 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9398
1283/1283 [==============================] - 1s 724us/step - loss: 0.2085 - acc: 0.9400 - val_loss: 0.9620 - val_acc: 0.5415

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1148 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.1496 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1524 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1672 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1574 - acc: 0.9531
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1539 - acc: 0.9551
 576/1283 [============>.................] - ETA: 0s - loss: 0.1563 - acc: 0.9566
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1608 - acc: 0.9560
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1561 - acc: 0.9591
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1607 - acc: 0.9542
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1596 - acc: 0.9561
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1710 - acc: 0.9566
1280/1283 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9570
1283/1283 [==============================] - 1s 827us/step - loss: 0.1708 - acc: 0.9571 - val_loss: 1.1215 - val_acc: 0.5677

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1057 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1382 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1533 - acc: 0.9570
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1402 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1362 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1349 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.1303 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1292 - acc: 0.9759
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1253 - acc: 0.9772
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1242 - acc: 0.9777
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1225 - acc: 0.9785
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1266 - acc: 0.9757
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1252 - acc: 0.9770
1280/1283 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9781
1283/1283 [==============================] - 1s 906us/step - loss: 0.1231 - acc: 0.9782 - val_loss: 1.0715 - val_acc: 0.5153

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0873 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1011 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0971 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0994 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0919 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0942 - acc: 0.9818
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0968 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0977 - acc: 0.9826
 640/1283 [=============>................] - ETA: 0s - loss: 0.0970 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0961 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0929 - acc: 0.9857
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0913 - acc: 0.9868
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0922 - acc: 0.9866
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0908 - acc: 0.9875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0903 - acc: 0.9863
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0887 - acc: 0.9871
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0864 - acc: 0.9885
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0855 - acc: 0.9883 - val_loss: 1.1380 - val_acc: 0.5109

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0641 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0581 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0614 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0649 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0649 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0636 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0644 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0627 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0637 - acc: 0.9943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0625 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0627 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0628 - acc: 0.9948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0625 - acc: 0.9951
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0614 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0623 - acc: 0.9948
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0615 - acc: 0.9951
1280/1283 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9953
1283/1283 [==============================] - 1s 983us/step - loss: 0.0606 - acc: 0.9953 - val_loss: 1.1822 - val_acc: 0.5066

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0513 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0478 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0424 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0449 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0476 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0463 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0463 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0456 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0453 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0457 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0454 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0455 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0456 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0442 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0436 - acc: 0.9992
1280/1283 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9992
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0436 - acc: 0.9992 - val_loss: 1.2959 - val_acc: 0.5240

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0405 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0368 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0353 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0325 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0303 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0322 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0312 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0326 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0338 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0332 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0328 - acc: 0.9992
1283/1283 [==============================] - 1s 802us/step - loss: 0.0326 - acc: 0.9992 - val_loss: 1.3202 - val_acc: 0.5153

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=20
epochs=100
mode=AV
accuracy=0.5393586005830904
best_valid_accuracy=0.4897959183673469
