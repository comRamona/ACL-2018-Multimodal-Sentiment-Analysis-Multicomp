/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:140: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:142: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-27 13:57:03.832165: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.7293 - acc: 0.4219
 192/1283 [===>..........................] - ETA: 2s - loss: 0.7655 - acc: 0.4740
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7607 - acc: 0.4719
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7333 - acc: 0.5078
 640/1283 [=============>................] - ETA: 0s - loss: 0.7296 - acc: 0.4984
 768/1283 [================>.............] - ETA: 0s - loss: 0.7197 - acc: 0.5143
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7194 - acc: 0.5167
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7136 - acc: 0.5285
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7079 - acc: 0.5312
1283/1283 [==============================] - 1s 794us/step - loss: 0.7072 - acc: 0.5339 - val_loss: 0.7227 - val_acc: 0.5328

Epoch 00001: val_acc improved from -inf to 0.53275, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6619 - acc: 0.5781
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6619 - acc: 0.5625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6405 - acc: 0.5990
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6395 - acc: 0.6094
 640/1283 [=============>................] - ETA: 0s - loss: 0.6299 - acc: 0.6188
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6272 - acc: 0.6278
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6260 - acc: 0.6442
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6251 - acc: 0.6438
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6238 - acc: 0.6461
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6224 - acc: 0.6513
1283/1283 [==============================] - 1s 628us/step - loss: 0.6237 - acc: 0.6516 - val_loss: 0.7122 - val_acc: 0.4978

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5365 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5420 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5705 - acc: 0.7063
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5796 - acc: 0.6875
 576/1283 [============>.................] - ETA: 0s - loss: 0.5758 - acc: 0.6997
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5727 - acc: 0.6974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5667 - acc: 0.7067
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5667 - acc: 0.7121
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5738 - acc: 0.7041
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5709 - acc: 0.7014
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5715 - acc: 0.7023
1280/1283 [============================>.] - ETA: 0s - loss: 0.5675 - acc: 0.7063
1283/1283 [==============================] - 1s 676us/step - loss: 0.5676 - acc: 0.7062 - val_loss: 0.6924 - val_acc: 0.5459

Epoch 00003: val_acc improved from 0.53275 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4303 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4661 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4976 - acc: 0.7906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5065 - acc: 0.7790
 576/1283 [============>.................] - ETA: 0s - loss: 0.5087 - acc: 0.7691
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5134 - acc: 0.7585
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5069 - acc: 0.7680
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5039 - acc: 0.7677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4995 - acc: 0.7721
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4973 - acc: 0.7763
1283/1283 [==============================] - 1s 622us/step - loss: 0.4960 - acc: 0.7779 - val_loss: 0.7266 - val_acc: 0.5633

Epoch 00004: val_acc improved from 0.54585 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3769 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4245 - acc: 0.8333
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4182 - acc: 0.8250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4187 - acc: 0.8229
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4174 - acc: 0.8184
 576/1283 [============>.................] - ETA: 0s - loss: 0.4191 - acc: 0.8229
 640/1283 [=============>................] - ETA: 0s - loss: 0.4169 - acc: 0.8250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4166 - acc: 0.8196
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4219 - acc: 0.8161
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4176 - acc: 0.8203
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4197 - acc: 0.8115
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4183 - acc: 0.8099
1280/1283 [============================>.] - ETA: 0s - loss: 0.4280 - acc: 0.8039
1283/1283 [==============================] - 1s 803us/step - loss: 0.4279 - acc: 0.8036 - val_loss: 0.7555 - val_acc: 0.5721

Epoch 00005: val_acc improved from 0.56332 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4001 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3620 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3729 - acc: 0.8320
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3621 - acc: 0.8516
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3627 - acc: 0.8457
 640/1283 [=============>................] - ETA: 0s - loss: 0.3591 - acc: 0.8516
 768/1283 [================>.............] - ETA: 0s - loss: 0.3559 - acc: 0.8477
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3557 - acc: 0.8449
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3595 - acc: 0.8438
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3584 - acc: 0.8438
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3612 - acc: 0.8405
1280/1283 [============================>.] - ETA: 0s - loss: 0.3587 - acc: 0.8438
1283/1283 [==============================] - 1s 757us/step - loss: 0.3588 - acc: 0.8433 - val_loss: 0.8164 - val_acc: 0.5415

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3052 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.3023 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3275 - acc: 0.8490
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3033 - acc: 0.8633
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2952 - acc: 0.8781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3016 - acc: 0.8672
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3075 - acc: 0.8616
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3107 - acc: 0.8633
 576/1283 [============>.................] - ETA: 0s - loss: 0.3082 - acc: 0.8681
 640/1283 [=============>................] - ETA: 0s - loss: 0.3047 - acc: 0.8672
 768/1283 [================>.............] - ETA: 0s - loss: 0.3062 - acc: 0.8698
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3033 - acc: 0.8714
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3022 - acc: 0.8705
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3021 - acc: 0.8719
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3017 - acc: 0.8750
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2955 - acc: 0.8799
1280/1283 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.8836
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2910 - acc: 0.8839 - val_loss: 0.8799 - val_acc: 0.5677

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2714 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2128 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2245 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2398 - acc: 0.9125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2182 - acc: 0.9308
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2169 - acc: 0.9355
 640/1283 [=============>................] - ETA: 0s - loss: 0.2279 - acc: 0.9344
 768/1283 [================>.............] - ETA: 0s - loss: 0.2279 - acc: 0.9349
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2281 - acc: 0.9342
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2231 - acc: 0.9346
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2241 - acc: 0.9329
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2208 - acc: 0.9326
1280/1283 [============================>.] - ETA: 0s - loss: 0.2211 - acc: 0.9328
1283/1283 [==============================] - 1s 845us/step - loss: 0.2207 - acc: 0.9330 - val_loss: 1.2119 - val_acc: 0.5284

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1227 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1505 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1888 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1941 - acc: 0.9406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1831 - acc: 0.9442
 576/1283 [============>.................] - ETA: 0s - loss: 0.1811 - acc: 0.9462
 640/1283 [=============>................] - ETA: 0s - loss: 0.1818 - acc: 0.9422
 768/1283 [================>.............] - ETA: 0s - loss: 0.1807 - acc: 0.9427
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1771 - acc: 0.9435
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1769 - acc: 0.9448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1754 - acc: 0.9430
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1704 - acc: 0.9449
1283/1283 [==============================] - 1s 870us/step - loss: 0.1698 - acc: 0.9447 - val_loss: 1.2023 - val_acc: 0.5415

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1128 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2394 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2148 - acc: 0.9180
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2351 - acc: 0.9010
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2274 - acc: 0.9004
 640/1283 [=============>................] - ETA: 0s - loss: 0.2598 - acc: 0.8875
 768/1283 [================>.............] - ETA: 0s - loss: 0.2500 - acc: 0.8893
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2418 - acc: 0.8917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2497 - acc: 0.8838
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2442 - acc: 0.8880
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2385 - acc: 0.8914
1283/1283 [==============================] - 1s 751us/step - loss: 0.2352 - acc: 0.8940 - val_loss: 1.2783 - val_acc: 0.4978

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3607 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2377 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2033 - acc: 0.9125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1800 - acc: 0.9245
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1723 - acc: 0.9286
 576/1283 [============>.................] - ETA: 0s - loss: 0.1658 - acc: 0.9340
 640/1283 [=============>................] - ETA: 0s - loss: 0.1609 - acc: 0.9391
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1591 - acc: 0.9418
 768/1283 [================>.............] - ETA: 0s - loss: 0.1658 - acc: 0.9427
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1627 - acc: 0.9447
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1560 - acc: 0.9469
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1541 - acc: 0.9492
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1512 - acc: 0.9514
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1488 - acc: 0.9515
1283/1283 [==============================] - 1s 989us/step - loss: 0.1468 - acc: 0.9532 - val_loss: 1.1975 - val_acc: 0.5109

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1151 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1054 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1056 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1041 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0964 - acc: 0.9766
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0902 - acc: 0.9785
 640/1283 [=============>................] - ETA: 0s - loss: 0.0870 - acc: 0.9797
 768/1283 [================>.............] - ETA: 0s - loss: 0.0861 - acc: 0.9831
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0870 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0852 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0820 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0802 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0832 - acc: 0.9835
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0849 - acc: 0.9819
1280/1283 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9828
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0837 - acc: 0.9829 - val_loss: 1.2377 - val_acc: 0.5284

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0600 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0537 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0498 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0615 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0602 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0580 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0610 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0579 - acc: 0.9861
 640/1283 [=============>................] - ETA: 0s - loss: 0.0563 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0567 - acc: 0.9872
 768/1283 [================>.............] - ETA: 0s - loss: 0.0574 - acc: 0.9883
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0552 - acc: 0.9892
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0533 - acc: 0.9900
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0547 - acc: 0.9885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0539 - acc: 0.9883
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0531 - acc: 0.9881
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0518 - acc: 0.9887
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0531 - acc: 0.9885
1280/1283 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9891
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0528 - acc: 0.9891 - val_loss: 1.3811 - val_acc: 0.4978

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0335 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0357 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0322 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0584 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0754 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0840 - acc: 0.9740
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0756 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.0662 - acc: 0.9826
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0676 - acc: 0.9801
 768/1283 [================>.............] - ETA: 0s - loss: 0.0676 - acc: 0.9805
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0665 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0656 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0633 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0621 - acc: 0.9853
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0701 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9844
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0681 - acc: 0.9844 - val_loss: 1.4017 - val_acc: 0.5502

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0470 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1262 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1168 - acc: 0.9492
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1024 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1088 - acc: 0.9509
 576/1283 [============>.................] - ETA: 0s - loss: 0.1038 - acc: 0.9514
 640/1283 [=============>................] - ETA: 0s - loss: 0.0993 - acc: 0.9547
 768/1283 [================>.............] - ETA: 0s - loss: 0.0999 - acc: 0.9570
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0978 - acc: 0.9591
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0921 - acc: 0.9625
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0920 - acc: 0.9632
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0895 - acc: 0.9653
1280/1283 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9664
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0873 - acc: 0.9665 - val_loss: 1.4140 - val_acc: 0.5546

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=15
epochs=100
mode=AV
accuracy=0.5568513119533528
best_valid_accuracy=0.532069970845481
