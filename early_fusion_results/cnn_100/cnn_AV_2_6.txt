/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:140: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:142: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-27 13:57:05.370811: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.7810 - acc: 0.3750
 128/1283 [=>............................] - ETA: 5s - loss: 0.7797 - acc: 0.4766 
 192/1283 [===>..........................] - ETA: 3s - loss: 0.7907 - acc: 0.4531
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7713 - acc: 0.4609
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7435 - acc: 0.4948
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7367 - acc: 0.5137
 576/1283 [============>.................] - ETA: 1s - loss: 0.7341 - acc: 0.5122
 640/1283 [=============>................] - ETA: 1s - loss: 0.7229 - acc: 0.5359
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7230 - acc: 0.5327
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7276 - acc: 0.5325
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7264 - acc: 0.5324
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7203 - acc: 0.5332
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7185 - acc: 0.5365
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7141 - acc: 0.5411
1280/1283 [============================>.] - ETA: 0s - loss: 0.7112 - acc: 0.5477
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7109 - acc: 0.5479 - val_loss: 0.7210 - val_acc: 0.5022

Epoch 00001: val_acc improved from -inf to 0.50218, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6518 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6392 - acc: 0.5938
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6472 - acc: 0.5813
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6489 - acc: 0.5703
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6431 - acc: 0.5848
 576/1283 [============>.................] - ETA: 0s - loss: 0.6506 - acc: 0.5972
 640/1283 [=============>................] - ETA: 0s - loss: 0.6481 - acc: 0.6031
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6471 - acc: 0.6009
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6414 - acc: 0.6142
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6394 - acc: 0.6146
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6384 - acc: 0.6152
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6357 - acc: 0.6204
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6353 - acc: 0.6198
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6332 - acc: 0.6250
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6318 - acc: 0.6282 - val_loss: 0.7443 - val_acc: 0.5328

Epoch 00002: val_acc improved from 0.50218 to 0.53275, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5910 - acc: 0.6875
 128/1283 [=>............................] - ETA: 0s - loss: 0.5788 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6173 - acc: 0.6823
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5856 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5905 - acc: 0.6937
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5810 - acc: 0.6979
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5803 - acc: 0.6897
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5846 - acc: 0.6836
 576/1283 [============>.................] - ETA: 1s - loss: 0.5855 - acc: 0.6806
 640/1283 [=============>................] - ETA: 0s - loss: 0.5826 - acc: 0.6797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5840 - acc: 0.6790
 768/1283 [================>.............] - ETA: 0s - loss: 0.5817 - acc: 0.6810
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5833 - acc: 0.6815
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5815 - acc: 0.6886
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5825 - acc: 0.6906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5824 - acc: 0.6895
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5890 - acc: 0.6875
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5910 - acc: 0.6814
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5881 - acc: 0.6842
1280/1283 [============================>.] - ETA: 0s - loss: 0.5885 - acc: 0.6805
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5888 - acc: 0.6797 - val_loss: 0.7342 - val_acc: 0.4847

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5595 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.5357 - acc: 0.7109
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5273 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5247 - acc: 0.7461
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5186 - acc: 0.7500
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5176 - acc: 0.7422
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5288 - acc: 0.7299
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5369 - acc: 0.7207
 576/1283 [============>.................] - ETA: 0s - loss: 0.5451 - acc: 0.7118
 640/1283 [=============>................] - ETA: 0s - loss: 0.5466 - acc: 0.7078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5471 - acc: 0.7060
 768/1283 [================>.............] - ETA: 0s - loss: 0.5419 - acc: 0.7122
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5419 - acc: 0.7163
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5380 - acc: 0.7221
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5346 - acc: 0.7260
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5341 - acc: 0.7236
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5330 - acc: 0.7261
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5312 - acc: 0.7283
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5285 - acc: 0.7294
1280/1283 [============================>.] - ETA: 0s - loss: 0.5304 - acc: 0.7281
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5301 - acc: 0.7288 - val_loss: 0.7502 - val_acc: 0.5066

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4780 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.5129 - acc: 0.7578
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4926 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4967 - acc: 0.7688
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4877 - acc: 0.7734
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4906 - acc: 0.7679
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4825 - acc: 0.7754
 576/1283 [============>.................] - ETA: 0s - loss: 0.4865 - acc: 0.7726
 640/1283 [=============>................] - ETA: 0s - loss: 0.4874 - acc: 0.7641
 768/1283 [================>.............] - ETA: 0s - loss: 0.4775 - acc: 0.7760
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4775 - acc: 0.7740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4735 - acc: 0.7790
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4715 - acc: 0.7823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4701 - acc: 0.7803
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4686 - acc: 0.7803
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4696 - acc: 0.7795
1280/1283 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.7898
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4611 - acc: 0.7896 - val_loss: 0.7849 - val_acc: 0.5240

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4383 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.3914 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3703 - acc: 0.8542
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3905 - acc: 0.8359
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4155 - acc: 0.8094
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4136 - acc: 0.8021
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4160 - acc: 0.8013
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4167 - acc: 0.7988
 576/1283 [============>.................] - ETA: 0s - loss: 0.4128 - acc: 0.8021
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4132 - acc: 0.8054
 768/1283 [================>.............] - ETA: 0s - loss: 0.4112 - acc: 0.8151
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4062 - acc: 0.8197
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4037 - acc: 0.8214
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4101 - acc: 0.8156
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4098 - acc: 0.8115
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4075 - acc: 0.8134
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4125 - acc: 0.8099
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4112 - acc: 0.8117
1280/1283 [============================>.] - ETA: 0s - loss: 0.4175 - acc: 0.8047
1283/1283 [==============================] - 2s 2ms/step - loss: 0.4180 - acc: 0.8044 - val_loss: 0.8533 - val_acc: 0.5371

Epoch 00006: val_acc improved from 0.53275 to 0.53712, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3840 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4250 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4091 - acc: 0.7760
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4200 - acc: 0.7844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4110 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4068 - acc: 0.8036
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4180 - acc: 0.7930
 576/1283 [============>.................] - ETA: 0s - loss: 0.4194 - acc: 0.7934
 640/1283 [=============>................] - ETA: 0s - loss: 0.4227 - acc: 0.7891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4183 - acc: 0.7940
 768/1283 [================>.............] - ETA: 0s - loss: 0.4144 - acc: 0.7995
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4082 - acc: 0.8077
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4089 - acc: 0.8058
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4111 - acc: 0.8042
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4254 - acc: 0.8018
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4226 - acc: 0.8024
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4246 - acc: 0.7995
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4210 - acc: 0.8010
1280/1283 [============================>.] - ETA: 0s - loss: 0.4179 - acc: 0.8008
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4178 - acc: 0.8012 - val_loss: 0.8513 - val_acc: 0.5502

Epoch 00007: val_acc improved from 0.53712 to 0.55022, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_20.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3605 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.3870 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3544 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3308 - acc: 0.8672
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3271 - acc: 0.8656
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3230 - acc: 0.8705
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3226 - acc: 0.8672
 576/1283 [============>.................] - ETA: 1s - loss: 0.3292 - acc: 0.8628
 640/1283 [=============>................] - ETA: 0s - loss: 0.3257 - acc: 0.8641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3303 - acc: 0.8608
 768/1283 [================>.............] - ETA: 0s - loss: 0.3332 - acc: 0.8594
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3293 - acc: 0.8606
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3248 - acc: 0.8627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3250 - acc: 0.8615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3274 - acc: 0.8594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3239 - acc: 0.8603
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3230 - acc: 0.8602
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3169 - acc: 0.8635
1280/1283 [============================>.] - ETA: 0s - loss: 0.3178 - acc: 0.8625
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3174 - acc: 0.8628 - val_loss: 0.8885 - val_acc: 0.4978

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2667 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.2966 - acc: 0.8672
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2647 - acc: 0.8958
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2704 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2718 - acc: 0.8781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2730 - acc: 0.8802
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2810 - acc: 0.8728
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2771 - acc: 0.8770
 576/1283 [============>.................] - ETA: 0s - loss: 0.2847 - acc: 0.8698
 640/1283 [=============>................] - ETA: 0s - loss: 0.2754 - acc: 0.8766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2692 - acc: 0.8835
 768/1283 [================>.............] - ETA: 0s - loss: 0.2664 - acc: 0.8867
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2654 - acc: 0.8858
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2589 - acc: 0.8929
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2624 - acc: 0.8875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2614 - acc: 0.8867
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2584 - acc: 0.8897
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2570 - acc: 0.8906
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2543 - acc: 0.8931
1280/1283 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.8938
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2556 - acc: 0.8940 - val_loss: 0.9457 - val_acc: 0.5371

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1710 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1675 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1768 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1850 - acc: 0.9219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1780 - acc: 0.9297
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1779 - acc: 0.9308
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1778 - acc: 0.9316
 640/1283 [=============>................] - ETA: 0s - loss: 0.1928 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1907 - acc: 0.9233
 768/1283 [================>.............] - ETA: 0s - loss: 0.1872 - acc: 0.9271
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1872 - acc: 0.9267
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1850 - acc: 0.9302
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1848 - acc: 0.9307
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1842 - acc: 0.9320
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1840 - acc: 0.9297
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1814 - acc: 0.9326
1280/1283 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9328
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1803 - acc: 0.9330 - val_loss: 1.0203 - val_acc: 0.5502

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0886 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1298 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1314 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1326 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1313 - acc: 0.9479
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1355 - acc: 0.9473
 576/1283 [============>.................] - ETA: 0s - loss: 0.1345 - acc: 0.9531
 640/1283 [=============>................] - ETA: 0s - loss: 0.1435 - acc: 0.9469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1436 - acc: 0.9460
 768/1283 [================>.............] - ETA: 0s - loss: 0.1425 - acc: 0.9466
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1420 - acc: 0.9471
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1448 - acc: 0.9464
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1491 - acc: 0.9458
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1474 - acc: 0.9473
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1533 - acc: 0.9476
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1522 - acc: 0.9479
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1511 - acc: 0.9474
1280/1283 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9461
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1604 - acc: 0.9462 - val_loss: 1.1482 - val_acc: 0.5415

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1046 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1092 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1136 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1104 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1397 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1444 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1522 - acc: 0.9464
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1495 - acc: 0.9473
 576/1283 [============>.................] - ETA: 0s - loss: 0.1469 - acc: 0.9497
 640/1283 [=============>................] - ETA: 0s - loss: 0.1525 - acc: 0.9422
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1615 - acc: 0.9375
 768/1283 [================>.............] - ETA: 0s - loss: 0.1604 - acc: 0.9401
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1570 - acc: 0.9423
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1579 - acc: 0.9408
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1608 - acc: 0.9375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1608 - acc: 0.9355
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1669 - acc: 0.9320
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1679 - acc: 0.9323
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1656 - acc: 0.9326
1280/1283 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9336
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1640 - acc: 0.9337 - val_loss: 1.2617 - val_acc: 0.4760

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1567 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.1572 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1460 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2040 - acc: 0.9141
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1964 - acc: 0.9187
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1833 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1762 - acc: 0.9308
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1802 - acc: 0.9277
 576/1283 [============>.................] - ETA: 0s - loss: 0.1826 - acc: 0.9271
 640/1283 [=============>................] - ETA: 0s - loss: 0.1920 - acc: 0.9203
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1850 - acc: 0.9233
 768/1283 [================>.............] - ETA: 0s - loss: 0.1791 - acc: 0.9284
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1858 - acc: 0.9267
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1855 - acc: 0.9275
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1835 - acc: 0.9271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1783 - acc: 0.9307
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1723 - acc: 0.9332
1280/1283 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9352
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1675 - acc: 0.9353 - val_loss: 1.2402 - val_acc: 0.5066

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1119 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1010 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0955 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0975 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1073 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1057 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1019 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1046 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.1022 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1004 - acc: 0.9673
 768/1283 [================>.............] - ETA: 0s - loss: 0.1049 - acc: 0.9635
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1035 - acc: 0.9639
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1054 - acc: 0.9632
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1028 - acc: 0.9635
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1022 - acc: 0.9639
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0989 - acc: 0.9651
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0990 - acc: 0.9635
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0980 - acc: 0.9646
1280/1283 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9656
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0959 - acc: 0.9657 - val_loss: 1.3092 - val_acc: 0.4978

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0756 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0815 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0738 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0672 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0641 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0701 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0677 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0680 - acc: 0.9809
 640/1283 [=============>................] - ETA: 0s - loss: 0.0686 - acc: 0.9797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0687 - acc: 0.9801
 768/1283 [================>.............] - ETA: 0s - loss: 0.0649 - acc: 0.9818
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0647 - acc: 0.9808
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0652 - acc: 0.9810
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0653 - acc: 0.9812
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0657 - acc: 0.9814
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0644 - acc: 0.9807
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0621 - acc: 0.9818
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0619 - acc: 0.9811
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0617 - acc: 0.9821 - val_loss: 1.5008 - val_acc: 0.5415

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0641 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0709 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0695 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0635 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0590 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0543 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0491 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0464 - acc: 0.9883
 576/1283 [============>.................] - ETA: 0s - loss: 0.0487 - acc: 0.9861
 640/1283 [=============>................] - ETA: 0s - loss: 0.0536 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0529 - acc: 0.9830
 768/1283 [================>.............] - ETA: 0s - loss: 0.0514 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0549 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0555 - acc: 0.9823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0543 - acc: 0.9834
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0536 - acc: 0.9835
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0527 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0518 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9844
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0522 - acc: 0.9844 - val_loss: 1.5364 - val_acc: 0.5459

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0391 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0439 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0538 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0519 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0487 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0510 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0501 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0474 - acc: 0.9859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0484 - acc: 0.9858
 768/1283 [================>.............] - ETA: 0s - loss: 0.0459 - acc: 0.9870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0453 - acc: 0.9868
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0463 - acc: 0.9865
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0468 - acc: 0.9863
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0496 - acc: 0.9835
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0479 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0463 - acc: 0.9852
1280/1283 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9859
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0450 - acc: 0.9860 - val_loss: 1.8007 - val_acc: 0.5284

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=20
epochs=100
mode=AV
accuracy=0.4912536443148688
best_valid_accuracy=0.4329446064139942
