/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:140: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:142: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-27 13:51:09.728082: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.7427 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 2s - loss: 1.1150 - acc: 0.5417
 256/1283 [====>.........................] - ETA: 1s - loss: 0.9994 - acc: 0.5586
 384/1283 [=======>......................] - ETA: 1s - loss: 0.9751 - acc: 0.5417
 448/1283 [=========>....................] - ETA: 1s - loss: 0.9375 - acc: 0.5491
 512/1283 [==========>...................] - ETA: 1s - loss: 0.9052 - acc: 0.5488
 576/1283 [============>.................] - ETA: 0s - loss: 0.8761 - acc: 0.5503
 704/1283 [===============>..............] - ETA: 0s - loss: 0.8393 - acc: 0.5497
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8123 - acc: 0.5529
 896/1283 [===================>..........] - ETA: 0s - loss: 0.8054 - acc: 0.5424
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7885 - acc: 0.5430
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7831 - acc: 0.5441
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7698 - acc: 0.5485
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7674 - acc: 0.5425 - val_loss: 0.6994 - val_acc: 0.5066

Epoch 00001: val_acc improved from -inf to 0.50655, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6316 - acc: 0.6406
 128/1283 [=>............................] - ETA: 0s - loss: 0.6377 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6438 - acc: 0.6198
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6440 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6495 - acc: 0.5969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6483 - acc: 0.5964
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6632 - acc: 0.5737
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6583 - acc: 0.5781
 640/1283 [=============>................] - ETA: 0s - loss: 0.6597 - acc: 0.5766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6557 - acc: 0.5866
 768/1283 [================>.............] - ETA: 0s - loss: 0.6501 - acc: 0.6016
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6486 - acc: 0.6046
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6455 - acc: 0.6116
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6434 - acc: 0.6167
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6535 - acc: 0.6113
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6567 - acc: 0.6029
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6526 - acc: 0.6028
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6529 - acc: 0.6041 - val_loss: 0.7043 - val_acc: 0.4803

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6376 - acc: 0.6562
 128/1283 [=>............................] - ETA: 0s - loss: 0.6172 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6104 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6066 - acc: 0.6625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6063 - acc: 0.6518
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6100 - acc: 0.6445
 576/1283 [============>.................] - ETA: 0s - loss: 0.6108 - acc: 0.6424
 640/1283 [=============>................] - ETA: 0s - loss: 0.6124 - acc: 0.6344
 768/1283 [================>.............] - ETA: 0s - loss: 0.6139 - acc: 0.6380
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6115 - acc: 0.6418
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6124 - acc: 0.6373
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6160 - acc: 0.6357
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6135 - acc: 0.6360
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6108 - acc: 0.6406
1280/1283 [============================>.] - ETA: 0s - loss: 0.6105 - acc: 0.6398
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6104 - acc: 0.6399 - val_loss: 0.7375 - val_acc: 0.5153

Epoch 00003: val_acc improved from 0.50655 to 0.51528, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5595 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5255 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5528 - acc: 0.7070
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5638 - acc: 0.6901
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5707 - acc: 0.6830
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5655 - acc: 0.6914
 640/1283 [=============>................] - ETA: 0s - loss: 0.5692 - acc: 0.6953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5674 - acc: 0.6989
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5624 - acc: 0.7019
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5665 - acc: 0.6953
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5624 - acc: 0.7031
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5619 - acc: 0.7031
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5634 - acc: 0.7031
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5606 - acc: 0.7075
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5590 - acc: 0.7089
1280/1283 [============================>.] - ETA: 0s - loss: 0.5586 - acc: 0.7063
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5583 - acc: 0.7069 - val_loss: 0.7393 - val_acc: 0.5633

Epoch 00004: val_acc improved from 0.51528 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5910 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.5759 - acc: 0.6484
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5155 - acc: 0.7292
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5299 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5276 - acc: 0.7156
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5157 - acc: 0.7370
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5384 - acc: 0.7168
 640/1283 [=============>................] - ETA: 0s - loss: 0.5345 - acc: 0.7156
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5286 - acc: 0.7216
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5264 - acc: 0.7248
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5240 - acc: 0.7243
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5231 - acc: 0.7285
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5146 - acc: 0.7370
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5119 - acc: 0.7377
1280/1283 [============================>.] - ETA: 0s - loss: 0.5204 - acc: 0.7336
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5213 - acc: 0.7334 - val_loss: 0.7229 - val_acc: 0.5808

Epoch 00005: val_acc improved from 0.56332 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4450 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4673 - acc: 0.8021
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4765 - acc: 0.7937
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4726 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4748 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4703 - acc: 0.8047
 576/1283 [============>.................] - ETA: 0s - loss: 0.4715 - acc: 0.8003
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4710 - acc: 0.7983
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4702 - acc: 0.7945
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4713 - acc: 0.7924
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4687 - acc: 0.7917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4689 - acc: 0.7871
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4683 - acc: 0.7868
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4665 - acc: 0.7873
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4671 - acc: 0.7878
1280/1283 [============================>.] - ETA: 0s - loss: 0.4640 - acc: 0.7898
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4636 - acc: 0.7903 - val_loss: 0.7708 - val_acc: 0.5677

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3838 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.4052 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4231 - acc: 0.7917
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4322 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4192 - acc: 0.8031
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4211 - acc: 0.8073
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4156 - acc: 0.8192
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4211 - acc: 0.8145
 640/1283 [=============>................] - ETA: 0s - loss: 0.4102 - acc: 0.8172
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4123 - acc: 0.8125
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4265 - acc: 0.7957
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4266 - acc: 0.8063
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4244 - acc: 0.8057
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4216 - acc: 0.8042
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4201 - acc: 0.8038
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4173 - acc: 0.8059
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4167 - acc: 0.8083 - val_loss: 0.7940 - val_acc: 0.5764

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2854 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.3322 - acc: 0.8672
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3080 - acc: 0.8958
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3098 - acc: 0.8945
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3211 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3334 - acc: 0.8839
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3319 - acc: 0.8809
 576/1283 [============>.................] - ETA: 0s - loss: 0.3284 - acc: 0.8802
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3324 - acc: 0.8778
 768/1283 [================>.............] - ETA: 0s - loss: 0.3321 - acc: 0.8776
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3276 - acc: 0.8762
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3235 - acc: 0.8772
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3275 - acc: 0.8708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3283 - acc: 0.8730
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3268 - acc: 0.8750
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3264 - acc: 0.8750
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3247 - acc: 0.8750
1280/1283 [============================>.] - ETA: 0s - loss: 0.3261 - acc: 0.8758
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3267 - acc: 0.8753 - val_loss: 0.8005 - val_acc: 0.5459

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2262 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.2750 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2867 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2847 - acc: 0.8828
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2972 - acc: 0.8750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2848 - acc: 0.8802
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2885 - acc: 0.8772
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2918 - acc: 0.8828
 576/1283 [============>.................] - ETA: 0s - loss: 0.2935 - acc: 0.8837
 640/1283 [=============>................] - ETA: 0s - loss: 0.2936 - acc: 0.8844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2864 - acc: 0.8892
 768/1283 [================>.............] - ETA: 0s - loss: 0.2978 - acc: 0.8750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2987 - acc: 0.8762
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3022 - acc: 0.8739
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3058 - acc: 0.8740
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3075 - acc: 0.8730
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3089 - acc: 0.8732
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3039 - acc: 0.8767
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3015 - acc: 0.8766
1280/1283 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.8727
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3069 - acc: 0.8730 - val_loss: 0.8457 - val_acc: 0.5808

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2382 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2442 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2505 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2646 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2588 - acc: 0.9062
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2694 - acc: 0.9036
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2733 - acc: 0.9062
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2799 - acc: 0.9043
 576/1283 [============>.................] - ETA: 0s - loss: 0.2745 - acc: 0.9045
 640/1283 [=============>................] - ETA: 0s - loss: 0.2696 - acc: 0.9078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2668 - acc: 0.9077
 768/1283 [================>.............] - ETA: 0s - loss: 0.2643 - acc: 0.9089
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2613 - acc: 0.9123
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2608 - acc: 0.9096
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2574 - acc: 0.9141
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2562 - acc: 0.9145
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2513 - acc: 0.9167
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2503 - acc: 0.9161
1280/1283 [============================>.] - ETA: 0s - loss: 0.2503 - acc: 0.9164
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2507 - acc: 0.9158 - val_loss: 0.9647 - val_acc: 0.5371

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2291 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.2378 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2238 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2180 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2095 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2062 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2048 - acc: 0.9531
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2124 - acc: 0.9453
 576/1283 [============>.................] - ETA: 0s - loss: 0.2173 - acc: 0.9444
 640/1283 [=============>................] - ETA: 0s - loss: 0.2168 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2178 - acc: 0.9432
 768/1283 [================>.............] - ETA: 0s - loss: 0.2285 - acc: 0.9349
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2281 - acc: 0.9327
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2228 - acc: 0.9364
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2191 - acc: 0.9375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2174 - acc: 0.9365
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2162 - acc: 0.9375
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2126 - acc: 0.9401
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2127 - acc: 0.9391
1280/1283 [============================>.] - ETA: 0s - loss: 0.2139 - acc: 0.9391
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2136 - acc: 0.9392 - val_loss: 0.9323 - val_acc: 0.5590

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1040 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1272 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1398 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1457 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1511 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1546 - acc: 0.9661
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1660 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1658 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.1661 - acc: 0.9583
 640/1283 [=============>................] - ETA: 0s - loss: 0.1694 - acc: 0.9563
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1668 - acc: 0.9574
 768/1283 [================>.............] - ETA: 0s - loss: 0.1635 - acc: 0.9583
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1626 - acc: 0.9603
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1611 - acc: 0.9621
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1615 - acc: 0.9615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1593 - acc: 0.9609
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1585 - acc: 0.9605
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1559 - acc: 0.9609
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1557 - acc: 0.9605
1280/1283 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9625
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1550 - acc: 0.9626 - val_loss: 1.1246 - val_acc: 0.4934

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1414 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1233 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1366 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1333 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1288 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1338 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1260 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.1249 - acc: 0.9774
 640/1283 [=============>................] - ETA: 0s - loss: 0.1206 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1222 - acc: 0.9773
 768/1283 [================>.............] - ETA: 0s - loss: 0.1215 - acc: 0.9792
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1241 - acc: 0.9784
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1226 - acc: 0.9792
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1195 - acc: 0.9805
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1187 - acc: 0.9798
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1177 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1165 - acc: 0.9794
1280/1283 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9805
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1152 - acc: 0.9805 - val_loss: 1.1352 - val_acc: 0.5895

Epoch 00013: val_acc improved from 0.58079 to 0.58952, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0755 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0662 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0669 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0694 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0704 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0705 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0691 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0704 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0723 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0762 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0800 - acc: 0.9904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0763 - acc: 0.9917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0763 - acc: 0.9902
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0755 - acc: 0.9908
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0753 - acc: 0.9913
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0749 - acc: 0.9910
1280/1283 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9906
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0867 - acc: 0.9906 - val_loss: 1.1562 - val_acc: 0.5808

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0434 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0662 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0747 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0786 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0765 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0712 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0984 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0916 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0903 - acc: 0.9859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0882 - acc: 0.9872
 768/1283 [================>.............] - ETA: 0s - loss: 0.0853 - acc: 0.9883
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0824 - acc: 0.9892
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0809 - acc: 0.9900
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0810 - acc: 0.9896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0797 - acc: 0.9893
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0770 - acc: 0.9899
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0757 - acc: 0.9905
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0747 - acc: 0.9910
1280/1283 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9914
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0749 - acc: 0.9906 - val_loss: 1.3302 - val_acc: 0.5197

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0578 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0663 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1366 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1314 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1306 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1317 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.1440 - acc: 0.9740
 640/1283 [=============>................] - ETA: 0s - loss: 0.1371 - acc: 0.9719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1310 - acc: 0.9730
 768/1283 [================>.............] - ETA: 0s - loss: 0.1316 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1289 - acc: 0.9724
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1312 - acc: 0.9677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1302 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1268 - acc: 0.9706
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1236 - acc: 0.9714
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1205 - acc: 0.9720
1280/1283 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9734
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1171 - acc: 0.9735 - val_loss: 1.2501 - val_acc: 0.5808

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0662 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0815 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0681 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0650 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0640 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0665 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0655 - acc: 0.9861
 640/1283 [=============>................] - ETA: 0s - loss: 0.0625 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0604 - acc: 0.9886
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0611 - acc: 0.9880
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0614 - acc: 0.9877
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0607 - acc: 0.9885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0593 - acc: 0.9893
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0596 - acc: 0.9890
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0600 - acc: 0.9887
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0695 - acc: 0.9885
1280/1283 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9883
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0700 - acc: 0.9875 - val_loss: 1.5074 - val_acc: 0.5633

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0444 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1129 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0961 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0886 - acc: 0.9635
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0878 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.0903 - acc: 0.9653
 640/1283 [=============>................] - ETA: 0s - loss: 0.0969 - acc: 0.9656
 768/1283 [================>.............] - ETA: 0s - loss: 0.1045 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1195 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1226 - acc: 0.9598
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1195 - acc: 0.9615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1173 - acc: 0.9639
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1142 - acc: 0.9651
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1168 - acc: 0.9638
1280/1283 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9648
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1150 - acc: 0.9641 - val_loss: 1.4197 - val_acc: 0.5415

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0516 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0537 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0798 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0799 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0797 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0852 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.0973 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0973 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0974 - acc: 0.9688
 768/1283 [================>.............] - ETA: 0s - loss: 0.0959 - acc: 0.9688
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1023 - acc: 0.9643
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1051 - acc: 0.9625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1064 - acc: 0.9609
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1058 - acc: 0.9614
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1078 - acc: 0.9592
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1070 - acc: 0.9597
1280/1283 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9602
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1051 - acc: 0.9602 - val_loss: 1.4630 - val_acc: 0.5371

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0712 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0770 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0831 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0716 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0677 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0651 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0623 - acc: 0.9863
 576/1283 [============>.................] - ETA: 0s - loss: 0.0631 - acc: 0.9878
 640/1283 [=============>................] - ETA: 0s - loss: 0.0639 - acc: 0.9859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0639 - acc: 0.9858
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0603 - acc: 0.9880
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0590 - acc: 0.9877
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0573 - acc: 0.9883
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0572 - acc: 0.9881
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0563 - acc: 0.9887
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0555 - acc: 0.9885
1280/1283 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9883
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0545 - acc: 0.9883 - val_loss: 1.4432 - val_acc: 0.5459

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0317 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0285 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0257 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0244 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0238 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0233 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0236 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0240 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0237 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0246 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0247 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0246 - acc: 0.9983
1280/1283 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9984
1283/1283 [==============================] - 1s 939us/step - loss: 0.0236 - acc: 0.9984 - val_loss: 1.5484 - val_acc: 0.5415

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0121 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0137 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0163 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0160 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0158 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0154 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0152 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0152 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0158 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0154 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0147 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0149 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0150 - acc: 1.0000
1283/1283 [==============================] - 1s 963us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 1.8281 - val_acc: 0.5502

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0183 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0194 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0337 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0335 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0314 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0284 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0352 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0387 - acc: 0.9901
 768/1283 [================>.............] - ETA: 0s - loss: 0.0427 - acc: 0.9883
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0430 - acc: 0.9888
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0465 - acc: 0.9885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0453 - acc: 0.9893
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0444 - acc: 0.9890
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0457 - acc: 0.9887
1280/1283 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9898
1283/1283 [==============================] - 1s 993us/step - loss: 0.0432 - acc: 0.9899 - val_loss: 1.6779 - val_acc: 0.5109

Epoch 00023: val_acc did not improve
Epoch 00023: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=30
epochs=100
mode=AV
accuracy=0.5204081632653061
best_valid_accuracy=0.5058309037900874
