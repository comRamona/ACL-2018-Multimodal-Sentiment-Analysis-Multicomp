/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:140: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:142: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-27 13:51:49.593094: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 9s - loss: 0.6668 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 3s - loss: 0.8447 - acc: 0.5885
 256/1283 [====>.........................] - ETA: 2s - loss: 0.8414 - acc: 0.5781
 320/1283 [======>.......................] - ETA: 2s - loss: 0.8256 - acc: 0.5844
 448/1283 [=========>....................] - ETA: 1s - loss: 0.8162 - acc: 0.5625
 512/1283 [==========>...................] - ETA: 1s - loss: 0.8038 - acc: 0.5547
 576/1283 [============>.................] - ETA: 1s - loss: 0.8007 - acc: 0.5451
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7849 - acc: 0.5298
 768/1283 [================>.............] - ETA: 0s - loss: 0.7733 - acc: 0.5404
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7601 - acc: 0.5402
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7517 - acc: 0.5479
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7577 - acc: 0.5460
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7548 - acc: 0.5477
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7519 - acc: 0.5485
1280/1283 [============================>.] - ETA: 0s - loss: 0.7479 - acc: 0.5516
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7480 - acc: 0.5511 - val_loss: 0.7730 - val_acc: 0.4978

Epoch 00001: val_acc improved from -inf to 0.49782, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6073 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6097 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6186 - acc: 0.6281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6299 - acc: 0.6094
 576/1283 [============>.................] - ETA: 0s - loss: 0.6303 - acc: 0.6181
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6287 - acc: 0.6193
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6276 - acc: 0.6298
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6248 - acc: 0.6302
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6233 - acc: 0.6360
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6219 - acc: 0.6365
1283/1283 [==============================] - 1s 764us/step - loss: 0.6214 - acc: 0.6376 - val_loss: 0.7382 - val_acc: 0.5022

Epoch 00002: val_acc improved from 0.49782 to 0.50218, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5708 - acc: 0.6875
 128/1283 [=>............................] - ETA: 0s - loss: 0.5334 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5426 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5648 - acc: 0.6914
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5657 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5465 - acc: 0.7207
 640/1283 [=============>................] - ETA: 0s - loss: 0.5507 - acc: 0.7172
 768/1283 [================>.............] - ETA: 0s - loss: 0.5523 - acc: 0.7070
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5508 - acc: 0.7121
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5479 - acc: 0.7148
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5408 - acc: 0.7257
1280/1283 [============================>.] - ETA: 0s - loss: 0.5428 - acc: 0.7203
1283/1283 [==============================] - 1s 782us/step - loss: 0.5420 - acc: 0.7210 - val_loss: 0.7606 - val_acc: 0.4847

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5054 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4797 - acc: 0.7552
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4556 - acc: 0.7781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4457 - acc: 0.7790
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4448 - acc: 0.7871
 576/1283 [============>.................] - ETA: 0s - loss: 0.4586 - acc: 0.7743
 640/1283 [=============>................] - ETA: 0s - loss: 0.4565 - acc: 0.7766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4568 - acc: 0.7798
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4621 - acc: 0.7704
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4613 - acc: 0.7701
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4639 - acc: 0.7676
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4696 - acc: 0.7622
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4732 - acc: 0.7607
1280/1283 [============================>.] - ETA: 0s - loss: 0.4713 - acc: 0.7617
1283/1283 [==============================] - 1s 861us/step - loss: 0.4711 - acc: 0.7623 - val_loss: 0.8391 - val_acc: 0.4978

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4454 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.4737 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4312 - acc: 0.7812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4495 - acc: 0.7656
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4469 - acc: 0.7656
 576/1283 [============>.................] - ETA: 0s - loss: 0.4436 - acc: 0.7708
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4412 - acc: 0.7827
 768/1283 [================>.............] - ETA: 0s - loss: 0.4448 - acc: 0.7786
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4411 - acc: 0.7861
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4343 - acc: 0.7937
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4238 - acc: 0.8042
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4275 - acc: 0.7995
1280/1283 [============================>.] - ETA: 0s - loss: 0.4262 - acc: 0.8023
1283/1283 [==============================] - 1s 763us/step - loss: 0.4259 - acc: 0.8028 - val_loss: 0.9175 - val_acc: 0.4629

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4003 - acc: 0.8594
 128/1283 [=>............................] - ETA: 0s - loss: 0.3588 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3420 - acc: 0.8867
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3446 - acc: 0.8620
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3470 - acc: 0.8616
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3515 - acc: 0.8535
 640/1283 [=============>................] - ETA: 0s - loss: 0.3569 - acc: 0.8500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3547 - acc: 0.8523
 768/1283 [================>.............] - ETA: 0s - loss: 0.3519 - acc: 0.8529
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3479 - acc: 0.8582
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3470 - acc: 0.8594
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3499 - acc: 0.8583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3441 - acc: 0.8603
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3473 - acc: 0.8528
1283/1283 [==============================] - 1s 836us/step - loss: 0.3455 - acc: 0.8535 - val_loss: 0.9588 - val_acc: 0.5328

Epoch 00006: val_acc improved from 0.50218 to 0.53275, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2959 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2802 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2612 - acc: 0.9094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2730 - acc: 0.9018
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2730 - acc: 0.9043
 640/1283 [=============>................] - ETA: 0s - loss: 0.2742 - acc: 0.9016
 768/1283 [================>.............] - ETA: 0s - loss: 0.2756 - acc: 0.9023
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2751 - acc: 0.9026
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2800 - acc: 0.9007
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2846 - acc: 0.8994
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2838 - acc: 0.9002
1280/1283 [============================>.] - ETA: 0s - loss: 0.2881 - acc: 0.8922
1283/1283 [==============================] - 1s 778us/step - loss: 0.2878 - acc: 0.8924 - val_loss: 1.0550 - val_acc: 0.5022

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2788 - acc: 0.9219
 128/1283 [=>............................] - ETA: 0s - loss: 0.3190 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2821 - acc: 0.8828
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2783 - acc: 0.8880
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2730 - acc: 0.8884
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2621 - acc: 0.9004
 640/1283 [=============>................] - ETA: 0s - loss: 0.2592 - acc: 0.9047
 768/1283 [================>.............] - ETA: 0s - loss: 0.2597 - acc: 0.9076
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2572 - acc: 0.9062
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2558 - acc: 0.9043
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2541 - acc: 0.9072
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2494 - acc: 0.9104
1283/1283 [==============================] - 1s 793us/step - loss: 0.2499 - acc: 0.9096 - val_loss: 1.0873 - val_acc: 0.5066

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1620 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2362 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2306 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2184 - acc: 0.9036
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2252 - acc: 0.8996
 576/1283 [============>.................] - ETA: 0s - loss: 0.2127 - acc: 0.9167
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2067 - acc: 0.9176
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2102 - acc: 0.9147
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2148 - acc: 0.9115
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2110 - acc: 0.9154
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2126 - acc: 0.9161
1280/1283 [============================>.] - ETA: 0s - loss: 0.2242 - acc: 0.9133
1283/1283 [==============================] - 1s 745us/step - loss: 0.2244 - acc: 0.9135 - val_loss: 1.0690 - val_acc: 0.4672

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1704 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1817 - acc: 0.9297
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1875 - acc: 0.9414
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1920 - acc: 0.9349
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2065 - acc: 0.9238
 640/1283 [=============>................] - ETA: 0s - loss: 0.2083 - acc: 0.9219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2017 - acc: 0.9290
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2009 - acc: 0.9303
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2042 - acc: 0.9260
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2097 - acc: 0.9237
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2063 - acc: 0.9245
1280/1283 [============================>.] - ETA: 0s - loss: 0.2024 - acc: 0.9273
1283/1283 [==============================] - 1s 779us/step - loss: 0.2026 - acc: 0.9275 - val_loss: 1.2123 - val_acc: 0.4585

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2099 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2178 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2107 - acc: 0.9094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2087 - acc: 0.9107
 576/1283 [============>.................] - ETA: 0s - loss: 0.2091 - acc: 0.9149
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2008 - acc: 0.9205
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1994 - acc: 0.9243
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1935 - acc: 0.9323
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1989 - acc: 0.9366
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1987 - acc: 0.9359
1283/1283 [==============================] - 1s 729us/step - loss: 0.1951 - acc: 0.9369 - val_loss: 1.1873 - val_acc: 0.4891

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1273 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1212 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1156 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1153 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.1235 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1210 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1203 - acc: 0.9663
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1378 - acc: 0.9656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1325 - acc: 0.9651
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1314 - acc: 0.9661
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1288 - acc: 0.9679
1283/1283 [==============================] - 1s 743us/step - loss: 0.1277 - acc: 0.9680 - val_loss: 1.3311 - val_acc: 0.4934

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0750 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0810 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0781 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1386 - acc: 0.9883
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1256 - acc: 0.9818
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1184 - acc: 0.9824
 640/1283 [=============>................] - ETA: 0s - loss: 0.1087 - acc: 0.9859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1054 - acc: 0.9872
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0997 - acc: 0.9868
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0935 - acc: 0.9885
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0887 - acc: 0.9890
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0894 - acc: 0.9885
1283/1283 [==============================] - 1s 786us/step - loss: 0.0886 - acc: 0.9883 - val_loss: 1.3995 - val_acc: 0.4934

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0637 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0956 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0958 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0864 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0891 - acc: 0.9826
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0879 - acc: 0.9830
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0828 - acc: 0.9856
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0845 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0855 - acc: 0.9834
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0839 - acc: 0.9835
1280/1283 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9844
1283/1283 [==============================] - 1s 789us/step - loss: 0.0826 - acc: 0.9844 - val_loss: 1.4718 - val_acc: 0.4891

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0634 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.0684 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0991 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0818 - acc: 0.9870
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0729 - acc: 0.9883
 576/1283 [============>.................] - ETA: 0s - loss: 0.0717 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0708 - acc: 0.9872
 768/1283 [================>.............] - ETA: 0s - loss: 0.0869 - acc: 0.9831
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0850 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0826 - acc: 0.9833
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0787 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0772 - acc: 0.9844
1283/1283 [==============================] - 1s 770us/step - loss: 0.0757 - acc: 0.9844 - val_loss: 1.4233 - val_acc: 0.5328

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0510 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0486 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0461 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0449 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0428 - acc: 0.9922
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0699 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0660 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0632 - acc: 0.9922
 768/1283 [================>.............] - ETA: 0s - loss: 0.0584 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0568 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0550 - acc: 0.9944
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0532 - acc: 0.9948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0540 - acc: 0.9936
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0540 - acc: 0.9918
1280/1283 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9914
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0540 - acc: 0.9914 - val_loss: 1.5051 - val_acc: 0.4978

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
epochs=100
mode=AV
accuracy=0.4868804664723032
best_valid_accuracy=0.48542274052478135
