/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:140: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:142: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-27 13:43:37.040275: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 3s - loss: 1.1612 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 1s - loss: 1.2388 - acc: 0.5052
 320/1283 [======>.......................] - ETA: 0s - loss: 1.0801 - acc: 0.4688
 448/1283 [=========>....................] - ETA: 0s - loss: 1.0307 - acc: 0.4844
 576/1283 [============>.................] - ETA: 0s - loss: 0.9683 - acc: 0.5087
 704/1283 [===============>..............] - ETA: 0s - loss: 0.9198 - acc: 0.5213
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8920 - acc: 0.5361
 960/1283 [=====================>........] - ETA: 0s - loss: 0.8734 - acc: 0.5375
1088/1283 [========================>.....] - ETA: 0s - loss: 0.8519 - acc: 0.5423
1216/1283 [===========================>..] - ETA: 0s - loss: 0.8357 - acc: 0.5419
1283/1283 [==============================] - 1s 774us/step - loss: 0.8294 - acc: 0.5479 - val_loss: 0.7390 - val_acc: 0.5808

Epoch 00001: val_acc improved from -inf to 0.58079, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4956 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5293 - acc: 0.7292
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5052 - acc: 0.7688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4949 - acc: 0.7790
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4951 - acc: 0.7773
 640/1283 [=============>................] - ETA: 0s - loss: 0.4895 - acc: 0.7781
 768/1283 [================>.............] - ETA: 0s - loss: 0.4847 - acc: 0.7826
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4735 - acc: 0.7946
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4690 - acc: 0.7969
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4613 - acc: 0.8047
1280/1283 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8063
1283/1283 [==============================] - 1s 711us/step - loss: 0.4586 - acc: 0.8067 - val_loss: 0.6742 - val_acc: 0.6507

Epoch 00002: val_acc improved from 0.58079 to 0.65066, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3091 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3076 - acc: 0.9115
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3301 - acc: 0.8719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3361 - acc: 0.8705
 576/1283 [============>.................] - ETA: 0s - loss: 0.3237 - acc: 0.8854
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3160 - acc: 0.8878
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3115 - acc: 0.8918
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3165 - acc: 0.8865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3158 - acc: 0.8869
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3086 - acc: 0.8923
1283/1283 [==============================] - 1s 627us/step - loss: 0.3065 - acc: 0.8932 - val_loss: 0.7139 - val_acc: 0.6376

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1535 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1962 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2056 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2129 - acc: 0.9297
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2090 - acc: 0.9355
 640/1283 [=============>................] - ETA: 0s - loss: 0.2105 - acc: 0.9344
 768/1283 [================>.............] - ETA: 0s - loss: 0.2105 - acc: 0.9336
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2053 - acc: 0.9364
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2023 - acc: 0.9355
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1992 - acc: 0.9366
1280/1283 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9391
1283/1283 [==============================] - 1s 648us/step - loss: 0.1952 - acc: 0.9392 - val_loss: 0.7231 - val_acc: 0.6812

Epoch 00004: val_acc improved from 0.65066 to 0.68122, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1391 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1355 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1392 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1309 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.1268 - acc: 0.9774
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1266 - acc: 0.9801
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1225 - acc: 0.9820
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1200 - acc: 0.9823
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1197 - acc: 0.9825
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1173 - acc: 0.9827
1283/1283 [==============================] - 1s 627us/step - loss: 0.1178 - acc: 0.9829 - val_loss: 0.7973 - val_acc: 0.6376

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0637 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0646 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0722 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0763 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0750 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0747 - acc: 0.9858
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0786 - acc: 0.9820
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0846 - acc: 0.9792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0845 - acc: 0.9807
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0842 - acc: 0.9827
1283/1283 [==============================] - 1s 651us/step - loss: 0.0816 - acc: 0.9836 - val_loss: 0.8807 - val_acc: 0.6507

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0759 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0605 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0608 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0621 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0560 - acc: 0.9878
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0555 - acc: 0.9886
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0562 - acc: 0.9868
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0546 - acc: 0.9875
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0523 - acc: 0.9890
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0498 - acc: 0.9901
1283/1283 [==============================] - 1s 673us/step - loss: 0.0487 - acc: 0.9906 - val_loss: 0.9275 - val_acc: 0.6638

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0369 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0264 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0266 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0258 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0319 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0301 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0288 - acc: 0.9948
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0275 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0281 - acc: 0.9948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0298 - acc: 0.9936
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0293 - acc: 0.9934
1283/1283 [==============================] - 1s 698us/step - loss: 0.0289 - acc: 0.9938 - val_loss: 1.0114 - val_acc: 0.6638

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0275 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0193 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0238 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0231 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0238 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0221 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0210 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0210 - acc: 0.9987
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0206 - acc: 0.9989
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0196 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0200 - acc: 0.9983
1280/1283 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9945
1283/1283 [==============================] - 1s 691us/step - loss: 0.0223 - acc: 0.9945 - val_loss: 1.0747 - val_acc: 0.6681

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0259 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0204 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0182 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0145 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0153 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0154 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0150 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0155 - acc: 0.9969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0174 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0171 - acc: 0.9959
1283/1283 [==============================] - 1s 731us/step - loss: 0.0170 - acc: 0.9961 - val_loss: 1.1417 - val_acc: 0.6594

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0311 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0289 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0230 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0194 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0185 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0181 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0174 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0159 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0152 - acc: 0.9979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0163 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0156 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0153 - acc: 0.9967
1283/1283 [==============================] - 1s 839us/step - loss: 0.0150 - acc: 0.9969 - val_loss: 1.1923 - val_acc: 0.6550

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0290 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0241 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0294 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0294 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0241 - acc: 0.9888
 576/1283 [============>.................] - ETA: 0s - loss: 0.0231 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0214 - acc: 0.9915
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0221 - acc: 0.9916
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0227 - acc: 0.9917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0221 - acc: 0.9922
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0219 - acc: 0.9931
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0220 - acc: 0.9934
1283/1283 [==============================] - 1s 806us/step - loss: 0.0221 - acc: 0.9938 - val_loss: 1.2272 - val_acc: 0.6812

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0143 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0128 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0162 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0191 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0200 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0193 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0192 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0185 - acc: 0.9955
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0185 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0181 - acc: 0.9963
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0188 - acc: 0.9959
1283/1283 [==============================] - 1s 746us/step - loss: 0.0181 - acc: 0.9961 - val_loss: 1.1852 - val_acc: 0.6550

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0063 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0056 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0073 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0142 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0156 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0149 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0138 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0125 - acc: 0.9972
 768/1283 [================>.............] - ETA: 0s - loss: 0.0128 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0135 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0145 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0139 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0135 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0140 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0139 - acc: 0.9959
1280/1283 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9961
1283/1283 [==============================] - 1s 969us/step - loss: 0.0137 - acc: 0.9961 - val_loss: 1.2765 - val_acc: 0.6638

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
epochs=100
mode=AT
accuracy=0.6064139941690962
best_valid_accuracy=0.6180758017492711
