/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:140: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:142: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-27 13:51:16.170226: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.7353 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 3s - loss: 0.8696 - acc: 0.4844 
 320/1283 [======>.......................] - ETA: 1s - loss: 0.8416 - acc: 0.4906
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7982 - acc: 0.5156
 576/1283 [============>.................] - ETA: 0s - loss: 0.7885 - acc: 0.5017
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7718 - acc: 0.5000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7644 - acc: 0.5084
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7581 - acc: 0.5156
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7490 - acc: 0.5257
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7381 - acc: 0.5312
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7358 - acc: 0.5308 - val_loss: 0.7433 - val_acc: 0.4891

Epoch 00001: val_acc improved from -inf to 0.48908, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6430 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6537 - acc: 0.5885
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6389 - acc: 0.6031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6249 - acc: 0.6161
 640/1283 [=============>................] - ETA: 0s - loss: 0.6170 - acc: 0.6344
 768/1283 [================>.............] - ETA: 0s - loss: 0.6250 - acc: 0.6341
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6184 - acc: 0.6406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6146 - acc: 0.6484
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6130 - acc: 0.6502
1280/1283 [============================>.] - ETA: 0s - loss: 0.6133 - acc: 0.6508
1283/1283 [==============================] - 1s 519us/step - loss: 0.6134 - acc: 0.6508 - val_loss: 0.7347 - val_acc: 0.4978

Epoch 00002: val_acc improved from 0.48908 to 0.49782, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5422 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5525 - acc: 0.7148
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5661 - acc: 0.6979
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5676 - acc: 0.6934
 576/1283 [============>.................] - ETA: 0s - loss: 0.5642 - acc: 0.6979
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5577 - acc: 0.7003
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5511 - acc: 0.7055
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5599 - acc: 0.7042
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5586 - acc: 0.7051
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5581 - acc: 0.7114
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5536 - acc: 0.7163
1280/1283 [============================>.] - ETA: 0s - loss: 0.5497 - acc: 0.7195
1283/1283 [==============================] - 1s 659us/step - loss: 0.5496 - acc: 0.7194 - val_loss: 0.7467 - val_acc: 0.5415

Epoch 00003: val_acc improved from 0.49782 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4150 - acc: 0.8906
 128/1283 [=>............................] - ETA: 0s - loss: 0.4635 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4872 - acc: 0.7906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5026 - acc: 0.7812
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5029 - acc: 0.7754
 640/1283 [=============>................] - ETA: 0s - loss: 0.5042 - acc: 0.7719
 768/1283 [================>.............] - ETA: 0s - loss: 0.4970 - acc: 0.7773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4989 - acc: 0.7764
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4974 - acc: 0.7760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4934 - acc: 0.7803
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4904 - acc: 0.7821
1280/1283 [============================>.] - ETA: 0s - loss: 0.4872 - acc: 0.7844
1283/1283 [==============================] - 1s 656us/step - loss: 0.4875 - acc: 0.7833 - val_loss: 0.7472 - val_acc: 0.5284

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3851 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4142 - acc: 0.8438
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4108 - acc: 0.8359
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4127 - acc: 0.8398
 640/1283 [=============>................] - ETA: 0s - loss: 0.4146 - acc: 0.8344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4186 - acc: 0.8245
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4168 - acc: 0.8248
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4186 - acc: 0.8213
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4212 - acc: 0.8186
1280/1283 [============================>.] - ETA: 0s - loss: 0.4266 - acc: 0.8156
1283/1283 [==============================] - 1s 686us/step - loss: 0.4265 - acc: 0.8161 - val_loss: 0.7615 - val_acc: 0.5415

Epoch 00005: val_acc improved from 0.54148 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4099 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3800 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3804 - acc: 0.8438
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3764 - acc: 0.8490
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3755 - acc: 0.8496
 640/1283 [=============>................] - ETA: 0s - loss: 0.3723 - acc: 0.8469
 768/1283 [================>.............] - ETA: 0s - loss: 0.3759 - acc: 0.8411
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3742 - acc: 0.8460
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3719 - acc: 0.8516
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3788 - acc: 0.8455
1280/1283 [============================>.] - ETA: 0s - loss: 0.3804 - acc: 0.8445
1283/1283 [==============================] - 1s 736us/step - loss: 0.3811 - acc: 0.8441 - val_loss: 0.8154 - val_acc: 0.5502

Epoch 00006: val_acc improved from 0.54148 to 0.55022, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3151 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3175 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3246 - acc: 0.8812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3391 - acc: 0.8750
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3398 - acc: 0.8750
 576/1283 [============>.................] - ETA: 0s - loss: 0.3387 - acc: 0.8785
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3533 - acc: 0.8636
 768/1283 [================>.............] - ETA: 0s - loss: 0.3557 - acc: 0.8620
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3457 - acc: 0.8694
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3480 - acc: 0.8677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3505 - acc: 0.8667
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3440 - acc: 0.8709
1280/1283 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.8742
1283/1283 [==============================] - 1s 712us/step - loss: 0.3407 - acc: 0.8737 - val_loss: 0.8982 - val_acc: 0.5502

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2722 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.2931 - acc: 0.8516
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3004 - acc: 0.8516
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2973 - acc: 0.8672
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3020 - acc: 0.8638
 640/1283 [=============>................] - ETA: 0s - loss: 0.3033 - acc: 0.8734
 768/1283 [================>.............] - ETA: 0s - loss: 0.3063 - acc: 0.8711
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3060 - acc: 0.8694
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2978 - acc: 0.8779
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2975 - acc: 0.8785
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2946 - acc: 0.8799
1283/1283 [==============================] - 1s 682us/step - loss: 0.2928 - acc: 0.8831 - val_loss: 1.0739 - val_acc: 0.5677

Epoch 00008: val_acc improved from 0.55022 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1879 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2828 - acc: 0.8802
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2642 - acc: 0.8828
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2658 - acc: 0.8984
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2706 - acc: 0.8929
 576/1283 [============>.................] - ETA: 0s - loss: 0.2916 - acc: 0.8733
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2761 - acc: 0.8821
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2668 - acc: 0.8870
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2694 - acc: 0.8896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2676 - acc: 0.8925
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2664 - acc: 0.8956
1283/1283 [==============================] - 1s 628us/step - loss: 0.2679 - acc: 0.8917 - val_loss: 0.8890 - val_acc: 0.5764

Epoch 00009: val_acc improved from 0.56769 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1501 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2555 - acc: 0.9115
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2758 - acc: 0.9036
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2703 - acc: 0.9043
 576/1283 [============>.................] - ETA: 0s - loss: 0.2850 - acc: 0.8993
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2946 - acc: 0.8878
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2841 - acc: 0.8942
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2901 - acc: 0.8927
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3071 - acc: 0.8805
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3019 - acc: 0.8863
1280/1283 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.8945
1283/1283 [==============================] - 1s 692us/step - loss: 0.2933 - acc: 0.8940 - val_loss: 0.9361 - val_acc: 0.5371

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4555 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2809 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2442 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2320 - acc: 0.9583
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2222 - acc: 0.9512
 576/1283 [============>.................] - ETA: 0s - loss: 0.2194 - acc: 0.9479
 768/1283 [================>.............] - ETA: 0s - loss: 0.2238 - acc: 0.9362
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2273 - acc: 0.9375
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2267 - acc: 0.9365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2244 - acc: 0.9395
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2239 - acc: 0.9393
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2223 - acc: 0.9384
1280/1283 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9367
1283/1283 [==============================] - 1s 789us/step - loss: 0.2178 - acc: 0.9369 - val_loss: 0.9834 - val_acc: 0.5633

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1694 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1845 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1760 - acc: 0.9281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1637 - acc: 0.9397
 576/1283 [============>.................] - ETA: 0s - loss: 0.1574 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1553 - acc: 0.9503
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1546 - acc: 0.9543
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1582 - acc: 0.9521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1655 - acc: 0.9559
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1628 - acc: 0.9581
1283/1283 [==============================] - 1s 609us/step - loss: 0.1610 - acc: 0.9595 - val_loss: 1.0600 - val_acc: 0.5328

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1340 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1310 - acc: 0.9740
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1385 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1353 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.1336 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1354 - acc: 0.9659
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1316 - acc: 0.9700
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1327 - acc: 0.9676
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1344 - acc: 0.9677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1353 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1335 - acc: 0.9688
1280/1283 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9688
1283/1283 [==============================] - 1s 782us/step - loss: 0.1355 - acc: 0.9688 - val_loss: 1.2694 - val_acc: 0.5721

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0935 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1067 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0941 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1322 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1327 - acc: 0.9609
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1242 - acc: 0.9648
 640/1283 [=============>................] - ETA: 0s - loss: 0.1313 - acc: 0.9609
 768/1283 [================>.............] - ETA: 0s - loss: 0.1254 - acc: 0.9674
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1419 - acc: 0.9665
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1370 - acc: 0.9688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1354 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1340 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9703
1283/1283 [==============================] - 1s 829us/step - loss: 0.1337 - acc: 0.9696 - val_loss: 1.2296 - val_acc: 0.5415

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0860 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1406 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1332 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1431 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1422 - acc: 0.9531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1342 - acc: 0.9560
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1295 - acc: 0.9603
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1312 - acc: 0.9594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1260 - acc: 0.9623
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1253 - acc: 0.9613
1283/1283 [==============================] - 1s 709us/step - loss: 0.1260 - acc: 0.9610 - val_loss: 1.2854 - val_acc: 0.5633

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0748 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0774 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0784 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0791 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0822 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0827 - acc: 0.9913
 640/1283 [=============>................] - ETA: 0s - loss: 0.0805 - acc: 0.9922
 768/1283 [================>.............] - ETA: 0s - loss: 0.0822 - acc: 0.9883
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0789 - acc: 0.9888
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0794 - acc: 0.9865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0803 - acc: 0.9853
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0807 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9844
1283/1283 [==============================] - 1s 775us/step - loss: 0.0801 - acc: 0.9844 - val_loss: 1.3194 - val_acc: 0.5022

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0693 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0870 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0880 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0871 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0876 - acc: 0.9805
 576/1283 [============>.................] - ETA: 0s - loss: 0.0847 - acc: 0.9809
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0895 - acc: 0.9801
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0849 - acc: 0.9820
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0842 - acc: 0.9812
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0863 - acc: 0.9805
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0887 - acc: 0.9774
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0883 - acc: 0.9762
1280/1283 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9766
1283/1283 [==============================] - 1s 674us/step - loss: 0.0868 - acc: 0.9766 - val_loss: 1.4905 - val_acc: 0.5459

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0698 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0758 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0599 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0573 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0558 - acc: 0.9902
 640/1283 [=============>................] - ETA: 0s - loss: 0.0557 - acc: 0.9906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0557 - acc: 0.9904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0555 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0570 - acc: 0.9899
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0549 - acc: 0.9901
1283/1283 [==============================] - 1s 678us/step - loss: 0.0542 - acc: 0.9899 - val_loss: 1.5059 - val_acc: 0.5415

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0545 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0561 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0558 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0567 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0546 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0506 - acc: 0.9883
 576/1283 [============>.................] - ETA: 0s - loss: 0.0514 - acc: 0.9878
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0552 - acc: 0.9886
 768/1283 [================>.............] - ETA: 0s - loss: 0.0539 - acc: 0.9896
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0544 - acc: 0.9900
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0536 - acc: 0.9896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0534 - acc: 0.9899
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0518 - acc: 0.9910
1283/1283 [==============================] - 1s 688us/step - loss: 0.0518 - acc: 0.9906 - val_loss: 1.4842 - val_acc: 0.5153

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
epochs=100
mode=AV
accuracy=0.5043731778425656
best_valid_accuracy=0.49854227405247814
