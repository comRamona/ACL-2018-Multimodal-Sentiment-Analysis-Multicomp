/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:140: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:142: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-27 13:51:18.921819: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.7353 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 3s - loss: 0.8696 - acc: 0.4844 
 256/1283 [====>.........................] - ETA: 2s - loss: 0.8473 - acc: 0.5039
 384/1283 [=======>......................] - ETA: 1s - loss: 0.8272 - acc: 0.4974
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7982 - acc: 0.4980
 576/1283 [============>.................] - ETA: 1s - loss: 0.7885 - acc: 0.5017
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7718 - acc: 0.5000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7644 - acc: 0.5084
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7581 - acc: 0.5156
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7490 - acc: 0.5267
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7428 - acc: 0.5278
1280/1283 [============================>.] - ETA: 0s - loss: 0.7357 - acc: 0.5328
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7358 - acc: 0.5323 - val_loss: 0.7434 - val_acc: 0.4847

Epoch 00001: val_acc improved from -inf to 0.48472, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6430 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6511 - acc: 0.5820
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6264 - acc: 0.6172
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6255 - acc: 0.6172
 640/1283 [=============>................] - ETA: 0s - loss: 0.6172 - acc: 0.6344
 768/1283 [================>.............] - ETA: 0s - loss: 0.6251 - acc: 0.6341
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6186 - acc: 0.6395
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6148 - acc: 0.6475
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6139 - acc: 0.6489
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6135 - acc: 0.6497
1283/1283 [==============================] - 1s 623us/step - loss: 0.6136 - acc: 0.6500 - val_loss: 0.7345 - val_acc: 0.4891

Epoch 00002: val_acc improved from 0.48472 to 0.48908, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5406 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5496 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5656 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5678 - acc: 0.6875
 576/1283 [============>.................] - ETA: 0s - loss: 0.5631 - acc: 0.6944
 640/1283 [=============>................] - ETA: 0s - loss: 0.5506 - acc: 0.7125
 768/1283 [================>.............] - ETA: 0s - loss: 0.5549 - acc: 0.7005
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5506 - acc: 0.7076
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5581 - acc: 0.7061
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5555 - acc: 0.7144
1280/1283 [============================>.] - ETA: 0s - loss: 0.5495 - acc: 0.7211
1283/1283 [==============================] - 1s 598us/step - loss: 0.5494 - acc: 0.7210 - val_loss: 0.7500 - val_acc: 0.5590

Epoch 00003: val_acc improved from 0.48908 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4144 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4863 - acc: 0.7891
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4867 - acc: 0.7844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5016 - acc: 0.7723
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5021 - acc: 0.7676
 576/1283 [============>.................] - ETA: 0s - loss: 0.5017 - acc: 0.7674
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4998 - acc: 0.7699
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4980 - acc: 0.7716
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4920 - acc: 0.7764
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4912 - acc: 0.7760
1280/1283 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.7812
1283/1283 [==============================] - 1s 582us/step - loss: 0.4861 - acc: 0.7802 - val_loss: 0.7518 - val_acc: 0.5328

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3849 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4174 - acc: 0.8542
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4112 - acc: 0.8438
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4121 - acc: 0.8359
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4134 - acc: 0.8398
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4155 - acc: 0.8338
 768/1283 [================>.............] - ETA: 0s - loss: 0.4221 - acc: 0.8268
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4175 - acc: 0.8270
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4147 - acc: 0.8292
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4214 - acc: 0.8212
1280/1283 [============================>.] - ETA: 0s - loss: 0.4267 - acc: 0.8187
1283/1283 [==============================] - 1s 706us/step - loss: 0.4265 - acc: 0.8192 - val_loss: 0.7648 - val_acc: 0.5546

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4186 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3829 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3844 - acc: 0.8531
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3790 - acc: 0.8555
 576/1283 [============>.................] - ETA: 0s - loss: 0.3835 - acc: 0.8438
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3795 - acc: 0.8452
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3742 - acc: 0.8474
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3763 - acc: 0.8482
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3743 - acc: 0.8535
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3807 - acc: 0.8455
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3839 - acc: 0.8446
1283/1283 [==============================] - 1s 705us/step - loss: 0.3833 - acc: 0.8449 - val_loss: 0.8332 - val_acc: 0.5328

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3084 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3143 - acc: 0.8867
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3344 - acc: 0.8724
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3367 - acc: 0.8730
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3511 - acc: 0.8622
 768/1283 [================>.............] - ETA: 0s - loss: 0.3547 - acc: 0.8607
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3465 - acc: 0.8683
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3498 - acc: 0.8658
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3435 - acc: 0.8725
1283/1283 [==============================] - 1s 664us/step - loss: 0.3406 - acc: 0.8737 - val_loss: 0.8989 - val_acc: 0.5502

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2769 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2806 - acc: 0.8646
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2920 - acc: 0.8516
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3054 - acc: 0.8469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2943 - acc: 0.8661
 576/1283 [============>.................] - ETA: 0s - loss: 0.2923 - acc: 0.8767
 640/1283 [=============>................] - ETA: 0s - loss: 0.2956 - acc: 0.8750
 768/1283 [================>.............] - ETA: 0s - loss: 0.2990 - acc: 0.8724
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3003 - acc: 0.8690
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2981 - acc: 0.8717
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2901 - acc: 0.8809
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2909 - acc: 0.8802
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2883 - acc: 0.8840
1283/1283 [==============================] - 1s 780us/step - loss: 0.2866 - acc: 0.8862 - val_loss: 1.0790 - val_acc: 0.5546

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1906 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2693 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2543 - acc: 0.8945
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2560 - acc: 0.9036
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2751 - acc: 0.8887
 576/1283 [============>.................] - ETA: 0s - loss: 0.2821 - acc: 0.8837
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2677 - acc: 0.8920
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2621 - acc: 0.8966
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2651 - acc: 0.8948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2611 - acc: 0.8998
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2606 - acc: 0.9013
1280/1283 [============================>.] - ETA: 0s - loss: 0.2602 - acc: 0.8992
1283/1283 [==============================] - 1s 692us/step - loss: 0.2614 - acc: 0.8987 - val_loss: 0.9578 - val_acc: 0.5677

Epoch 00009: val_acc improved from 0.55895 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1514 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2912 - acc: 0.8542
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2953 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2805 - acc: 0.8795
 576/1283 [============>.................] - ETA: 0s - loss: 0.2883 - acc: 0.8785
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2899 - acc: 0.8750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2763 - acc: 0.8894
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2771 - acc: 0.8917
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2826 - acc: 0.8880
1280/1283 [============================>.] - ETA: 0s - loss: 0.2785 - acc: 0.8938
1283/1283 [==============================] - 1s 563us/step - loss: 0.2790 - acc: 0.8932 - val_loss: 0.9867 - val_acc: 0.5677

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4142 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2836 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2472 - acc: 0.9437
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2177 - acc: 0.9492
 640/1283 [=============>................] - ETA: 0s - loss: 0.2182 - acc: 0.9437
 768/1283 [================>.............] - ETA: 0s - loss: 0.2197 - acc: 0.9349
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2215 - acc: 0.9342
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2236 - acc: 0.9302
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2205 - acc: 0.9297
1280/1283 [============================>.] - ETA: 0s - loss: 0.2156 - acc: 0.9320
1283/1283 [==============================] - 1s 535us/step - loss: 0.2154 - acc: 0.9322 - val_loss: 0.9998 - val_acc: 0.5590

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1641 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1546 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1620 - acc: 0.9414
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1614 - acc: 0.9479
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1531 - acc: 0.9531
 640/1283 [=============>................] - ETA: 0s - loss: 0.1549 - acc: 0.9547
 768/1283 [================>.............] - ETA: 0s - loss: 0.1526 - acc: 0.9570
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1530 - acc: 0.9591
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1582 - acc: 0.9542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1576 - acc: 0.9577
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1555 - acc: 0.9597
1283/1283 [==============================] - 1s 657us/step - loss: 0.1539 - acc: 0.9602 - val_loss: 1.0840 - val_acc: 0.5153

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1483 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1532 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1593 - acc: 0.9609
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1442 - acc: 0.9714
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1452 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.1386 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1363 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1313 - acc: 0.9724
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1304 - acc: 0.9719
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1321 - acc: 0.9697
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1307 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9672
1283/1283 [==============================] - 1s 742us/step - loss: 0.1332 - acc: 0.9673 - val_loss: 1.2439 - val_acc: 0.5546

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0873 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0929 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1334 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1263 - acc: 0.9621
 640/1283 [=============>................] - ETA: 0s - loss: 0.1286 - acc: 0.9609
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1296 - acc: 0.9639
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1292 - acc: 0.9646
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1243 - acc: 0.9678
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1256 - acc: 0.9688
1283/1283 [==============================] - 1s 617us/step - loss: 0.1252 - acc: 0.9696 - val_loss: 1.2301 - val_acc: 0.5371

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0806 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.1157 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1356 - acc: 0.9609
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1356 - acc: 0.9583
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1358 - acc: 0.9551
 640/1283 [=============>................] - ETA: 0s - loss: 0.1368 - acc: 0.9563
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1295 - acc: 0.9627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1317 - acc: 0.9594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1295 - acc: 0.9609
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1256 - acc: 0.9613
1283/1283 [==============================] - 1s 634us/step - loss: 0.1262 - acc: 0.9610 - val_loss: 1.2892 - val_acc: 0.5415

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0819 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0782 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0811 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0789 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0811 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0827 - acc: 0.9878
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0816 - acc: 0.9901
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0860 - acc: 0.9892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0829 - acc: 0.9875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0854 - acc: 0.9863
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0837 - acc: 0.9862
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0834 - acc: 0.9852
1283/1283 [==============================] - 1s 713us/step - loss: 0.0824 - acc: 0.9860 - val_loss: 1.2904 - val_acc: 0.5066

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0671 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0830 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1160 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1060 - acc: 0.9866
 640/1283 [=============>................] - ETA: 0s - loss: 0.0947 - acc: 0.9859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1014 - acc: 0.9830
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0928 - acc: 0.9855
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0932 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0963 - acc: 0.9800
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0955 - acc: 0.9794
1283/1283 [==============================] - 1s 657us/step - loss: 0.0936 - acc: 0.9797 - val_loss: 1.4637 - val_acc: 0.5371

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0711 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0770 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0632 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0626 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0594 - acc: 0.9883
 640/1283 [=============>................] - ETA: 0s - loss: 0.0580 - acc: 0.9906
 768/1283 [================>.............] - ETA: 0s - loss: 0.0587 - acc: 0.9909
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0569 - acc: 0.9922
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0565 - acc: 0.9912
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0567 - acc: 0.9913
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0562 - acc: 0.9910
1283/1283 [==============================] - 1s 584us/step - loss: 0.0556 - acc: 0.9906 - val_loss: 1.5078 - val_acc: 0.5546

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0590 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0601 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0584 - acc: 0.9888
 576/1283 [============>.................] - ETA: 0s - loss: 0.0557 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0598 - acc: 0.9858
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0596 - acc: 0.9866
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0582 - acc: 0.9873
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0582 - acc: 0.9878
1283/1283 [==============================] - 1s 510us/step - loss: 0.0576 - acc: 0.9883 - val_loss: 1.4584 - val_acc: 0.5415

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
epochs=100
mode=AV
accuracy=0.5116618075801749
best_valid_accuracy=0.49854227405247814
