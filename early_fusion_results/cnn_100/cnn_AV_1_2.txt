/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:140: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:142: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-27 13:51:04.183204: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.7023 - acc: 0.5625
 320/1283 [======>.......................] - ETA: 0s - loss: 0.9134 - acc: 0.5188
 576/1283 [============>.................] - ETA: 0s - loss: 0.8368 - acc: 0.5191
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8239 - acc: 0.5252
1088/1283 [========================>.....] - ETA: 0s - loss: 0.8048 - acc: 0.5211
1280/1283 [============================>.] - ETA: 0s - loss: 0.7897 - acc: 0.5195
1283/1283 [==============================] - 1s 485us/step - loss: 0.7892 - acc: 0.5199 - val_loss: 0.7022 - val_acc: 0.5240

Epoch 00001: val_acc improved from -inf to 0.52402, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6107 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6364 - acc: 0.6281
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6369 - acc: 0.6250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6455 - acc: 0.6250
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6371 - acc: 0.6272
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6318 - acc: 0.6363
1283/1283 [==============================] - 0s 315us/step - loss: 0.6254 - acc: 0.6477 - val_loss: 0.7176 - val_acc: 0.5284

Epoch 00002: val_acc improved from 0.52402 to 0.52838, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5739 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5588 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5570 - acc: 0.6853
 640/1283 [=============>................] - ETA: 0s - loss: 0.5628 - acc: 0.6875
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5712 - acc: 0.6935
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5623 - acc: 0.7100
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5733 - acc: 0.7089
1283/1283 [==============================] - 0s 347us/step - loss: 0.5740 - acc: 0.7054 - val_loss: 0.7275 - val_acc: 0.5459

Epoch 00003: val_acc improved from 0.52838 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4935 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4854 - acc: 0.7930
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4906 - acc: 0.7790
 640/1283 [=============>................] - ETA: 0s - loss: 0.5101 - acc: 0.7578
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5033 - acc: 0.7608
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4939 - acc: 0.7705
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4930 - acc: 0.7717
1283/1283 [==============================] - 0s 368us/step - loss: 0.4938 - acc: 0.7732 - val_loss: 0.7868 - val_acc: 0.5284

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4575 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4472 - acc: 0.7773
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4377 - acc: 0.7891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4416 - acc: 0.8011
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4302 - acc: 0.8125
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4328 - acc: 0.8097
1280/1283 [============================>.] - ETA: 0s - loss: 0.4331 - acc: 0.8094
1283/1283 [==============================] - 0s 322us/step - loss: 0.4331 - acc: 0.8098 - val_loss: 0.7865 - val_acc: 0.5721

Epoch 00005: val_acc improved from 0.54585 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4054 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3431 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3791 - acc: 0.8438
 576/1283 [============>.................] - ETA: 0s - loss: 0.3833 - acc: 0.8403
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3900 - acc: 0.8381
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3876 - acc: 0.8413
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3931 - acc: 0.8369
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3913 - acc: 0.8368
1280/1283 [============================>.] - ETA: 0s - loss: 0.3946 - acc: 0.8328
1283/1283 [==============================] - 1s 406us/step - loss: 0.3951 - acc: 0.8324 - val_loss: 0.7613 - val_acc: 0.5764

Epoch 00006: val_acc improved from 0.57205 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3290 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3457 - acc: 0.8490
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3467 - acc: 0.8568
 576/1283 [============>.................] - ETA: 0s - loss: 0.3478 - acc: 0.8628
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3507 - acc: 0.8651
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3470 - acc: 0.8739
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3616 - acc: 0.8721
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3626 - acc: 0.8698
1280/1283 [============================>.] - ETA: 0s - loss: 0.3603 - acc: 0.8672
1283/1283 [==============================] - 1s 459us/step - loss: 0.3601 - acc: 0.8675 - val_loss: 0.7732 - val_acc: 0.5721

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2488 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2616 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2869 - acc: 0.9281
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2992 - acc: 0.8965
 640/1283 [=============>................] - ETA: 0s - loss: 0.2989 - acc: 0.8938
 768/1283 [================>.............] - ETA: 0s - loss: 0.3009 - acc: 0.8945
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3021 - acc: 0.8906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3011 - acc: 0.8916
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2973 - acc: 0.8958
1280/1283 [============================>.] - ETA: 0s - loss: 0.2945 - acc: 0.8945
1283/1283 [==============================] - 1s 530us/step - loss: 0.2945 - acc: 0.8948 - val_loss: 0.8072 - val_acc: 0.5328

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2396 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2861 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2811 - acc: 0.8812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2872 - acc: 0.8795
 576/1283 [============>.................] - ETA: 0s - loss: 0.2973 - acc: 0.8628
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2766 - acc: 0.8807
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2820 - acc: 0.8750
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2792 - acc: 0.8792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2779 - acc: 0.8824
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2857 - acc: 0.8857
1283/1283 [==============================] - 1s 502us/step - loss: 0.2834 - acc: 0.8885 - val_loss: 0.8353 - val_acc: 0.5546

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1838 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2047 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2131 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2067 - acc: 0.9330
 576/1283 [============>.................] - ETA: 0s - loss: 0.2166 - acc: 0.9219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2133 - acc: 0.9276
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2107 - acc: 0.9308
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2070 - acc: 0.9326
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2024 - acc: 0.9375
1283/1283 [==============================] - 1s 501us/step - loss: 0.2008 - acc: 0.9376 - val_loss: 0.9715 - val_acc: 0.5721

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1345 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1546 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1646 - acc: 0.9406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1554 - acc: 0.9442
 576/1283 [============>.................] - ETA: 0s - loss: 0.1602 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1639 - acc: 0.9446
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1588 - acc: 0.9483
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1655 - acc: 0.9414
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1672 - acc: 0.9436
1280/1283 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9453
1283/1283 [==============================] - 1s 553us/step - loss: 0.1674 - acc: 0.9454 - val_loss: 0.9850 - val_acc: 0.5328

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0929 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1254 - acc: 0.9635
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1371 - acc: 0.9635
 576/1283 [============>.................] - ETA: 0s - loss: 0.1386 - acc: 0.9688
 768/1283 [================>.............] - ETA: 0s - loss: 0.1320 - acc: 0.9766
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1306 - acc: 0.9760
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1383 - acc: 0.9705
1283/1283 [==============================] - 1s 426us/step - loss: 0.1357 - acc: 0.9727 - val_loss: 1.0215 - val_acc: 0.5109

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1093 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1272 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1650 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1761 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.1663 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1528 - acc: 0.9730
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1404 - acc: 0.9772
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1347 - acc: 0.9802
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1287 - acc: 0.9807
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1261 - acc: 0.9818
1280/1283 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9828
1283/1283 [==============================] - 1s 559us/step - loss: 0.1213 - acc: 0.9829 - val_loss: 1.0608 - val_acc: 0.5109

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0782 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0691 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0732 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0716 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0731 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0722 - acc: 0.9915
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0700 - acc: 0.9928
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0697 - acc: 0.9927
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0688 - acc: 0.9936
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0682 - acc: 0.9934
1283/1283 [==============================] - 1s 584us/step - loss: 0.0756 - acc: 0.9930 - val_loss: 1.1143 - val_acc: 0.5153

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0639 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0524 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0521 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0529 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0534 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0558 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0550 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0545 - acc: 0.9979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0539 - acc: 0.9982
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0520 - acc: 0.9984
1283/1283 [==============================] - 1s 573us/step - loss: 0.0519 - acc: 0.9984 - val_loss: 1.1938 - val_acc: 0.5284

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0425 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0398 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0396 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0351 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0357 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0369 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0359 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0389 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0381 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0376 - acc: 0.9992
1283/1283 [==============================] - 1s 540us/step - loss: 0.0374 - acc: 0.9992 - val_loss: 1.2651 - val_acc: 0.5284

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
epochs=100
mode=AV
accuracy=0.521865889212828
best_valid_accuracy=0.5116618075801749
