/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 22:27:23.420791: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.8450 - acc: 0.4219
 192/1283 [===>..........................] - ETA: 1s - loss: 1.1629 - acc: 0.4740
 320/1283 [======>.......................] - ETA: 1s - loss: 1.0290 - acc: 0.5062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.9694 - acc: 0.5156
 576/1283 [============>.................] - ETA: 0s - loss: 0.9034 - acc: 0.5208
 704/1283 [===============>..............] - ETA: 0s - loss: 0.8665 - acc: 0.5241
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8359 - acc: 0.5349
 960/1283 [=====================>........] - ETA: 0s - loss: 0.8147 - acc: 0.5354
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7996 - acc: 0.5423
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7840 - acc: 0.5510
1283/1283 [==============================] - 1s 789us/step - loss: 0.7798 - acc: 0.5472 - val_loss: 0.7062 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6227 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6379 - acc: 0.6146
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6419 - acc: 0.5969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6504 - acc: 0.5670
 576/1283 [============>.................] - ETA: 0s - loss: 0.6438 - acc: 0.5868
 640/1283 [=============>................] - ETA: 0s - loss: 0.6456 - acc: 0.5828
 768/1283 [================>.............] - ETA: 0s - loss: 0.6367 - acc: 0.6068
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6300 - acc: 0.6194
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6375 - acc: 0.6270
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6386 - acc: 0.6189
1280/1283 [============================>.] - ETA: 0s - loss: 0.6337 - acc: 0.6273
1283/1283 [==============================] - 1s 709us/step - loss: 0.6337 - acc: 0.6274 - val_loss: 0.7064 - val_acc: 0.5240

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6010 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5865 - acc: 0.6823
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5762 - acc: 0.6914
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5735 - acc: 0.6844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5688 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5691 - acc: 0.6973
 576/1283 [============>.................] - ETA: 0s - loss: 0.5670 - acc: 0.7135
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5704 - acc: 0.7060
 768/1283 [================>.............] - ETA: 0s - loss: 0.5749 - acc: 0.7005
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5761 - acc: 0.6995
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5759 - acc: 0.6975
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5784 - acc: 0.6958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5803 - acc: 0.6924
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5829 - acc: 0.6903
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5844 - acc: 0.6892
1280/1283 [============================>.] - ETA: 0s - loss: 0.5798 - acc: 0.6961
1283/1283 [==============================] - 1s 989us/step - loss: 0.5799 - acc: 0.6960 - val_loss: 0.7003 - val_acc: 0.5459

Epoch 00003: val_acc improved from 0.52838 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5273 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.5043 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5055 - acc: 0.7760
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5210 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5233 - acc: 0.7604
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5277 - acc: 0.7461
 576/1283 [============>.................] - ETA: 0s - loss: 0.5368 - acc: 0.7344
 640/1283 [=============>................] - ETA: 0s - loss: 0.5347 - acc: 0.7375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5354 - acc: 0.7358
 768/1283 [================>.............] - ETA: 0s - loss: 0.5353 - acc: 0.7344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5332 - acc: 0.7356
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5403 - acc: 0.7277
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5333 - acc: 0.7363
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5302 - acc: 0.7344
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5304 - acc: 0.7311
1280/1283 [============================>.] - ETA: 0s - loss: 0.5302 - acc: 0.7312
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5301 - acc: 0.7311 - val_loss: 0.6984 - val_acc: 0.5764

Epoch 00004: val_acc improved from 0.54585 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4653 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4625 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4384 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4613 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4773 - acc: 0.7906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4718 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4724 - acc: 0.7946
 576/1283 [============>.................] - ETA: 0s - loss: 0.4708 - acc: 0.7830
 640/1283 [=============>................] - ETA: 0s - loss: 0.4764 - acc: 0.7734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4707 - acc: 0.7741
 768/1283 [================>.............] - ETA: 0s - loss: 0.4734 - acc: 0.7734
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4733 - acc: 0.7752
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4719 - acc: 0.7723
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4738 - acc: 0.7719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4733 - acc: 0.7695
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4707 - acc: 0.7730
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4671 - acc: 0.7778
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4650 - acc: 0.7796
1280/1283 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.7781
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4751 - acc: 0.7779 - val_loss: 0.6977 - val_acc: 0.5983

Epoch 00005: val_acc improved from 0.57642 to 0.59825, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4036 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4273 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4409 - acc: 0.8021
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4341 - acc: 0.8047
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4394 - acc: 0.8031
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4340 - acc: 0.8047
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4335 - acc: 0.8103
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4290 - acc: 0.8184
 576/1283 [============>.................] - ETA: 0s - loss: 0.4313 - acc: 0.8160
 640/1283 [=============>................] - ETA: 0s - loss: 0.4372 - acc: 0.8109
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4334 - acc: 0.8168
 768/1283 [================>.............] - ETA: 0s - loss: 0.4308 - acc: 0.8177
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4265 - acc: 0.8173
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4277 - acc: 0.8147
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4275 - acc: 0.8115
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4253 - acc: 0.8096
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4242 - acc: 0.8088
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4231 - acc: 0.8099
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4255 - acc: 0.8100
1280/1283 [============================>.] - ETA: 0s - loss: 0.4231 - acc: 0.8117
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4227 - acc: 0.8122 - val_loss: 0.7761 - val_acc: 0.5633

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3502 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.3466 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3832 - acc: 0.8320
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3752 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3685 - acc: 0.8482
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3774 - acc: 0.8398
 576/1283 [============>.................] - ETA: 0s - loss: 0.3752 - acc: 0.8420
 640/1283 [=============>................] - ETA: 0s - loss: 0.3689 - acc: 0.8500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3684 - acc: 0.8480
 768/1283 [================>.............] - ETA: 0s - loss: 0.3678 - acc: 0.8490
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3739 - acc: 0.8377
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3727 - acc: 0.8426
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3672 - acc: 0.8469
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3665 - acc: 0.8477
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3643 - acc: 0.8493
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3638 - acc: 0.8498
1280/1283 [============================>.] - ETA: 0s - loss: 0.3635 - acc: 0.8523
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3630 - acc: 0.8527 - val_loss: 0.7926 - val_acc: 0.5895

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2585 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.2849 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2708 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2868 - acc: 0.8969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2825 - acc: 0.9036
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2911 - acc: 0.8973
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2898 - acc: 0.8926
 576/1283 [============>.................] - ETA: 0s - loss: 0.2917 - acc: 0.8924
 640/1283 [=============>................] - ETA: 0s - loss: 0.2926 - acc: 0.8891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2970 - acc: 0.8821
 768/1283 [================>.............] - ETA: 0s - loss: 0.2973 - acc: 0.8815
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2935 - acc: 0.8834
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2918 - acc: 0.8873
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2947 - acc: 0.8844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2916 - acc: 0.8887
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2918 - acc: 0.8888
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2900 - acc: 0.8906
1280/1283 [============================>.] - ETA: 0s - loss: 0.2900 - acc: 0.8898
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2908 - acc: 0.8893 - val_loss: 0.8444 - val_acc: 0.5459

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2219 - acc: 0.9375
 128/1283 [=>............................] - ETA: 2s - loss: 0.2636 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 2s - loss: 0.2566 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 2s - loss: 0.2686 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2758 - acc: 0.9000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2625 - acc: 0.9115
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2668 - acc: 0.9040
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2679 - acc: 0.9062
 576/1283 [============>.................] - ETA: 1s - loss: 0.2716 - acc: 0.9097
 640/1283 [=============>................] - ETA: 1s - loss: 0.2770 - acc: 0.9047
 704/1283 [===============>..............] - ETA: 1s - loss: 0.2731 - acc: 0.9062
 768/1283 [================>.............] - ETA: 0s - loss: 0.2855 - acc: 0.8932
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2863 - acc: 0.8918
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2940 - acc: 0.8850
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2956 - acc: 0.8833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2939 - acc: 0.8857
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2926 - acc: 0.8869
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2880 - acc: 0.8898
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2850 - acc: 0.8914
1280/1283 [============================>.] - ETA: 0s - loss: 0.2881 - acc: 0.8875
1283/1283 [==============================] - 3s 2ms/step - loss: 0.2887 - acc: 0.8870 - val_loss: 0.8881 - val_acc: 0.5633

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.1961 - acc: 0.9375
 128/1283 [=>............................] - ETA: 4s - loss: 0.2150 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 3s - loss: 0.2399 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 3s - loss: 0.2545 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 2s - loss: 0.2454 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 2s - loss: 0.2735 - acc: 0.9167
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2799 - acc: 0.9174
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2870 - acc: 0.9121
 576/1283 [============>.................] - ETA: 1s - loss: 0.2868 - acc: 0.9149
 640/1283 [=============>................] - ETA: 1s - loss: 0.2778 - acc: 0.9172
 704/1283 [===============>..............] - ETA: 1s - loss: 0.2761 - acc: 0.9148
 768/1283 [================>.............] - ETA: 1s - loss: 0.2722 - acc: 0.9141
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2659 - acc: 0.9159
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2638 - acc: 0.9185
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2604 - acc: 0.9177
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2621 - acc: 0.9160
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2615 - acc: 0.9154
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2553 - acc: 0.9175
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2544 - acc: 0.9169
1280/1283 [============================>.] - ETA: 0s - loss: 0.2534 - acc: 0.9180
1283/1283 [==============================] - 3s 2ms/step - loss: 0.2536 - acc: 0.9174 - val_loss: 0.9885 - val_acc: 0.5546

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2140 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2272 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2147 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2039 - acc: 0.9414
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1940 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1925 - acc: 0.9330
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2038 - acc: 0.9219
 576/1283 [============>.................] - ETA: 1s - loss: 0.2092 - acc: 0.9219
 640/1283 [=============>................] - ETA: 1s - loss: 0.2166 - acc: 0.9156
 704/1283 [===============>..............] - ETA: 1s - loss: 0.2127 - acc: 0.9190
 768/1283 [================>.............] - ETA: 0s - loss: 0.2229 - acc: 0.9115
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2226 - acc: 0.9123
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2175 - acc: 0.9152
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2148 - acc: 0.9156
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2138 - acc: 0.9160
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2145 - acc: 0.9154
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2119 - acc: 0.9184
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2101 - acc: 0.9202
1280/1283 [============================>.] - ETA: 0s - loss: 0.2117 - acc: 0.9219
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2113 - acc: 0.9221 - val_loss: 0.9393 - val_acc: 0.5415

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0921 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1144 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1227 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1381 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1378 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1377 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1450 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1454 - acc: 0.9668
 576/1283 [============>.................] - ETA: 0s - loss: 0.1466 - acc: 0.9670
 640/1283 [=============>................] - ETA: 0s - loss: 0.1471 - acc: 0.9656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1456 - acc: 0.9659
 768/1283 [================>.............] - ETA: 0s - loss: 0.1423 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1413 - acc: 0.9675
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1399 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1422 - acc: 0.9656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1392 - acc: 0.9668
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1368 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1345 - acc: 0.9696
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1344 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9703
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1337 - acc: 0.9704 - val_loss: 1.1741 - val_acc: 0.4934

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1280 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.1097 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1340 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1242 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 2s - loss: 0.1170 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 2s - loss: 0.1096 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1171 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1116 - acc: 0.9746
 576/1283 [============>.................] - ETA: 1s - loss: 0.1147 - acc: 0.9722
 640/1283 [=============>................] - ETA: 1s - loss: 0.1135 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1148 - acc: 0.9744
 768/1283 [================>.............] - ETA: 1s - loss: 0.1206 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1231 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1234 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1289 - acc: 0.9656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1232 - acc: 0.9688
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1225 - acc: 0.9679
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1230 - acc: 0.9671
1280/1283 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9680
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1208 - acc: 0.9680 - val_loss: 1.1587 - val_acc: 0.5721

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0879 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0724 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0723 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0783 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0847 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0843 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0818 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0800 - acc: 0.9805
 576/1283 [============>.................] - ETA: 1s - loss: 0.0808 - acc: 0.9809
 640/1283 [=============>................] - ETA: 1s - loss: 0.0811 - acc: 0.9812
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0812 - acc: 0.9830
 768/1283 [================>.............] - ETA: 0s - loss: 0.0853 - acc: 0.9831
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0875 - acc: 0.9820
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0854 - acc: 0.9833
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0835 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0821 - acc: 0.9854
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0815 - acc: 0.9862
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0810 - acc: 0.9870
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0850 - acc: 0.9860
1280/1283 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9859
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0965 - acc: 0.9860 - val_loss: 1.1644 - val_acc: 0.5852

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0472 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0645 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0761 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0937 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0909 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0886 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0858 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1127 - acc: 0.9824
 576/1283 [============>.................] - ETA: 1s - loss: 0.1053 - acc: 0.9844
 640/1283 [=============>................] - ETA: 1s - loss: 0.1060 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1018 - acc: 0.9844
 768/1283 [================>.............] - ETA: 1s - loss: 0.0988 - acc: 0.9831
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0949 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0948 - acc: 0.9833
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0949 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0928 - acc: 0.9834
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0899 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0878 - acc: 0.9852
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0859 - acc: 0.9860
1280/1283 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9852
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0862 - acc: 0.9852 - val_loss: 1.3196 - val_acc: 0.5109

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
epochs=100
mode=AV
accuracy=0.5087463556851312
best_valid_accuracy=0.4839650145772595
