/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 22:27:25.330451: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.8450 - acc: 0.4219
 192/1283 [===>..........................] - ETA: 2s - loss: 1.1629 - acc: 0.4740
 256/1283 [====>.........................] - ETA: 2s - loss: 1.0456 - acc: 0.5000
 320/1283 [======>.......................] - ETA: 1s - loss: 1.0260 - acc: 0.5031
 384/1283 [=======>......................] - ETA: 1s - loss: 1.0111 - acc: 0.5052
 448/1283 [=========>....................] - ETA: 1s - loss: 0.9730 - acc: 0.5134
 512/1283 [==========>...................] - ETA: 1s - loss: 0.9332 - acc: 0.5234
 576/1283 [============>.................] - ETA: 1s - loss: 0.9056 - acc: 0.5226
 640/1283 [=============>................] - ETA: 0s - loss: 0.8850 - acc: 0.5219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.8675 - acc: 0.5270
 768/1283 [================>.............] - ETA: 0s - loss: 0.8514 - acc: 0.5260
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8365 - acc: 0.5373
 960/1283 [=====================>........] - ETA: 0s - loss: 0.8158 - acc: 0.5354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.8059 - acc: 0.5371
1088/1283 [========================>.....] - ETA: 0s - loss: 0.8003 - acc: 0.5395
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7844 - acc: 0.5477
1280/1283 [============================>.] - ETA: 0s - loss: 0.7806 - acc: 0.5453
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7803 - acc: 0.5456 - val_loss: 0.7064 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6244 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6412 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6444 - acc: 0.6055
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6468 - acc: 0.5969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6429 - acc: 0.5938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6559 - acc: 0.5670
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6507 - acc: 0.5781
 576/1283 [============>.................] - ETA: 0s - loss: 0.6485 - acc: 0.5868
 640/1283 [=============>................] - ETA: 0s - loss: 0.6492 - acc: 0.5875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6452 - acc: 0.5994
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6379 - acc: 0.6154
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6346 - acc: 0.6205
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6322 - acc: 0.6250
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6411 - acc: 0.6279
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6441 - acc: 0.6176
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6421 - acc: 0.6181
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6374 - acc: 0.6242
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6383 - acc: 0.6251 - val_loss: 0.7069 - val_acc: 0.5328

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5905 - acc: 0.7188
 128/1283 [=>............................] - ETA: 1s - loss: 0.5640 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5780 - acc: 0.7083
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5711 - acc: 0.7000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5720 - acc: 0.7005
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5684 - acc: 0.7031
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5685 - acc: 0.7090
 576/1283 [============>.................] - ETA: 0s - loss: 0.5662 - acc: 0.7188
 640/1283 [=============>................] - ETA: 0s - loss: 0.5653 - acc: 0.7219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5691 - acc: 0.7102
 768/1283 [================>.............] - ETA: 0s - loss: 0.5726 - acc: 0.7057
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5741 - acc: 0.7043
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5733 - acc: 0.7065
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5751 - acc: 0.7052
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5787 - acc: 0.7002
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5817 - acc: 0.6985
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5839 - acc: 0.6944
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5809 - acc: 0.6957
1280/1283 [============================>.] - ETA: 0s - loss: 0.5783 - acc: 0.6984
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5783 - acc: 0.6984 - val_loss: 0.7021 - val_acc: 0.5546

Epoch 00003: val_acc improved from 0.53712 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5316 - acc: 0.7656
 128/1283 [=>............................] - ETA: 0s - loss: 0.5243 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5181 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5302 - acc: 0.7383
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5291 - acc: 0.7469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5296 - acc: 0.7318
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5363 - acc: 0.7254
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5357 - acc: 0.7188
 576/1283 [============>.................] - ETA: 0s - loss: 0.5436 - acc: 0.7049
 640/1283 [=============>................] - ETA: 0s - loss: 0.5398 - acc: 0.7172
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5378 - acc: 0.7230
 768/1283 [================>.............] - ETA: 0s - loss: 0.5372 - acc: 0.7253
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5374 - acc: 0.7224
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5450 - acc: 0.7143
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5412 - acc: 0.7188
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5382 - acc: 0.7236
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5384 - acc: 0.7178
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5347 - acc: 0.7222
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5363 - acc: 0.7188
1280/1283 [============================>.] - ETA: 0s - loss: 0.5361 - acc: 0.7188
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5361 - acc: 0.7186 - val_loss: 0.7037 - val_acc: 0.5677

Epoch 00004: val_acc improved from 0.55459 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4705 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4657 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4376 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4604 - acc: 0.8086
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4777 - acc: 0.7906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4743 - acc: 0.7995
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4728 - acc: 0.7991
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4768 - acc: 0.7891
 576/1283 [============>.................] - ETA: 1s - loss: 0.4712 - acc: 0.7882
 640/1283 [=============>................] - ETA: 0s - loss: 0.4792 - acc: 0.7797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4745 - acc: 0.7770
 768/1283 [================>.............] - ETA: 0s - loss: 0.4775 - acc: 0.7747
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4766 - acc: 0.7764
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4754 - acc: 0.7768
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4780 - acc: 0.7750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4772 - acc: 0.7715
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4741 - acc: 0.7748
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4700 - acc: 0.7804
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4679 - acc: 0.7812
1280/1283 [============================>.] - ETA: 0s - loss: 0.4751 - acc: 0.7820
1283/1283 [==============================] - 2s 2ms/step - loss: 0.4758 - acc: 0.7818 - val_loss: 0.7089 - val_acc: 0.6070

Epoch 00005: val_acc improved from 0.56769 to 0.60699, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4153 - acc: 0.7969
 128/1283 [=>............................] - ETA: 2s - loss: 0.4331 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 2s - loss: 0.4454 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4439 - acc: 0.7773
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4499 - acc: 0.7781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4465 - acc: 0.7760
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4474 - acc: 0.7835
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4428 - acc: 0.7930
 576/1283 [============>.................] - ETA: 1s - loss: 0.4433 - acc: 0.7969
 640/1283 [=============>................] - ETA: 1s - loss: 0.4478 - acc: 0.7906
 704/1283 [===============>..............] - ETA: 1s - loss: 0.4429 - acc: 0.7969
 768/1283 [================>.............] - ETA: 1s - loss: 0.4416 - acc: 0.7995
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4353 - acc: 0.8029
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4348 - acc: 0.8025
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4332 - acc: 0.8010
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4316 - acc: 0.7998
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4297 - acc: 0.8006
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4282 - acc: 0.8012
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4298 - acc: 0.7985
1280/1283 [============================>.] - ETA: 0s - loss: 0.4272 - acc: 0.8000
1283/1283 [==============================] - 3s 2ms/step - loss: 0.4269 - acc: 0.8005 - val_loss: 0.7863 - val_acc: 0.5371

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3483 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.3486 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3685 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3828 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3755 - acc: 0.8375
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3772 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3719 - acc: 0.8415
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3800 - acc: 0.8340
 576/1283 [============>.................] - ETA: 1s - loss: 0.3779 - acc: 0.8351
 640/1283 [=============>................] - ETA: 0s - loss: 0.3706 - acc: 0.8422
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3717 - acc: 0.8381
 768/1283 [================>.............] - ETA: 0s - loss: 0.3707 - acc: 0.8385
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3764 - acc: 0.8269
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3737 - acc: 0.8337
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3680 - acc: 0.8396
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3677 - acc: 0.8398
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3652 - acc: 0.8410
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3632 - acc: 0.8446
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3599 - acc: 0.8479
1280/1283 [============================>.] - ETA: 0s - loss: 0.3620 - acc: 0.8469
1283/1283 [==============================] - 2s 2ms/step - loss: 0.3614 - acc: 0.8472 - val_loss: 0.7738 - val_acc: 0.5852

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2570 - acc: 0.9375
 128/1283 [=>............................] - ETA: 2s - loss: 0.2727 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2690 - acc: 0.9115
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2716 - acc: 0.9141
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2881 - acc: 0.8969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2824 - acc: 0.9036
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2883 - acc: 0.8996
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2865 - acc: 0.8984
 576/1283 [============>.................] - ETA: 1s - loss: 0.2876 - acc: 0.8993
 640/1283 [=============>................] - ETA: 1s - loss: 0.2886 - acc: 0.9000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2946 - acc: 0.8949
 768/1283 [================>.............] - ETA: 0s - loss: 0.2956 - acc: 0.8932
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2916 - acc: 0.8942
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2900 - acc: 0.8984
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2941 - acc: 0.8948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2917 - acc: 0.8975
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2938 - acc: 0.8952
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2938 - acc: 0.8958
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2915 - acc: 0.8980
1280/1283 [============================>.] - ETA: 0s - loss: 0.2930 - acc: 0.8969
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2937 - acc: 0.8956 - val_loss: 0.8403 - val_acc: 0.5721

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2164 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.2549 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2537 - acc: 0.8958
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2676 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2850 - acc: 0.8844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2706 - acc: 0.8958
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2742 - acc: 0.8929
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2755 - acc: 0.8984
 576/1283 [============>.................] - ETA: 0s - loss: 0.2780 - acc: 0.8993
 640/1283 [=============>................] - ETA: 0s - loss: 0.2834 - acc: 0.8984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2781 - acc: 0.9020
 768/1283 [================>.............] - ETA: 0s - loss: 0.2883 - acc: 0.8919
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2872 - acc: 0.8918
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2948 - acc: 0.8817
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2954 - acc: 0.8833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2940 - acc: 0.8838
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2943 - acc: 0.8833
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2929 - acc: 0.8845
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2897 - acc: 0.8857
1280/1283 [============================>.] - ETA: 0s - loss: 0.2905 - acc: 0.8852
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2903 - acc: 0.8854 - val_loss: 0.8852 - val_acc: 0.5415

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1898 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.2349 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2472 - acc: 0.9271
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2886 - acc: 0.9141
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2658 - acc: 0.9281
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2802 - acc: 0.9141
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2752 - acc: 0.9160
 576/1283 [============>.................] - ETA: 1s - loss: 0.2678 - acc: 0.9201
 640/1283 [=============>................] - ETA: 0s - loss: 0.2603 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2529 - acc: 0.9247
 768/1283 [================>.............] - ETA: 0s - loss: 0.2488 - acc: 0.9271
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2428 - acc: 0.9279
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2429 - acc: 0.9263
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2398 - acc: 0.9271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2459 - acc: 0.9238
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2458 - acc: 0.9228
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2411 - acc: 0.9245
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2383 - acc: 0.9260
1280/1283 [============================>.] - ETA: 0s - loss: 0.2374 - acc: 0.9273
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2376 - acc: 0.9267 - val_loss: 0.9139 - val_acc: 0.5808

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1693 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1649 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1575 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1540 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1540 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1559 - acc: 0.9661
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1578 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1658 - acc: 0.9551
 576/1283 [============>.................] - ETA: 1s - loss: 0.1713 - acc: 0.9514
 640/1283 [=============>................] - ETA: 0s - loss: 0.1765 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1760 - acc: 0.9474
 768/1283 [================>.............] - ETA: 0s - loss: 0.1838 - acc: 0.9414
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1846 - acc: 0.9411
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1834 - acc: 0.9431
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1806 - acc: 0.9437
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1797 - acc: 0.9443
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1801 - acc: 0.9449
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1779 - acc: 0.9462
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1764 - acc: 0.9474
1280/1283 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9461
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1785 - acc: 0.9462 - val_loss: 0.9626 - val_acc: 0.5677

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0917 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1083 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1174 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1286 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1315 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1331 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1425 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1410 - acc: 0.9629
 576/1283 [============>.................] - ETA: 1s - loss: 0.1403 - acc: 0.9635
 640/1283 [=============>................] - ETA: 1s - loss: 0.1413 - acc: 0.9609
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1406 - acc: 0.9602
 768/1283 [================>.............] - ETA: 0s - loss: 0.1388 - acc: 0.9609
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1377 - acc: 0.9603
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1369 - acc: 0.9621
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1367 - acc: 0.9625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1336 - acc: 0.9639
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1311 - acc: 0.9651
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1287 - acc: 0.9661
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1294 - acc: 0.9655
1280/1283 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9672
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1282 - acc: 0.9673 - val_loss: 1.1278 - val_acc: 0.4978

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1234 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.1045 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1196 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1110 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 2s - loss: 0.1069 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1030 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1103 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1035 - acc: 0.9824
 576/1283 [============>.................] - ETA: 1s - loss: 0.1026 - acc: 0.9826
 640/1283 [=============>................] - ETA: 1s - loss: 0.0997 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1015 - acc: 0.9830
 768/1283 [================>.............] - ETA: 0s - loss: 0.1039 - acc: 0.9818
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1044 - acc: 0.9832
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1032 - acc: 0.9844
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1059 - acc: 0.9823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1045 - acc: 0.9834
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1037 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1024 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1017 - acc: 0.9836
1280/1283 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9844
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1000 - acc: 0.9844 - val_loss: 1.1825 - val_acc: 0.5677

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0577 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0524 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0538 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0557 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0595 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0613 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0597 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0608 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0611 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0624 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0661 - acc: 0.9935
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0676 - acc: 0.9922
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0655 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0647 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0641 - acc: 0.9936
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0636 - acc: 0.9939
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0631 - acc: 0.9934
1280/1283 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9938
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0629 - acc: 0.9938 - val_loss: 1.2315 - val_acc: 0.5633

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0456 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0601 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0788 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0914 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0895 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0862 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0831 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0782 - acc: 0.9805
 576/1283 [============>.................] - ETA: 0s - loss: 0.0735 - acc: 0.9826
 640/1283 [=============>................] - ETA: 0s - loss: 0.0734 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0706 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0700 - acc: 0.9831
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0681 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0675 - acc: 0.9855
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0679 - acc: 0.9854
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0669 - acc: 0.9863
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0648 - acc: 0.9871
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0649 - acc: 0.9878
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0650 - acc: 0.9877
1280/1283 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9883
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0652 - acc: 0.9883 - val_loss: 1.3981 - val_acc: 0.5371

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=30
epochs=100
mode=AV
accuracy=0.5058309037900874
best_valid_accuracy=0.4679300291545189
