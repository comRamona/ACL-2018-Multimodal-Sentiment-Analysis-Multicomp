/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_cnn.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_cnn.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-20 22:28:08.148117: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.8211 - acc: 0.4375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.8390 - acc: 0.4844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.8854 - acc: 0.4906
 512/1283 [==========>...................] - ETA: 0s - loss: 0.8303 - acc: 0.5254
 640/1283 [=============>................] - ETA: 0s - loss: 0.7919 - acc: 0.5453
 768/1283 [================>.............] - ETA: 0s - loss: 0.7898 - acc: 0.5469
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7909 - acc: 0.5413
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7872 - acc: 0.5303
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7829 - acc: 0.5295
1280/1283 [============================>.] - ETA: 0s - loss: 0.7699 - acc: 0.5375
1283/1283 [==============================] - 1s 717us/step - loss: 0.7692 - acc: 0.5386 - val_loss: 0.7296 - val_acc: 0.4978

Epoch 00001: val_acc improved from -inf to 0.49782, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5989 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6083 - acc: 0.6680
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6136 - acc: 0.6536
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6149 - acc: 0.6562
 640/1283 [=============>................] - ETA: 0s - loss: 0.6177 - acc: 0.6641
 768/1283 [================>.............] - ETA: 0s - loss: 0.6137 - acc: 0.6654
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6110 - acc: 0.6652
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6065 - acc: 0.6748
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6016 - acc: 0.6793
1283/1283 [==============================] - 1s 518us/step - loss: 0.6010 - acc: 0.6789 - val_loss: 0.8023 - val_acc: 0.4891

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6126 - acc: 0.6250
 128/1283 [=>............................] - ETA: 0s - loss: 0.5627 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5721 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5598 - acc: 0.6979
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5673 - acc: 0.6973
 640/1283 [=============>................] - ETA: 0s - loss: 0.5625 - acc: 0.7063
 768/1283 [================>.............] - ETA: 0s - loss: 0.5612 - acc: 0.7096
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5607 - acc: 0.7076
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5560 - acc: 0.7129
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5640 - acc: 0.7049
1280/1283 [============================>.] - ETA: 0s - loss: 0.5613 - acc: 0.7070
1283/1283 [==============================] - 1s 691us/step - loss: 0.5613 - acc: 0.7077 - val_loss: 0.7654 - val_acc: 0.5153

Epoch 00003: val_acc improved from 0.49782 to 0.51528, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5164 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5018 - acc: 0.7500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4948 - acc: 0.7474
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5090 - acc: 0.7402
 640/1283 [=============>................] - ETA: 0s - loss: 0.5178 - acc: 0.7375
 768/1283 [================>.............] - ETA: 0s - loss: 0.5123 - acc: 0.7526
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5077 - acc: 0.7612
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5016 - acc: 0.7684
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4953 - acc: 0.7730
1283/1283 [==============================] - 1s 547us/step - loss: 0.4969 - acc: 0.7701 - val_loss: 0.8182 - val_acc: 0.5153

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4366 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4489 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4570 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4543 - acc: 0.7723
 576/1283 [============>.................] - ETA: 0s - loss: 0.4510 - acc: 0.7760
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4513 - acc: 0.7912
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4443 - acc: 0.7981
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4470 - acc: 0.7990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4446 - acc: 0.8006
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4417 - acc: 0.8026
1283/1283 [==============================] - 1s 547us/step - loss: 0.4403 - acc: 0.8036 - val_loss: 0.8140 - val_acc: 0.5328

Epoch 00005: val_acc improved from 0.51528 to 0.53275, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4114 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3599 - acc: 0.8477
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4036 - acc: 0.7995
 576/1283 [============>.................] - ETA: 0s - loss: 0.4006 - acc: 0.8056
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4043 - acc: 0.8054
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3970 - acc: 0.8173
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4003 - acc: 0.8146
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4058 - acc: 0.8125
1280/1283 [============================>.] - ETA: 0s - loss: 0.4061 - acc: 0.8141
1283/1283 [==============================] - 1s 441us/step - loss: 0.4066 - acc: 0.8129 - val_loss: 0.8024 - val_acc: 0.5415

Epoch 00006: val_acc improved from 0.53275 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3326 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3224 - acc: 0.8789
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3405 - acc: 0.8661
 576/1283 [============>.................] - ETA: 0s - loss: 0.3385 - acc: 0.8750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3441 - acc: 0.8764
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3399 - acc: 0.8774
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3398 - acc: 0.8771
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3520 - acc: 0.8686
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3523 - acc: 0.8651
1283/1283 [==============================] - 1s 455us/step - loss: 0.3507 - acc: 0.8667 - val_loss: 0.8197 - val_acc: 0.5284

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2482 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2650 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2920 - acc: 0.9031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2955 - acc: 0.8884
 576/1283 [============>.................] - ETA: 0s - loss: 0.3084 - acc: 0.8785
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3096 - acc: 0.8793
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3089 - acc: 0.8806
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3021 - acc: 0.8888
1280/1283 [============================>.] - ETA: 0s - loss: 0.2974 - acc: 0.8930
1283/1283 [==============================] - 1s 459us/step - loss: 0.2977 - acc: 0.8932 - val_loss: 0.8771 - val_acc: 0.5328

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2589 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3332 - acc: 0.8229
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3108 - acc: 0.8438
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3233 - acc: 0.8516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3004 - acc: 0.8651
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2953 - acc: 0.8705
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2929 - acc: 0.8741
1280/1283 [============================>.] - ETA: 0s - loss: 0.2894 - acc: 0.8812
1283/1283 [==============================] - 1s 412us/step - loss: 0.2891 - acc: 0.8815 - val_loss: 0.8671 - val_acc: 0.5459

Epoch 00009: val_acc improved from 0.54148 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2091 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2181 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2141 - acc: 0.9323
 576/1283 [============>.................] - ETA: 0s - loss: 0.2276 - acc: 0.9236
 768/1283 [================>.............] - ETA: 0s - loss: 0.2227 - acc: 0.9271
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2187 - acc: 0.9313
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2151 - acc: 0.9323
1283/1283 [==============================] - 0s 362us/step - loss: 0.2079 - acc: 0.9369 - val_loss: 0.9619 - val_acc: 0.5808

Epoch 00010: val_acc improved from 0.54585 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1224 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1412 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1433 - acc: 0.9643
 640/1283 [=============>................] - ETA: 0s - loss: 0.1469 - acc: 0.9625
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1460 - acc: 0.9621
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1490 - acc: 0.9592
1283/1283 [==============================] - 0s 323us/step - loss: 0.1497 - acc: 0.9587 - val_loss: 0.9660 - val_acc: 0.5240

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0968 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1030 - acc: 0.9883
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0968 - acc: 0.9888
 640/1283 [=============>................] - ETA: 0s - loss: 0.1002 - acc: 0.9859
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0991 - acc: 0.9856
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1006 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1061 - acc: 0.9803
1283/1283 [==============================] - 0s 351us/step - loss: 0.1051 - acc: 0.9805 - val_loss: 1.1087 - val_acc: 0.5197

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0800 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0948 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0910 - acc: 0.9911
 640/1283 [=============>................] - ETA: 0s - loss: 0.0890 - acc: 0.9906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0868 - acc: 0.9904
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0855 - acc: 0.9893
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0825 - acc: 0.9885
1283/1283 [==============================] - 0s 332us/step - loss: 0.0823 - acc: 0.9883 - val_loss: 1.1697 - val_acc: 0.5284

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0449 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0796 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0768 - acc: 0.9933
 640/1283 [=============>................] - ETA: 0s - loss: 0.0774 - acc: 0.9891
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0755 - acc: 0.9916
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0786 - acc: 0.9883
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0819 - acc: 0.9860
1283/1283 [==============================] - 0s 352us/step - loss: 0.0813 - acc: 0.9867 - val_loss: 1.1401 - val_acc: 0.5415

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0404 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0469 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0566 - acc: 0.9978
 640/1283 [=============>................] - ETA: 0s - loss: 0.0522 - acc: 0.9984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0540 - acc: 0.9964
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0524 - acc: 0.9971
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0510 - acc: 0.9959
1283/1283 [==============================] - 0s 343us/step - loss: 0.0505 - acc: 0.9961 - val_loss: 1.2526 - val_acc: 0.5764

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0506 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0426 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0343 - acc: 0.9955
 640/1283 [=============>................] - ETA: 0s - loss: 0.0347 - acc: 0.9953
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0334 - acc: 0.9964
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0360 - acc: 0.9961
1280/1283 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9961
1283/1283 [==============================] - 0s 321us/step - loss: 0.0350 - acc: 0.9961 - val_loss: 1.2909 - val_acc: 0.5371

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0279 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0283 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0267 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0276 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0281 - acc: 0.9988
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0276 - acc: 0.9990
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0271 - acc: 0.9992
1283/1283 [==============================] - 0s 339us/step - loss: 0.0267 - acc: 0.9992 - val_loss: 1.3209 - val_acc: 0.5895

Epoch 00017: val_acc improved from 0.58079 to 0.58952, saving model to classification_logs//cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AV_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_20.ckpt
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0153 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0193 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0195 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0180 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0191 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0193 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0202 - acc: 0.9992
1283/1283 [==============================] - 0s 331us/step - loss: 0.0199 - acc: 0.9992 - val_loss: 1.3735 - val_acc: 0.5240

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0209 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0149 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0141 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0139 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0144 - acc: 0.9987
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0147 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0149 - acc: 0.9991
1283/1283 [==============================] - 0s 347us/step - loss: 0.0148 - acc: 0.9992 - val_loss: 1.4599 - val_acc: 0.5459

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0100 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0101 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0113 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0109 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0108 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0105 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0111 - acc: 0.9991
1283/1283 [==============================] - 0s 357us/step - loss: 0.0115 - acc: 0.9992 - val_loss: 1.5582 - val_acc: 0.5677

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0114 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0559 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0515 - acc: 0.9866
 640/1283 [=============>................] - ETA: 0s - loss: 0.0489 - acc: 0.9875
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0424 - acc: 0.9904
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0433 - acc: 0.9912
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0411 - acc: 0.9918
1283/1283 [==============================] - 0s 345us/step - loss: 0.0403 - acc: 0.9922 - val_loss: 1.7445 - val_acc: 0.5240

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0436 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0302 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0266 - acc: 0.9978
 640/1283 [=============>................] - ETA: 0s - loss: 0.0238 - acc: 0.9984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0233 - acc: 0.9976
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0220 - acc: 0.9980
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0210 - acc: 0.9984
1283/1283 [==============================] - 0s 343us/step - loss: 0.0205 - acc: 0.9984 - val_loss: 1.4863 - val_acc: 0.5459

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0109 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0131 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0124 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0126 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0116 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0114 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0110 - acc: 1.0000
1283/1283 [==============================] - 0s 363us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.5782 - val_acc: 0.5546

Epoch 00023: val_acc did not improve
Epoch 24/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0061 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0076 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0074 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0070 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0071 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 1.0000
1283/1283 [==============================] - 0s 336us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.6542 - val_acc: 0.5459

Epoch 00024: val_acc did not improve
Epoch 25/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0049 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0046 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0048 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0054 - acc: 1.0000
1283/1283 [==============================] - 0s 349us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.6702 - val_acc: 0.5459

Epoch 00025: val_acc did not improve
Epoch 26/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0041 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0047 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0045 - acc: 1.0000
1283/1283 [==============================] - 0s 351us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.6965 - val_acc: 0.5459

Epoch 00026: val_acc did not improve
Epoch 27/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0074 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0037 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0037 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0036 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0036 - acc: 1.0000
1283/1283 [==============================] - 0s 350us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.7178 - val_acc: 0.5546

Epoch 00027: val_acc did not improve
Epoch 00027: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=20
epochs=100
mode=AV
accuracy=0.5247813411078717
best_valid_accuracy=0.5204081632653061
