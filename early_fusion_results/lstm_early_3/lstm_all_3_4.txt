/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
early_fusion_lstm.py:139: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
early_fusion_lstm.py:141: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-19 18:09:54.745826: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5:34 - loss: 0.6886 - acc: 0.5156/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (15.011356). Check your callbacks.
  % delta_t_median)

 128/1283 [=>............................] - ETA: 7:07 - loss: 0.6925 - acc: 0.5078/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (7.505806). Check your callbacks.
  % delta_t_median)

 192/1283 [===>..........................] - ETA: 4:30 - loss: 0.6937 - acc: 0.4896
 256/1283 [====>.........................] - ETA: 3:11 - loss: 0.6928 - acc: 0.4961
 320/1283 [======>.......................] - ETA: 2:23 - loss: 0.6912 - acc: 0.5094
 384/1283 [=======>......................] - ETA: 1:51 - loss: 0.6893 - acc: 0.5286
 448/1283 [=========>....................] - ETA: 1:29 - loss: 0.6889 - acc: 0.5290
 512/1283 [==========>...................] - ETA: 1:12 - loss: 0.6863 - acc: 0.5410
 576/1283 [============>.................] - ETA: 59s - loss: 0.6865 - acc: 0.5347 
 640/1283 [=============>................] - ETA: 48s - loss: 0.6848 - acc: 0.5406
 704/1283 [===============>..............] - ETA: 39s - loss: 0.6857 - acc: 0.5412
 768/1283 [================>.............] - ETA: 32s - loss: 0.6829 - acc: 0.5482
 832/1283 [==================>...........] - ETA: 26s - loss: 0.6802 - acc: 0.5601
 896/1283 [===================>..........] - ETA: 21s - loss: 0.6805 - acc: 0.5636
 960/1283 [=====================>........] - ETA: 16s - loss: 0.6814 - acc: 0.5604
1024/1283 [======================>.......] - ETA: 12s - loss: 0.6798 - acc: 0.5645
1088/1283 [========================>.....] - ETA: 8s - loss: 0.6783 - acc: 0.5662 
1152/1283 [=========================>....] - ETA: 5s - loss: 0.6772 - acc: 0.5660
1216/1283 [===========================>..] - ETA: 2s - loss: 0.6761 - acc: 0.5715
1280/1283 [============================>.] - ETA: 0s - loss: 0.6747 - acc: 0.5719
1283/1283 [==============================] - 51s 40ms/step - loss: 0.6749 - acc: 0.5713 - val_loss: 0.6544 - val_acc: 0.5939

Epoch 00001: val_acc improved from -inf to 0.59389, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.6259 - acc: 0.6875/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.693112). Check your callbacks.
  % delta_t_median)

 128/1283 [=>............................] - ETA: 22s - loss: 0.6082 - acc: 0.7422/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.846691). Check your callbacks.
  % delta_t_median)

 192/1283 [===>..........................] - ETA: 18s - loss: 0.6033 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 17s - loss: 0.6018 - acc: 0.7266
 320/1283 [======>.......................] - ETA: 14s - loss: 0.5977 - acc: 0.7250
 384/1283 [=======>......................] - ETA: 12s - loss: 0.6033 - acc: 0.7031
 448/1283 [=========>....................] - ETA: 11s - loss: 0.6137 - acc: 0.6786
 512/1283 [==========>...................] - ETA: 10s - loss: 0.6084 - acc: 0.6738
 576/1283 [============>.................] - ETA: 9s - loss: 0.6011 - acc: 0.6858 
 640/1283 [=============>................] - ETA: 9s - loss: 0.6029 - acc: 0.6813
 704/1283 [===============>..............] - ETA: 8s - loss: 0.6026 - acc: 0.6847
 768/1283 [================>.............] - ETA: 6s - loss: 0.5992 - acc: 0.6901
 832/1283 [==================>...........] - ETA: 5s - loss: 0.5958 - acc: 0.6983
 896/1283 [===================>..........] - ETA: 4s - loss: 0.5900 - acc: 0.7054
 960/1283 [=====================>........] - ETA: 4s - loss: 0.5840 - acc: 0.7115
1024/1283 [======================>.......] - ETA: 3s - loss: 0.5839 - acc: 0.7119
1088/1283 [========================>.....] - ETA: 2s - loss: 0.5832 - acc: 0.7105
1152/1283 [=========================>....] - ETA: 1s - loss: 0.5877 - acc: 0.7083
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5850 - acc: 0.7097
1280/1283 [============================>.] - ETA: 0s - loss: 0.5842 - acc: 0.7086
1283/1283 [==============================] - 14s 11ms/step - loss: 0.5848 - acc: 0.7085 - val_loss: 0.6431 - val_acc: 0.6812

Epoch 00002: val_acc improved from 0.59389 to 0.68122, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 15s - loss: 0.5455 - acc: 0.7969
 128/1283 [=>............................] - ETA: 13s - loss: 0.5038 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 13s - loss: 0.5029 - acc: 0.7552
 256/1283 [====>.........................] - ETA: 12s - loss: 0.4809 - acc: 0.7773
 320/1283 [======>.......................] - ETA: 12s - loss: 0.4734 - acc: 0.7844
 384/1283 [=======>......................] - ETA: 11s - loss: 0.4630 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 10s - loss: 0.4684 - acc: 0.7902
 512/1283 [==========>...................] - ETA: 10s - loss: 0.4634 - acc: 0.7891
 576/1283 [============>.................] - ETA: 9s - loss: 0.4701 - acc: 0.7847 
 640/1283 [=============>................] - ETA: 7s - loss: 0.4658 - acc: 0.7859
 704/1283 [===============>..............] - ETA: 10s - loss: 0.4646 - acc: 0.7898
 768/1283 [================>.............] - ETA: 9s - loss: 0.4623 - acc: 0.7969 
 832/1283 [==================>...........] - ETA: 7s - loss: 0.4653 - acc: 0.7957
 896/1283 [===================>..........] - ETA: 6s - loss: 0.4667 - acc: 0.7913
 960/1283 [=====================>........] - ETA: 5s - loss: 0.4606 - acc: 0.7948
1024/1283 [======================>.......] - ETA: 4s - loss: 0.4496 - acc: 0.7988
1088/1283 [========================>.....] - ETA: 3s - loss: 0.4482 - acc: 0.7987
1152/1283 [=========================>....] - ETA: 2s - loss: 0.4519 - acc: 0.7969
1216/1283 [===========================>..] - ETA: 1s - loss: 0.4506 - acc: 0.7952
1280/1283 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.7977
1283/1283 [==============================] - 21s 16ms/step - loss: 0.4464 - acc: 0.7973 - val_loss: 0.6493 - val_acc: 0.7074

Epoch 00003: val_acc improved from 0.68122 to 0.70742, saving model to classification_logs//lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30/saved_models/best_validation_lstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_3_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.3740 - acc: 0.7812
 128/1283 [=>............................] - ETA: 13s - loss: 0.3240 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 13s - loss: 0.3049 - acc: 0.8698
 256/1283 [====>.........................] - ETA: 12s - loss: 0.3143 - acc: 0.8672
 320/1283 [======>.......................] - ETA: 12s - loss: 0.3292 - acc: 0.8594
 384/1283 [=======>......................] - ETA: 11s - loss: 0.3550 - acc: 0.8490
 448/1283 [=========>....................] - ETA: 10s - loss: 0.3565 - acc: 0.8482
 512/1283 [==========>...................] - ETA: 9s - loss: 0.3522 - acc: 0.8477 
 576/1283 [============>.................] - ETA: 8s - loss: 0.3518 - acc: 0.8472
 640/1283 [=============>................] - ETA: 7s - loss: 0.3442 - acc: 0.8516
 704/1283 [===============>..............] - ETA: 6s - loss: 0.3463 - acc: 0.8494
 768/1283 [================>.............] - ETA: 6s - loss: 0.3355 - acc: 0.8581
 832/1283 [==================>...........] - ETA: 5s - loss: 0.3413 - acc: 0.8582
 896/1283 [===================>..........] - ETA: 4s - loss: 0.3397 - acc: 0.8594
 960/1283 [=====================>........] - ETA: 3s - loss: 0.3355 - acc: 0.8625
1024/1283 [======================>.......] - ETA: 3s - loss: 0.3330 - acc: 0.8623
1088/1283 [========================>.....] - ETA: 2s - loss: 0.3282 - acc: 0.8667
1152/1283 [=========================>....] - ETA: 1s - loss: 0.3272 - acc: 0.8672
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3219 - acc: 0.8701
1280/1283 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.8695
1283/1283 [==============================] - 17s 13ms/step - loss: 0.3209 - acc: 0.8698 - val_loss: 0.7790 - val_acc: 0.6725

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 17s - loss: 0.1835 - acc: 0.9219
 128/1283 [=>............................] - ETA: 15s - loss: 0.1988 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 13s - loss: 0.1919 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 12s - loss: 0.2065 - acc: 0.9141
 320/1283 [======>.......................] - ETA: 11s - loss: 0.2120 - acc: 0.9156
 384/1283 [=======>......................] - ETA: 11s - loss: 0.1966 - acc: 0.9245
 448/1283 [=========>....................] - ETA: 10s - loss: 0.1964 - acc: 0.9241
 512/1283 [==========>...................] - ETA: 9s - loss: 0.1893 - acc: 0.9297 
 576/1283 [============>.................] - ETA: 8s - loss: 0.1871 - acc: 0.9306
 640/1283 [=============>................] - ETA: 7s - loss: 0.1913 - acc: 0.9250
 704/1283 [===============>..............] - ETA: 7s - loss: 0.1921 - acc: 0.9233
 768/1283 [================>.............] - ETA: 6s - loss: 0.1862 - acc: 0.9232
 832/1283 [==================>...........] - ETA: 6s - loss: 0.1847 - acc: 0.9243
 896/1283 [===================>..........] - ETA: 5s - loss: 0.1831 - acc: 0.9241
 960/1283 [=====================>........] - ETA: 4s - loss: 0.1902 - acc: 0.9219
1024/1283 [======================>.......] - ETA: 3s - loss: 0.1914 - acc: 0.9199
1088/1283 [========================>.....] - ETA: 2s - loss: 0.1949 - acc: 0.9210
1152/1283 [=========================>....] - ETA: 1s - loss: 0.2019 - acc: 0.9193
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2019 - acc: 0.9194
1280/1283 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9195
1283/1283 [==============================] - 19s 15ms/step - loss: 0.2003 - acc: 0.9197 - val_loss: 0.8902 - val_acc: 0.6594

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 18s - loss: 0.0762 - acc: 0.9844
 128/1283 [=>............................] - ETA: 15s - loss: 0.0773 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 13s - loss: 0.0834 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 12s - loss: 0.0872 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 11s - loss: 0.0881 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 10s - loss: 0.0945 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 9s - loss: 0.0945 - acc: 0.9732 
 512/1283 [==========>...................] - ETA: 8s - loss: 0.1089 - acc: 0.9688
 576/1283 [============>.................] - ETA: 7s - loss: 0.1104 - acc: 0.9688
 640/1283 [=============>................] - ETA: 7s - loss: 0.1107 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 6s - loss: 0.1105 - acc: 0.9673
 768/1283 [================>.............] - ETA: 5s - loss: 0.1149 - acc: 0.9648
 832/1283 [==================>...........] - ETA: 4s - loss: 0.1231 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 4s - loss: 0.1261 - acc: 0.9587
 960/1283 [=====================>........] - ETA: 3s - loss: 0.1239 - acc: 0.9583
1024/1283 [======================>.......] - ETA: 2s - loss: 0.1199 - acc: 0.9600
1088/1283 [========================>.....] - ETA: 2s - loss: 0.1199 - acc: 0.9596
1152/1283 [=========================>....] - ETA: 1s - loss: 0.1198 - acc: 0.9583
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1173 - acc: 0.9597
1280/1283 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9594
1283/1283 [==============================] - 16s 13ms/step - loss: 0.1207 - acc: 0.9595 - val_loss: 1.1080 - val_acc: 0.6463

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 19s - loss: 0.0959 - acc: 0.9688
 128/1283 [=>............................] - ETA: 17s - loss: 0.1112 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 16s - loss: 0.1064 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 16s - loss: 0.1149 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 14s - loss: 0.1145 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 12s - loss: 0.1093 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 11s - loss: 0.1072 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 10s - loss: 0.0999 - acc: 0.9668
 576/1283 [============>.................] - ETA: 9s - loss: 0.1003 - acc: 0.9653 
 640/1283 [=============>................] - ETA: 8s - loss: 0.1076 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 7s - loss: 0.1072 - acc: 0.9645
 768/1283 [================>.............] - ETA: 6s - loss: 0.1138 - acc: 0.9622
 832/1283 [==================>...........] - ETA: 6s - loss: 0.1231 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 5s - loss: 0.1168 - acc: 0.9621
 960/1283 [=====================>........] - ETA: 4s - loss: 0.1142 - acc: 0.9625
1024/1283 [======================>.......] - ETA: 3s - loss: 0.1185 - acc: 0.9600
1088/1283 [========================>.....] - ETA: 2s - loss: 0.1131 - acc: 0.9623
1152/1283 [=========================>....] - ETA: 1s - loss: 0.1108 - acc: 0.9627
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1074 - acc: 0.9638
1280/1283 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9617
1283/1283 [==============================] - 19s 15ms/step - loss: 0.1134 - acc: 0.9610 - val_loss: 1.2631 - val_acc: 0.6638

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.1132 - acc: 0.9531
 128/1283 [=>............................] - ETA: 11s - loss: 0.1793 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 11s - loss: 0.1729 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 9s - loss: 0.1660 - acc: 0.9336 
 320/1283 [======>.......................] - ETA: 9s - loss: 0.1455 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 9s - loss: 0.1461 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 9s - loss: 0.1382 - acc: 0.9464
 512/1283 [==========>...................] - ETA: 8s - loss: 0.1431 - acc: 0.9395
 576/1283 [============>.................] - ETA: 7s - loss: 0.1512 - acc: 0.9358
 640/1283 [=============>................] - ETA: 6s - loss: 0.1593 - acc: 0.9344
 704/1283 [===============>..............] - ETA: 6s - loss: 0.1636 - acc: 0.9304
 768/1283 [================>.............] - ETA: 5s - loss: 0.1660 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 5s - loss: 0.1612 - acc: 0.9327
 896/1283 [===================>..........] - ETA: 4s - loss: 0.1650 - acc: 0.9319
 960/1283 [=====================>........] - ETA: 3s - loss: 0.1648 - acc: 0.9313
1024/1283 [======================>.......] - ETA: 3s - loss: 0.1618 - acc: 0.9336
1088/1283 [========================>.....] - ETA: 2s - loss: 0.1620 - acc: 0.9329
1152/1283 [=========================>....] - ETA: 1s - loss: 0.1584 - acc: 0.9349
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1590 - acc: 0.9342
1280/1283 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9359
1283/1283 [==============================] - 17s 13ms/step - loss: 0.1573 - acc: 0.9361 - val_loss: 0.8813 - val_acc: 0.6507

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 14s - loss: 0.1232 - acc: 0.9688
 128/1283 [=>............................] - ETA: 12s - loss: 0.1218 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 12s - loss: 0.1293 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 11s - loss: 0.1301 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 10s - loss: 0.1189 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 10s - loss: 0.1186 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 9s - loss: 0.1089 - acc: 0.9598 
 512/1283 [==========>...................] - ETA: 8s - loss: 0.1013 - acc: 0.9648
 576/1283 [============>.................] - ETA: 7s - loss: 0.0995 - acc: 0.9653
 640/1283 [=============>................] - ETA: 7s - loss: 0.0957 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 6s - loss: 0.0905 - acc: 0.9702
 768/1283 [================>.............] - ETA: 5s - loss: 0.0889 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 4s - loss: 0.0894 - acc: 0.9675
 896/1283 [===================>..........] - ETA: 4s - loss: 0.0856 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 3s - loss: 0.0854 - acc: 0.9698
1024/1283 [======================>.......] - ETA: 2s - loss: 0.0850 - acc: 0.9697
1088/1283 [========================>.....] - ETA: 2s - loss: 0.0870 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 1s - loss: 0.0845 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0820 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9695
1283/1283 [==============================] - 13s 10ms/step - loss: 0.0834 - acc: 0.9696 - val_loss: 1.3988 - val_acc: 0.6725

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.0147 - acc: 1.0000
 128/1283 [=>............................] - ETA: 9s - loss: 0.0185 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 9s - loss: 0.0251 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 9s - loss: 0.0374 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 8s - loss: 0.0373 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 8s - loss: 0.0461 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 8s - loss: 0.0450 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 7s - loss: 0.0427 - acc: 0.9805
 576/1283 [============>.................] - ETA: 6s - loss: 0.0393 - acc: 0.9826
 640/1283 [=============>................] - ETA: 6s - loss: 0.0390 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 5s - loss: 0.0398 - acc: 0.9830
 768/1283 [================>.............] - ETA: 4s - loss: 0.0375 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 4s - loss: 0.0353 - acc: 0.9856
 896/1283 [===================>..........] - ETA: 3s - loss: 0.0339 - acc: 0.9866
 960/1283 [=====================>........] - ETA: 2s - loss: 0.0336 - acc: 0.9865
1024/1283 [======================>.......] - ETA: 2s - loss: 0.0323 - acc: 0.9873
1088/1283 [========================>.....] - ETA: 1s - loss: 0.0326 - acc: 0.9871
1152/1283 [=========================>....] - ETA: 1s - loss: 0.0324 - acc: 0.9870
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0326 - acc: 0.9868
1280/1283 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9875
1283/1283 [==============================] - 12s 10ms/step - loss: 0.0315 - acc: 0.9875 - val_loss: 1.6566 - val_acc: 0.6812

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.0267 - acc: 0.9844
 128/1283 [=>............................] - ETA: 8s - loss: 0.0154 - acc: 0.9922 
 192/1283 [===>..........................] - ETA: 9s - loss: 0.0157 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 8s - loss: 0.0194 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 7s - loss: 0.0182 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 7s - loss: 0.0157 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 6s - loss: 0.0164 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 6s - loss: 0.0149 - acc: 0.9961
 576/1283 [============>.................] - ETA: 5s - loss: 0.0146 - acc: 0.9965
 640/1283 [=============>................] - ETA: 5s - loss: 0.0137 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 4s - loss: 0.0133 - acc: 0.9972
 768/1283 [================>.............] - ETA: 4s - loss: 0.0129 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 4s - loss: 0.0123 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 3s - loss: 0.0131 - acc: 0.9978
 960/1283 [=====================>........] - ETA: 2s - loss: 0.0128 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 2s - loss: 0.0123 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 1s - loss: 0.0123 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 1s - loss: 0.0120 - acc: 0.9983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0115 - acc: 0.9984
1280/1283 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9984
1283/1283 [==============================] - 11s 9ms/step - loss: 0.0111 - acc: 0.9984 - val_loss: 1.7322 - val_acc: 0.6638

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.0117 - acc: 1.0000
 128/1283 [=>............................] - ETA: 8s - loss: 0.0184 - acc: 0.9922 
 192/1283 [===>..........................] - ETA: 7s - loss: 0.0133 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 7s - loss: 0.0104 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 7s - loss: 0.0096 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 6s - loss: 0.0099 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 5s - loss: 0.0159 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 5s - loss: 0.0142 - acc: 0.9961
 576/1283 [============>.................] - ETA: 4s - loss: 0.0135 - acc: 0.9965
 640/1283 [=============>................] - ETA: 4s - loss: 0.0135 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 4s - loss: 0.0127 - acc: 0.9972
 768/1283 [================>.............] - ETA: 3s - loss: 0.0118 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 3s - loss: 0.0110 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 2s - loss: 0.0103 - acc: 0.9978
 960/1283 [=====================>........] - ETA: 2s - loss: 0.0102 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 1s - loss: 0.0099 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 1s - loss: 0.0098 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0104 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0105 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9977
1283/1283 [==============================] - 9s 7ms/step - loss: 0.0101 - acc: 0.9977 - val_loss: 1.8286 - val_acc: 0.6856

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.0050 - acc: 1.0000
 128/1283 [=>............................] - ETA: 7s - loss: 0.0049 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 7s - loss: 0.0045 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 6s - loss: 0.0044 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 6s - loss: 0.0056 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 6s - loss: 0.0048 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 5s - loss: 0.0046 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 5s - loss: 0.0041 - acc: 1.0000
 576/1283 [============>.................] - ETA: 4s - loss: 0.0052 - acc: 1.0000
 640/1283 [=============>................] - ETA: 4s - loss: 0.0049 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 3s - loss: 0.0055 - acc: 1.0000
 768/1283 [================>.............] - ETA: 3s - loss: 0.0051 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 2s - loss: 0.0048 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 2s - loss: 0.0045 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 2s - loss: 0.0044 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 1s - loss: 0.0042 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 1s - loss: 0.0040 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0038 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0051 - acc: 0.9992
1280/1283 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9992
1283/1283 [==============================] - 9s 7ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 1.9242 - val_acc: 0.6812

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=3
max_len=30
mode=all
accuracy=0.6807580174927114
best_valid_accuracy=0.5932944606413995
