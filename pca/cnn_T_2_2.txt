/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:23:47.370045: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.8285 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 2s - loss: 0.7825 - acc: 0.5104
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7700 - acc: 0.4781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7520 - acc: 0.5156
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7323 - acc: 0.5332
 640/1283 [=============>................] - ETA: 0s - loss: 0.7337 - acc: 0.5188
 768/1283 [================>.............] - ETA: 0s - loss: 0.7286 - acc: 0.5299
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7254 - acc: 0.5368
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7166 - acc: 0.5459
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7113 - acc: 0.5495
1280/1283 [============================>.] - ETA: 0s - loss: 0.7113 - acc: 0.5453
1283/1283 [==============================] - 1s 971us/step - loss: 0.7114 - acc: 0.5448 - val_loss: 0.6960 - val_acc: 0.5677

Epoch 00001: val_acc improved from -inf to 0.56769, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6279 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5995 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5882 - acc: 0.7148
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5857 - acc: 0.7292
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5772 - acc: 0.7500
 640/1283 [=============>................] - ETA: 0s - loss: 0.5778 - acc: 0.7469
 768/1283 [================>.............] - ETA: 0s - loss: 0.5730 - acc: 0.7578
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5677 - acc: 0.7723
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5678 - acc: 0.7729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5650 - acc: 0.7684
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5644 - acc: 0.7632
1283/1283 [==============================] - 1s 657us/step - loss: 0.5616 - acc: 0.7654 - val_loss: 0.7133 - val_acc: 0.5764

Epoch 00002: val_acc improved from 0.56769 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4268 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4784 - acc: 0.8021
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4614 - acc: 0.8375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4561 - acc: 0.8307
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4540 - acc: 0.8359
 576/1283 [============>.................] - ETA: 0s - loss: 0.4539 - acc: 0.8403
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4402 - acc: 0.8509
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4322 - acc: 0.8534
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4340 - acc: 0.8469
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4301 - acc: 0.8474
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4256 - acc: 0.8462
1283/1283 [==============================] - 1s 706us/step - loss: 0.4277 - acc: 0.8410 - val_loss: 0.7389 - val_acc: 0.5677

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3396 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3281 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3151 - acc: 0.8719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3161 - acc: 0.8728
 640/1283 [=============>................] - ETA: 0s - loss: 0.3194 - acc: 0.8609
 768/1283 [================>.............] - ETA: 0s - loss: 0.3143 - acc: 0.8685
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3120 - acc: 0.8690
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3117 - acc: 0.8661
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3117 - acc: 0.8677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3105 - acc: 0.8672
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3090 - acc: 0.8704
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3053 - acc: 0.8715
1280/1283 [============================>.] - ETA: 0s - loss: 0.3006 - acc: 0.8750
1283/1283 [==============================] - 1s 789us/step - loss: 0.3005 - acc: 0.8745 - val_loss: 0.7696 - val_acc: 0.6157

Epoch 00004: val_acc improved from 0.57642 to 0.61572, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1594 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1744 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1904 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2086 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2098 - acc: 0.9297
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2074 - acc: 0.9308
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2077 - acc: 0.9258
 640/1283 [=============>................] - ETA: 0s - loss: 0.2064 - acc: 0.9234
 768/1283 [================>.............] - ETA: 0s - loss: 0.2137 - acc: 0.9141
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2141 - acc: 0.9123
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2068 - acc: 0.9208
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2033 - acc: 0.9229
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2009 - acc: 0.9245
1280/1283 [============================>.] - ETA: 0s - loss: 0.1969 - acc: 0.9281
1283/1283 [==============================] - 1s 860us/step - loss: 0.1972 - acc: 0.9283 - val_loss: 0.8769 - val_acc: 0.6026

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1508 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1133 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1111 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1246 - acc: 0.9576
 576/1283 [============>.................] - ETA: 0s - loss: 0.1210 - acc: 0.9635
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1263 - acc: 0.9574
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1258 - acc: 0.9543
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1280 - acc: 0.9542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1331 - acc: 0.9513
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1327 - acc: 0.9523
1283/1283 [==============================] - 1s 689us/step - loss: 0.1283 - acc: 0.9548 - val_loss: 1.0545 - val_acc: 0.6201

Epoch 00006: val_acc improved from 0.61572 to 0.62009, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1112 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1099 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0980 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0959 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0995 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.1036 - acc: 0.9653
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0983 - acc: 0.9659
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1013 - acc: 0.9639
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1000 - acc: 0.9643
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1000 - acc: 0.9635
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0995 - acc: 0.9623
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0980 - acc: 0.9646
1283/1283 [==============================] - 1s 807us/step - loss: 0.0981 - acc: 0.9657 - val_loss: 1.1447 - val_acc: 0.6288

Epoch 00007: val_acc improved from 0.62009 to 0.62882, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1119 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0703 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0745 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0816 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.0813 - acc: 0.9740
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0772 - acc: 0.9744
 768/1283 [================>.............] - ETA: 0s - loss: 0.0762 - acc: 0.9766
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0726 - acc: 0.9784
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0823 - acc: 0.9781
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0845 - acc: 0.9779
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0844 - acc: 0.9753
1283/1283 [==============================] - 1s 738us/step - loss: 0.0857 - acc: 0.9743 - val_loss: 1.1727 - val_acc: 0.6376

Epoch 00008: val_acc improved from 0.62882 to 0.63755, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0464 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0656 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0699 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0686 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.0667 - acc: 0.9757
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0615 - acc: 0.9773
 768/1283 [================>.............] - ETA: 0s - loss: 0.0596 - acc: 0.9792
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0603 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0590 - acc: 0.9802
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0575 - acc: 0.9816
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0640 - acc: 0.9819
1283/1283 [==============================] - 1s 760us/step - loss: 0.0655 - acc: 0.9813 - val_loss: 1.2937 - val_acc: 0.6376

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0927 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1544 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1236 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1114 - acc: 0.9643
 576/1283 [============>.................] - ETA: 0s - loss: 0.1029 - acc: 0.9653
 640/1283 [=============>................] - ETA: 0s - loss: 0.0966 - acc: 0.9688
 768/1283 [================>.............] - ETA: 0s - loss: 0.0982 - acc: 0.9661
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0960 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0955 - acc: 0.9688
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0976 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0970 - acc: 0.9638
1283/1283 [==============================] - 1s 705us/step - loss: 0.0945 - acc: 0.9649 - val_loss: 1.3051 - val_acc: 0.6114

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0314 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1183 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1329 - acc: 0.9563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1088 - acc: 0.9643
 576/1283 [============>.................] - ETA: 0s - loss: 0.1112 - acc: 0.9635
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1144 - acc: 0.9560
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1057 - acc: 0.9603
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1025 - acc: 0.9621
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1023 - acc: 0.9639
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1058 - acc: 0.9627
1280/1283 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9602
1283/1283 [==============================] - 1s 675us/step - loss: 0.1117 - acc: 0.9595 - val_loss: 1.2387 - val_acc: 0.5983

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0474 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1469 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1965 - acc: 0.9180
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1758 - acc: 0.9323
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1707 - acc: 0.9316
 640/1283 [=============>................] - ETA: 0s - loss: 0.1602 - acc: 0.9375
 768/1283 [================>.............] - ETA: 0s - loss: 0.1543 - acc: 0.9388
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1492 - acc: 0.9442
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1447 - acc: 0.9473
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1523 - acc: 0.9444
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1542 - acc: 0.9424
1280/1283 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9437
1283/1283 [==============================] - 1s 751us/step - loss: 0.1513 - acc: 0.9431 - val_loss: 1.4137 - val_acc: 0.5895

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0688 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1494 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1352 - acc: 0.9648
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1285 - acc: 0.9609
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1358 - acc: 0.9512
 640/1283 [=============>................] - ETA: 0s - loss: 0.1661 - acc: 0.9375
 768/1283 [================>.............] - ETA: 0s - loss: 0.1557 - acc: 0.9427
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1427 - acc: 0.9487
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1433 - acc: 0.9482
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1394 - acc: 0.9494
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1384 - acc: 0.9505
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1366 - acc: 0.9507
1283/1283 [==============================] - 1s 784us/step - loss: 0.1325 - acc: 0.9525 - val_loss: 1.4356 - val_acc: 0.5590

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0655 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0519 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0556 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0553 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0540 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0524 - acc: 0.9792
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0551 - acc: 0.9773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0568 - acc: 0.9736
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0567 - acc: 0.9740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0543 - acc: 0.9752
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0550 - acc: 0.9757
1280/1283 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9766
1283/1283 [==============================] - 1s 789us/step - loss: 0.0547 - acc: 0.9766 - val_loss: 1.4911 - val_acc: 0.6245

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0464 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0593 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0439 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0461 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0432 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.0376 - acc: 0.9861
 640/1283 [=============>................] - ETA: 0s - loss: 0.0374 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0339 - acc: 0.9870
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0360 - acc: 0.9866
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0386 - acc: 0.9863
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0385 - acc: 0.9862
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0398 - acc: 0.9852
1283/1283 [==============================] - 1s 764us/step - loss: 0.0392 - acc: 0.9852 - val_loss: 1.5007 - val_acc: 0.6201

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0091 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0237 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0297 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0344 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0320 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0314 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0322 - acc: 0.9832
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0363 - acc: 0.9823
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0359 - acc: 0.9825
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0342 - acc: 0.9844
1283/1283 [==============================] - 1s 685us/step - loss: 0.0347 - acc: 0.9836 - val_loss: 1.5945 - val_acc: 0.6114

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0360 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0210 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0285 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0377 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0365 - acc: 0.9863
 640/1283 [=============>................] - ETA: 0s - loss: 0.0342 - acc: 0.9859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0315 - acc: 0.9872
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0321 - acc: 0.9856
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0299 - acc: 0.9865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0300 - acc: 0.9862
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0318 - acc: 0.9852
1280/1283 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9852
1283/1283 [==============================] - 1s 732us/step - loss: 0.0324 - acc: 0.9852 - val_loss: 1.5774 - val_acc: 0.6288

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0153 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0163 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0275 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0317 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.0331 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0335 - acc: 0.9815
 768/1283 [================>.............] - ETA: 0s - loss: 0.0316 - acc: 0.9831
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0289 - acc: 0.9855
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0270 - acc: 0.9873
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0273 - acc: 0.9870
1280/1283 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9852
1283/1283 [==============================] - 1s 670us/step - loss: 0.0308 - acc: 0.9852 - val_loss: 1.6315 - val_acc: 0.5983

Epoch 00018: val_acc did not improve
Epoch 00018: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6034985422740525
best_valid_accuracy=0.6049562682215743
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:28:58.991449: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 15s - loss: 0.7381 - acc: 0.4688
 128/1283 [=>............................] - ETA: 7s - loss: 0.7858 - acc: 0.5312 
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7700 - acc: 0.5781
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7545 - acc: 0.5755
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7577 - acc: 0.5508
 640/1283 [=============>................] - ETA: 1s - loss: 0.7451 - acc: 0.5563
 768/1283 [================>.............] - ETA: 0s - loss: 0.7338 - acc: 0.5599
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7322 - acc: 0.5529
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7275 - acc: 0.5490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7237 - acc: 0.5488
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7217 - acc: 0.5450
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7217 - acc: 0.5370
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7243 - acc: 0.5323 - val_loss: 0.7029 - val_acc: 0.5153

Epoch 00001: val_acc improved from -inf to 0.51528, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5876 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5986 - acc: 0.7240
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5933 - acc: 0.7188
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5885 - acc: 0.7121
 576/1283 [============>.................] - ETA: 0s - loss: 0.5829 - acc: 0.7153
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5740 - acc: 0.7315
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5682 - acc: 0.7400
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5604 - acc: 0.7422
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5600 - acc: 0.7387
1283/1283 [==============================] - 1s 532us/step - loss: 0.5574 - acc: 0.7412 - val_loss: 0.6982 - val_acc: 0.5721

Epoch 00002: val_acc improved from 0.51528 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4199 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4370 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4344 - acc: 0.8406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4365 - acc: 0.8326
 576/1283 [============>.................] - ETA: 0s - loss: 0.4339 - acc: 0.8299
 768/1283 [================>.............] - ETA: 0s - loss: 0.4346 - acc: 0.8268
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4257 - acc: 0.8348
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4235 - acc: 0.8359
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4190 - acc: 0.8411
1283/1283 [==============================] - 1s 494us/step - loss: 0.4156 - acc: 0.8402 - val_loss: 0.7314 - val_acc: 0.6288

Epoch 00003: val_acc improved from 0.57205 to 0.62882, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2882 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2702 - acc: 0.8984
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2791 - acc: 0.8880
 576/1283 [============>.................] - ETA: 0s - loss: 0.2754 - acc: 0.8993
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2790 - acc: 0.8991
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2793 - acc: 0.9002
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2810 - acc: 0.8990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2745 - acc: 0.9035
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2686 - acc: 0.9079
1283/1283 [==============================] - 1s 536us/step - loss: 0.2686 - acc: 0.9065 - val_loss: 0.8380 - val_acc: 0.5983

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2108 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1997 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1961 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1862 - acc: 0.9509
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1765 - acc: 0.9474
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1894 - acc: 0.9297
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1839 - acc: 0.9314
1283/1283 [==============================] - 1s 398us/step - loss: 0.1793 - acc: 0.9337 - val_loss: 0.9219 - val_acc: 0.6157

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1514 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1374 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1253 - acc: 0.9576
 640/1283 [=============>................] - ETA: 0s - loss: 0.1188 - acc: 0.9641
 768/1283 [================>.............] - ETA: 0s - loss: 0.1123 - acc: 0.9661
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1127 - acc: 0.9656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1123 - acc: 0.9651
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1127 - acc: 0.9638
1283/1283 [==============================] - 1s 441us/step - loss: 0.1112 - acc: 0.9641 - val_loss: 1.0432 - val_acc: 0.6114

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1377 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0964 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1036 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0980 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.0968 - acc: 0.9757
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0946 - acc: 0.9759
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0929 - acc: 0.9754
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0984 - acc: 0.9715
1280/1283 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9680
1283/1283 [==============================] - 1s 524us/step - loss: 0.0988 - acc: 0.9680 - val_loss: 1.2501 - val_acc: 0.6114

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1069 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1114 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1025 - acc: 0.9648
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0950 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.0885 - acc: 0.9722
 768/1283 [================>.............] - ETA: 0s - loss: 0.0855 - acc: 0.9701
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0827 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0821 - acc: 0.9708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0821 - acc: 0.9707
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0791 - acc: 0.9714
1280/1283 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9719
1283/1283 [==============================] - 1s 604us/step - loss: 0.0786 - acc: 0.9719 - val_loss: 1.1653 - val_acc: 0.6114

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0578 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0799 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0680 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0699 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.0679 - acc: 0.9740
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0702 - acc: 0.9730
 768/1283 [================>.............] - ETA: 0s - loss: 0.0708 - acc: 0.9740
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0678 - acc: 0.9748
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0661 - acc: 0.9743
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0642 - acc: 0.9750
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0626 - acc: 0.9779
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0605 - acc: 0.9792
1280/1283 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9781
1283/1283 [==============================] - 1s 729us/step - loss: 0.0607 - acc: 0.9782 - val_loss: 1.2468 - val_acc: 0.6070

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0458 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0544 - acc: 0.9792
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0474 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0445 - acc: 0.9863
 640/1283 [=============>................] - ETA: 0s - loss: 0.0514 - acc: 0.9828
 768/1283 [================>.............] - ETA: 0s - loss: 0.0495 - acc: 0.9831
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0493 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0479 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0456 - acc: 0.9852
1283/1283 [==============================] - 1s 551us/step - loss: 0.0502 - acc: 0.9821 - val_loss: 1.2446 - val_acc: 0.6114

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0124 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0218 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0323 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0277 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0343 - acc: 0.9883
 640/1283 [=============>................] - ETA: 0s - loss: 0.0345 - acc: 0.9859
 768/1283 [================>.............] - ETA: 0s - loss: 0.0322 - acc: 0.9883
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0349 - acc: 0.9866
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0363 - acc: 0.9863
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0369 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0375 - acc: 0.9835
1283/1283 [==============================] - 1s 785us/step - loss: 0.0418 - acc: 0.9829 - val_loss: 1.3949 - val_acc: 0.6026

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0249 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0194 - acc: 0.9896
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0316 - acc: 0.9870
 576/1283 [============>.................] - ETA: 0s - loss: 0.0336 - acc: 0.9861
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0349 - acc: 0.9858
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0319 - acc: 0.9880
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0303 - acc: 0.9885
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0322 - acc: 0.9870
1280/1283 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9852
1283/1283 [==============================] - 1s 540us/step - loss: 0.0370 - acc: 0.9844 - val_loss: 1.3824 - val_acc: 0.6070

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0176 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0337 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0514 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0479 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0606 - acc: 0.9757
 640/1283 [=============>................] - ETA: 0s - loss: 0.0611 - acc: 0.9750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0602 - acc: 0.9772
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0557 - acc: 0.9792
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0536 - acc: 0.9805
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0526 - acc: 0.9809
1283/1283 [==============================] - 1s 504us/step - loss: 0.0523 - acc: 0.9805 - val_loss: 1.4739 - val_acc: 0.5808

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=110
accuracy=0.597667638483965
best_valid_accuracy=0.6064139941690962
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:41:54.581030: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 9s - loss: 0.7841 - acc: 0.4844
 128/1283 [=>............................] - ETA: 4s - loss: 0.8069 - acc: 0.5078
 192/1283 [===>..........................] - ETA: 3s - loss: 0.8112 - acc: 0.4948
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7995 - acc: 0.4805
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7841 - acc: 0.4813
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7733 - acc: 0.4896
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7816 - acc: 0.4777
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7748 - acc: 0.4863
 576/1283 [============>.................] - ETA: 1s - loss: 0.7656 - acc: 0.4913
 640/1283 [=============>................] - ETA: 1s - loss: 0.7586 - acc: 0.4891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7603 - acc: 0.4830
 768/1283 [================>.............] - ETA: 0s - loss: 0.7578 - acc: 0.4909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7514 - acc: 0.4940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7440 - acc: 0.5052
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7402 - acc: 0.5059
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7368 - acc: 0.5092
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7338 - acc: 0.5156
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7322 - acc: 0.5152 - val_loss: 0.6969 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6141 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5856 - acc: 0.7396
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5880 - acc: 0.7344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5938 - acc: 0.7214
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5852 - acc: 0.7344
 640/1283 [=============>................] - ETA: 0s - loss: 0.5823 - acc: 0.7266
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5844 - acc: 0.7173
 768/1283 [================>.............] - ETA: 0s - loss: 0.5796 - acc: 0.7227
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5803 - acc: 0.7139
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5802 - acc: 0.7165
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5795 - acc: 0.7167
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5758 - acc: 0.7266
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5747 - acc: 0.7266
1280/1283 [============================>.] - ETA: 0s - loss: 0.5717 - acc: 0.7320
1283/1283 [==============================] - 1s 811us/step - loss: 0.5716 - acc: 0.7319 - val_loss: 0.7568 - val_acc: 0.5415

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4823 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.5222 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5055 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4840 - acc: 0.8307
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4790 - acc: 0.8415
 576/1283 [============>.................] - ETA: 0s - loss: 0.4769 - acc: 0.8316
 640/1283 [=============>................] - ETA: 0s - loss: 0.4678 - acc: 0.8375
 768/1283 [================>.............] - ETA: 0s - loss: 0.4630 - acc: 0.8359
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4623 - acc: 0.8389
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4548 - acc: 0.8438
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4486 - acc: 0.8438
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4441 - acc: 0.8420
1280/1283 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8344
1283/1283 [==============================] - 1s 780us/step - loss: 0.4435 - acc: 0.8340 - val_loss: 0.7467 - val_acc: 0.6026

Epoch 00003: val_acc improved from 0.55022 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3548 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3398 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3291 - acc: 0.8867
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3296 - acc: 0.9000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3165 - acc: 0.9062
 576/1283 [============>.................] - ETA: 0s - loss: 0.3159 - acc: 0.9062
 640/1283 [=============>................] - ETA: 0s - loss: 0.3140 - acc: 0.9062
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3102 - acc: 0.9077
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3085 - acc: 0.8990
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3073 - acc: 0.8927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3071 - acc: 0.8945
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3066 - acc: 0.8925
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3064 - acc: 0.8914
1283/1283 [==============================] - 1s 875us/step - loss: 0.3113 - acc: 0.8878 - val_loss: 0.8624 - val_acc: 0.5721

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1967 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1974 - acc: 0.9609
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2235 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2179 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2166 - acc: 0.9349
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2109 - acc: 0.9353
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2129 - acc: 0.9316
 640/1283 [=============>................] - ETA: 0s - loss: 0.2058 - acc: 0.9313
 768/1283 [================>.............] - ETA: 0s - loss: 0.2059 - acc: 0.9271
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2083 - acc: 0.9279
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2066 - acc: 0.9286
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2082 - acc: 0.9281
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2095 - acc: 0.9248
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2117 - acc: 0.9219
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2120 - acc: 0.9202
1280/1283 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9227
1283/1283 [==============================] - 1s 894us/step - loss: 0.2103 - acc: 0.9228 - val_loss: 0.9908 - val_acc: 0.5764

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1242 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1301 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1220 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1198 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1169 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1200 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.1257 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.1282 - acc: 0.9609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1285 - acc: 0.9588
 768/1283 [================>.............] - ETA: 0s - loss: 0.1311 - acc: 0.9583
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1312 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1288 - acc: 0.9609
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1293 - acc: 0.9590
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1295 - acc: 0.9575
1280/1283 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9555
1283/1283 [==============================] - 1s 879us/step - loss: 0.1323 - acc: 0.9556 - val_loss: 1.1988 - val_acc: 0.5546

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1110 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1100 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1009 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1081 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.1048 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1033 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0972 - acc: 0.9724
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0969 - acc: 0.9729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0951 - acc: 0.9715
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0942 - acc: 0.9720
1283/1283 [==============================] - 1s 747us/step - loss: 0.0959 - acc: 0.9704 - val_loss: 1.2354 - val_acc: 0.5764

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0713 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0973 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0956 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1263 - acc: 0.9656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1092 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.1024 - acc: 0.9757
 640/1283 [=============>................] - ETA: 0s - loss: 0.1035 - acc: 0.9734
 768/1283 [================>.............] - ETA: 0s - loss: 0.1093 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1072 - acc: 0.9712
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1080 - acc: 0.9698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1059 - acc: 0.9697
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1043 - acc: 0.9688
1280/1283 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9625
1283/1283 [==============================] - 1s 865us/step - loss: 0.1115 - acc: 0.9626 - val_loss: 1.4028 - val_acc: 0.5721

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0645 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1013 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0981 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1000 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0994 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.0942 - acc: 0.9719
 768/1283 [================>.............] - ETA: 0s - loss: 0.1012 - acc: 0.9648
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0995 - acc: 0.9654
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0971 - acc: 0.9667
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0966 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0954 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9711
1283/1283 [==============================] - 1s 769us/step - loss: 0.0910 - acc: 0.9712 - val_loss: 1.4471 - val_acc: 0.5852

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0297 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0347 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0544 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0633 - acc: 0.9792
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0602 - acc: 0.9785
 640/1283 [=============>................] - ETA: 0s - loss: 0.0607 - acc: 0.9797
 768/1283 [================>.............] - ETA: 0s - loss: 0.0585 - acc: 0.9792
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0586 - acc: 0.9796
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0573 - acc: 0.9799
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0558 - acc: 0.9802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0563 - acc: 0.9795
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0553 - acc: 0.9807
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0580 - acc: 0.9800
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0590 - acc: 0.9794
1280/1283 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9797
1283/1283 [==============================] - 1s 987us/step - loss: 0.0578 - acc: 0.9797 - val_loss: 1.6655 - val_acc: 0.5764

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0573 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0404 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0336 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0350 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0374 - acc: 0.9863
 640/1283 [=============>................] - ETA: 0s - loss: 0.0427 - acc: 0.9812
 768/1283 [================>.............] - ETA: 0s - loss: 0.0477 - acc: 0.9805
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0510 - acc: 0.9799
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0477 - acc: 0.9824
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0467 - acc: 0.9826
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0456 - acc: 0.9836
1280/1283 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9828
1283/1283 [==============================] - 1s 746us/step - loss: 0.0489 - acc: 0.9829 - val_loss: 1.6420 - val_acc: 0.5895

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0451 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0345 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0379 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0481 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0438 - acc: 0.9826
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0416 - acc: 0.9830
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0452 - acc: 0.9820
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0500 - acc: 0.9812
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0490 - acc: 0.9814
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0550 - acc: 0.9789
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0535 - acc: 0.9811
1283/1283 [==============================] - 1s 687us/step - loss: 0.0541 - acc: 0.9797 - val_loss: 1.6594 - val_acc: 0.5721

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0216 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0372 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0431 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0383 - acc: 0.9818
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0451 - acc: 0.9805
 576/1283 [============>.................] - ETA: 0s - loss: 0.0439 - acc: 0.9809
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0459 - acc: 0.9787
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0426 - acc: 0.9808
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0393 - acc: 0.9823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0396 - acc: 0.9814
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0416 - acc: 0.9800
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0407 - acc: 0.9803
1280/1283 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9812
1283/1283 [==============================] - 1s 776us/step - loss: 0.0394 - acc: 0.9813 - val_loss: 1.6630 - val_acc: 0.5895

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=120
accuracy=0.5583090379008746
best_valid_accuracy=0.5306122448979592
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:52:40.883489: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.7962 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 2s - loss: 0.7983 - acc: 0.4583
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7635 - acc: 0.4781
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7380 - acc: 0.5078
 640/1283 [=============>................] - ETA: 0s - loss: 0.7357 - acc: 0.5016
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7262 - acc: 0.5072
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7239 - acc: 0.5000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7149 - acc: 0.5191
1280/1283 [============================>.] - ETA: 0s - loss: 0.7132 - acc: 0.5164
1283/1283 [==============================] - 1s 684us/step - loss: 0.7131 - acc: 0.5168 - val_loss: 0.7020 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5719 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5954 - acc: 0.6797
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5979 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5970 - acc: 0.6875
 640/1283 [=============>................] - ETA: 0s - loss: 0.5916 - acc: 0.6906
 768/1283 [================>.............] - ETA: 0s - loss: 0.5866 - acc: 0.7005
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5777 - acc: 0.7221
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5758 - acc: 0.7305
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5733 - acc: 0.7344
1283/1283 [==============================] - 1s 471us/step - loss: 0.5683 - acc: 0.7389 - val_loss: 0.6998 - val_acc: 0.5852

Epoch 00002: val_acc improved from 0.54148 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4797 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4480 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4467 - acc: 0.8438
 576/1283 [============>.................] - ETA: 0s - loss: 0.4332 - acc: 0.8368
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4255 - acc: 0.8381
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4173 - acc: 0.8315
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4207 - acc: 0.8309
1280/1283 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8305
1283/1283 [==============================] - 1s 395us/step - loss: 0.4120 - acc: 0.8309 - val_loss: 0.7527 - val_acc: 0.6201

Epoch 00003: val_acc improved from 0.58515 to 0.62009, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2040 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2741 - acc: 0.8984
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2765 - acc: 0.8958
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2783 - acc: 0.8867
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2732 - acc: 0.8892
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2755 - acc: 0.8850
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2754 - acc: 0.8860
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2721 - acc: 0.8890
1283/1283 [==============================] - 1s 401us/step - loss: 0.2694 - acc: 0.8893 - val_loss: 0.7849 - val_acc: 0.5895

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1978 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1942 - acc: 0.9336
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1946 - acc: 0.9442
 640/1283 [=============>................] - ETA: 0s - loss: 0.1906 - acc: 0.9375
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1867 - acc: 0.9351
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1818 - acc: 0.9355
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1783 - acc: 0.9350
1283/1283 [==============================] - 0s 387us/step - loss: 0.1772 - acc: 0.9361 - val_loss: 0.9552 - val_acc: 0.6245

Epoch 00005: val_acc improved from 0.62009 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0805 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0933 - acc: 0.9883
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0935 - acc: 0.9766
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1005 - acc: 0.9648
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1027 - acc: 0.9645
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1034 - acc: 0.9643
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1050 - acc: 0.9614
1280/1283 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9570
1283/1283 [==============================] - 1s 399us/step - loss: 0.1113 - acc: 0.9564 - val_loss: 1.0683 - val_acc: 0.5983

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1147 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0882 - acc: 0.9727
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0828 - acc: 0.9792
 576/1283 [============>.................] - ETA: 0s - loss: 0.0791 - acc: 0.9757
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0817 - acc: 0.9773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0808 - acc: 0.9760
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0827 - acc: 0.9729
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0812 - acc: 0.9722
1283/1283 [==============================] - 1s 424us/step - loss: 0.0846 - acc: 0.9688 - val_loss: 1.2324 - val_acc: 0.6114

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0535 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0592 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0565 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0577 - acc: 0.9824
 640/1283 [=============>................] - ETA: 0s - loss: 0.0555 - acc: 0.9828
 768/1283 [================>.............] - ETA: 0s - loss: 0.0554 - acc: 0.9818
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0546 - acc: 0.9833
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0615 - acc: 0.9798
1280/1283 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9797
1283/1283 [==============================] - 1s 426us/step - loss: 0.0603 - acc: 0.9797 - val_loss: 1.3677 - val_acc: 0.6026

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0399 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0576 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0558 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0512 - acc: 0.9824
 768/1283 [================>.............] - ETA: 0s - loss: 0.0473 - acc: 0.9805
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0469 - acc: 0.9795
1280/1283 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9812
1283/1283 [==============================] - 0s 319us/step - loss: 0.0453 - acc: 0.9813 - val_loss: 1.5608 - val_acc: 0.6157

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0495 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0494 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0430 - acc: 0.9824
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0419 - acc: 0.9830
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0491 - acc: 0.9823
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0457 - acc: 0.9819
1283/1283 [==============================] - 0s 277us/step - loss: 0.0463 - acc: 0.9821 - val_loss: 1.6773 - val_acc: 0.6114

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0725 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0470 - acc: 0.9781
 576/1283 [============>.................] - ETA: 0s - loss: 0.0425 - acc: 0.9774
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0413 - acc: 0.9784
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0381 - acc: 0.9795
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0347 - acc: 0.9827
1283/1283 [==============================] - 0s 301us/step - loss: 0.0338 - acc: 0.9836 - val_loss: 1.7886 - val_acc: 0.6201

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0133 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0172 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0214 - acc: 0.9955
 640/1283 [=============>................] - ETA: 0s - loss: 0.0247 - acc: 0.9938
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0335 - acc: 0.9877
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0355 - acc: 0.9862
1280/1283 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9844
1283/1283 [==============================] - 0s 301us/step - loss: 0.0412 - acc: 0.9844 - val_loss: 1.7079 - val_acc: 0.5895

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0556 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0333 - acc: 0.9750
 576/1283 [============>.................] - ETA: 0s - loss: 0.0302 - acc: 0.9809
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0289 - acc: 0.9820
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0404 - acc: 0.9779
1283/1283 [==============================] - 0s 241us/step - loss: 0.0406 - acc: 0.9774 - val_loss: 1.8124 - val_acc: 0.5721

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0231 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0282 - acc: 0.9824
 768/1283 [================>.............] - ETA: 0s - loss: 0.0300 - acc: 0.9831
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0302 - acc: 0.9834
1280/1283 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9828
1283/1283 [==============================] - 0s 256us/step - loss: 0.0304 - acc: 0.9829 - val_loss: 1.8834 - val_acc: 0.5983

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0489 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0348 - acc: 0.9875
 576/1283 [============>.................] - ETA: 0s - loss: 0.0326 - acc: 0.9878
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0309 - acc: 0.9868
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0329 - acc: 0.9854
1280/1283 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9844
1283/1283 [==============================] - 0s 265us/step - loss: 0.0325 - acc: 0.9844 - val_loss: 1.8683 - val_acc: 0.5939

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=T
PCA audio=10
PCA visual=30
PCA text=130
accuracy=0.6239067055393586
best_valid_accuracy=0.597667638483965
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 00:11:37.202576: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 12s - loss: 0.7296 - acc: 0.5625
 128/1283 [=>............................] - ETA: 6s - loss: 0.7469 - acc: 0.6172 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.8060 - acc: 0.5573
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7793 - acc: 0.5703
 320/1283 [======>.......................] - ETA: 2s - loss: 0.8094 - acc: 0.5437
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7980 - acc: 0.5391
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7899 - acc: 0.5201
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7848 - acc: 0.5215
 576/1283 [============>.................] - ETA: 1s - loss: 0.7794 - acc: 0.5191
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7699 - acc: 0.5227
 768/1283 [================>.............] - ETA: 0s - loss: 0.7670 - acc: 0.5208
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7624 - acc: 0.5252
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7583 - acc: 0.5234
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7583 - acc: 0.5271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7548 - acc: 0.5283
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7552 - acc: 0.5248
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7502 - acc: 0.5286
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7488 - acc: 0.5271
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7457 - acc: 0.5261 - val_loss: 0.7053 - val_acc: 0.5328

Epoch 00001: val_acc improved from -inf to 0.53275, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6083 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5831 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6026 - acc: 0.7156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6109 - acc: 0.6830
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6068 - acc: 0.6895
 640/1283 [=============>................] - ETA: 0s - loss: 0.6007 - acc: 0.7016
 768/1283 [================>.............] - ETA: 0s - loss: 0.5952 - acc: 0.7057
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5889 - acc: 0.7098
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5898 - acc: 0.7061
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5870 - acc: 0.7066
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5841 - acc: 0.7113
1280/1283 [============================>.] - ETA: 0s - loss: 0.5837 - acc: 0.7148
1283/1283 [==============================] - 1s 727us/step - loss: 0.5838 - acc: 0.7147 - val_loss: 0.7736 - val_acc: 0.5721

Epoch 00002: val_acc improved from 0.53275 to 0.57205, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5242 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.5006 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5149 - acc: 0.7760
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4976 - acc: 0.8008
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4828 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4867 - acc: 0.7773
 640/1283 [=============>................] - ETA: 0s - loss: 0.4794 - acc: 0.7844
 768/1283 [================>.............] - ETA: 0s - loss: 0.4824 - acc: 0.7839
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4780 - acc: 0.7857
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4782 - acc: 0.7865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4723 - acc: 0.7914
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4734 - acc: 0.7862
1283/1283 [==============================] - 1s 720us/step - loss: 0.4715 - acc: 0.7872 - val_loss: 0.8204 - val_acc: 0.5939

Epoch 00003: val_acc improved from 0.57205 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3301 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.3474 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3532 - acc: 0.8802
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3423 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3301 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3442 - acc: 0.8728
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3456 - acc: 0.8711
 576/1283 [============>.................] - ETA: 0s - loss: 0.3442 - acc: 0.8698
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3414 - acc: 0.8707
 768/1283 [================>.............] - ETA: 0s - loss: 0.3407 - acc: 0.8698
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3312 - acc: 0.8761
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3288 - acc: 0.8771
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3246 - acc: 0.8796
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3201 - acc: 0.8819
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3204 - acc: 0.8808
1283/1283 [==============================] - 1s 880us/step - loss: 0.3247 - acc: 0.8784 - val_loss: 0.7751 - val_acc: 0.5983

Epoch 00004: val_acc improved from 0.59389 to 0.59825, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2345 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.2290 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2441 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2399 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2538 - acc: 0.8862
 576/1283 [============>.................] - ETA: 0s - loss: 0.2448 - acc: 0.9028
 640/1283 [=============>................] - ETA: 0s - loss: 0.2389 - acc: 0.9031
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2340 - acc: 0.9048
 768/1283 [================>.............] - ETA: 0s - loss: 0.2396 - acc: 0.8997
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2423 - acc: 0.8966
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2378 - acc: 0.8996
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2306 - acc: 0.9043
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2289 - acc: 0.9053
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2333 - acc: 0.9021
1280/1283 [============================>.] - ETA: 0s - loss: 0.2328 - acc: 0.9023
1283/1283 [==============================] - 1s 882us/step - loss: 0.2323 - acc: 0.9026 - val_loss: 0.8663 - val_acc: 0.6157

Epoch 00005: val_acc improved from 0.59825 to 0.61572, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1508 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1523 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1705 - acc: 0.9297
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1556 - acc: 0.9401
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1654 - acc: 0.9355
 576/1283 [============>.................] - ETA: 0s - loss: 0.1581 - acc: 0.9427
 640/1283 [=============>................] - ETA: 0s - loss: 0.1541 - acc: 0.9453
 768/1283 [================>.............] - ETA: 0s - loss: 0.1458 - acc: 0.9505
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1455 - acc: 0.9475
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1468 - acc: 0.9463
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1442 - acc: 0.9462
1280/1283 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9437
1283/1283 [==============================] - 1s 697us/step - loss: 0.1460 - acc: 0.9439 - val_loss: 0.9601 - val_acc: 0.6201

Epoch 00006: val_acc improved from 0.61572 to 0.62009, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1106 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1076 - acc: 0.9766
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1111 - acc: 0.9648
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1085 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1074 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1093 - acc: 0.9609
 576/1283 [============>.................] - ETA: 0s - loss: 0.1125 - acc: 0.9566
 640/1283 [=============>................] - ETA: 0s - loss: 0.1106 - acc: 0.9563
 768/1283 [================>.............] - ETA: 0s - loss: 0.1034 - acc: 0.9609
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0985 - acc: 0.9654
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0973 - acc: 0.9677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0994 - acc: 0.9668
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1007 - acc: 0.9651
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0986 - acc: 0.9671
1283/1283 [==============================] - 1s 760us/step - loss: 0.0989 - acc: 0.9673 - val_loss: 1.1709 - val_acc: 0.6332

Epoch 00007: val_acc improved from 0.62009 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0703 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0895 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0860 - acc: 0.9648
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0884 - acc: 0.9635
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0850 - acc: 0.9648
 640/1283 [=============>................] - ETA: 0s - loss: 0.0831 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0798 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0854 - acc: 0.9675
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0820 - acc: 0.9698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0791 - acc: 0.9706
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0792 - acc: 0.9712
1283/1283 [==============================] - 1s 746us/step - loss: 0.0820 - acc: 0.9688 - val_loss: 1.3467 - val_acc: 0.5852

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0259 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0566 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0646 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0648 - acc: 0.9888
 576/1283 [============>.................] - ETA: 0s - loss: 0.0677 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0713 - acc: 0.9801
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0751 - acc: 0.9784
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0764 - acc: 0.9771
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0753 - acc: 0.9761
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0738 - acc: 0.9770
1283/1283 [==============================] - 1s 705us/step - loss: 0.0729 - acc: 0.9766 - val_loss: 1.3627 - val_acc: 0.6026

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0561 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0476 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0414 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0412 - acc: 0.9870
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0534 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0520 - acc: 0.9826
 640/1283 [=============>................] - ETA: 0s - loss: 0.0503 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0510 - acc: 0.9858
 768/1283 [================>.............] - ETA: 0s - loss: 0.0531 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0543 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0537 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0539 - acc: 0.9854
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0544 - acc: 0.9852
1280/1283 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9852
1283/1283 [==============================] - 1s 925us/step - loss: 0.0524 - acc: 0.9852 - val_loss: 1.4422 - val_acc: 0.6201

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0280 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0227 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0242 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0271 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0311 - acc: 0.9902
 576/1283 [============>.................] - ETA: 0s - loss: 0.0294 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0305 - acc: 0.9915
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0304 - acc: 0.9916
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0341 - acc: 0.9896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0355 - acc: 0.9890
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0402 - acc: 0.9877
1283/1283 [==============================] - 1s 790us/step - loss: 0.0447 - acc: 0.9844 - val_loss: 1.4592 - val_acc: 0.6288

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0305 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0406 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0542 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0639 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0581 - acc: 0.9785
 640/1283 [=============>................] - ETA: 0s - loss: 0.0580 - acc: 0.9797
 768/1283 [================>.............] - ETA: 0s - loss: 0.0545 - acc: 0.9792
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0535 - acc: 0.9796
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0497 - acc: 0.9823
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0473 - acc: 0.9835
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0442 - acc: 0.9844
1283/1283 [==============================] - 1s 692us/step - loss: 0.0427 - acc: 0.9852 - val_loss: 1.5383 - val_acc: 0.6026

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0513 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0558 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0425 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0429 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0419 - acc: 0.9805
 576/1283 [============>.................] - ETA: 0s - loss: 0.0407 - acc: 0.9809
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0367 - acc: 0.9830
 768/1283 [================>.............] - ETA: 0s - loss: 0.0368 - acc: 0.9831
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0364 - acc: 0.9844
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0351 - acc: 0.9854
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0343 - acc: 0.9862
1280/1283 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9844
1283/1283 [==============================] - 1s 696us/step - loss: 0.0392 - acc: 0.9844 - val_loss: 1.6155 - val_acc: 0.6245

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0360 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0265 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0254 - acc: 0.9883
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0257 - acc: 0.9870
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0371 - acc: 0.9824
 640/1283 [=============>................] - ETA: 0s - loss: 0.0353 - acc: 0.9812
 768/1283 [================>.............] - ETA: 0s - loss: 0.0324 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0318 - acc: 0.9855
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0296 - acc: 0.9873
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0322 - acc: 0.9862
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0337 - acc: 0.9860
1280/1283 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9844
1283/1283 [==============================] - 1s 735us/step - loss: 0.0364 - acc: 0.9844 - val_loss: 1.6463 - val_acc: 0.6201

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0711 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0442 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0346 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0353 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0357 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0317 - acc: 0.9858
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0295 - acc: 0.9856
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0323 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0321 - acc: 0.9853
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0311 - acc: 0.9860
1283/1283 [==============================] - 1s 615us/step - loss: 0.0343 - acc: 0.9852 - val_loss: 1.7508 - val_acc: 0.6114

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0239 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0285 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0239 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0251 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0250 - acc: 0.9915
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0256 - acc: 0.9892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0278 - acc: 0.9875
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0292 - acc: 0.9871
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0310 - acc: 0.9860
1283/1283 [==============================] - 1s 569us/step - loss: 0.0348 - acc: 0.9836 - val_loss: 1.7620 - val_acc: 0.6245

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0195 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0163 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0187 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0235 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0253 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0245 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0223 - acc: 0.9868
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0253 - acc: 0.9875
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0275 - acc: 0.9862
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0298 - acc: 0.9827
1280/1283 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9828
1283/1283 [==============================] - 1s 639us/step - loss: 0.0312 - acc: 0.9829 - val_loss: 1.7876 - val_acc: 0.6201

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=T
PCA audio=10
PCA visual=30
PCA text=140
accuracy=0.5932944606413995
best_valid_accuracy=0.6049562682215743
