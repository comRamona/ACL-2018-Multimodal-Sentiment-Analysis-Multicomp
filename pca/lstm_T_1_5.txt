/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 20:51:39.769389: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 27s - loss: 0.6944 - acc: 0.4844
 256/1283 [====>.........................] - ETA: 6s - loss: 0.6856 - acc: 0.5234 
 384/1283 [=======>......................] - ETA: 3s - loss: 0.6860 - acc: 0.5286
 512/1283 [==========>...................] - ETA: 2s - loss: 0.6897 - acc: 0.5215
 640/1283 [=============>................] - ETA: 1s - loss: 0.6877 - acc: 0.5188
 768/1283 [================>.............] - ETA: 1s - loss: 0.6841 - acc: 0.5247
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6813 - acc: 0.5357
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6815 - acc: 0.5312
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6800 - acc: 0.5340
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6807 - acc: 0.5387
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6804 - acc: 0.5386 - val_loss: 0.6574 - val_acc: 0.6376

Epoch 00001: val_acc improved from -inf to 0.63755, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6369 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6471 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6397 - acc: 0.6594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6404 - acc: 0.6518
 576/1283 [============>.................] - ETA: 0s - loss: 0.6395 - acc: 0.6580
 640/1283 [=============>................] - ETA: 0s - loss: 0.6401 - acc: 0.6578
 768/1283 [================>.............] - ETA: 0s - loss: 0.6378 - acc: 0.6549
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6378 - acc: 0.6562
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6354 - acc: 0.6615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6345 - acc: 0.6641
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6342 - acc: 0.6627
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6321 - acc: 0.6658
1280/1283 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.6555
1283/1283 [==============================] - 1s 830us/step - loss: 0.6335 - acc: 0.6563 - val_loss: 0.6196 - val_acc: 0.7031

Epoch 00002: val_acc improved from 0.63755 to 0.70306, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5851 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5788 - acc: 0.7760
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5871 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5888 - acc: 0.7531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5882 - acc: 0.7455
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5874 - acc: 0.7422
 640/1283 [=============>................] - ETA: 0s - loss: 0.5831 - acc: 0.7344
 768/1283 [================>.............] - ETA: 0s - loss: 0.5807 - acc: 0.7344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5829 - acc: 0.7248
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5798 - acc: 0.7271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5741 - acc: 0.7316
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5753 - acc: 0.7262
1283/1283 [==============================] - 1s 873us/step - loss: 0.5762 - acc: 0.7249 - val_loss: 0.5745 - val_acc: 0.7293

Epoch 00003: val_acc improved from 0.70306 to 0.72926, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5436 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5524 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5443 - acc: 0.7000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5331 - acc: 0.7161
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5368 - acc: 0.7210
 576/1283 [============>.................] - ETA: 0s - loss: 0.5295 - acc: 0.7326
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5301 - acc: 0.7386
 768/1283 [================>.............] - ETA: 0s - loss: 0.5257 - acc: 0.7435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5202 - acc: 0.7489
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5223 - acc: 0.7451
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5190 - acc: 0.7500
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5180 - acc: 0.7516
1283/1283 [==============================] - 1s 816us/step - loss: 0.5159 - acc: 0.7514 - val_loss: 0.5391 - val_acc: 0.7380

Epoch 00004: val_acc improved from 0.72926 to 0.73799, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5453 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4892 - acc: 0.7552
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4517 - acc: 0.7875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4610 - acc: 0.7857
 576/1283 [============>.................] - ETA: 0s - loss: 0.4863 - acc: 0.7708
 640/1283 [=============>................] - ETA: 0s - loss: 0.4804 - acc: 0.7688
 768/1283 [================>.............] - ETA: 0s - loss: 0.4889 - acc: 0.7669
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4894 - acc: 0.7656
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4869 - acc: 0.7623
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4719 - acc: 0.7783
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4704 - acc: 0.7794
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4726 - acc: 0.7812
1283/1283 [==============================] - 1s 734us/step - loss: 0.4739 - acc: 0.7779 - val_loss: 0.5323 - val_acc: 0.7249

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3965 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4315 - acc: 0.7917
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4224 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4213 - acc: 0.8058
 576/1283 [============>.................] - ETA: 0s - loss: 0.4258 - acc: 0.8003
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4161 - acc: 0.8040
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4201 - acc: 0.8029
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4208 - acc: 0.8031
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4254 - acc: 0.8015
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4250 - acc: 0.8018
1283/1283 [==============================] - 1s 657us/step - loss: 0.4213 - acc: 0.8051 - val_loss: 0.5432 - val_acc: 0.7293

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4150 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4110 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4138 - acc: 0.8313
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3961 - acc: 0.8371
 576/1283 [============>.................] - ETA: 0s - loss: 0.3980 - acc: 0.8403
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3906 - acc: 0.8438
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3869 - acc: 0.8377
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3873 - acc: 0.8365
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3854 - acc: 0.8364
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3883 - acc: 0.8363
1283/1283 [==============================] - 1s 609us/step - loss: 0.3857 - acc: 0.8394 - val_loss: 0.5548 - val_acc: 0.7424

Epoch 00007: val_acc improved from 0.73799 to 0.74236, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3776 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3592 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3582 - acc: 0.8469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3467 - acc: 0.8549
 576/1283 [============>.................] - ETA: 0s - loss: 0.3599 - acc: 0.8438
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3570 - acc: 0.8509
 768/1283 [================>.............] - ETA: 0s - loss: 0.3565 - acc: 0.8516
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3524 - acc: 0.8549
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3618 - acc: 0.8506
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3626 - acc: 0.8502
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3579 - acc: 0.8503
1280/1283 [============================>.] - ETA: 0s - loss: 0.3522 - acc: 0.8539
1283/1283 [==============================] - 1s 783us/step - loss: 0.3517 - acc: 0.8542 - val_loss: 0.5855 - val_acc: 0.7162

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2588 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2570 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2717 - acc: 0.9000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2744 - acc: 0.9010
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2898 - acc: 0.8887
 576/1283 [============>.................] - ETA: 0s - loss: 0.2862 - acc: 0.8889
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2915 - acc: 0.8920
 768/1283 [================>.............] - ETA: 0s - loss: 0.2822 - acc: 0.8971
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2807 - acc: 0.8966
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2836 - acc: 0.8927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2911 - acc: 0.8896
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2909 - acc: 0.8872
1280/1283 [============================>.] - ETA: 0s - loss: 0.2861 - acc: 0.8883
1283/1283 [==============================] - 1s 855us/step - loss: 0.2870 - acc: 0.8878 - val_loss: 0.6253 - val_acc: 0.6943

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3061 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2839 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2758 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2768 - acc: 0.9000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2869 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2900 - acc: 0.8884
 576/1283 [============>.................] - ETA: 0s - loss: 0.2919 - acc: 0.8802
 640/1283 [=============>................] - ETA: 0s - loss: 0.2938 - acc: 0.8781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2901 - acc: 0.8793
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2893 - acc: 0.8810
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2829 - acc: 0.8812
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2792 - acc: 0.8857
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2722 - acc: 0.8906
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2685 - acc: 0.8923
1283/1283 [==============================] - 1s 841us/step - loss: 0.2701 - acc: 0.8924 - val_loss: 0.6395 - val_acc: 0.7205

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2153 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2329 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2278 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2196 - acc: 0.9330
 576/1283 [============>.................] - ETA: 0s - loss: 0.2334 - acc: 0.9184
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2403 - acc: 0.9148
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2451 - acc: 0.9099
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2475 - acc: 0.9104
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2470 - acc: 0.9111
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2539 - acc: 0.9080
1280/1283 [============================>.] - ETA: 0s - loss: 0.2563 - acc: 0.9078
1283/1283 [==============================] - 1s 771us/step - loss: 0.2566 - acc: 0.9072 - val_loss: 0.6564 - val_acc: 0.6769

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2396 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2412 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2281 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2393 - acc: 0.9330
 576/1283 [============>.................] - ETA: 0s - loss: 0.2430 - acc: 0.9219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2491 - acc: 0.9148
 768/1283 [================>.............] - ETA: 0s - loss: 0.2431 - acc: 0.9206
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2410 - acc: 0.9196
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2385 - acc: 0.9219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2398 - acc: 0.9175
1280/1283 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.9203
1283/1283 [==============================] - 1s 804us/step - loss: 0.2356 - acc: 0.9205 - val_loss: 0.6963 - val_acc: 0.6900

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1556 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1779 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2184 - acc: 0.9313
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1981 - acc: 0.9375
 576/1283 [============>.................] - ETA: 0s - loss: 0.1967 - acc: 0.9358
 640/1283 [=============>................] - ETA: 0s - loss: 0.2045 - acc: 0.9328
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1976 - acc: 0.9347
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1990 - acc: 0.9339
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1966 - acc: 0.9342
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1933 - acc: 0.9344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1961 - acc: 0.9326
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1898 - acc: 0.9332
1280/1283 [============================>.] - ETA: 0s - loss: 0.1850 - acc: 0.9336
1283/1283 [==============================] - 1s 846us/step - loss: 0.1847 - acc: 0.9337 - val_loss: 0.7229 - val_acc: 0.6725

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2477 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1520 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1656 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1643 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1612 - acc: 0.9509
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1632 - acc: 0.9453
 576/1283 [============>.................] - ETA: 0s - loss: 0.1633 - acc: 0.9427
 640/1283 [=============>................] - ETA: 0s - loss: 0.1574 - acc: 0.9469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1553 - acc: 0.9503
 768/1283 [================>.............] - ETA: 0s - loss: 0.1542 - acc: 0.9505
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1577 - acc: 0.9509
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1579 - acc: 0.9500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1521 - acc: 0.9531
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1539 - acc: 0.9523
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1546 - acc: 0.9523
1280/1283 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9516
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1568 - acc: 0.9509 - val_loss: 0.7794 - val_acc: 0.6681

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0922 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1395 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1397 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1252 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1293 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1271 - acc: 0.9576
 576/1283 [============>.................] - ETA: 0s - loss: 0.1245 - acc: 0.9618
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1315 - acc: 0.9588
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1370 - acc: 0.9543
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1401 - acc: 0.9500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1354 - acc: 0.9522
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1443 - acc: 0.9474
1283/1283 [==============================] - 1s 876us/step - loss: 0.1444 - acc: 0.9478 - val_loss: 0.8254 - val_acc: 0.6725

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1324 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1227 - acc: 0.9609
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1290 - acc: 0.9570
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1211 - acc: 0.9583
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1208 - acc: 0.9590
 640/1283 [=============>................] - ETA: 0s - loss: 0.1182 - acc: 0.9609
 768/1283 [================>.............] - ETA: 0s - loss: 0.1212 - acc: 0.9596
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1193 - acc: 0.9587
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1214 - acc: 0.9590
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1192 - acc: 0.9596
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1177 - acc: 0.9609
1280/1283 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9609
1283/1283 [==============================] - 1s 828us/step - loss: 0.1185 - acc: 0.9610 - val_loss: 0.8674 - val_acc: 0.6856

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1086 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0918 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0892 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0852 - acc: 0.9818
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0987 - acc: 0.9707
 640/1283 [=============>................] - ETA: 0s - loss: 0.0964 - acc: 0.9750
 768/1283 [================>.............] - ETA: 0s - loss: 0.0949 - acc: 0.9740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0933 - acc: 0.9743
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0920 - acc: 0.9736
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0989 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9695
1283/1283 [==============================] - 1s 767us/step - loss: 0.0989 - acc: 0.9696 - val_loss: 0.9140 - val_acc: 0.6856

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=70
accuracy=0.6749271137026239
best_valid_accuracy=0.673469387755102
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:19:51.114773: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 32s - loss: 0.6792 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 10s - loss: 0.6897 - acc: 0.5521
 320/1283 [======>.......................] - ETA: 5s - loss: 0.6894 - acc: 0.5312 
 384/1283 [=======>......................] - ETA: 4s - loss: 0.6924 - acc: 0.5208
 512/1283 [==========>...................] - ETA: 3s - loss: 0.6898 - acc: 0.5332
 640/1283 [=============>................] - ETA: 2s - loss: 0.6868 - acc: 0.5422
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6857 - acc: 0.5497
 768/1283 [================>.............] - ETA: 1s - loss: 0.6859 - acc: 0.5573
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6857 - acc: 0.5589
 896/1283 [===================>..........] - ETA: 1s - loss: 0.6849 - acc: 0.5614
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6844 - acc: 0.5625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6838 - acc: 0.5664
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6805 - acc: 0.5790
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6797 - acc: 0.5831
1280/1283 [============================>.] - ETA: 0s - loss: 0.6791 - acc: 0.5859
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6792 - acc: 0.5853 - val_loss: 0.6596 - val_acc: 0.6288

Epoch 00001: val_acc improved from -inf to 0.62882, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6380 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6348 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6318 - acc: 0.6906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6303 - acc: 0.6942
 576/1283 [============>.................] - ETA: 0s - loss: 0.6274 - acc: 0.6910
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6294 - acc: 0.6790
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6312 - acc: 0.6707
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6279 - acc: 0.6719
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6224 - acc: 0.6847
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6229 - acc: 0.6875
1283/1283 [==============================] - 1s 597us/step - loss: 0.6239 - acc: 0.6859 - val_loss: 0.6142 - val_acc: 0.6987

Epoch 00002: val_acc improved from 0.62882 to 0.69869, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5658 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5886 - acc: 0.7266
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5805 - acc: 0.7344
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5817 - acc: 0.7344
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5809 - acc: 0.7216
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5745 - acc: 0.7260
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5705 - acc: 0.7333
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5689 - acc: 0.7335
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5667 - acc: 0.7378
1280/1283 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7414
1283/1283 [==============================] - 1s 558us/step - loss: 0.5654 - acc: 0.7412 - val_loss: 0.5727 - val_acc: 0.7336

Epoch 00003: val_acc improved from 0.69869 to 0.73362, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5464 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5233 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5299 - acc: 0.7500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5306 - acc: 0.7589
 576/1283 [============>.................] - ETA: 0s - loss: 0.5296 - acc: 0.7569
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5190 - acc: 0.7585
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5124 - acc: 0.7680
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5143 - acc: 0.7698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5139 - acc: 0.7702
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5135 - acc: 0.7673
1283/1283 [==============================] - 1s 597us/step - loss: 0.5101 - acc: 0.7708 - val_loss: 0.5357 - val_acc: 0.7555

Epoch 00004: val_acc improved from 0.73362 to 0.75546, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4689 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4461 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4473 - acc: 0.8125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4605 - acc: 0.8036
 576/1283 [============>.................] - ETA: 0s - loss: 0.4422 - acc: 0.8212
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4399 - acc: 0.8125
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4464 - acc: 0.8017
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4474 - acc: 0.7969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4499 - acc: 0.7996
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4446 - acc: 0.8010
1283/1283 [==============================] - 1s 546us/step - loss: 0.4472 - acc: 0.7989 - val_loss: 0.5340 - val_acc: 0.7162

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4089 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4207 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3867 - acc: 0.8562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3769 - acc: 0.8616
 576/1283 [============>.................] - ETA: 0s - loss: 0.3875 - acc: 0.8420
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4030 - acc: 0.8324
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4077 - acc: 0.8257
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4047 - acc: 0.8271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4025 - acc: 0.8263
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4024 - acc: 0.8281
1283/1283 [==============================] - 1s 565us/step - loss: 0.4063 - acc: 0.8246 - val_loss: 0.5283 - val_acc: 0.7380

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3268 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3487 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3298 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3448 - acc: 0.8705
 576/1283 [============>.................] - ETA: 0s - loss: 0.3647 - acc: 0.8646
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3657 - acc: 0.8523
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3640 - acc: 0.8498
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3604 - acc: 0.8542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3575 - acc: 0.8566
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3587 - acc: 0.8553
1283/1283 [==============================] - 1s 546us/step - loss: 0.3553 - acc: 0.8581 - val_loss: 0.5425 - val_acc: 0.7336

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4599 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3684 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3512 - acc: 0.8719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3476 - acc: 0.8750
 576/1283 [============>.................] - ETA: 0s - loss: 0.3527 - acc: 0.8681
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3444 - acc: 0.8693
 768/1283 [================>.............] - ETA: 0s - loss: 0.3384 - acc: 0.8698
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3366 - acc: 0.8694
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3293 - acc: 0.8750
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3240 - acc: 0.8767
1280/1283 [============================>.] - ETA: 0s - loss: 0.3234 - acc: 0.8742
1283/1283 [==============================] - 1s 677us/step - loss: 0.3236 - acc: 0.8737 - val_loss: 0.5537 - val_acc: 0.7293

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2825 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2903 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2677 - acc: 0.8938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2671 - acc: 0.8951
 576/1283 [============>.................] - ETA: 0s - loss: 0.2709 - acc: 0.8941
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2570 - acc: 0.9006
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2623 - acc: 0.8942
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2647 - acc: 0.8948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2668 - acc: 0.8961
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2720 - acc: 0.8931
1283/1283 [==============================] - 1s 621us/step - loss: 0.2687 - acc: 0.8948 - val_loss: 0.6026 - val_acc: 0.7162

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1997 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2481 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2385 - acc: 0.9031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2347 - acc: 0.9107
 576/1283 [============>.................] - ETA: 0s - loss: 0.2326 - acc: 0.9062
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2215 - acc: 0.9119
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2305 - acc: 0.9087
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2306 - acc: 0.9062
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2273 - acc: 0.9072
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2247 - acc: 0.9106
1280/1283 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9102
1283/1283 [==============================] - 1s 723us/step - loss: 0.2255 - acc: 0.9104 - val_loss: 0.6278 - val_acc: 0.7118

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1881 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1852 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1764 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1708 - acc: 0.9464
 576/1283 [============>.................] - ETA: 0s - loss: 0.1642 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1667 - acc: 0.9446
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1697 - acc: 0.9387
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1700 - acc: 0.9396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1739 - acc: 0.9403
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1754 - acc: 0.9383
1283/1283 [==============================] - 1s 585us/step - loss: 0.1755 - acc: 0.9392 - val_loss: 0.6668 - val_acc: 0.7074

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1371 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1472 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1466 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1424 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1587 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1590 - acc: 0.9420
 576/1283 [============>.................] - ETA: 0s - loss: 0.1644 - acc: 0.9427
 640/1283 [=============>................] - ETA: 0s - loss: 0.1637 - acc: 0.9437
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1576 - acc: 0.9474
 768/1283 [================>.............] - ETA: 0s - loss: 0.1534 - acc: 0.9492
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1511 - acc: 0.9487
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1554 - acc: 0.9443
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1537 - acc: 0.9458
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1531 - acc: 0.9465
1283/1283 [==============================] - 1s 885us/step - loss: 0.1544 - acc: 0.9462 - val_loss: 0.6965 - val_acc: 0.7118

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0703 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1007 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1158 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1133 - acc: 0.9635
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1087 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.1112 - acc: 0.9672
 768/1283 [================>.............] - ETA: 0s - loss: 0.1091 - acc: 0.9674
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1084 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1108 - acc: 0.9688
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1101 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9688
1283/1283 [==============================] - 1s 777us/step - loss: 0.1111 - acc: 0.9688 - val_loss: 0.7211 - val_acc: 0.7293

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0859 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1636 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1428 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1196 - acc: 0.9570
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1114 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1138 - acc: 0.9621
 576/1283 [============>.................] - ETA: 0s - loss: 0.1104 - acc: 0.9635
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1056 - acc: 0.9659
 768/1283 [================>.............] - ETA: 0s - loss: 0.1031 - acc: 0.9688
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1038 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0995 - acc: 0.9717
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0980 - acc: 0.9714
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0965 - acc: 0.9720
1283/1283 [==============================] - 1s 871us/step - loss: 0.0943 - acc: 0.9735 - val_loss: 0.7495 - val_acc: 0.7205

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=80
accuracy=0.6997084548104956
best_valid_accuracy=0.6778425655976676
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:29:31.079453: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 24s - loss: 0.7110 - acc: 0.4688
 192/1283 [===>..........................] - ETA: 7s - loss: 0.6944 - acc: 0.5312 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.6879 - acc: 0.5437
 448/1283 [=========>....................] - ETA: 2s - loss: 0.6879 - acc: 0.5558
 576/1283 [============>.................] - ETA: 1s - loss: 0.6888 - acc: 0.5573
 640/1283 [=============>................] - ETA: 1s - loss: 0.6892 - acc: 0.5516
 768/1283 [================>.............] - ETA: 1s - loss: 0.6877 - acc: 0.5534
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6870 - acc: 0.5525
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6880 - acc: 0.5527
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6877 - acc: 0.5547
1280/1283 [============================>.] - ETA: 0s - loss: 0.6865 - acc: 0.5516
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6866 - acc: 0.5511 - val_loss: 0.6627 - val_acc: 0.6376

Epoch 00001: val_acc improved from -inf to 0.63755, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6584 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6541 - acc: 0.6146
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6495 - acc: 0.6531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6512 - acc: 0.6432
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6491 - acc: 0.6406
 576/1283 [============>.................] - ETA: 0s - loss: 0.6508 - acc: 0.6354
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6463 - acc: 0.6378
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6422 - acc: 0.6454
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6417 - acc: 0.6479
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6431 - acc: 0.6388
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6419 - acc: 0.6406
1280/1283 [============================>.] - ETA: 0s - loss: 0.6388 - acc: 0.6461
1283/1283 [==============================] - 1s 680us/step - loss: 0.6385 - acc: 0.6469 - val_loss: 0.6358 - val_acc: 0.6681

Epoch 00002: val_acc improved from 0.63755 to 0.66812, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6606 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6260 - acc: 0.6667
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6056 - acc: 0.7125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6090 - acc: 0.7009
 576/1283 [============>.................] - ETA: 0s - loss: 0.6098 - acc: 0.7135
 640/1283 [=============>................] - ETA: 0s - loss: 0.6072 - acc: 0.7141
 768/1283 [================>.............] - ETA: 0s - loss: 0.6028 - acc: 0.7161
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5985 - acc: 0.7154
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5973 - acc: 0.7177
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5931 - acc: 0.7233
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5945 - acc: 0.7188
1283/1283 [==============================] - 1s 705us/step - loss: 0.5931 - acc: 0.7163 - val_loss: 0.5977 - val_acc: 0.7162

Epoch 00003: val_acc improved from 0.66812 to 0.71616, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5765 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5406 - acc: 0.7552
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5420 - acc: 0.7406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5590 - acc: 0.7344
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5559 - acc: 0.7324
 640/1283 [=============>................] - ETA: 0s - loss: 0.5551 - acc: 0.7297
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5528 - acc: 0.7344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5506 - acc: 0.7380
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5476 - acc: 0.7438
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5373 - acc: 0.7583
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5352 - acc: 0.7558
1283/1283 [==============================] - 1s 677us/step - loss: 0.5326 - acc: 0.7568 - val_loss: 0.5715 - val_acc: 0.6856

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5802 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4957 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4966 - acc: 0.7750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4899 - acc: 0.7835
 576/1283 [============>.................] - ETA: 0s - loss: 0.4888 - acc: 0.7865
 640/1283 [=============>................] - ETA: 0s - loss: 0.4976 - acc: 0.7781
 768/1283 [================>.............] - ETA: 0s - loss: 0.4910 - acc: 0.7852
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4956 - acc: 0.7868
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4860 - acc: 0.7920
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4803 - acc: 0.7969
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4818 - acc: 0.7919
1280/1283 [============================>.] - ETA: 0s - loss: 0.4795 - acc: 0.7937
1283/1283 [==============================] - 1s 786us/step - loss: 0.4796 - acc: 0.7935 - val_loss: 0.5576 - val_acc: 0.6987

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3990 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4501 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4415 - acc: 0.7930
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4232 - acc: 0.8021
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4287 - acc: 0.8058
 576/1283 [============>.................] - ETA: 0s - loss: 0.4202 - acc: 0.8160
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4377 - acc: 0.8097
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4266 - acc: 0.8185
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4241 - acc: 0.8203
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4277 - acc: 0.8177
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4268 - acc: 0.8193
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4234 - acc: 0.8238
1280/1283 [============================>.] - ETA: 0s - loss: 0.4190 - acc: 0.8250
1283/1283 [==============================] - 1s 787us/step - loss: 0.4189 - acc: 0.8246 - val_loss: 0.5582 - val_acc: 0.7118

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4497 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4030 - acc: 0.8177
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3864 - acc: 0.8344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3883 - acc: 0.8371
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3925 - acc: 0.8281
 576/1283 [============>.................] - ETA: 0s - loss: 0.3923 - acc: 0.8264
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3772 - acc: 0.8366
 768/1283 [================>.............] - ETA: 0s - loss: 0.3752 - acc: 0.8385
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3691 - acc: 0.8425
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3675 - acc: 0.8460
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3626 - acc: 0.8490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3610 - acc: 0.8477
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3590 - acc: 0.8493
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3559 - acc: 0.8495
1283/1283 [==============================] - 1s 810us/step - loss: 0.3582 - acc: 0.8496 - val_loss: 0.5748 - val_acc: 0.7074

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3092 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.3554 - acc: 0.8828
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3183 - acc: 0.8945
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3230 - acc: 0.8724
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3074 - acc: 0.8848
 640/1283 [=============>................] - ETA: 0s - loss: 0.3074 - acc: 0.8859
 768/1283 [================>.............] - ETA: 0s - loss: 0.3046 - acc: 0.8880
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3000 - acc: 0.8918
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2990 - acc: 0.8929
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3147 - acc: 0.8828
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3103 - acc: 0.8828
1280/1283 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.8797
1283/1283 [==============================] - 1s 682us/step - loss: 0.3180 - acc: 0.8792 - val_loss: 0.5904 - val_acc: 0.6943

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2769 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3013 - acc: 0.8646
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3045 - acc: 0.8672
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2905 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2899 - acc: 0.8795
 576/1283 [============>.................] - ETA: 0s - loss: 0.2915 - acc: 0.8819
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2904 - acc: 0.8835
 768/1283 [================>.............] - ETA: 0s - loss: 0.2871 - acc: 0.8893
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2880 - acc: 0.8894
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2947 - acc: 0.8823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2872 - acc: 0.8867
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2815 - acc: 0.8872
1280/1283 [============================>.] - ETA: 0s - loss: 0.2752 - acc: 0.8914
1283/1283 [==============================] - 1s 734us/step - loss: 0.2754 - acc: 0.8909 - val_loss: 0.6367 - val_acc: 0.7031

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1935 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1871 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2151 - acc: 0.9344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2183 - acc: 0.9308
 576/1283 [============>.................] - ETA: 0s - loss: 0.2251 - acc: 0.9253
 640/1283 [=============>................] - ETA: 0s - loss: 0.2324 - acc: 0.9219
 768/1283 [================>.............] - ETA: 0s - loss: 0.2306 - acc: 0.9232
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2304 - acc: 0.9208
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2245 - acc: 0.9229
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2235 - acc: 0.9227
1280/1283 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9195
1283/1283 [==============================] - 1s 647us/step - loss: 0.2245 - acc: 0.9197 - val_loss: 0.7104 - val_acc: 0.6943

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1997 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2186 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1998 - acc: 0.9156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1904 - acc: 0.9241
 576/1283 [============>.................] - ETA: 0s - loss: 0.1776 - acc: 0.9306
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1784 - acc: 0.9332
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1769 - acc: 0.9327
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1814 - acc: 0.9313
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1831 - acc: 0.9311
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1848 - acc: 0.9309
1283/1283 [==============================] - 1s 578us/step - loss: 0.1870 - acc: 0.9314 - val_loss: 0.7480 - val_acc: 0.6725

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2075 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1688 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1524 - acc: 0.9406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1524 - acc: 0.9453
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1475 - acc: 0.9453
 640/1283 [=============>................] - ETA: 0s - loss: 0.1435 - acc: 0.9484
 768/1283 [================>.............] - ETA: 0s - loss: 0.1537 - acc: 0.9427
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1464 - acc: 0.9464
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1475 - acc: 0.9482
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1479 - acc: 0.9505
1280/1283 [============================>.] - ETA: 0s - loss: 0.1461 - acc: 0.9508
1283/1283 [==============================] - 1s 688us/step - loss: 0.1477 - acc: 0.9501 - val_loss: 0.7307 - val_acc: 0.6856

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0856 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1179 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1219 - acc: 0.9500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1321 - acc: 0.9442
 576/1283 [============>.................] - ETA: 0s - loss: 0.1398 - acc: 0.9392
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1342 - acc: 0.9460
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1394 - acc: 0.9447
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1398 - acc: 0.9431
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1405 - acc: 0.9434
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1417 - acc: 0.9444
1280/1283 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9461
1283/1283 [==============================] - 1s 683us/step - loss: 0.1441 - acc: 0.9454 - val_loss: 0.7866 - val_acc: 0.6943

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=90
accuracy=0.6720116618075802
best_valid_accuracy=0.6282798833819242
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:42:55.324311: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 29s - loss: 0.6856 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 9s - loss: 0.6949 - acc: 0.5260 
 320/1283 [======>.......................] - ETA: 5s - loss: 0.6970 - acc: 0.5219
 448/1283 [=========>....................] - ETA: 3s - loss: 0.6933 - acc: 0.5402
 576/1283 [============>.................] - ETA: 2s - loss: 0.6934 - acc: 0.5365
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6923 - acc: 0.5341
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6901 - acc: 0.5397
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6883 - acc: 0.5391
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6867 - acc: 0.5459
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6859 - acc: 0.5503
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6859 - acc: 0.5526
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6851 - acc: 0.5511 - val_loss: 0.6520 - val_acc: 0.6812

Epoch 00001: val_acc improved from -inf to 0.68122, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6644 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6390 - acc: 0.6823
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6397 - acc: 0.6813
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6370 - acc: 0.6927
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6301 - acc: 0.7090
 576/1283 [============>.................] - ETA: 0s - loss: 0.6337 - acc: 0.6979
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6294 - acc: 0.6946
 768/1283 [================>.............] - ETA: 0s - loss: 0.6303 - acc: 0.6914
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6345 - acc: 0.6752
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6338 - acc: 0.6738
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6331 - acc: 0.6736
1280/1283 [============================>.] - ETA: 0s - loss: 0.6317 - acc: 0.6703
1283/1283 [==============================] - 1s 677us/step - loss: 0.6317 - acc: 0.6703 - val_loss: 0.6130 - val_acc: 0.7249

Epoch 00002: val_acc improved from 0.68122 to 0.72489, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5873 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5695 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5660 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5689 - acc: 0.7562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5680 - acc: 0.7545
 576/1283 [============>.................] - ETA: 0s - loss: 0.5747 - acc: 0.7257
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5708 - acc: 0.7344
 768/1283 [================>.............] - ETA: 0s - loss: 0.5693 - acc: 0.7344
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5682 - acc: 0.7355
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5653 - acc: 0.7417
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5621 - acc: 0.7399
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5649 - acc: 0.7327
1280/1283 [============================>.] - ETA: 0s - loss: 0.5643 - acc: 0.7344
1283/1283 [==============================] - 1s 945us/step - loss: 0.5644 - acc: 0.7342 - val_loss: 0.5650 - val_acc: 0.7293

Epoch 00003: val_acc improved from 0.72489 to 0.72926, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5201 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5170 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5243 - acc: 0.7688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5228 - acc: 0.7604
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5320 - acc: 0.7461
 576/1283 [============>.................] - ETA: 0s - loss: 0.5280 - acc: 0.7483
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5215 - acc: 0.7528
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5196 - acc: 0.7548
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5078 - acc: 0.7656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5047 - acc: 0.7715
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5008 - acc: 0.7743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4967 - acc: 0.7788
1283/1283 [==============================] - 1s 709us/step - loss: 0.4962 - acc: 0.7763 - val_loss: 0.5269 - val_acc: 0.7511

Epoch 00004: val_acc improved from 0.72926 to 0.75109, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4100 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4068 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4072 - acc: 0.8406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4261 - acc: 0.8281
 576/1283 [============>.................] - ETA: 0s - loss: 0.4233 - acc: 0.8229
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4335 - acc: 0.8168
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4338 - acc: 0.8101
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4366 - acc: 0.8104
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4369 - acc: 0.8070
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4366 - acc: 0.8084
1280/1283 [============================>.] - ETA: 0s - loss: 0.4354 - acc: 0.8078
1283/1283 [==============================] - 1s 702us/step - loss: 0.4358 - acc: 0.8075 - val_loss: 0.5454 - val_acc: 0.7205

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3637 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3965 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3761 - acc: 0.8719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3733 - acc: 0.8698
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3781 - acc: 0.8652
 576/1283 [============>.................] - ETA: 0s - loss: 0.3863 - acc: 0.8594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3879 - acc: 0.8537
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3891 - acc: 0.8474
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3817 - acc: 0.8510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3777 - acc: 0.8520
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3735 - acc: 0.8520
1280/1283 [============================>.] - ETA: 0s - loss: 0.3726 - acc: 0.8516
1283/1283 [==============================] - 1s 767us/step - loss: 0.3735 - acc: 0.8504 - val_loss: 0.5484 - val_acc: 0.7293

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3909 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.3427 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3353 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3385 - acc: 0.8438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3243 - acc: 0.8571
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3152 - acc: 0.8672
 576/1283 [============>.................] - ETA: 0s - loss: 0.3112 - acc: 0.8750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3229 - acc: 0.8764
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3248 - acc: 0.8774
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3218 - acc: 0.8781
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3137 - acc: 0.8842
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3154 - acc: 0.8840
1283/1283 [==============================] - 1s 809us/step - loss: 0.3224 - acc: 0.8792 - val_loss: 0.5831 - val_acc: 0.7031

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3020 - acc: 0.8594
 128/1283 [=>............................] - ETA: 0s - loss: 0.3106 - acc: 0.8828
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2746 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2534 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2463 - acc: 0.9250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2574 - acc: 0.9174
 576/1283 [============>.................] - ETA: 0s - loss: 0.2731 - acc: 0.9045
 640/1283 [=============>................] - ETA: 0s - loss: 0.2696 - acc: 0.9062
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2756 - acc: 0.9048
 768/1283 [================>.............] - ETA: 0s - loss: 0.2754 - acc: 0.9076
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2686 - acc: 0.9096
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2655 - acc: 0.9111
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2601 - acc: 0.9141
1280/1283 [============================>.] - ETA: 0s - loss: 0.2557 - acc: 0.9148
1283/1283 [==============================] - 1s 920us/step - loss: 0.2553 - acc: 0.9150 - val_loss: 0.5908 - val_acc: 0.7380

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2311 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.2101 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1971 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2077 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1991 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2068 - acc: 0.9330
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2027 - acc: 0.9297
 576/1283 [============>.................] - ETA: 0s - loss: 0.2042 - acc: 0.9306
 640/1283 [=============>................] - ETA: 0s - loss: 0.1995 - acc: 0.9344
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1981 - acc: 0.9332
 768/1283 [================>.............] - ETA: 0s - loss: 0.2031 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2129 - acc: 0.9255
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2141 - acc: 0.9263
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2190 - acc: 0.9229
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2164 - acc: 0.9238
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2185 - acc: 0.9219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2147 - acc: 0.9245
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2114 - acc: 0.9252
1280/1283 [============================>.] - ETA: 0s - loss: 0.2091 - acc: 0.9258
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2094 - acc: 0.9252 - val_loss: 0.6674 - val_acc: 0.6856

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1306 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1666 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1696 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1906 - acc: 0.9297
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1902 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1851 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1936 - acc: 0.9353
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1921 - acc: 0.9355
 640/1283 [=============>................] - ETA: 0s - loss: 0.2022 - acc: 0.9297
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1977 - acc: 0.9318
 768/1283 [================>.............] - ETA: 0s - loss: 0.1926 - acc: 0.9349
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1883 - acc: 0.9363
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1903 - acc: 0.9364
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1916 - acc: 0.9354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1922 - acc: 0.9355
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1879 - acc: 0.9366
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1854 - acc: 0.9366
1280/1283 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9359
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1831 - acc: 0.9361 - val_loss: 0.6416 - val_acc: 0.7380

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1310 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1187 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1185 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1221 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1161 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.1183 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.1158 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1180 - acc: 0.9730
 768/1283 [================>.............] - ETA: 0s - loss: 0.1178 - acc: 0.9740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1226 - acc: 0.9665
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1217 - acc: 0.9656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1301 - acc: 0.9619
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1321 - acc: 0.9605
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1300 - acc: 0.9627
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1322 - acc: 0.9613
1280/1283 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9609
1283/1283 [==============================] - 1s 897us/step - loss: 0.1333 - acc: 0.9610 - val_loss: 0.7865 - val_acc: 0.7074

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0850 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1744 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1421 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1310 - acc: 0.9570
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1287 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1217 - acc: 0.9576
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1228 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1206 - acc: 0.9566
 640/1283 [=============>................] - ETA: 0s - loss: 0.1178 - acc: 0.9578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1210 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1185 - acc: 0.9570
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1185 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1158 - acc: 0.9609
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1157 - acc: 0.9625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1137 - acc: 0.9639
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1151 - acc: 0.9632
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1119 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1091 - acc: 0.9655
1280/1283 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9648
1283/1283 [==============================] - 1s 982us/step - loss: 0.1108 - acc: 0.9649 - val_loss: 0.7351 - val_acc: 0.7205

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0667 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0897 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0806 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0875 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0924 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0897 - acc: 0.9661
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0931 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0893 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0870 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0834 - acc: 0.9703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0817 - acc: 0.9716
 768/1283 [================>.............] - ETA: 0s - loss: 0.0795 - acc: 0.9740
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0808 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0784 - acc: 0.9721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0759 - acc: 0.9740
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0773 - acc: 0.9746
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0831 - acc: 0.9724
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0811 - acc: 0.9740
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0808 - acc: 0.9737
1280/1283 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9742
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0805 - acc: 0.9743 - val_loss: 0.8240 - val_acc: 0.7336

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0541 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0711 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0600 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0609 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0552 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0589 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0579 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0597 - acc: 0.9863
 576/1283 [============>.................] - ETA: 0s - loss: 0.0605 - acc: 0.9861
 640/1283 [=============>................] - ETA: 0s - loss: 0.0614 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0636 - acc: 0.9858
 768/1283 [================>.............] - ETA: 0s - loss: 0.0608 - acc: 0.9870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0595 - acc: 0.9880
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0570 - acc: 0.9888
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0572 - acc: 0.9883
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0584 - acc: 0.9871
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0571 - acc: 0.9878
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0561 - acc: 0.9885
1280/1283 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9867
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0590 - acc: 0.9867 - val_loss: 0.8477 - val_acc: 0.7162

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6909620991253644
best_valid_accuracy=0.6763848396501457
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:51:08.920704: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 14s - loss: 0.7197 - acc: 0.4219
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6922 - acc: 0.5273 
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6962 - acc: 0.5104
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6915 - acc: 0.5234
 640/1283 [=============>................] - ETA: 1s - loss: 0.6891 - acc: 0.5312
 768/1283 [================>.............] - ETA: 0s - loss: 0.6882 - acc: 0.5299
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6862 - acc: 0.5357
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6863 - acc: 0.5410
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6846 - acc: 0.5512
1280/1283 [============================>.] - ETA: 0s - loss: 0.6835 - acc: 0.5539
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6836 - acc: 0.5542 - val_loss: 0.6634 - val_acc: 0.6201

Epoch 00001: val_acc improved from -inf to 0.62009, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5963 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6357 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6400 - acc: 0.6500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6400 - acc: 0.6589
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6403 - acc: 0.6641
 640/1283 [=============>................] - ETA: 0s - loss: 0.6379 - acc: 0.6687
 768/1283 [================>.............] - ETA: 0s - loss: 0.6362 - acc: 0.6680
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6337 - acc: 0.6708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6328 - acc: 0.6738
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6310 - acc: 0.6771
1280/1283 [============================>.] - ETA: 0s - loss: 0.6309 - acc: 0.6773
1283/1283 [==============================] - 1s 600us/step - loss: 0.6309 - acc: 0.6773 - val_loss: 0.6296 - val_acc: 0.6769

Epoch 00002: val_acc improved from 0.62009 to 0.67686, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6342 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5948 - acc: 0.7396
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5986 - acc: 0.7250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5913 - acc: 0.7254
 576/1283 [============>.................] - ETA: 0s - loss: 0.5923 - acc: 0.7240
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5894 - acc: 0.7244
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5866 - acc: 0.7332
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5833 - acc: 0.7271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5826 - acc: 0.7266
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5754 - acc: 0.7335
1280/1283 [============================>.] - ETA: 0s - loss: 0.5746 - acc: 0.7344
1283/1283 [==============================] - 1s 638us/step - loss: 0.5749 - acc: 0.7334 - val_loss: 0.5927 - val_acc: 0.7118

Epoch 00003: val_acc improved from 0.67686 to 0.71179, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5805 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5311 - acc: 0.7708
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5263 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5294 - acc: 0.7679
 576/1283 [============>.................] - ETA: 0s - loss: 0.5215 - acc: 0.7708
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5205 - acc: 0.7727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5128 - acc: 0.7788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5156 - acc: 0.7750
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5113 - acc: 0.7803
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5077 - acc: 0.7821
1283/1283 [==============================] - 1s 617us/step - loss: 0.5101 - acc: 0.7794 - val_loss: 0.5558 - val_acc: 0.7249

Epoch 00004: val_acc improved from 0.71179 to 0.72489, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5014 - acc: 0.7656
 128/1283 [=>............................] - ETA: 0s - loss: 0.4755 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4687 - acc: 0.8177
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4687 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4609 - acc: 0.8013
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4656 - acc: 0.7949
 640/1283 [=============>................] - ETA: 0s - loss: 0.4715 - acc: 0.7906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4683 - acc: 0.7955
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4547 - acc: 0.8065
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4483 - acc: 0.8114
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4489 - acc: 0.8125
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4485 - acc: 0.8116
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4478 - acc: 0.8133
1283/1283 [==============================] - 1s 763us/step - loss: 0.4444 - acc: 0.8145 - val_loss: 0.5361 - val_acc: 0.7249

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4160 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4414 - acc: 0.7865
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4175 - acc: 0.8156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4021 - acc: 0.8281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4018 - acc: 0.8304
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4004 - acc: 0.8301
 576/1283 [============>.................] - ETA: 0s - loss: 0.4059 - acc: 0.8281
 640/1283 [=============>................] - ETA: 0s - loss: 0.4057 - acc: 0.8313
 768/1283 [================>.............] - ETA: 0s - loss: 0.4069 - acc: 0.8333
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4024 - acc: 0.8337
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3999 - acc: 0.8359
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3930 - acc: 0.8420
1280/1283 [============================>.] - ETA: 0s - loss: 0.3898 - acc: 0.8398
1283/1283 [==============================] - 1s 693us/step - loss: 0.3899 - acc: 0.8394 - val_loss: 0.5533 - val_acc: 0.6856

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3555 - acc: 0.8906
 128/1283 [=>............................] - ETA: 0s - loss: 0.3613 - acc: 0.8828
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3339 - acc: 0.8867
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3362 - acc: 0.8828
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3313 - acc: 0.8789
 640/1283 [=============>................] - ETA: 0s - loss: 0.3309 - acc: 0.8766
 768/1283 [================>.............] - ETA: 0s - loss: 0.3318 - acc: 0.8802
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3297 - acc: 0.8822
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3267 - acc: 0.8828
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3305 - acc: 0.8799
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3302 - acc: 0.8828
1280/1283 [============================>.] - ETA: 0s - loss: 0.3290 - acc: 0.8805
1283/1283 [==============================] - 1s 698us/step - loss: 0.3288 - acc: 0.8807 - val_loss: 0.5499 - val_acc: 0.7205

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2487 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2430 - acc: 0.9115
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2534 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2541 - acc: 0.9174
 576/1283 [============>.................] - ETA: 0s - loss: 0.2443 - acc: 0.9167
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2440 - acc: 0.9119
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2614 - acc: 0.9026
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2627 - acc: 0.9018
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2600 - acc: 0.9053
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2608 - acc: 0.9054
1280/1283 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.9023
1283/1283 [==============================] - 1s 681us/step - loss: 0.2692 - acc: 0.9018 - val_loss: 0.5749 - val_acc: 0.7162

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1934 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.1969 - acc: 0.9297
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2225 - acc: 0.9336
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2146 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2121 - acc: 0.9349
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2103 - acc: 0.9336
 576/1283 [============>.................] - ETA: 0s - loss: 0.2084 - acc: 0.9340
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2210 - acc: 0.9233
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2170 - acc: 0.9243
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2216 - acc: 0.9196
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2194 - acc: 0.9208
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2222 - acc: 0.9210
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2231 - acc: 0.9201
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2250 - acc: 0.9178
1283/1283 [==============================] - 1s 935us/step - loss: 0.2261 - acc: 0.9166 - val_loss: 0.6267 - val_acc: 0.6987

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1748 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1829 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1780 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1934 - acc: 0.9505
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1966 - acc: 0.9492
 640/1283 [=============>................] - ETA: 0s - loss: 0.1970 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1942 - acc: 0.9460
 768/1283 [================>.............] - ETA: 0s - loss: 0.1963 - acc: 0.9453
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1931 - acc: 0.9447
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1976 - acc: 0.9408
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1956 - acc: 0.9417
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1909 - acc: 0.9434
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1880 - acc: 0.9439
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1895 - acc: 0.9418
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1854 - acc: 0.9424
1280/1283 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9406
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1864 - acc: 0.9408 - val_loss: 0.6683 - val_acc: 0.7118

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0948 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1039 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1193 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1274 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1130 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1094 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1140 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1158 - acc: 0.9707
 576/1283 [============>.................] - ETA: 0s - loss: 0.1241 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.1243 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1256 - acc: 0.9631
 768/1283 [================>.............] - ETA: 0s - loss: 0.1288 - acc: 0.9609
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1287 - acc: 0.9603
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1342 - acc: 0.9576
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1330 - acc: 0.9573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1352 - acc: 0.9580
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1350 - acc: 0.9586
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1321 - acc: 0.9601
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1315 - acc: 0.9613
1280/1283 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9625
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1294 - acc: 0.9626 - val_loss: 0.7237 - val_acc: 0.7074

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0992 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1111 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1240 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1216 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1122 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1090 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1078 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1075 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.1126 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1112 - acc: 0.9645
 768/1283 [================>.............] - ETA: 0s - loss: 0.1094 - acc: 0.9648
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1094 - acc: 0.9651
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1116 - acc: 0.9604
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1131 - acc: 0.9600
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1090 - acc: 0.9623
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1074 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1071 - acc: 0.9646
1280/1283 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9648
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1070 - acc: 0.9649 - val_loss: 0.8267 - val_acc: 0.7118

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0691 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0542 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0638 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0544 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0540 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0562 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0548 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0586 - acc: 0.9913
 640/1283 [=============>................] - ETA: 0s - loss: 0.0572 - acc: 0.9922
 768/1283 [================>.............] - ETA: 0s - loss: 0.0613 - acc: 0.9896
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0606 - acc: 0.9880
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0643 - acc: 0.9866
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0643 - acc: 0.9875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0640 - acc: 0.9873
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0650 - acc: 0.9862
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0664 - acc: 0.9852
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0672 - acc: 0.9852
1280/1283 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9844
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0673 - acc: 0.9844 - val_loss: 0.9544 - val_acc: 0.7031

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0345 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0390 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0425 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0486 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0476 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0531 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0545 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0510 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0510 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0515 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0529 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0529 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0529 - acc: 0.9844
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0517 - acc: 0.9854
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0510 - acc: 0.9854
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0532 - acc: 0.9835
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0526 - acc: 0.9835
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0551 - acc: 0.9819
1280/1283 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9820
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0550 - acc: 0.9821 - val_loss: 1.0085 - val_acc: 0.6987

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=110
accuracy=0.717201166180758
best_valid_accuracy=0.6807580174927114
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:09:00.105112: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 24s - loss: 0.7055 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 7s - loss: 0.6964 - acc: 0.5156 
 256/1283 [====>.........................] - ETA: 5s - loss: 0.6957 - acc: 0.5156
 320/1283 [======>.......................] - ETA: 4s - loss: 0.6956 - acc: 0.4938
 384/1283 [=======>......................] - ETA: 3s - loss: 0.6946 - acc: 0.5052
 448/1283 [=========>....................] - ETA: 3s - loss: 0.6916 - acc: 0.5112
 512/1283 [==========>...................] - ETA: 2s - loss: 0.6920 - acc: 0.5176
 576/1283 [============>.................] - ETA: 2s - loss: 0.6928 - acc: 0.5139
 640/1283 [=============>................] - ETA: 1s - loss: 0.6906 - acc: 0.5250
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6908 - acc: 0.5270
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6910 - acc: 0.5252
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6898 - acc: 0.5312
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6896 - acc: 0.5294
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6903 - acc: 0.5260
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6891 - acc: 0.5271
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6885 - acc: 0.5316 - val_loss: 0.6692 - val_acc: 0.6201

Epoch 00001: val_acc improved from -inf to 0.62009, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6378 - acc: 0.6719
 128/1283 [=>............................] - ETA: 1s - loss: 0.6441 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6453 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6505 - acc: 0.6523
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6502 - acc: 0.6594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6490 - acc: 0.6589
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6491 - acc: 0.6629
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6475 - acc: 0.6641
 576/1283 [============>.................] - ETA: 0s - loss: 0.6485 - acc: 0.6701
 640/1283 [=============>................] - ETA: 0s - loss: 0.6496 - acc: 0.6625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6517 - acc: 0.6534
 768/1283 [================>.............] - ETA: 0s - loss: 0.6504 - acc: 0.6615
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6469 - acc: 0.6659
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6459 - acc: 0.6663
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6440 - acc: 0.6646
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6438 - acc: 0.6621
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6425 - acc: 0.6627
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6419 - acc: 0.6641
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6407 - acc: 0.6645
1280/1283 [============================>.] - ETA: 0s - loss: 0.6405 - acc: 0.6656
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6403 - acc: 0.6664 - val_loss: 0.6387 - val_acc: 0.6638

Epoch 00002: val_acc improved from 0.62009 to 0.66376, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5667 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5941 - acc: 0.7240
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5966 - acc: 0.7148
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5935 - acc: 0.7125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5916 - acc: 0.7135
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5927 - acc: 0.7143
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5933 - acc: 0.7031
 640/1283 [=============>................] - ETA: 0s - loss: 0.5936 - acc: 0.7063
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5901 - acc: 0.7074
 768/1283 [================>.............] - ETA: 0s - loss: 0.5894 - acc: 0.7083
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5894 - acc: 0.7067
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5875 - acc: 0.7098
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5889 - acc: 0.7073
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5861 - acc: 0.7148
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5877 - acc: 0.7123
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5875 - acc: 0.7109
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5889 - acc: 0.7113
1280/1283 [============================>.] - ETA: 0s - loss: 0.5899 - acc: 0.7086
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5899 - acc: 0.7085 - val_loss: 0.6021 - val_acc: 0.7205

Epoch 00003: val_acc improved from 0.66376 to 0.72052, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5794 - acc: 0.7031
 128/1283 [=>............................] - ETA: 0s - loss: 0.5793 - acc: 0.6953
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5727 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5591 - acc: 0.7461
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5577 - acc: 0.7406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5544 - acc: 0.7396
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5448 - acc: 0.7455
 576/1283 [============>.................] - ETA: 0s - loss: 0.5411 - acc: 0.7483
 640/1283 [=============>................] - ETA: 0s - loss: 0.5331 - acc: 0.7578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5290 - acc: 0.7642
 768/1283 [================>.............] - ETA: 0s - loss: 0.5261 - acc: 0.7669
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5275 - acc: 0.7656
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5280 - acc: 0.7679
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5267 - acc: 0.7719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5250 - acc: 0.7734
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5234 - acc: 0.7776
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5255 - acc: 0.7752
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5263 - acc: 0.7730
1280/1283 [============================>.] - ETA: 0s - loss: 0.5215 - acc: 0.7773
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5219 - acc: 0.7771 - val_loss: 0.5642 - val_acc: 0.7031

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4362 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4338 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4525 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4899 - acc: 0.7773
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4891 - acc: 0.7781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4804 - acc: 0.7839
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4718 - acc: 0.7924
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4603 - acc: 0.8027
 576/1283 [============>.................] - ETA: 0s - loss: 0.4706 - acc: 0.7899
 640/1283 [=============>................] - ETA: 0s - loss: 0.4672 - acc: 0.7969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4678 - acc: 0.7940
 768/1283 [================>.............] - ETA: 0s - loss: 0.4698 - acc: 0.7917
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4664 - acc: 0.7969
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4634 - acc: 0.8002
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4637 - acc: 0.8021
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4620 - acc: 0.8027
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4634 - acc: 0.8024
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4609 - acc: 0.8047
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4577 - acc: 0.8067
1280/1283 [============================>.] - ETA: 0s - loss: 0.4558 - acc: 0.8047
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4563 - acc: 0.8044 - val_loss: 0.5494 - val_acc: 0.7336

Epoch 00005: val_acc improved from 0.72052 to 0.73362, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4335 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.3836 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4025 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4241 - acc: 0.8125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4249 - acc: 0.8036
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4098 - acc: 0.8203
 576/1283 [============>.................] - ETA: 0s - loss: 0.3983 - acc: 0.8281
 640/1283 [=============>................] - ETA: 0s - loss: 0.4017 - acc: 0.8266
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3980 - acc: 0.8338
 768/1283 [================>.............] - ETA: 0s - loss: 0.3983 - acc: 0.8398
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3999 - acc: 0.8389
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3961 - acc: 0.8426
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3945 - acc: 0.8406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3926 - acc: 0.8398
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3894 - acc: 0.8410
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3902 - acc: 0.8429
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3868 - acc: 0.8446
1280/1283 [============================>.] - ETA: 0s - loss: 0.3829 - acc: 0.8477
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3824 - acc: 0.8480 - val_loss: 0.5315 - val_acc: 0.7467

Epoch 00006: val_acc improved from 0.73362 to 0.74672, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3267 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.3333 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3127 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3222 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3250 - acc: 0.8875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3391 - acc: 0.8776
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3425 - acc: 0.8772
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3428 - acc: 0.8789
 576/1283 [============>.................] - ETA: 0s - loss: 0.3331 - acc: 0.8802
 640/1283 [=============>................] - ETA: 0s - loss: 0.3305 - acc: 0.8781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3293 - acc: 0.8793
 768/1283 [================>.............] - ETA: 0s - loss: 0.3308 - acc: 0.8724
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3296 - acc: 0.8702
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3234 - acc: 0.8739
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3226 - acc: 0.8740
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3242 - acc: 0.8730
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3183 - acc: 0.8768
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3138 - acc: 0.8811
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3136 - acc: 0.8816
1280/1283 [============================>.] - ETA: 0s - loss: 0.3129 - acc: 0.8820
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3137 - acc: 0.8815 - val_loss: 0.5576 - val_acc: 0.7162

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2793 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.2199 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2232 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2208 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2223 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2411 - acc: 0.9349
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2454 - acc: 0.9330
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2362 - acc: 0.9395
 576/1283 [============>.................] - ETA: 0s - loss: 0.2400 - acc: 0.9392
 640/1283 [=============>................] - ETA: 0s - loss: 0.2412 - acc: 0.9375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2466 - acc: 0.9361
 768/1283 [================>.............] - ETA: 0s - loss: 0.2485 - acc: 0.9310
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2549 - acc: 0.9255
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2528 - acc: 0.9263
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2544 - acc: 0.9240
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2524 - acc: 0.9238
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2518 - acc: 0.9256
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2466 - acc: 0.9288
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2516 - acc: 0.9252
1280/1283 [============================>.] - ETA: 0s - loss: 0.2535 - acc: 0.9219
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2541 - acc: 0.9213 - val_loss: 0.5807 - val_acc: 0.6856

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2779 - acc: 0.8750
 128/1283 [=>............................] - ETA: 2s - loss: 0.2272 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2343 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2299 - acc: 0.9141
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2274 - acc: 0.9156
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2255 - acc: 0.9193
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2126 - acc: 0.9263
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2252 - acc: 0.9258
 576/1283 [============>.................] - ETA: 1s - loss: 0.2184 - acc: 0.9288
 640/1283 [=============>................] - ETA: 1s - loss: 0.2195 - acc: 0.9281
 704/1283 [===============>..............] - ETA: 1s - loss: 0.2164 - acc: 0.9290
 768/1283 [================>.............] - ETA: 0s - loss: 0.2170 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2139 - acc: 0.9291
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2149 - acc: 0.9275
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2172 - acc: 0.9240
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2149 - acc: 0.9248
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2125 - acc: 0.9274
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2090 - acc: 0.9280
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2095 - acc: 0.9268
1280/1283 [============================>.] - ETA: 0s - loss: 0.2117 - acc: 0.9258
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2114 - acc: 0.9260 - val_loss: 0.6095 - val_acc: 0.7074

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1412 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.1573 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1425 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1405 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1384 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1335 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1437 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1453 - acc: 0.9629
 576/1283 [============>.................] - ETA: 1s - loss: 0.1468 - acc: 0.9635
 640/1283 [=============>................] - ETA: 1s - loss: 0.1453 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1550 - acc: 0.9588
 768/1283 [================>.............] - ETA: 0s - loss: 0.1557 - acc: 0.9583
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1597 - acc: 0.9543
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1566 - acc: 0.9565
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1539 - acc: 0.9583
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1574 - acc: 0.9561
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1640 - acc: 0.9504
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1615 - acc: 0.9531
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1622 - acc: 0.9523
1280/1283 [============================>.] - ETA: 0s - loss: 0.1594 - acc: 0.9531
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1594 - acc: 0.9532 - val_loss: 0.6665 - val_acc: 0.7380

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1627 - acc: 0.9375
 128/1283 [=>............................] - ETA: 2s - loss: 0.1217 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1397 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1263 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1190 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1223 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1238 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1202 - acc: 0.9629
 576/1283 [============>.................] - ETA: 0s - loss: 0.1144 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.1172 - acc: 0.9609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1171 - acc: 0.9602
 768/1283 [================>.............] - ETA: 0s - loss: 0.1144 - acc: 0.9622
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1115 - acc: 0.9651
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1097 - acc: 0.9654
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1156 - acc: 0.9615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1131 - acc: 0.9629
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1105 - acc: 0.9651
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1113 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1163 - acc: 0.9622
1280/1283 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9617
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1175 - acc: 0.9618 - val_loss: 0.7176 - val_acc: 0.6943

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0674 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0520 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0580 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0589 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0609 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0635 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0654 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0651 - acc: 0.9863
 640/1283 [=============>................] - ETA: 1s - loss: 0.0709 - acc: 0.9812
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0729 - acc: 0.9801
 768/1283 [================>.............] - ETA: 0s - loss: 0.0744 - acc: 0.9779
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0738 - acc: 0.9796
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0749 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0772 - acc: 0.9771
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0774 - acc: 0.9766
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0788 - acc: 0.9770
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0808 - acc: 0.9748
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0820 - acc: 0.9753
1280/1283 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9750
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0809 - acc: 0.9751 - val_loss: 0.8031 - val_acc: 0.6725

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0627 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0562 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0550 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0536 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0502 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0588 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0578 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0596 - acc: 0.9913
 640/1283 [=============>................] - ETA: 0s - loss: 0.0592 - acc: 0.9906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0598 - acc: 0.9915
 768/1283 [================>.............] - ETA: 0s - loss: 0.0625 - acc: 0.9896
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0615 - acc: 0.9904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0584 - acc: 0.9906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0592 - acc: 0.9893
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0585 - acc: 0.9890
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0583 - acc: 0.9887
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0594 - acc: 0.9877
1280/1283 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9883
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0584 - acc: 0.9883 - val_loss: 0.8606 - val_acc: 0.6943

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0250 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0417 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0340 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0335 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0391 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0376 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0352 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0364 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0352 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0358 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0344 - acc: 0.9948
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0341 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0331 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0331 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0328 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0328 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0319 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9945
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0349 - acc: 0.9945 - val_loss: 0.9029 - val_acc: 0.7118

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0139 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0262 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0231 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0254 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0310 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0284 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0282 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0267 - acc: 0.9941
 576/1283 [============>.................] - ETA: 1s - loss: 0.0259 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0266 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0262 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0252 - acc: 0.9948
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0250 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0258 - acc: 0.9944
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0251 - acc: 0.9948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0254 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0269 - acc: 0.9945
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0270 - acc: 0.9939
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0269 - acc: 0.9942
1280/1283 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9938
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0269 - acc: 0.9938 - val_loss: 0.9896 - val_acc: 0.6900

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0316 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0237 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0224 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0210 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0207 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0191 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0184 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0186 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0190 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0188 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0175 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0169 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0162 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0163 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0204 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0197 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0204 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0198 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0197 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9961
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0209 - acc: 0.9961 - val_loss: 1.0195 - val_acc: 0.7031

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=120
accuracy=0.6880466472303207
best_valid_accuracy=0.6793002915451894
