/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:48:23.401818: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.7150 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 3s - loss: 0.6913 - acc: 0.5781 
 256/1283 [====>.........................] - ETA: 2s - loss: 0.6960 - acc: 0.5547
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6950 - acc: 0.5547
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6956 - acc: 0.5547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6979 - acc: 0.5526
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6985 - acc: 0.5517
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6961 - acc: 0.5531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6957 - acc: 0.5547
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6957 - acc: 0.5561
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6952 - acc: 0.5599
1280/1283 [============================>.] - ETA: 0s - loss: 0.6955 - acc: 0.5578
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6957 - acc: 0.5573 - val_loss: 0.6934 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.6821 - acc: 0.5781
 128/1283 [=>............................] - ETA: 2s - loss: 0.6536 - acc: 0.6328
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6601 - acc: 0.6367
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6631 - acc: 0.6250
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6644 - acc: 0.6250
 640/1283 [=============>................] - ETA: 0s - loss: 0.6661 - acc: 0.6172
 768/1283 [================>.............] - ETA: 0s - loss: 0.6639 - acc: 0.6211
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6609 - acc: 0.6228
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6612 - acc: 0.6198
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6601 - acc: 0.6230
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6585 - acc: 0.6268
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6588 - acc: 0.6192
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6569 - acc: 0.6220 - val_loss: 0.6866 - val_acc: 0.5546

Epoch 00002: val_acc improved from 0.55022 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5926 - acc: 0.7344
 128/1283 [=>............................] - ETA: 1s - loss: 0.6224 - acc: 0.6328
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6369 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6398 - acc: 0.6094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6252 - acc: 0.6362
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6266 - acc: 0.6348
 576/1283 [============>.................] - ETA: 0s - loss: 0.6239 - acc: 0.6441
 640/1283 [=============>................] - ETA: 0s - loss: 0.6234 - acc: 0.6453
 768/1283 [================>.............] - ETA: 0s - loss: 0.6209 - acc: 0.6523
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6244 - acc: 0.6514
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6263 - acc: 0.6542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6283 - acc: 0.6461
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6290 - acc: 0.6458
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6299 - acc: 0.6447
1280/1283 [============================>.] - ETA: 0s - loss: 0.6307 - acc: 0.6445
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6305 - acc: 0.6446 - val_loss: 0.6880 - val_acc: 0.5459

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6245 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5963 - acc: 0.6667
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5825 - acc: 0.6992
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5811 - acc: 0.7083
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5898 - acc: 0.6895
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5972 - acc: 0.6818
 768/1283 [================>.............] - ETA: 0s - loss: 0.5993 - acc: 0.6784
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5973 - acc: 0.6851
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5977 - acc: 0.6853
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5972 - acc: 0.6885
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5963 - acc: 0.6893
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5943 - acc: 0.6883
1280/1283 [============================>.] - ETA: 0s - loss: 0.5955 - acc: 0.6836
1283/1283 [==============================] - 1s 738us/step - loss: 0.5961 - acc: 0.6820 - val_loss: 0.7032 - val_acc: 0.5415

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.5625 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 2s - loss: 0.5588 - acc: 0.7135
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5668 - acc: 0.6914
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5840 - acc: 0.6615
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5681 - acc: 0.6875
 576/1283 [============>.................] - ETA: 1s - loss: 0.5650 - acc: 0.6962
 640/1283 [=============>................] - ETA: 0s - loss: 0.5618 - acc: 0.7047
 768/1283 [================>.............] - ETA: 0s - loss: 0.5630 - acc: 0.7044
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5621 - acc: 0.7098
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5653 - acc: 0.7052
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5642 - acc: 0.7070
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5666 - acc: 0.7066
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5697 - acc: 0.7056
1280/1283 [============================>.] - ETA: 0s - loss: 0.5660 - acc: 0.7117
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5658 - acc: 0.7124 - val_loss: 0.6998 - val_acc: 0.5677

Epoch 00005: val_acc improved from 0.55459 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4718 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4990 - acc: 0.7969
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5139 - acc: 0.7750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5265 - acc: 0.7630
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5139 - acc: 0.7715
 576/1283 [============>.................] - ETA: 0s - loss: 0.5147 - acc: 0.7708
 640/1283 [=============>................] - ETA: 0s - loss: 0.5083 - acc: 0.7781
 768/1283 [================>.............] - ETA: 0s - loss: 0.5087 - acc: 0.7760
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5094 - acc: 0.7746
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5138 - acc: 0.7688
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5170 - acc: 0.7638
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5157 - acc: 0.7613
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5131 - acc: 0.7615
1280/1283 [============================>.] - ETA: 0s - loss: 0.5122 - acc: 0.7609
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5119 - acc: 0.7615 - val_loss: 0.8111 - val_acc: 0.5502

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5222 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5871 - acc: 0.6979
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5588 - acc: 0.7156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5382 - acc: 0.7321
 576/1283 [============>.................] - ETA: 0s - loss: 0.5617 - acc: 0.7066
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5475 - acc: 0.7188
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5341 - acc: 0.7272
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5340 - acc: 0.7232
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5372 - acc: 0.7167
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5290 - acc: 0.7289
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5235 - acc: 0.7335
1280/1283 [============================>.] - ETA: 0s - loss: 0.5204 - acc: 0.7375
1283/1283 [==============================] - 1s 796us/step - loss: 0.5200 - acc: 0.7381 - val_loss: 0.7556 - val_acc: 0.5240

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5452 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.4722 - acc: 0.7734
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4276 - acc: 0.8203
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4457 - acc: 0.7865
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4435 - acc: 0.7930
 576/1283 [============>.................] - ETA: 0s - loss: 0.4366 - acc: 0.8003
 640/1283 [=============>................] - ETA: 0s - loss: 0.4335 - acc: 0.8078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4317 - acc: 0.8111
 768/1283 [================>.............] - ETA: 0s - loss: 0.4386 - acc: 0.8060
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4283 - acc: 0.8192
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4285 - acc: 0.8184
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4286 - acc: 0.8142
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4255 - acc: 0.8166
1283/1283 [==============================] - 1s 990us/step - loss: 0.4255 - acc: 0.8161 - val_loss: 0.7747 - val_acc: 0.5852

Epoch 00008: val_acc improved from 0.56769 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3527 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.3788 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3747 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3841 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3805 - acc: 0.8229
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3861 - acc: 0.8203
 576/1283 [============>.................] - ETA: 0s - loss: 0.3815 - acc: 0.8247
 640/1283 [=============>................] - ETA: 0s - loss: 0.3824 - acc: 0.8187
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3746 - acc: 0.8267
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3764 - acc: 0.8257
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3803 - acc: 0.8240
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3829 - acc: 0.8235
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3821 - acc: 0.8248
1280/1283 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8227
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3855 - acc: 0.8223 - val_loss: 0.8451 - val_acc: 0.5240

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3147 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.3495 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3655 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3566 - acc: 0.8477
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3509 - acc: 0.8500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3401 - acc: 0.8542
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3442 - acc: 0.8504
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3497 - acc: 0.8477
 576/1283 [============>.................] - ETA: 0s - loss: 0.3481 - acc: 0.8472
 640/1283 [=============>................] - ETA: 0s - loss: 0.3458 - acc: 0.8484
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3405 - acc: 0.8565
 768/1283 [================>.............] - ETA: 0s - loss: 0.3397 - acc: 0.8555
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3363 - acc: 0.8570
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3345 - acc: 0.8571
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3316 - acc: 0.8583
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3361 - acc: 0.8516
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3365 - acc: 0.8507
1280/1283 [============================>.] - ETA: 0s - loss: 0.3347 - acc: 0.8516
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3350 - acc: 0.8519 - val_loss: 0.8486 - val_acc: 0.5633

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2738 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3007 - acc: 0.8802
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3259 - acc: 0.8633
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3302 - acc: 0.8656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3226 - acc: 0.8620
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3183 - acc: 0.8683
 576/1283 [============>.................] - ETA: 0s - loss: 0.3163 - acc: 0.8663
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3147 - acc: 0.8736
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3146 - acc: 0.8690
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3091 - acc: 0.8728
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3067 - acc: 0.8721
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3067 - acc: 0.8715
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3084 - acc: 0.8725
1280/1283 [============================>.] - ETA: 0s - loss: 0.3114 - acc: 0.8688
1283/1283 [==============================] - 1s 988us/step - loss: 0.3118 - acc: 0.8683 - val_loss: 1.0050 - val_acc: 0.5284

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2955 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.3949 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3566 - acc: 0.8490
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3637 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3629 - acc: 0.8219
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3699 - acc: 0.8177
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3560 - acc: 0.8262
 576/1283 [============>.................] - ETA: 0s - loss: 0.3528 - acc: 0.8264
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3416 - acc: 0.8366
 768/1283 [================>.............] - ETA: 0s - loss: 0.3346 - acc: 0.8411
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3245 - acc: 0.8460
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3208 - acc: 0.8500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3161 - acc: 0.8557
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3200 - acc: 0.8524
1280/1283 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.8539
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3163 - acc: 0.8542 - val_loss: 0.9288 - val_acc: 0.5808

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2718 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.2340 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2432 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2324 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2500 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2470 - acc: 0.9107
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2488 - acc: 0.9082
 640/1283 [=============>................] - ETA: 0s - loss: 0.2478 - acc: 0.9000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2440 - acc: 0.9034
 768/1283 [================>.............] - ETA: 0s - loss: 0.2476 - acc: 0.8984
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2431 - acc: 0.9040
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2456 - acc: 0.9031
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2446 - acc: 0.9023
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2427 - acc: 0.9035
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2421 - acc: 0.9038
1280/1283 [============================>.] - ETA: 0s - loss: 0.2407 - acc: 0.9047
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2417 - acc: 0.9041 - val_loss: 0.9952 - val_acc: 0.5721

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1596 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.2078 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2225 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2642 - acc: 0.8875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2497 - acc: 0.8932
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2400 - acc: 0.8984
 640/1283 [=============>................] - ETA: 0s - loss: 0.2512 - acc: 0.8922
 768/1283 [================>.............] - ETA: 0s - loss: 0.2430 - acc: 0.8997
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2432 - acc: 0.8984
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2455 - acc: 0.8975
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2420 - acc: 0.8989
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2458 - acc: 0.8958
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2456 - acc: 0.8947
1280/1283 [============================>.] - ETA: 0s - loss: 0.2477 - acc: 0.8930
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2472 - acc: 0.8932 - val_loss: 0.9991 - val_acc: 0.5633

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1865 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1796 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1764 - acc: 0.9414
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1680 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1718 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1761 - acc: 0.9420
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1752 - acc: 0.9434
 640/1283 [=============>................] - ETA: 0s - loss: 0.1846 - acc: 0.9313
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1836 - acc: 0.9347
 768/1283 [================>.............] - ETA: 0s - loss: 0.1827 - acc: 0.9349
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1832 - acc: 0.9339
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1821 - acc: 0.9342
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1836 - acc: 0.9344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1851 - acc: 0.9336
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1829 - acc: 0.9347
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1885 - acc: 0.9285
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1889 - acc: 0.9299 - val_loss: 1.0794 - val_acc: 0.5764

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1362 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1555 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1710 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1711 - acc: 0.9353
 576/1283 [============>.................] - ETA: 0s - loss: 0.1693 - acc: 0.9410
 640/1283 [=============>................] - ETA: 0s - loss: 0.1680 - acc: 0.9422
 768/1283 [================>.............] - ETA: 0s - loss: 0.1602 - acc: 0.9440
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1591 - acc: 0.9435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1650 - acc: 0.9408
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1636 - acc: 0.9406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1629 - acc: 0.9395
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1628 - acc: 0.9384
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1613 - acc: 0.9408
1280/1283 [============================>.] - ETA: 0s - loss: 0.1612 - acc: 0.9414
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1619 - acc: 0.9408 - val_loss: 1.1592 - val_acc: 0.5590

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1221 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1356 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1571 - acc: 0.9250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1442 - acc: 0.9349
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1426 - acc: 0.9375
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1432 - acc: 0.9414
 640/1283 [=============>................] - ETA: 0s - loss: 0.1400 - acc: 0.9437
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1350 - acc: 0.9489
 768/1283 [================>.............] - ETA: 0s - loss: 0.1347 - acc: 0.9505
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1352 - acc: 0.9507
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1354 - acc: 0.9498
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1327 - acc: 0.9510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1359 - acc: 0.9482
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1364 - acc: 0.9485
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1351 - acc: 0.9497
1280/1283 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9523
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1327 - acc: 0.9525 - val_loss: 1.2302 - val_acc: 0.5808

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0953 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1415 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1323 - acc: 0.9453
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1293 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1262 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1232 - acc: 0.9566
 640/1283 [=============>................] - ETA: 0s - loss: 0.1253 - acc: 0.9563
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1287 - acc: 0.9517
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1236 - acc: 0.9543
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1203 - acc: 0.9563
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1172 - acc: 0.9590
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1171 - acc: 0.9586
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1159 - acc: 0.9605
1283/1283 [==============================] - 1s 912us/step - loss: 0.1170 - acc: 0.9602 - val_loss: 1.3206 - val_acc: 0.5590

Epoch 00018: val_acc did not improve
Epoch 00018: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5306122448979592
best_valid_accuracy=0.5422740524781341
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:55:07.549982: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.7672 - acc: 0.4375
 128/1283 [=>............................] - ETA: 4s - loss: 0.7299 - acc: 0.4844
 192/1283 [===>..........................] - ETA: 3s - loss: 0.7336 - acc: 0.5052
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7263 - acc: 0.5273
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7227 - acc: 0.5312
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7111 - acc: 0.5430
 640/1283 [=============>................] - ETA: 0s - loss: 0.7055 - acc: 0.5516
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7059 - acc: 0.5577
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7035 - acc: 0.5542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7011 - acc: 0.5597
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7008 - acc: 0.5567
1283/1283 [==============================] - 1s 934us/step - loss: 0.7005 - acc: 0.5581 - val_loss: 0.6865 - val_acc: 0.5590

Epoch 00001: val_acc improved from -inf to 0.55895, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6665 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6643 - acc: 0.6250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6614 - acc: 0.6183
 576/1283 [============>.................] - ETA: 0s - loss: 0.6651 - acc: 0.6042
 768/1283 [================>.............] - ETA: 0s - loss: 0.6608 - acc: 0.6120
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6616 - acc: 0.6062
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6598 - acc: 0.6121
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6591 - acc: 0.6135
1283/1283 [==============================] - 1s 437us/step - loss: 0.6598 - acc: 0.6126 - val_loss: 0.6894 - val_acc: 0.5328

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6105 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6365 - acc: 0.6562
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6344 - acc: 0.6615
 576/1283 [============>.................] - ETA: 0s - loss: 0.6271 - acc: 0.6875
 768/1283 [================>.............] - ETA: 0s - loss: 0.6261 - acc: 0.6810
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6285 - acc: 0.6677
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6279 - acc: 0.6641
1283/1283 [==============================] - 0s 365us/step - loss: 0.6285 - acc: 0.6617 - val_loss: 0.6943 - val_acc: 0.5677

Epoch 00003: val_acc improved from 0.55895 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5597 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5960 - acc: 0.6687
 640/1283 [=============>................] - ETA: 0s - loss: 0.5893 - acc: 0.6969
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5884 - acc: 0.6969
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5875 - acc: 0.6918
1283/1283 [==============================] - 0s 254us/step - loss: 0.5902 - acc: 0.6921 - val_loss: 0.6924 - val_acc: 0.5677

Epoch 00004: val_acc improved from 0.56769 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5775 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5514 - acc: 0.7344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5486 - acc: 0.7318
 576/1283 [============>.................] - ETA: 0s - loss: 0.5349 - acc: 0.7483
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5375 - acc: 0.7401
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5344 - acc: 0.7388
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5324 - acc: 0.7399
1280/1283 [============================>.] - ETA: 0s - loss: 0.5294 - acc: 0.7445
1283/1283 [==============================] - 0s 359us/step - loss: 0.5299 - acc: 0.7436 - val_loss: 0.7026 - val_acc: 0.5764

Epoch 00005: val_acc improved from 0.56769 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3983 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4897 - acc: 0.7625
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4928 - acc: 0.7598
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4847 - acc: 0.7699
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4821 - acc: 0.7734
1280/1283 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.7703
1283/1283 [==============================] - 0s 263us/step - loss: 0.4874 - acc: 0.7701 - val_loss: 0.8904 - val_acc: 0.5284

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5855 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5702 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5128 - acc: 0.7388
 576/1283 [============>.................] - ETA: 0s - loss: 0.5049 - acc: 0.7448
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4921 - acc: 0.7548
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4718 - acc: 0.7748
1280/1283 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.7789
1283/1283 [==============================] - 0s 328us/step - loss: 0.4694 - acc: 0.7794 - val_loss: 0.7504 - val_acc: 0.5240

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3298 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3867 - acc: 0.8542
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4294 - acc: 0.8125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4040 - acc: 0.8304
 640/1283 [=============>................] - ETA: 0s - loss: 0.3949 - acc: 0.8359
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3890 - acc: 0.8425
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3829 - acc: 0.8373
1283/1283 [==============================] - 0s 373us/step - loss: 0.3800 - acc: 0.8394 - val_loss: 0.8111 - val_acc: 0.5764

Epoch 00008: val_acc improved from 0.57642 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3514 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3463 - acc: 0.8625
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3362 - acc: 0.8633
 768/1283 [================>.............] - ETA: 0s - loss: 0.3296 - acc: 0.8633
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3249 - acc: 0.8656
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3239 - acc: 0.8709
1283/1283 [==============================] - 0s 266us/step - loss: 0.3250 - acc: 0.8691 - val_loss: 0.8552 - val_acc: 0.5590

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2484 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2636 - acc: 0.9102
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2668 - acc: 0.8984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2720 - acc: 0.8935
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2788 - acc: 0.8906
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2776 - acc: 0.8889
1283/1283 [==============================] - 0s 306us/step - loss: 0.2788 - acc: 0.8885 - val_loss: 0.8850 - val_acc: 0.5808

Epoch 00010: val_acc improved from 0.57642 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2314 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2496 - acc: 0.9258
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2386 - acc: 0.9258
 640/1283 [=============>................] - ETA: 0s - loss: 0.2352 - acc: 0.9234
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2211 - acc: 0.9308
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2191 - acc: 0.9283
1280/1283 [============================>.] - ETA: 0s - loss: 0.2186 - acc: 0.9273
1283/1283 [==============================] - 0s 356us/step - loss: 0.2186 - acc: 0.9267 - val_loss: 1.0571 - val_acc: 0.5328

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2082 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1939 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1909 - acc: 0.9464
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1831 - acc: 0.9432
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1801 - acc: 0.9396
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1792 - acc: 0.9375
1283/1283 [==============================] - 0s 304us/step - loss: 0.1837 - acc: 0.9314 - val_loss: 1.0879 - val_acc: 0.5677

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1860 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1775 - acc: 0.9187
 576/1283 [============>.................] - ETA: 0s - loss: 0.1723 - acc: 0.9271
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1667 - acc: 0.9387
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1644 - acc: 0.9421
1283/1283 [==============================] - 0s 253us/step - loss: 0.1659 - acc: 0.9431 - val_loss: 1.2241 - val_acc: 0.5415

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1733 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1487 - acc: 0.9531
 640/1283 [=============>................] - ETA: 0s - loss: 0.1349 - acc: 0.9578
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1309 - acc: 0.9604
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1287 - acc: 0.9638
1283/1283 [==============================] - 0s 232us/step - loss: 0.1272 - acc: 0.9641 - val_loss: 1.2184 - val_acc: 0.5764

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1253 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1424 - acc: 0.9531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1509 - acc: 0.9531
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1515 - acc: 0.9479
1280/1283 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9523
1283/1283 [==============================] - 0s 228us/step - loss: 0.1466 - acc: 0.9509 - val_loss: 1.3153 - val_acc: 0.5721

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0628 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2087 - acc: 0.9141
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2096 - acc: 0.9023
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2181 - acc: 0.9026
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2017 - acc: 0.9175
1283/1283 [==============================] - 0s 230us/step - loss: 0.1930 - acc: 0.9197 - val_loss: 1.4756 - val_acc: 0.5066

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1668 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1130 - acc: 0.9714
 768/1283 [================>.............] - ETA: 0s - loss: 0.1073 - acc: 0.9674
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1052 - acc: 0.9706
1280/1283 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9695
1283/1283 [==============================] - 0s 222us/step - loss: 0.1068 - acc: 0.9696 - val_loss: 1.4285 - val_acc: 0.5590

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0729 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0813 - acc: 0.9750
 640/1283 [=============>................] - ETA: 0s - loss: 0.0741 - acc: 0.9812
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0730 - acc: 0.9833
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0722 - acc: 0.9827
1283/1283 [==============================] - 0s 219us/step - loss: 0.0742 - acc: 0.9813 - val_loss: 1.6505 - val_acc: 0.5677

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1398 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1379 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1648 - acc: 0.9187
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1826 - acc: 0.9121
 768/1283 [================>.............] - ETA: 0s - loss: 0.1866 - acc: 0.9115
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1897 - acc: 0.9072
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1878 - acc: 0.9095
1283/1283 [==============================] - 0s 337us/step - loss: 0.1897 - acc: 0.9104 - val_loss: 1.5383 - val_acc: 0.5502

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1054 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1114 - acc: 0.9740
 640/1283 [=============>................] - ETA: 0s - loss: 0.1210 - acc: 0.9656
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1270 - acc: 0.9603
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1249 - acc: 0.9614
1283/1283 [==============================] - 0s 233us/step - loss: 0.1232 - acc: 0.9587 - val_loss: 1.5536 - val_acc: 0.5328

Epoch 00020: val_acc did not improve
Epoch 00020: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=15
PCA text=100
accuracy=0.532069970845481
best_valid_accuracy=0.4839650145772595
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:08:15.218147: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 27s - loss: 0.7027 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 8s - loss: 0.7145 - acc: 0.5260 
 256/1283 [====>.........................] - ETA: 6s - loss: 0.7121 - acc: 0.5156
 320/1283 [======>.......................] - ETA: 5s - loss: 0.7053 - acc: 0.5344
 384/1283 [=======>......................] - ETA: 4s - loss: 0.7124 - acc: 0.5182
 448/1283 [=========>....................] - ETA: 3s - loss: 0.7091 - acc: 0.5201
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7083 - acc: 0.5156
 576/1283 [============>.................] - ETA: 2s - loss: 0.7128 - acc: 0.5035
 640/1283 [=============>................] - ETA: 2s - loss: 0.7216 - acc: 0.4953
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7159 - acc: 0.5028
 768/1283 [================>.............] - ETA: 1s - loss: 0.7149 - acc: 0.5013
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7112 - acc: 0.5156
 896/1283 [===================>..........] - ETA: 1s - loss: 0.7097 - acc: 0.5179
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7061 - acc: 0.5271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7119 - acc: 0.5234
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7157 - acc: 0.5211
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7131 - acc: 0.5260
1280/1283 [============================>.] - ETA: 0s - loss: 0.7113 - acc: 0.5266
1283/1283 [==============================] - 4s 3ms/step - loss: 0.7110 - acc: 0.5277 - val_loss: 0.7022 - val_acc: 0.5022

Epoch 00001: val_acc improved from -inf to 0.50218, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6689 - acc: 0.5000
 128/1283 [=>............................] - ETA: 1s - loss: 0.6578 - acc: 0.5859
 192/1283 [===>..........................] - ETA: 2s - loss: 0.6576 - acc: 0.5677
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6689 - acc: 0.5625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6495 - acc: 0.5964
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6479 - acc: 0.5982
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6498 - acc: 0.6055
 576/1283 [============>.................] - ETA: 0s - loss: 0.6457 - acc: 0.6233
 640/1283 [=============>................] - ETA: 0s - loss: 0.6444 - acc: 0.6266
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6530 - acc: 0.6122
 768/1283 [================>.............] - ETA: 0s - loss: 0.6485 - acc: 0.6146
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6488 - acc: 0.6142
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6480 - acc: 0.6172
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6488 - acc: 0.6135
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6491 - acc: 0.6133
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6463 - acc: 0.6181
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6473 - acc: 0.6234
1280/1283 [============================>.] - ETA: 0s - loss: 0.6486 - acc: 0.6203
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6484 - acc: 0.6212 - val_loss: 0.6849 - val_acc: 0.5808

Epoch 00002: val_acc improved from 0.50218 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5787 - acc: 0.7344
 128/1283 [=>............................] - ETA: 1s - loss: 0.5785 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 2s - loss: 0.5985 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5905 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 3s - loss: 0.5930 - acc: 0.6906
 384/1283 [=======>......................] - ETA: 2s - loss: 0.5842 - acc: 0.7005
 448/1283 [=========>....................] - ETA: 2s - loss: 0.5887 - acc: 0.6987
 512/1283 [==========>...................] - ETA: 2s - loss: 0.5901 - acc: 0.6992
 576/1283 [============>.................] - ETA: 2s - loss: 0.5888 - acc: 0.6997
 640/1283 [=============>................] - ETA: 1s - loss: 0.5918 - acc: 0.6906
 704/1283 [===============>..............] - ETA: 1s - loss: 0.5906 - acc: 0.6918
 768/1283 [================>.............] - ETA: 1s - loss: 0.5925 - acc: 0.6940
 832/1283 [==================>...........] - ETA: 1s - loss: 0.5928 - acc: 0.6887
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5963 - acc: 0.6833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5975 - acc: 0.6816
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5954 - acc: 0.6847
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5946 - acc: 0.6866
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5959 - acc: 0.6834
1280/1283 [============================>.] - ETA: 0s - loss: 0.5950 - acc: 0.6828
1283/1283 [==============================] - 3s 2ms/step - loss: 0.5948 - acc: 0.6828 - val_loss: 0.6995 - val_acc: 0.5764

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6069 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5703 - acc: 0.7083
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5666 - acc: 0.7063
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5491 - acc: 0.7324
 576/1283 [============>.................] - ETA: 0s - loss: 0.5517 - acc: 0.7274
 640/1283 [=============>................] - ETA: 0s - loss: 0.5501 - acc: 0.7281
 768/1283 [================>.............] - ETA: 0s - loss: 0.5436 - acc: 0.7305
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5448 - acc: 0.7260
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5407 - acc: 0.7277
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5408 - acc: 0.7260
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5465 - acc: 0.7207
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5433 - acc: 0.7233
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5409 - acc: 0.7270
1280/1283 [============================>.] - ETA: 0s - loss: 0.5399 - acc: 0.7305
1283/1283 [==============================] - 1s 814us/step - loss: 0.5407 - acc: 0.7295 - val_loss: 0.7131 - val_acc: 0.5764

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4424 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4531 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4808 - acc: 0.7865
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4695 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4774 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4840 - acc: 0.7832
 576/1283 [============>.................] - ETA: 0s - loss: 0.4844 - acc: 0.7847
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4873 - acc: 0.7756
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4873 - acc: 0.7764
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4866 - acc: 0.7781
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4897 - acc: 0.7730
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4883 - acc: 0.7755
1283/1283 [==============================] - 1s 805us/step - loss: 0.4919 - acc: 0.7693 - val_loss: 0.7398 - val_acc: 0.5546

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4408 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.4085 - acc: 0.8516
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4257 - acc: 0.8242
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4142 - acc: 0.8281
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4181 - acc: 0.8229
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4197 - acc: 0.8170
 576/1283 [============>.................] - ETA: 0s - loss: 0.4208 - acc: 0.8160
 640/1283 [=============>................] - ETA: 0s - loss: 0.4283 - acc: 0.8063
 768/1283 [================>.............] - ETA: 0s - loss: 0.4356 - acc: 0.8008
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4351 - acc: 0.7993
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4319 - acc: 0.8021
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4323 - acc: 0.8006
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4283 - acc: 0.8051
1283/1283 [==============================] - 1s 941us/step - loss: 0.4246 - acc: 0.8114 - val_loss: 0.7560 - val_acc: 0.5590

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3251 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.3195 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3739 - acc: 0.8164
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3781 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3849 - acc: 0.8099
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3820 - acc: 0.8184
 576/1283 [============>.................] - ETA: 0s - loss: 0.3982 - acc: 0.8056
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3929 - acc: 0.8139
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3842 - acc: 0.8221
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3773 - acc: 0.8323
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3806 - acc: 0.8301
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3722 - acc: 0.8373
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3710 - acc: 0.8396
1280/1283 [============================>.] - ETA: 0s - loss: 0.3700 - acc: 0.8391
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3701 - acc: 0.8387 - val_loss: 0.8212 - val_acc: 0.5415

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2367 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.2654 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2758 - acc: 0.9115
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2953 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3006 - acc: 0.8812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3108 - acc: 0.8698
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3138 - acc: 0.8633
 576/1283 [============>.................] - ETA: 0s - loss: 0.3168 - acc: 0.8611
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3129 - acc: 0.8636
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3113 - acc: 0.8630
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3106 - acc: 0.8677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3106 - acc: 0.8672
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3080 - acc: 0.8686
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3086 - acc: 0.8672
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3093 - acc: 0.8668
1280/1283 [============================>.] - ETA: 0s - loss: 0.3090 - acc: 0.8688
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3084 - acc: 0.8691 - val_loss: 0.8703 - val_acc: 0.5546

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2933 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.2432 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2210 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2191 - acc: 0.9336
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2192 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2251 - acc: 0.9401
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2269 - acc: 0.9414
 640/1283 [=============>................] - ETA: 0s - loss: 0.2231 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2244 - acc: 0.9432
 768/1283 [================>.............] - ETA: 0s - loss: 0.2252 - acc: 0.9414
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2248 - acc: 0.9431
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2237 - acc: 0.9395
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2228 - acc: 0.9412
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2227 - acc: 0.9418
1280/1283 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9375
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2282 - acc: 0.9369 - val_loss: 0.9467 - val_acc: 0.5590

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1449 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1800 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1688 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1679 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1669 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1848 - acc: 0.9271
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1853 - acc: 0.9375
 576/1283 [============>.................] - ETA: 1s - loss: 0.1818 - acc: 0.9358
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1833 - acc: 0.9389
 768/1283 [================>.............] - ETA: 0s - loss: 0.1834 - acc: 0.9388
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1843 - acc: 0.9351
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1867 - acc: 0.9330
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1881 - acc: 0.9316
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1907 - acc: 0.9280
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1905 - acc: 0.9260
1280/1283 [============================>.] - ETA: 0s - loss: 0.1939 - acc: 0.9250
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1937 - acc: 0.9252 - val_loss: 1.0373 - val_acc: 0.5721

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1615 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1796 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1634 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1479 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1505 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1540 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1553 - acc: 0.9353
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1575 - acc: 0.9375
 576/1283 [============>.................] - ETA: 1s - loss: 0.1550 - acc: 0.9410
 640/1283 [=============>................] - ETA: 1s - loss: 0.1550 - acc: 0.9437
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1561 - acc: 0.9403
 768/1283 [================>.............] - ETA: 0s - loss: 0.1572 - acc: 0.9414
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1585 - acc: 0.9399
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1597 - acc: 0.9420
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1588 - acc: 0.9417
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1598 - acc: 0.9404
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1583 - acc: 0.9430
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1556 - acc: 0.9453
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1526 - acc: 0.9482
1280/1283 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9484
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1514 - acc: 0.9486 - val_loss: 1.2226 - val_acc: 0.4934

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1325 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.1253 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1288 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1244 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1279 - acc: 0.9740
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1243 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1221 - acc: 0.9707
 576/1283 [============>.................] - ETA: 0s - loss: 0.1226 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1248 - acc: 0.9673
 768/1283 [================>.............] - ETA: 0s - loss: 0.1311 - acc: 0.9635
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1299 - acc: 0.9639
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1266 - acc: 0.9643
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1269 - acc: 0.9635
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1296 - acc: 0.9609
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1324 - acc: 0.9586
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1324 - acc: 0.9572
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1345 - acc: 0.9556 - val_loss: 1.2632 - val_acc: 0.5371

Epoch 00012: val_acc did not improve
Epoch 00012: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=20
PCA text=100
accuracy=0.4912536443148688
best_valid_accuracy=0.5247813411078717
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:19:31.162014: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.7093 - acc: 0.5000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6979 - acc: 0.5375
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6962 - acc: 0.5566
 768/1283 [================>.............] - ETA: 0s - loss: 0.6943 - acc: 0.5651
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6913 - acc: 0.5719
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6906 - acc: 0.5694
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6903 - acc: 0.5699
1283/1283 [==============================] - 1s 561us/step - loss: 0.6927 - acc: 0.5674 - val_loss: 0.6883 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6061 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6489 - acc: 0.6094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6438 - acc: 0.6295
 640/1283 [=============>................] - ETA: 0s - loss: 0.6357 - acc: 0.6438
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6367 - acc: 0.6382
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6321 - acc: 0.6490
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6268 - acc: 0.6545
1283/1283 [==============================] - 0s 353us/step - loss: 0.6230 - acc: 0.6555 - val_loss: 0.6982 - val_acc: 0.5240

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5666 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5549 - acc: 0.7383
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5615 - acc: 0.7210
 640/1283 [=============>................] - ETA: 0s - loss: 0.5718 - acc: 0.7063
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5674 - acc: 0.7091
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5699 - acc: 0.7041
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5708 - acc: 0.7097
1283/1283 [==============================] - 0s 350us/step - loss: 0.5719 - acc: 0.7077 - val_loss: 0.7150 - val_acc: 0.5546

Epoch 00003: val_acc improved from 0.55022 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5495 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5270 - acc: 0.7552
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5229 - acc: 0.7344
 576/1283 [============>.................] - ETA: 0s - loss: 0.5151 - acc: 0.7517
 768/1283 [================>.............] - ETA: 0s - loss: 0.5082 - acc: 0.7513
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5080 - acc: 0.7562
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5071 - acc: 0.7578
1283/1283 [==============================] - 0s 360us/step - loss: 0.5058 - acc: 0.7584 - val_loss: 0.7381 - val_acc: 0.5808

Epoch 00004: val_acc improved from 0.55459 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4985 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4424 - acc: 0.7852
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4443 - acc: 0.7790
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4328 - acc: 0.7898
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4253 - acc: 0.8036
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4284 - acc: 0.7996
1283/1283 [==============================] - 0s 319us/step - loss: 0.4238 - acc: 0.8083 - val_loss: 0.9746 - val_acc: 0.5546

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4328 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3977 - acc: 0.7930
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4185 - acc: 0.7790
 576/1283 [============>.................] - ETA: 0s - loss: 0.3963 - acc: 0.8073
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3968 - acc: 0.8054
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4001 - acc: 0.7991
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4060 - acc: 0.7960
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3997 - acc: 0.8026
1283/1283 [==============================] - 0s 367us/step - loss: 0.3960 - acc: 0.8059 - val_loss: 0.9011 - val_acc: 0.5415

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3650 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3527 - acc: 0.8477
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3511 - acc: 0.8438
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3513 - acc: 0.8477
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3363 - acc: 0.8551
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3293 - acc: 0.8549
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3175 - acc: 0.8663
1283/1283 [==============================] - 0s 364us/step - loss: 0.3163 - acc: 0.8667 - val_loss: 0.8451 - val_acc: 0.5590

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2208 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2131 - acc: 0.9297
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2312 - acc: 0.9219
 640/1283 [=============>................] - ETA: 0s - loss: 0.2378 - acc: 0.9156
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2418 - acc: 0.9099
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2401 - acc: 0.9062
1280/1283 [============================>.] - ETA: 0s - loss: 0.2375 - acc: 0.9078
1283/1283 [==============================] - 0s 320us/step - loss: 0.2371 - acc: 0.9080 - val_loss: 0.9328 - val_acc: 0.5677

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1594 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1764 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1738 - acc: 0.9375
 576/1283 [============>.................] - ETA: 0s - loss: 0.1807 - acc: 0.9375
 768/1283 [================>.............] - ETA: 0s - loss: 0.1798 - acc: 0.9349
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1783 - acc: 0.9365
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1749 - acc: 0.9383
1283/1283 [==============================] - 0s 336us/step - loss: 0.1742 - acc: 0.9400 - val_loss: 1.0947 - val_acc: 0.5459

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0974 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1105 - acc: 0.9727
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1224 - acc: 0.9621
 640/1283 [=============>................] - ETA: 0s - loss: 0.1256 - acc: 0.9641
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1206 - acc: 0.9675
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1202 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1206 - acc: 0.9679
1283/1283 [==============================] - 0s 380us/step - loss: 0.1216 - acc: 0.9657 - val_loss: 1.1814 - val_acc: 0.5459

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1112 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0863 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0890 - acc: 0.9818
 576/1283 [============>.................] - ETA: 0s - loss: 0.0875 - acc: 0.9809
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0894 - acc: 0.9787
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0897 - acc: 0.9772
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0905 - acc: 0.9781
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0898 - acc: 0.9792
1283/1283 [==============================] - 1s 403us/step - loss: 0.0877 - acc: 0.9805 - val_loss: 1.3242 - val_acc: 0.5371

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0676 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0670 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0608 - acc: 0.9896
 576/1283 [============>.................] - ETA: 0s - loss: 0.0584 - acc: 0.9913
 768/1283 [================>.............] - ETA: 0s - loss: 0.0603 - acc: 0.9870
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0586 - acc: 0.9865
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0587 - acc: 0.9844
1283/1283 [==============================] - 0s 351us/step - loss: 0.0608 - acc: 0.9844 - val_loss: 1.3992 - val_acc: 0.5328

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0556 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0908 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0766 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0738 - acc: 0.9750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0748 - acc: 0.9736
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0685 - acc: 0.9775
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0654 - acc: 0.9794
1283/1283 [==============================] - 0s 349us/step - loss: 0.0658 - acc: 0.9790 - val_loss: 1.6056 - val_acc: 0.5328

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0303 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0627 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0528 - acc: 0.9812
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0620 - acc: 0.9785
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0584 - acc: 0.9815
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0597 - acc: 0.9808
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0573 - acc: 0.9823
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0640 - acc: 0.9792
1283/1283 [==============================] - 1s 398us/step - loss: 0.0628 - acc: 0.9790 - val_loss: 1.7396 - val_acc: 0.4803

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=25
PCA text=100
accuracy=0.532069970845481
best_valid_accuracy=0.5174927113702624
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:24:07.499494: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 27s - loss: 0.7093 - acc: 0.4844
 192/1283 [===>..........................] - ETA: 8s - loss: 0.7217 - acc: 0.5000 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.7176 - acc: 0.5156
 448/1283 [=========>....................] - ETA: 3s - loss: 0.7194 - acc: 0.5156
 576/1283 [============>.................] - ETA: 2s - loss: 0.7150 - acc: 0.5278
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7108 - acc: 0.5355
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7073 - acc: 0.5361
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7043 - acc: 0.5375
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7031 - acc: 0.5399
1280/1283 [============================>.] - ETA: 0s - loss: 0.7013 - acc: 0.5453
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7013 - acc: 0.5448 - val_loss: 0.6979 - val_acc: 0.4891

Epoch 00001: val_acc improved from -inf to 0.48908, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6003 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.6343 - acc: 0.6953
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6213 - acc: 0.6719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6303 - acc: 0.6562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6302 - acc: 0.6562
 576/1283 [============>.................] - ETA: 0s - loss: 0.6305 - acc: 0.6580
 640/1283 [=============>................] - ETA: 0s - loss: 0.6327 - acc: 0.6562
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6348 - acc: 0.6520
 768/1283 [================>.............] - ETA: 0s - loss: 0.6342 - acc: 0.6536
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6296 - acc: 0.6599
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6268 - acc: 0.6607
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6313 - acc: 0.6562
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6289 - acc: 0.6615
1280/1283 [============================>.] - ETA: 0s - loss: 0.6273 - acc: 0.6625
1283/1283 [==============================] - 1s 732us/step - loss: 0.6273 - acc: 0.6625 - val_loss: 0.6891 - val_acc: 0.5415

Epoch 00002: val_acc improved from 0.48908 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5691 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5562 - acc: 0.7344
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5529 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5503 - acc: 0.7612
 576/1283 [============>.................] - ETA: 0s - loss: 0.5560 - acc: 0.7431
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5663 - acc: 0.7230
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5680 - acc: 0.7236
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5679 - acc: 0.7177
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5706 - acc: 0.7161
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5681 - acc: 0.7179
1280/1283 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.7156
1283/1283 [==============================] - 1s 619us/step - loss: 0.5698 - acc: 0.7163 - val_loss: 0.7167 - val_acc: 0.5808

Epoch 00003: val_acc improved from 0.54148 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5386 - acc: 0.7344
 128/1283 [=>............................] - ETA: 1s - loss: 0.5186 - acc: 0.7891
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5016 - acc: 0.7930
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4992 - acc: 0.7839
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5011 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.5013 - acc: 0.7795
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4954 - acc: 0.7855
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4920 - acc: 0.7849
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4970 - acc: 0.7740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4959 - acc: 0.7721
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4939 - acc: 0.7730
1283/1283 [==============================] - 1s 690us/step - loss: 0.4934 - acc: 0.7740 - val_loss: 0.8062 - val_acc: 0.5677

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4763 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4148 - acc: 0.8229
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4222 - acc: 0.8125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4152 - acc: 0.8192
 576/1283 [============>.................] - ETA: 0s - loss: 0.4250 - acc: 0.8125
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4134 - acc: 0.8210
 768/1283 [================>.............] - ETA: 0s - loss: 0.4197 - acc: 0.8164
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4164 - acc: 0.8170
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4100 - acc: 0.8229
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4107 - acc: 0.8217
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4073 - acc: 0.8257
1283/1283 [==============================] - 1s 666us/step - loss: 0.4056 - acc: 0.8270 - val_loss: 0.7534 - val_acc: 0.5546

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3433 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3631 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3428 - acc: 0.8625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3599 - acc: 0.8393
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3619 - acc: 0.8379
 640/1283 [=============>................] - ETA: 0s - loss: 0.3558 - acc: 0.8391
 768/1283 [================>.............] - ETA: 0s - loss: 0.3554 - acc: 0.8359
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3547 - acc: 0.8371
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3473 - acc: 0.8477
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3458 - acc: 0.8507
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3413 - acc: 0.8528
1283/1283 [==============================] - 1s 568us/step - loss: 0.3401 - acc: 0.8535 - val_loss: 0.7999 - val_acc: 0.5459

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2781 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2617 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2478 - acc: 0.9344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2602 - acc: 0.9196
 576/1283 [============>.................] - ETA: 0s - loss: 0.2547 - acc: 0.9219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2523 - acc: 0.9219
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2540 - acc: 0.9231
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2495 - acc: 0.9250
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2513 - acc: 0.9219
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2497 - acc: 0.9202
1280/1283 [============================>.] - ETA: 0s - loss: 0.2518 - acc: 0.9148
1283/1283 [==============================] - 1s 640us/step - loss: 0.2515 - acc: 0.9150 - val_loss: 0.9377 - val_acc: 0.5546

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1939 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1738 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1766 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1746 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1664 - acc: 0.9583
 640/1283 [=============>................] - ETA: 0s - loss: 0.1651 - acc: 0.9594
 768/1283 [================>.............] - ETA: 0s - loss: 0.1658 - acc: 0.9570
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1649 - acc: 0.9542
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1643 - acc: 0.9541
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1681 - acc: 0.9497
1280/1283 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9477
1283/1283 [==============================] - 1s 684us/step - loss: 0.1711 - acc: 0.9478 - val_loss: 0.9824 - val_acc: 0.5546

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1099 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1268 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1234 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1292 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1283 - acc: 0.9583
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1295 - acc: 0.9574
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1318 - acc: 0.9579
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1273 - acc: 0.9615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1270 - acc: 0.9639
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1241 - acc: 0.9638
1283/1283 [==============================] - 1s 694us/step - loss: 0.1239 - acc: 0.9634 - val_loss: 1.1571 - val_acc: 0.5240

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1373 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1146 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1008 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1023 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.1027 - acc: 0.9705
 640/1283 [=============>................] - ETA: 0s - loss: 0.0982 - acc: 0.9734
 768/1283 [================>.............] - ETA: 0s - loss: 0.0999 - acc: 0.9740
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0983 - acc: 0.9754
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0990 - acc: 0.9736
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0996 - acc: 0.9714
1280/1283 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9719
1283/1283 [==============================] - 1s 660us/step - loss: 0.0988 - acc: 0.9719 - val_loss: 1.3514 - val_acc: 0.5371

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1013 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1054 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1121 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1186 - acc: 0.9576
 640/1283 [=============>................] - ETA: 0s - loss: 0.1154 - acc: 0.9609
 768/1283 [================>.............] - ETA: 0s - loss: 0.1148 - acc: 0.9648
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1163 - acc: 0.9635
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1211 - acc: 0.9609
1280/1283 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9625
1283/1283 [==============================] - 1s 454us/step - loss: 0.1201 - acc: 0.9618 - val_loss: 1.3946 - val_acc: 0.5284

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0728 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1596 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1658 - acc: 0.9297
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1752 - acc: 0.9277
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1765 - acc: 0.9276
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1795 - acc: 0.9207
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1770 - acc: 0.9229
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1744 - acc: 0.9252
1280/1283 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9266
1283/1283 [==============================] - 1s 457us/step - loss: 0.1730 - acc: 0.9267 - val_loss: 1.5729 - val_acc: 0.4934

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1038 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1008 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0939 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0893 - acc: 0.9766
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0888 - acc: 0.9785
 640/1283 [=============>................] - ETA: 0s - loss: 0.0920 - acc: 0.9719
 768/1283 [================>.............] - ETA: 0s - loss: 0.0914 - acc: 0.9727
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0896 - acc: 0.9732
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0866 - acc: 0.9756
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0844 - acc: 0.9766
1280/1283 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9758
1283/1283 [==============================] - 1s 639us/step - loss: 0.0842 - acc: 0.9758 - val_loss: 1.6862 - val_acc: 0.5415

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=30
PCA text=100
accuracy=0.49271137026239065
best_valid_accuracy=0.49854227405247814
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:44:54.137956: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.7121 - acc: 0.5625
 256/1283 [====>.........................] - ETA: 0s - loss: 0.7339 - acc: 0.5312
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7353 - acc: 0.5312
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7316 - acc: 0.5185
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7247 - acc: 0.5252
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7162 - acc: 0.5303
1280/1283 [============================>.] - ETA: 0s - loss: 0.7140 - acc: 0.5297
1283/1283 [==============================] - 1s 433us/step - loss: 0.7138 - acc: 0.5308 - val_loss: 0.6969 - val_acc: 0.5197

Epoch 00001: val_acc improved from -inf to 0.51965, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6178 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6065 - acc: 0.6992
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6097 - acc: 0.6786
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6034 - acc: 0.6861
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6084 - acc: 0.6823
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6071 - acc: 0.6850
1283/1283 [==============================] - 0s 267us/step - loss: 0.6092 - acc: 0.6789 - val_loss: 0.7045 - val_acc: 0.5328

Epoch 00002: val_acc improved from 0.51965 to 0.53275, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5785 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5575 - acc: 0.7344
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5489 - acc: 0.7480
 768/1283 [================>.............] - ETA: 0s - loss: 0.5382 - acc: 0.7630
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5465 - acc: 0.7510
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5440 - acc: 0.7467
1283/1283 [==============================] - 0s 266us/step - loss: 0.5415 - acc: 0.7482 - val_loss: 0.7149 - val_acc: 0.5677

Epoch 00003: val_acc improved from 0.53275 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4624 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4576 - acc: 0.8187
 576/1283 [============>.................] - ETA: 0s - loss: 0.4653 - acc: 0.8021
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4732 - acc: 0.7879
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4707 - acc: 0.7891
1283/1283 [==============================] - 0s 224us/step - loss: 0.4696 - acc: 0.7864 - val_loss: 0.7941 - val_acc: 0.5590

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4496 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4183 - acc: 0.8203
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3973 - acc: 0.8340
 768/1283 [================>.............] - ETA: 0s - loss: 0.3911 - acc: 0.8438
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3824 - acc: 0.8448
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3758 - acc: 0.8481
1283/1283 [==============================] - 0s 305us/step - loss: 0.3769 - acc: 0.8426 - val_loss: 0.8464 - val_acc: 0.5328

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2941 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3466 - acc: 0.8477
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3368 - acc: 0.8646
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3494 - acc: 0.8516
 768/1283 [================>.............] - ETA: 0s - loss: 0.3336 - acc: 0.8672
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3245 - acc: 0.8711
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3279 - acc: 0.8635
1283/1283 [==============================] - 0s 348us/step - loss: 0.3279 - acc: 0.8659 - val_loss: 0.9573 - val_acc: 0.5590

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2561 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2523 - acc: 0.9125
 576/1283 [============>.................] - ETA: 0s - loss: 0.2525 - acc: 0.9149
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2533 - acc: 0.9062
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2542 - acc: 0.9062
1280/1283 [============================>.] - ETA: 0s - loss: 0.2593 - acc: 0.9031
1283/1283 [==============================] - 0s 276us/step - loss: 0.2589 - acc: 0.9034 - val_loss: 0.8807 - val_acc: 0.5764

Epoch 00007: val_acc improved from 0.56769 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2003 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1822 - acc: 0.9414
 576/1283 [============>.................] - ETA: 0s - loss: 0.1897 - acc: 0.9323
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1979 - acc: 0.9339
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1899 - acc: 0.9414
1283/1283 [==============================] - 0s 240us/step - loss: 0.1887 - acc: 0.9408 - val_loss: 1.0742 - val_acc: 0.5764

Epoch 00008: val_acc improved from 0.57642 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1116 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1547 - acc: 0.9563
 640/1283 [=============>................] - ETA: 0s - loss: 0.1496 - acc: 0.9625
 768/1283 [================>.............] - ETA: 0s - loss: 0.1555 - acc: 0.9557
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1580 - acc: 0.9521
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1610 - acc: 0.9498
1283/1283 [==============================] - 0s 251us/step - loss: 0.1588 - acc: 0.9509 - val_loss: 1.1502 - val_acc: 0.5808

Epoch 00009: val_acc improved from 0.57642 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1493 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1450 - acc: 0.9531
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1356 - acc: 0.9512
 768/1283 [================>.............] - ETA: 0s - loss: 0.1246 - acc: 0.9570
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1188 - acc: 0.9639
1280/1283 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9664
1283/1283 [==============================] - 0s 247us/step - loss: 0.1158 - acc: 0.9665 - val_loss: 1.3605 - val_acc: 0.5852

Epoch 00010: val_acc improved from 0.58079 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0862 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0968 - acc: 0.9727
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0898 - acc: 0.9732
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1027 - acc: 0.9631
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0982 - acc: 0.9643
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1006 - acc: 0.9639
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0995 - acc: 0.9622
1283/1283 [==============================] - 0s 383us/step - loss: 0.0990 - acc: 0.9641 - val_loss: 1.3531 - val_acc: 0.5633

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0866 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0790 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0815 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0837 - acc: 0.9665
 640/1283 [=============>................] - ETA: 0s - loss: 0.0742 - acc: 0.9750
 768/1283 [================>.............] - ETA: 0s - loss: 0.0744 - acc: 0.9753
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0676 - acc: 0.9795
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0651 - acc: 0.9818
1283/1283 [==============================] - 0s 390us/step - loss: 0.0674 - acc: 0.9790 - val_loss: 1.3653 - val_acc: 0.5939

Epoch 00012: val_acc improved from 0.58515 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_20.ckpt
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0446 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0518 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0569 - acc: 0.9821
 640/1283 [=============>................] - ETA: 0s - loss: 0.0591 - acc: 0.9812
 768/1283 [================>.............] - ETA: 0s - loss: 0.0602 - acc: 0.9805
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0560 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0593 - acc: 0.9835
1280/1283 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9836
1283/1283 [==============================] - 1s 606us/step - loss: 0.0593 - acc: 0.9836 - val_loss: 1.4045 - val_acc: 0.5677

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0541 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0627 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0607 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0636 - acc: 0.9866
 576/1283 [============>.................] - ETA: 0s - loss: 0.0679 - acc: 0.9809
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0676 - acc: 0.9796
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0677 - acc: 0.9799
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0660 - acc: 0.9812
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0656 - acc: 0.9800
1280/1283 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9805
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0651 - acc: 0.9805 - val_loss: 1.6286 - val_acc: 0.5546

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0428 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0331 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0388 - acc: 0.9915
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0388 - acc: 0.9902
1280/1283 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9906
1283/1283 [==============================] - 0s 213us/step - loss: 0.0375 - acc: 0.9906 - val_loss: 1.6537 - val_acc: 0.5808

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0322 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0246 - acc: 0.9938
 576/1283 [============>.................] - ETA: 0s - loss: 0.0250 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0256 - acc: 0.9943
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0276 - acc: 0.9922
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0288 - acc: 0.9918
1283/1283 [==============================] - 0s 294us/step - loss: 0.0292 - acc: 0.9914 - val_loss: 1.7064 - val_acc: 0.5721

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0337 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0219 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0234 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0269 - acc: 0.9896
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0287 - acc: 0.9886
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0262 - acc: 0.9904
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0283 - acc: 0.9881
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0285 - acc: 0.9878
1280/1283 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9875
1283/1283 [==============================] - 1s 886us/step - loss: 0.0281 - acc: 0.9875 - val_loss: 1.7574 - val_acc: 0.5677

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0077 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0159 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0202 - acc: 0.9933
 768/1283 [================>.............] - ETA: 0s - loss: 0.0234 - acc: 0.9922
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0242 - acc: 0.9912
1280/1283 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9914
1283/1283 [==============================] - 0s 316us/step - loss: 0.0231 - acc: 0.9914 - val_loss: 1.8374 - val_acc: 0.5808

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0091 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0264 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0194 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0206 - acc: 0.9922
 768/1283 [================>.............] - ETA: 0s - loss: 0.0201 - acc: 0.9935
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0214 - acc: 0.9922
1280/1283 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9922
1283/1283 [==============================] - 1s 610us/step - loss: 0.0209 - acc: 0.9922 - val_loss: 1.8804 - val_acc: 0.5808

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0134 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0382 - acc: 0.9875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0329 - acc: 0.9922
 768/1283 [================>.............] - ETA: 0s - loss: 0.0423 - acc: 0.9883
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0406 - acc: 0.9873
1280/1283 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9859
1283/1283 [==============================] - 0s 273us/step - loss: 0.0393 - acc: 0.9860 - val_loss: 2.0016 - val_acc: 0.5590

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0277 - acc: 0.9888
 640/1283 [=============>................] - ETA: 0s - loss: 0.0241 - acc: 0.9922
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0236 - acc: 0.9922
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0236 - acc: 0.9917
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0248 - acc: 0.9905
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0256 - acc: 0.9901
1280/1283 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9906
1283/1283 [==============================] - 1s 604us/step - loss: 0.0247 - acc: 0.9906 - val_loss: 2.0082 - val_acc: 0.5633

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0076 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0174 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0171 - acc: 0.9955
 640/1283 [=============>................] - ETA: 0s - loss: 0.0209 - acc: 0.9922
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0261 - acc: 0.9911
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0252 - acc: 0.9913
1283/1283 [==============================] - 0s 271us/step - loss: 0.0259 - acc: 0.9914 - val_loss: 2.1712 - val_acc: 0.5677

Epoch 00022: val_acc did not improve
Epoch 00022: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=35
PCA text=100
accuracy=0.5145772594752187
best_valid_accuracy=0.4620991253644315
