/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:12:26.119867: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 16s - loss: 0.6977 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 5s - loss: 0.6919 - acc: 0.5625 
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6953 - acc: 0.5281
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7017 - acc: 0.5022
 576/1283 [============>.................] - ETA: 1s - loss: 0.6996 - acc: 0.5069
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7009 - acc: 0.4915
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6987 - acc: 0.4940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6975 - acc: 0.5031
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6983 - acc: 0.5028
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6989 - acc: 0.4984
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6986 - acc: 0.4973 - val_loss: 0.6892 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6964 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6926 - acc: 0.5208
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6894 - acc: 0.5375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6866 - acc: 0.5536
 576/1283 [============>.................] - ETA: 0s - loss: 0.6820 - acc: 0.5764
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6792 - acc: 0.5852
 768/1283 [================>.............] - ETA: 0s - loss: 0.6806 - acc: 0.5781
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6803 - acc: 0.5781
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6775 - acc: 0.5840
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6787 - acc: 0.5773
1280/1283 [============================>.] - ETA: 0s - loss: 0.6789 - acc: 0.5750
1283/1283 [==============================] - 1s 603us/step - loss: 0.6793 - acc: 0.5744 - val_loss: 0.6829 - val_acc: 0.5764

Epoch 00002: val_acc improved from 0.52838 to 0.57642, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6390 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6604 - acc: 0.6146
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6682 - acc: 0.5813
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6753 - acc: 0.5759
 576/1283 [============>.................] - ETA: 0s - loss: 0.6793 - acc: 0.5590
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6770 - acc: 0.5653
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6748 - acc: 0.5757
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6761 - acc: 0.5708
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6763 - acc: 0.5680
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6755 - acc: 0.5707
1283/1283 [==============================] - 1s 551us/step - loss: 0.6755 - acc: 0.5729 - val_loss: 0.6798 - val_acc: 0.5939

Epoch 00003: val_acc improved from 0.57642 to 0.59389, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6448 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6861 - acc: 0.5469
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6835 - acc: 0.5625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6717 - acc: 0.5871
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6742 - acc: 0.5781
 640/1283 [=============>................] - ETA: 0s - loss: 0.6721 - acc: 0.5859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6704 - acc: 0.5923
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6699 - acc: 0.5901
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6682 - acc: 0.5960
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6705 - acc: 0.5906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6680 - acc: 0.5882
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6696 - acc: 0.5859
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6685 - acc: 0.5888
1283/1283 [==============================] - 1s 868us/step - loss: 0.6676 - acc: 0.5947 - val_loss: 0.6805 - val_acc: 0.5502

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6505 - acc: 0.5938
 128/1283 [=>............................] - ETA: 1s - loss: 0.6395 - acc: 0.6328
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6532 - acc: 0.6042
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6507 - acc: 0.6211
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6499 - acc: 0.6219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6579 - acc: 0.6027
 576/1283 [============>.................] - ETA: 0s - loss: 0.6568 - acc: 0.6163
 640/1283 [=============>................] - ETA: 0s - loss: 0.6628 - acc: 0.6078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6608 - acc: 0.6108
 768/1283 [================>.............] - ETA: 0s - loss: 0.6610 - acc: 0.6120
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6613 - acc: 0.6094
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6626 - acc: 0.6010
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6619 - acc: 0.6035
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6604 - acc: 0.6050
1280/1283 [============================>.] - ETA: 0s - loss: 0.6588 - acc: 0.6078
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6589 - acc: 0.6072 - val_loss: 0.6843 - val_acc: 0.5459

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6378 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6467 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6442 - acc: 0.6344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6530 - acc: 0.6183
 576/1283 [============>.................] - ETA: 0s - loss: 0.6451 - acc: 0.6267
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6593 - acc: 0.6051
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6551 - acc: 0.6142
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6578 - acc: 0.6049
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6529 - acc: 0.6143
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6551 - acc: 0.6094
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6564 - acc: 0.6077
1283/1283 [==============================] - 1s 830us/step - loss: 0.6573 - acc: 0.6041 - val_loss: 0.6937 - val_acc: 0.5284

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6795 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6643 - acc: 0.6042
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6611 - acc: 0.6219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6600 - acc: 0.6362
 576/1283 [============>.................] - ETA: 0s - loss: 0.6563 - acc: 0.6319
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6480 - acc: 0.6349
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6492 - acc: 0.6286
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6469 - acc: 0.6323
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6512 - acc: 0.6278
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6501 - acc: 0.6250
1283/1283 [==============================] - 1s 779us/step - loss: 0.6508 - acc: 0.6189 - val_loss: 0.6964 - val_acc: 0.5328

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.7262 - acc: 0.4531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6551 - acc: 0.5885
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6606 - acc: 0.5906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6606 - acc: 0.5960
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6548 - acc: 0.6035
 640/1283 [=============>................] - ETA: 0s - loss: 0.6533 - acc: 0.6094
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6555 - acc: 0.6065
 768/1283 [================>.............] - ETA: 0s - loss: 0.6530 - acc: 0.6094
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6525 - acc: 0.6130
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6506 - acc: 0.6188
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6505 - acc: 0.6195
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6514 - acc: 0.6151
1283/1283 [==============================] - 1s 875us/step - loss: 0.6497 - acc: 0.6150 - val_loss: 0.6962 - val_acc: 0.5328

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6317 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6165 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6200 - acc: 0.6531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6233 - acc: 0.6473
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6365 - acc: 0.6211
 576/1283 [============>.................] - ETA: 0s - loss: 0.6364 - acc: 0.6250
 640/1283 [=============>................] - ETA: 0s - loss: 0.6396 - acc: 0.6203
 768/1283 [================>.............] - ETA: 0s - loss: 0.6394 - acc: 0.6263
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6371 - acc: 0.6298
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6345 - acc: 0.6362
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6360 - acc: 0.6354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6368 - acc: 0.6396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6340 - acc: 0.6443
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6364 - acc: 0.6398
1280/1283 [============================>.] - ETA: 0s - loss: 0.6362 - acc: 0.6414
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6362 - acc: 0.6415 - val_loss: 0.6947 - val_acc: 0.5633

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6346 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.6105 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6086 - acc: 0.6510
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6106 - acc: 0.6445
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6247 - acc: 0.6344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6221 - acc: 0.6432
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6247 - acc: 0.6496
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6230 - acc: 0.6484
 640/1283 [=============>................] - ETA: 0s - loss: 0.6287 - acc: 0.6469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6238 - acc: 0.6491
 768/1283 [================>.............] - ETA: 0s - loss: 0.6157 - acc: 0.6641
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6132 - acc: 0.6647
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6185 - acc: 0.6562
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6242 - acc: 0.6500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6246 - acc: 0.6484
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6254 - acc: 0.6452
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6272 - acc: 0.6458
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6338 - acc: 0.6365
1280/1283 [============================>.] - ETA: 0s - loss: 0.6349 - acc: 0.6336
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6348 - acc: 0.6337 - val_loss: 0.6900 - val_acc: 0.5546

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.7379 - acc: 0.4531
 128/1283 [=>............................] - ETA: 2s - loss: 0.6753 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 2s - loss: 0.6510 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 2s - loss: 0.6322 - acc: 0.6172
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6356 - acc: 0.6031
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6347 - acc: 0.6094
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6327 - acc: 0.6094
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6334 - acc: 0.6074
 576/1283 [============>.................] - ETA: 1s - loss: 0.6306 - acc: 0.6163
 640/1283 [=============>................] - ETA: 0s - loss: 0.6292 - acc: 0.6219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6325 - acc: 0.6151
 768/1283 [================>.............] - ETA: 0s - loss: 0.6270 - acc: 0.6237
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6293 - acc: 0.6238
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6266 - acc: 0.6344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6314 - acc: 0.6318
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6312 - acc: 0.6342
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6272 - acc: 0.6398
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6289 - acc: 0.6398
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6283 - acc: 0.6376 - val_loss: 0.6994 - val_acc: 0.5371

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6269 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6391 - acc: 0.6484
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6146 - acc: 0.6771
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6210 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6228 - acc: 0.6687
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6170 - acc: 0.6797
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6139 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6068 - acc: 0.6992
 576/1283 [============>.................] - ETA: 0s - loss: 0.6086 - acc: 0.6962
 640/1283 [=============>................] - ETA: 0s - loss: 0.6064 - acc: 0.7016
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6120 - acc: 0.6960
 768/1283 [================>.............] - ETA: 0s - loss: 0.6088 - acc: 0.7005
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6112 - acc: 0.6923
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6137 - acc: 0.6886
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6147 - acc: 0.6813
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6209 - acc: 0.6729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6197 - acc: 0.6746
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6195 - acc: 0.6701
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6208 - acc: 0.6653
1280/1283 [============================>.] - ETA: 0s - loss: 0.6197 - acc: 0.6648
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6203 - acc: 0.6641 - val_loss: 0.7048 - val_acc: 0.5371

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5940 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.5766 - acc: 0.7266
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5897 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6017 - acc: 0.6836
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6117 - acc: 0.6719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6097 - acc: 0.6849
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6118 - acc: 0.6741
 576/1283 [============>.................] - ETA: 0s - loss: 0.6100 - acc: 0.6823
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6130 - acc: 0.6761
 768/1283 [================>.............] - ETA: 0s - loss: 0.6106 - acc: 0.6810
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6121 - acc: 0.6741
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6099 - acc: 0.6740
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6094 - acc: 0.6738
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6094 - acc: 0.6746
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6130 - acc: 0.6684
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6137 - acc: 0.6694
1280/1283 [============================>.] - ETA: 0s - loss: 0.6174 - acc: 0.6633
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6176 - acc: 0.6633 - val_loss: 0.6947 - val_acc: 0.5590

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5262390670553936
best_valid_accuracy=0.4679300291545189
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:21:11.655179: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.6904 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 4s - loss: 0.6864 - acc: 0.5365 
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6899 - acc: 0.5312
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6932 - acc: 0.5156
 576/1283 [============>.................] - ETA: 1s - loss: 0.6945 - acc: 0.5156
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6948 - acc: 0.5128
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6920 - acc: 0.5240
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6929 - acc: 0.5229
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6949 - acc: 0.5211
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6956 - acc: 0.5173
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6940 - acc: 0.5230 - val_loss: 0.6802 - val_acc: 0.5808

Epoch 00001: val_acc improved from -inf to 0.58079, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6767 - acc: 0.5469
 128/1283 [=>............................] - ETA: 0s - loss: 0.6784 - acc: 0.5703
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6716 - acc: 0.5938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6649 - acc: 0.6224
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6713 - acc: 0.5996
 640/1283 [=============>................] - ETA: 0s - loss: 0.6724 - acc: 0.5953
 768/1283 [================>.............] - ETA: 0s - loss: 0.6774 - acc: 0.5755
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6791 - acc: 0.5681
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6760 - acc: 0.5762
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6757 - acc: 0.5773
1280/1283 [============================>.] - ETA: 0s - loss: 0.6753 - acc: 0.5789
1283/1283 [==============================] - 1s 622us/step - loss: 0.6753 - acc: 0.5791 - val_loss: 0.6790 - val_acc: 0.5459

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6501 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6603 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6711 - acc: 0.5938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6677 - acc: 0.6146
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6696 - acc: 0.6071
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6695 - acc: 0.6074
 640/1283 [=============>................] - ETA: 0s - loss: 0.6696 - acc: 0.5984
 768/1283 [================>.............] - ETA: 0s - loss: 0.6649 - acc: 0.6146
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6689 - acc: 0.6083
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6676 - acc: 0.6123
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6640 - acc: 0.6181
1280/1283 [============================>.] - ETA: 0s - loss: 0.6653 - acc: 0.6086
1283/1283 [==============================] - 1s 799us/step - loss: 0.6651 - acc: 0.6087 - val_loss: 0.6760 - val_acc: 0.5895

Epoch 00003: val_acc improved from 0.58079 to 0.58952, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6707 - acc: 0.5781
 128/1283 [=>............................] - ETA: 0s - loss: 0.6503 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6575 - acc: 0.6016
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6503 - acc: 0.6188
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6527 - acc: 0.6116
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6518 - acc: 0.6055
 640/1283 [=============>................] - ETA: 0s - loss: 0.6558 - acc: 0.6031
 768/1283 [================>.............] - ETA: 0s - loss: 0.6568 - acc: 0.6068
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6561 - acc: 0.6094
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6560 - acc: 0.6083
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6591 - acc: 0.6074
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6592 - acc: 0.6039
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6579 - acc: 0.6076
1280/1283 [============================>.] - ETA: 0s - loss: 0.6577 - acc: 0.6133
1283/1283 [==============================] - 1s 863us/step - loss: 0.6573 - acc: 0.6142 - val_loss: 0.6809 - val_acc: 0.5852

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6783 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6607 - acc: 0.6146
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6506 - acc: 0.6438
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6546 - acc: 0.6276
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6559 - acc: 0.6272
 576/1283 [============>.................] - ETA: 0s - loss: 0.6510 - acc: 0.6233
 640/1283 [=============>................] - ETA: 0s - loss: 0.6497 - acc: 0.6250
 768/1283 [================>.............] - ETA: 0s - loss: 0.6478 - acc: 0.6250
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6518 - acc: 0.6217
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6498 - acc: 0.6281
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6471 - acc: 0.6296
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6473 - acc: 0.6283
1283/1283 [==============================] - 1s 858us/step - loss: 0.6491 - acc: 0.6251 - val_loss: 0.6831 - val_acc: 0.5939

Epoch 00005: val_acc improved from 0.58952 to 0.59389, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6358 - acc: 0.6250
 128/1283 [=>............................] - ETA: 0s - loss: 0.6438 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6362 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6351 - acc: 0.6367
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6362 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6301 - acc: 0.6484
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6328 - acc: 0.6523
 576/1283 [============>.................] - ETA: 0s - loss: 0.6343 - acc: 0.6545
 640/1283 [=============>................] - ETA: 0s - loss: 0.6406 - acc: 0.6484
 768/1283 [================>.............] - ETA: 0s - loss: 0.6403 - acc: 0.6510
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6357 - acc: 0.6538
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6332 - acc: 0.6542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6361 - acc: 0.6480
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6401 - acc: 0.6390
1280/1283 [============================>.] - ETA: 0s - loss: 0.6397 - acc: 0.6414
1283/1283 [==============================] - 1s 881us/step - loss: 0.6399 - acc: 0.6407 - val_loss: 0.6820 - val_acc: 0.6114

Epoch 00006: val_acc improved from 0.59389 to 0.61135, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6224 - acc: 0.6406
 128/1283 [=>............................] - ETA: 0s - loss: 0.6513 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6515 - acc: 0.5990
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6466 - acc: 0.6172
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6314 - acc: 0.6354
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6275 - acc: 0.6362
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6286 - acc: 0.6270
 640/1283 [=============>................] - ETA: 0s - loss: 0.6337 - acc: 0.6172
 768/1283 [================>.............] - ETA: 0s - loss: 0.6367 - acc: 0.6120
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6391 - acc: 0.6194
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6442 - acc: 0.6167
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6442 - acc: 0.6133
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6455 - acc: 0.6112
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6404 - acc: 0.6209
1283/1283 [==============================] - 1s 897us/step - loss: 0.6388 - acc: 0.6267 - val_loss: 0.6798 - val_acc: 0.5808

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5821 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6239 - acc: 0.6510
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6293 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6292 - acc: 0.6406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6398 - acc: 0.6317
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6328 - acc: 0.6367
 640/1283 [=============>................] - ETA: 0s - loss: 0.6412 - acc: 0.6312
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6382 - acc: 0.6321
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6364 - acc: 0.6346
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6371 - acc: 0.6306
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6366 - acc: 0.6323
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6388 - acc: 0.6338
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6365 - acc: 0.6351
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6315 - acc: 0.6415
1280/1283 [============================>.] - ETA: 0s - loss: 0.6285 - acc: 0.6422
1283/1283 [==============================] - 1s 899us/step - loss: 0.6283 - acc: 0.6430 - val_loss: 0.6825 - val_acc: 0.5939

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5678 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6271 - acc: 0.6458
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6133 - acc: 0.6625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6086 - acc: 0.6719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6135 - acc: 0.6674
 576/1283 [============>.................] - ETA: 0s - loss: 0.6085 - acc: 0.6701
 640/1283 [=============>................] - ETA: 0s - loss: 0.6074 - acc: 0.6734
 768/1283 [================>.............] - ETA: 0s - loss: 0.6132 - acc: 0.6615
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6197 - acc: 0.6502
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6152 - acc: 0.6615
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6157 - acc: 0.6599
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6146 - acc: 0.6589
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6136 - acc: 0.6587
1283/1283 [==============================] - 1s 891us/step - loss: 0.6132 - acc: 0.6625 - val_loss: 0.6837 - val_acc: 0.5852

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5839 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5861 - acc: 0.7135
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6185 - acc: 0.6758
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6162 - acc: 0.6687
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6100 - acc: 0.6652
 576/1283 [============>.................] - ETA: 0s - loss: 0.6063 - acc: 0.6649
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6055 - acc: 0.6562
 768/1283 [================>.............] - ETA: 0s - loss: 0.6085 - acc: 0.6549
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6098 - acc: 0.6538
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6076 - acc: 0.6607
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6023 - acc: 0.6698
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6043 - acc: 0.6680
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6033 - acc: 0.6675
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6040 - acc: 0.6711
1283/1283 [==============================] - 1s 858us/step - loss: 0.6037 - acc: 0.6711 - val_loss: 0.6926 - val_acc: 0.5808

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5697 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5756 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5829 - acc: 0.6969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5831 - acc: 0.7054
 576/1283 [============>.................] - ETA: 0s - loss: 0.5892 - acc: 0.6927
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5900 - acc: 0.6889
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5857 - acc: 0.6983
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5832 - acc: 0.7009
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5883 - acc: 0.6865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5890 - acc: 0.6847
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5881 - acc: 0.6832
1280/1283 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.6813
1283/1283 [==============================] - 1s 810us/step - loss: 0.5923 - acc: 0.6797 - val_loss: 0.6913 - val_acc: 0.5895

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5343 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5693 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5723 - acc: 0.7031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5715 - acc: 0.7057
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5755 - acc: 0.7009
 576/1283 [============>.................] - ETA: 0s - loss: 0.5888 - acc: 0.6701
 640/1283 [=============>................] - ETA: 0s - loss: 0.5910 - acc: 0.6672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5924 - acc: 0.6619
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5884 - acc: 0.6659
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5853 - acc: 0.6685
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5820 - acc: 0.6740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5836 - acc: 0.6820
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5829 - acc: 0.6832
1280/1283 [============================>.] - ETA: 0s - loss: 0.5820 - acc: 0.6844
1283/1283 [==============================] - 1s 910us/step - loss: 0.5814 - acc: 0.6851 - val_loss: 0.6900 - val_acc: 0.5939

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5539 - acc: 0.7656
 128/1283 [=>............................] - ETA: 1s - loss: 0.5334 - acc: 0.7734
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5312 - acc: 0.7552
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5552 - acc: 0.7383
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5549 - acc: 0.7406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5537 - acc: 0.7344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5584 - acc: 0.7299
 576/1283 [============>.................] - ETA: 0s - loss: 0.5704 - acc: 0.7170
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5630 - acc: 0.7188
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5671 - acc: 0.7067
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5655 - acc: 0.7087
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5664 - acc: 0.7119
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5629 - acc: 0.7132
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5636 - acc: 0.7089
1280/1283 [============================>.] - ETA: 0s - loss: 0.5636 - acc: 0.7086
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5631 - acc: 0.7093 - val_loss: 0.7014 - val_acc: 0.5764

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5852 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.5836 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5588 - acc: 0.6979
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5625 - acc: 0.6953
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5590 - acc: 0.7094
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5480 - acc: 0.7214
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5478 - acc: 0.7254
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5469 - acc: 0.7168
 576/1283 [============>.................] - ETA: 0s - loss: 0.5387 - acc: 0.7205
 640/1283 [=============>................] - ETA: 0s - loss: 0.5429 - acc: 0.7109
 768/1283 [================>.............] - ETA: 0s - loss: 0.5475 - acc: 0.7096
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5422 - acc: 0.7154
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5411 - acc: 0.7227
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5417 - acc: 0.7252
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5436 - acc: 0.7231
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5466 - acc: 0.7229
1280/1283 [============================>.] - ETA: 0s - loss: 0.5429 - acc: 0.7289
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5434 - acc: 0.7288 - val_loss: 0.7298 - val_acc: 0.5764

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5442 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5430 - acc: 0.7292
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5525 - acc: 0.7250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5547 - acc: 0.7214
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5482 - acc: 0.7277
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5538 - acc: 0.7266
 640/1283 [=============>................] - ETA: 0s - loss: 0.5536 - acc: 0.7141
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5554 - acc: 0.7102
 768/1283 [================>.............] - ETA: 0s - loss: 0.5601 - acc: 0.7031
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5531 - acc: 0.7087
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5487 - acc: 0.7177
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5449 - acc: 0.7207
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5459 - acc: 0.7206
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5489 - acc: 0.7163
1283/1283 [==============================] - 1s 937us/step - loss: 0.5505 - acc: 0.7163 - val_loss: 0.7232 - val_acc: 0.5852

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5203 - acc: 0.7500
 128/1283 [=>............................] - ETA: 0s - loss: 0.5579 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5319 - acc: 0.7227
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5436 - acc: 0.7219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5321 - acc: 0.7210
 576/1283 [============>.................] - ETA: 0s - loss: 0.5328 - acc: 0.7222
 640/1283 [=============>................] - ETA: 0s - loss: 0.5354 - acc: 0.7234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5415 - acc: 0.7188
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5398 - acc: 0.7224
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5324 - acc: 0.7323
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5249 - acc: 0.7381
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5250 - acc: 0.7396
1280/1283 [============================>.] - ETA: 0s - loss: 0.5244 - acc: 0.7398
1283/1283 [==============================] - 1s 799us/step - loss: 0.5247 - acc: 0.7397 - val_loss: 0.7310 - val_acc: 0.5546

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=15
PCA text=100
accuracy=0.5276967930029155
best_valid_accuracy=0.5306122448979592
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:30:02.649147: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 30s - loss: 0.6935 - acc: 0.5625
 128/1283 [=>............................] - ETA: 15s - loss: 0.6959 - acc: 0.4922
 192/1283 [===>..........................] - ETA: 9s - loss: 0.6984 - acc: 0.4688 
 320/1283 [======>.......................] - ETA: 5s - loss: 0.6978 - acc: 0.4875
 384/1283 [=======>......................] - ETA: 4s - loss: 0.6978 - acc: 0.4870
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7001 - acc: 0.5000
 576/1283 [============>.................] - ETA: 2s - loss: 0.6989 - acc: 0.5035
 640/1283 [=============>................] - ETA: 2s - loss: 0.6996 - acc: 0.4922
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7000 - acc: 0.4915
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7003 - acc: 0.4964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7001 - acc: 0.5022
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6982 - acc: 0.5107
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6964 - acc: 0.5156
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6962 - acc: 0.5189
1280/1283 [============================>.] - ETA: 0s - loss: 0.6955 - acc: 0.5219
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6958 - acc: 0.5214 - val_loss: 0.6801 - val_acc: 0.5590

Epoch 00001: val_acc improved from -inf to 0.55895, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6920 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.6923 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6875 - acc: 0.5677
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6811 - acc: 0.5742
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6825 - acc: 0.5687
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6832 - acc: 0.5599
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6794 - acc: 0.5742
 576/1283 [============>.................] - ETA: 0s - loss: 0.6803 - acc: 0.5747
 640/1283 [=============>................] - ETA: 0s - loss: 0.6803 - acc: 0.5750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6805 - acc: 0.5739
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6789 - acc: 0.5733
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6791 - acc: 0.5714
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6770 - acc: 0.5742
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6782 - acc: 0.5744
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6800 - acc: 0.5691
1280/1283 [============================>.] - ETA: 0s - loss: 0.6797 - acc: 0.5695
1283/1283 [==============================] - 1s 980us/step - loss: 0.6798 - acc: 0.5690 - val_loss: 0.6797 - val_acc: 0.5633

Epoch 00002: val_acc improved from 0.55895 to 0.56332, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6724 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6715 - acc: 0.5729
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6654 - acc: 0.5906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6639 - acc: 0.5982
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6659 - acc: 0.5977
 640/1283 [=============>................] - ETA: 0s - loss: 0.6640 - acc: 0.6000
 768/1283 [================>.............] - ETA: 0s - loss: 0.6667 - acc: 0.5872
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6646 - acc: 0.5982
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6649 - acc: 0.6025
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6659 - acc: 0.5990
1280/1283 [============================>.] - ETA: 0s - loss: 0.6681 - acc: 0.5945
1283/1283 [==============================] - 1s 854us/step - loss: 0.6679 - acc: 0.5947 - val_loss: 0.6784 - val_acc: 0.5721

Epoch 00003: val_acc improved from 0.56332 to 0.57205, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6735 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.6696 - acc: 0.6172
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6743 - acc: 0.6172
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6674 - acc: 0.6172
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6652 - acc: 0.6270
 576/1283 [============>.................] - ETA: 0s - loss: 0.6626 - acc: 0.6250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6666 - acc: 0.6108
 768/1283 [================>.............] - ETA: 0s - loss: 0.6652 - acc: 0.6133
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6625 - acc: 0.6142
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6619 - acc: 0.6150
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6611 - acc: 0.6172
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6601 - acc: 0.6195
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6601 - acc: 0.6198
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6588 - acc: 0.6234
1280/1283 [============================>.] - ETA: 0s - loss: 0.6590 - acc: 0.6234
1283/1283 [==============================] - 1s 875us/step - loss: 0.6591 - acc: 0.6235 - val_loss: 0.6751 - val_acc: 0.5808

Epoch 00004: val_acc improved from 0.57205 to 0.58079, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6441 - acc: 0.6250
 128/1283 [=>............................] - ETA: 0s - loss: 0.6402 - acc: 0.6328
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6516 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6540 - acc: 0.6055
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6509 - acc: 0.6062
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6452 - acc: 0.6224
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6469 - acc: 0.6250
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6521 - acc: 0.6074
 576/1283 [============>.................] - ETA: 0s - loss: 0.6572 - acc: 0.6059
 640/1283 [=============>................] - ETA: 0s - loss: 0.6538 - acc: 0.6156
 768/1283 [================>.............] - ETA: 0s - loss: 0.6541 - acc: 0.6211
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6530 - acc: 0.6226
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6528 - acc: 0.6219
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6514 - acc: 0.6221
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6523 - acc: 0.6232
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6509 - acc: 0.6234
1280/1283 [============================>.] - ETA: 0s - loss: 0.6493 - acc: 0.6258
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6493 - acc: 0.6259 - val_loss: 0.6743 - val_acc: 0.5721

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6153 - acc: 0.6875
 128/1283 [=>............................] - ETA: 0s - loss: 0.6424 - acc: 0.6484
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6384 - acc: 0.6523
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6423 - acc: 0.6375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6380 - acc: 0.6473
 576/1283 [============>.................] - ETA: 0s - loss: 0.6408 - acc: 0.6389
 640/1283 [=============>................] - ETA: 0s - loss: 0.6355 - acc: 0.6453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6359 - acc: 0.6420
 768/1283 [================>.............] - ETA: 0s - loss: 0.6362 - acc: 0.6380
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6327 - acc: 0.6466
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6364 - acc: 0.6417
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6335 - acc: 0.6479
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6312 - acc: 0.6514
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6339 - acc: 0.6489
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6330 - acc: 0.6476
1280/1283 [============================>.] - ETA: 0s - loss: 0.6325 - acc: 0.6492
1283/1283 [==============================] - 1s 926us/step - loss: 0.6325 - acc: 0.6493 - val_loss: 0.6831 - val_acc: 0.5764

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6444 - acc: 0.6250
 128/1283 [=>............................] - ETA: 0s - loss: 0.6130 - acc: 0.6953
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6113 - acc: 0.6979
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6149 - acc: 0.6813
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6260 - acc: 0.6562
 576/1283 [============>.................] - ETA: 0s - loss: 0.6271 - acc: 0.6615
 640/1283 [=============>................] - ETA: 0s - loss: 0.6279 - acc: 0.6609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6246 - acc: 0.6662
 768/1283 [================>.............] - ETA: 0s - loss: 0.6226 - acc: 0.6667
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6302 - acc: 0.6596
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6303 - acc: 0.6583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6317 - acc: 0.6553
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6316 - acc: 0.6580
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6314 - acc: 0.6604
1280/1283 [============================>.] - ETA: 0s - loss: 0.6295 - acc: 0.6586
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6302 - acc: 0.6571 - val_loss: 0.6800 - val_acc: 0.5808

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5958 - acc: 0.7344
 128/1283 [=>............................] - ETA: 0s - loss: 0.6157 - acc: 0.6641
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6160 - acc: 0.6797
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6373 - acc: 0.6432
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6310 - acc: 0.6582
 640/1283 [=============>................] - ETA: 0s - loss: 0.6260 - acc: 0.6641
 768/1283 [================>.............] - ETA: 0s - loss: 0.6180 - acc: 0.6745
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6145 - acc: 0.6803
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6069 - acc: 0.6885
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6079 - acc: 0.6903
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6096 - acc: 0.6859
1280/1283 [============================>.] - ETA: 0s - loss: 0.6100 - acc: 0.6820
1283/1283 [==============================] - 1s 882us/step - loss: 0.6100 - acc: 0.6820 - val_loss: 0.6793 - val_acc: 0.5721

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5418 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.5540 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5649 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5693 - acc: 0.7422
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5777 - acc: 0.7312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5865 - acc: 0.7277
 576/1283 [============>.................] - ETA: 0s - loss: 0.5970 - acc: 0.7118
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5942 - acc: 0.7045
 768/1283 [================>.............] - ETA: 0s - loss: 0.5930 - acc: 0.7096
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5943 - acc: 0.7043
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6001 - acc: 0.6937
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5972 - acc: 0.6934
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5978 - acc: 0.6921
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5986 - acc: 0.6924
1283/1283 [==============================] - 1s 859us/step - loss: 0.5980 - acc: 0.6929 - val_loss: 0.6901 - val_acc: 0.5721

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6359 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5927 - acc: 0.6927
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5842 - acc: 0.7070
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5949 - acc: 0.6979
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5924 - acc: 0.7031
 640/1283 [=============>................] - ETA: 0s - loss: 0.5885 - acc: 0.7031
 768/1283 [================>.............] - ETA: 0s - loss: 0.5802 - acc: 0.7122
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5781 - acc: 0.7121
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5854 - acc: 0.7002
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5852 - acc: 0.6976
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5894 - acc: 0.6944
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5883 - acc: 0.6949
1280/1283 [============================>.] - ETA: 0s - loss: 0.5874 - acc: 0.6969
1283/1283 [==============================] - 1s 804us/step - loss: 0.5872 - acc: 0.6968 - val_loss: 0.6846 - val_acc: 0.6070

Epoch 00010: val_acc improved from 0.58079 to 0.60699, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6280 - acc: 0.6406
 128/1283 [=>............................] - ETA: 0s - loss: 0.6086 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5813 - acc: 0.6979
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5775 - acc: 0.7070
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5772 - acc: 0.7005
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5903 - acc: 0.7009
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5878 - acc: 0.7090
 576/1283 [============>.................] - ETA: 0s - loss: 0.5737 - acc: 0.7240
 640/1283 [=============>................] - ETA: 0s - loss: 0.5769 - acc: 0.7141
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5836 - acc: 0.6989
 768/1283 [================>.............] - ETA: 0s - loss: 0.5831 - acc: 0.7005
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5791 - acc: 0.7031
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5778 - acc: 0.7020
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5785 - acc: 0.6969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5728 - acc: 0.6994
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5718 - acc: 0.6997
1280/1283 [============================>.] - ETA: 0s - loss: 0.5726 - acc: 0.6984
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5724 - acc: 0.6984 - val_loss: 0.6904 - val_acc: 0.5852

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5903 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.6232 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6058 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5868 - acc: 0.6641
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5776 - acc: 0.6844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5737 - acc: 0.6901
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5714 - acc: 0.6942
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5678 - acc: 0.7031
 576/1283 [============>.................] - ETA: 0s - loss: 0.5647 - acc: 0.7066
 640/1283 [=============>................] - ETA: 0s - loss: 0.5575 - acc: 0.7172
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5571 - acc: 0.7131
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5520 - acc: 0.7212
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5540 - acc: 0.7176
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5589 - acc: 0.7090
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5534 - acc: 0.7169
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5499 - acc: 0.7179
1280/1283 [============================>.] - ETA: 0s - loss: 0.5437 - acc: 0.7289
1283/1283 [==============================] - 1s 937us/step - loss: 0.5433 - acc: 0.7295 - val_loss: 0.6910 - val_acc: 0.6026

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5028 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5213 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4902 - acc: 0.7844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5085 - acc: 0.7656
 576/1283 [============>.................] - ETA: 0s - loss: 0.5131 - acc: 0.7500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5188 - acc: 0.7514
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5158 - acc: 0.7536
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5170 - acc: 0.7542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5274 - acc: 0.7482
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5240 - acc: 0.7508
1280/1283 [============================>.] - ETA: 0s - loss: 0.5234 - acc: 0.7516
1283/1283 [==============================] - 1s 718us/step - loss: 0.5230 - acc: 0.7521 - val_loss: 0.7039 - val_acc: 0.6070

Epoch 00013: val_acc improved from 0.60699 to 0.60699, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4508 - acc: 0.7969
 128/1283 [=>............................] - ETA: 0s - loss: 0.4417 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4643 - acc: 0.8021
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4833 - acc: 0.7773
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4855 - acc: 0.7760
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4815 - acc: 0.7746
 576/1283 [============>.................] - ETA: 0s - loss: 0.4812 - acc: 0.7708
 640/1283 [=============>................] - ETA: 0s - loss: 0.4805 - acc: 0.7734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4856 - acc: 0.7727
 768/1283 [================>.............] - ETA: 0s - loss: 0.4892 - acc: 0.7708
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4984 - acc: 0.7620
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4980 - acc: 0.7634
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5036 - acc: 0.7594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5050 - acc: 0.7588
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5041 - acc: 0.7592
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4987 - acc: 0.7648
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5011 - acc: 0.7599
1280/1283 [============================>.] - ETA: 0s - loss: 0.5051 - acc: 0.7586
1283/1283 [==============================] - 1s 978us/step - loss: 0.5060 - acc: 0.7584 - val_loss: 0.7116 - val_acc: 0.5764

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4326 - acc: 0.8125
 128/1283 [=>............................] - ETA: 0s - loss: 0.4248 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4557 - acc: 0.7760
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4786 - acc: 0.7578
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4941 - acc: 0.7526
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5001 - acc: 0.7500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4920 - acc: 0.7656
 576/1283 [============>.................] - ETA: 0s - loss: 0.4865 - acc: 0.7691
 640/1283 [=============>................] - ETA: 0s - loss: 0.4800 - acc: 0.7734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4833 - acc: 0.7741
 768/1283 [================>.............] - ETA: 0s - loss: 0.4824 - acc: 0.7747
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4860 - acc: 0.7752
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4862 - acc: 0.7779
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4864 - acc: 0.7781
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4863 - acc: 0.7803
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4847 - acc: 0.7803
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4883 - acc: 0.7755
1280/1283 [============================>.] - ETA: 0s - loss: 0.4871 - acc: 0.7766
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4868 - acc: 0.7763 - val_loss: 0.7194 - val_acc: 0.5721

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4321 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4541 - acc: 0.7708
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4712 - acc: 0.7594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4649 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4734 - acc: 0.7589
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4771 - acc: 0.7539
 576/1283 [============>.................] - ETA: 0s - loss: 0.4742 - acc: 0.7639
 640/1283 [=============>................] - ETA: 0s - loss: 0.4746 - acc: 0.7594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4618 - acc: 0.7699
 768/1283 [================>.............] - ETA: 0s - loss: 0.4663 - acc: 0.7669
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4738 - acc: 0.7589
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4712 - acc: 0.7656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4699 - acc: 0.7693
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4629 - acc: 0.7743
1280/1283 [============================>.] - ETA: 0s - loss: 0.4596 - acc: 0.7773
1283/1283 [==============================] - 1s 868us/step - loss: 0.4598 - acc: 0.7771 - val_loss: 0.7549 - val_acc: 0.5764

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4705 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4613 - acc: 0.7917
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4527 - acc: 0.7930
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4399 - acc: 0.8000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4260 - acc: 0.8036
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4320 - acc: 0.8008
 576/1283 [============>.................] - ETA: 0s - loss: 0.4316 - acc: 0.8038
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4383 - acc: 0.7969
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4348 - acc: 0.8041
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4288 - acc: 0.8052
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4296 - acc: 0.8037
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4289 - acc: 0.8038
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4274 - acc: 0.8076
1280/1283 [============================>.] - ETA: 0s - loss: 0.4273 - acc: 0.8070
1283/1283 [==============================] - 1s 880us/step - loss: 0.4271 - acc: 0.8075 - val_loss: 0.7503 - val_acc: 0.6070

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4144 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3684 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3691 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3791 - acc: 0.8187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3916 - acc: 0.8192
 576/1283 [============>.................] - ETA: 0s - loss: 0.4010 - acc: 0.8160
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4055 - acc: 0.8111
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4056 - acc: 0.8077
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4016 - acc: 0.8115
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4029 - acc: 0.8105
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4064 - acc: 0.8097
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4104 - acc: 0.8056
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4072 - acc: 0.8092
1280/1283 [============================>.] - ETA: 0s - loss: 0.4097 - acc: 0.8086
1283/1283 [==============================] - 1s 825us/step - loss: 0.4098 - acc: 0.8090 - val_loss: 0.7671 - val_acc: 0.5852

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4233 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.4375 - acc: 0.7734
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4108 - acc: 0.7865
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3896 - acc: 0.7969
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3876 - acc: 0.8063
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4015 - acc: 0.7943
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3895 - acc: 0.8080
 576/1283 [============>.................] - ETA: 0s - loss: 0.3806 - acc: 0.8160
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3789 - acc: 0.8182
 768/1283 [================>.............] - ETA: 0s - loss: 0.3844 - acc: 0.8151
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3766 - acc: 0.8221
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3821 - acc: 0.8208
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3859 - acc: 0.8217
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3886 - acc: 0.8224
1280/1283 [============================>.] - ETA: 0s - loss: 0.3908 - acc: 0.8195
1283/1283 [==============================] - 1s 980us/step - loss: 0.3906 - acc: 0.8192 - val_loss: 0.8005 - val_acc: 0.5808

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3585 - acc: 0.8906
 128/1283 [=>............................] - ETA: 0s - loss: 0.3625 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3578 - acc: 0.8802
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3456 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3478 - acc: 0.8812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3580 - acc: 0.8616
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3642 - acc: 0.8555
 640/1283 [=============>................] - ETA: 0s - loss: 0.3714 - acc: 0.8500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3744 - acc: 0.8509
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3705 - acc: 0.8486
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3773 - acc: 0.8415
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3801 - acc: 0.8365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3757 - acc: 0.8369
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3782 - acc: 0.8377
1280/1283 [============================>.] - ETA: 0s - loss: 0.3753 - acc: 0.8383
1283/1283 [==============================] - 1s 965us/step - loss: 0.3751 - acc: 0.8387 - val_loss: 0.7960 - val_acc: 0.5590

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3780 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3340 - acc: 0.8542
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3306 - acc: 0.8477
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3302 - acc: 0.8469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3447 - acc: 0.8359
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3464 - acc: 0.8326
 576/1283 [============>.................] - ETA: 0s - loss: 0.3400 - acc: 0.8420
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3446 - acc: 0.8409
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3374 - acc: 0.8474
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3380 - acc: 0.8500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3373 - acc: 0.8474
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3415 - acc: 0.8462
1280/1283 [============================>.] - ETA: 0s - loss: 0.3471 - acc: 0.8422
1283/1283 [==============================] - 1s 902us/step - loss: 0.3466 - acc: 0.8426 - val_loss: 0.8167 - val_acc: 0.5764

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3106 - acc: 0.8438
 128/1283 [=>............................] - ETA: 0s - loss: 0.2906 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2940 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3177 - acc: 0.8531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3085 - acc: 0.8672
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3081 - acc: 0.8728
 576/1283 [============>.................] - ETA: 0s - loss: 0.3087 - acc: 0.8750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3157 - acc: 0.8693
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3146 - acc: 0.8714
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3158 - acc: 0.8717
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3189 - acc: 0.8677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3200 - acc: 0.8643
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3179 - acc: 0.8640
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3169 - acc: 0.8637
1280/1283 [============================>.] - ETA: 0s - loss: 0.3150 - acc: 0.8641
1283/1283 [==============================] - 1s 873us/step - loss: 0.3152 - acc: 0.8644 - val_loss: 0.8339 - val_acc: 0.5939

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3026 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.2696 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2727 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2647 - acc: 0.8938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2878 - acc: 0.8772
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2930 - acc: 0.8691
 640/1283 [=============>................] - ETA: 0s - loss: 0.2938 - acc: 0.8656
 768/1283 [================>.............] - ETA: 0s - loss: 0.2930 - acc: 0.8685
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3019 - acc: 0.8650
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2981 - acc: 0.8682
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3028 - acc: 0.8681
1280/1283 [============================>.] - ETA: 0s - loss: 0.3063 - acc: 0.8641
1283/1283 [==============================] - 1s 852us/step - loss: 0.3057 - acc: 0.8644 - val_loss: 0.8951 - val_acc: 0.5677

Epoch 00023: val_acc did not improve
Epoch 00023: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=20
PCA text=100
accuracy=0.5131195335276968
best_valid_accuracy=0.5174927113702624
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:38:23.118589: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 12s - loss: 0.7055 - acc: 0.4844
 192/1283 [===>..........................] - ETA: 4s - loss: 0.6984 - acc: 0.5260 
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7006 - acc: 0.5031
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7026 - acc: 0.5045
 576/1283 [============>.................] - ETA: 1s - loss: 0.7006 - acc: 0.5052
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6984 - acc: 0.5000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6980 - acc: 0.4952
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6950 - acc: 0.5062
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6954 - acc: 0.5138
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6927 - acc: 0.5222
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6916 - acc: 0.5269 - val_loss: 0.6825 - val_acc: 0.6026

Epoch 00001: val_acc improved from -inf to 0.60262, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6864 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6921 - acc: 0.5469
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6813 - acc: 0.5750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6700 - acc: 0.6027
 576/1283 [============>.................] - ETA: 0s - loss: 0.6739 - acc: 0.5851
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6710 - acc: 0.5909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6721 - acc: 0.5805
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6741 - acc: 0.5729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6726 - acc: 0.5790
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6734 - acc: 0.5773
1283/1283 [==============================] - 1s 612us/step - loss: 0.6724 - acc: 0.5799 - val_loss: 0.6798 - val_acc: 0.5895

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6643 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6701 - acc: 0.5833
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6568 - acc: 0.6156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6522 - acc: 0.6161
 576/1283 [============>.................] - ETA: 0s - loss: 0.6577 - acc: 0.6024
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6527 - acc: 0.6065
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6509 - acc: 0.6142
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6531 - acc: 0.6083
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6561 - acc: 0.6048
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6548 - acc: 0.6044
1283/1283 [==============================] - 1s 571us/step - loss: 0.6536 - acc: 0.6087 - val_loss: 0.6797 - val_acc: 0.5939

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6693 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6584 - acc: 0.5990
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6540 - acc: 0.6156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6533 - acc: 0.6183
 576/1283 [============>.................] - ETA: 0s - loss: 0.6393 - acc: 0.6337
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6388 - acc: 0.6364
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6352 - acc: 0.6406
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6384 - acc: 0.6350
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6359 - acc: 0.6438
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6347 - acc: 0.6465
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6350 - acc: 0.6461
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6361 - acc: 0.6398
1283/1283 [==============================] - 1s 657us/step - loss: 0.6362 - acc: 0.6407 - val_loss: 0.6811 - val_acc: 0.5983

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6471 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6390 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6191 - acc: 0.6781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6244 - acc: 0.6763
 576/1283 [============>.................] - ETA: 0s - loss: 0.6289 - acc: 0.6701
 640/1283 [=============>................] - ETA: 0s - loss: 0.6306 - acc: 0.6687
 768/1283 [================>.............] - ETA: 0s - loss: 0.6223 - acc: 0.6719
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6242 - acc: 0.6707
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6208 - acc: 0.6741
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6180 - acc: 0.6781
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6200 - acc: 0.6709
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6185 - acc: 0.6710
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6208 - acc: 0.6669
1283/1283 [==============================] - 1s 862us/step - loss: 0.6199 - acc: 0.6672 - val_loss: 0.6918 - val_acc: 0.5808

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5873 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.5684 - acc: 0.6641
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5859 - acc: 0.6797
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6021 - acc: 0.6615
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6009 - acc: 0.6696
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6087 - acc: 0.6582
 640/1283 [=============>................] - ETA: 0s - loss: 0.6062 - acc: 0.6547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6093 - acc: 0.6534
 768/1283 [================>.............] - ETA: 0s - loss: 0.6131 - acc: 0.6484
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6139 - acc: 0.6484
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6108 - acc: 0.6533
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6094 - acc: 0.6535
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6104 - acc: 0.6510
1280/1283 [============================>.] - ETA: 0s - loss: 0.6048 - acc: 0.6594
1283/1283 [==============================] - 1s 868us/step - loss: 0.6048 - acc: 0.6602 - val_loss: 0.6924 - val_acc: 0.5721

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6121 - acc: 0.7344
 128/1283 [=>............................] - ETA: 1s - loss: 0.5884 - acc: 0.7266
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5961 - acc: 0.7148
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5842 - acc: 0.7188
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5811 - acc: 0.7214
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5899 - acc: 0.6987
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5834 - acc: 0.7051
 576/1283 [============>.................] - ETA: 0s - loss: 0.5786 - acc: 0.7066
 640/1283 [=============>................] - ETA: 0s - loss: 0.5798 - acc: 0.7047
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5842 - acc: 0.6960
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5852 - acc: 0.6875
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5883 - acc: 0.6842
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5881 - acc: 0.6816
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5848 - acc: 0.6857
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5844 - acc: 0.6840
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5816 - acc: 0.6859
1280/1283 [============================>.] - ETA: 0s - loss: 0.5874 - acc: 0.6820
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5872 - acc: 0.6820 - val_loss: 0.7036 - val_acc: 0.5939

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6152 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.5905 - acc: 0.6641
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5879 - acc: 0.6823
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5798 - acc: 0.6992
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5923 - acc: 0.6901
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5772 - acc: 0.7090
 576/1283 [============>.................] - ETA: 0s - loss: 0.5807 - acc: 0.7083
 640/1283 [=============>................] - ETA: 0s - loss: 0.5707 - acc: 0.7203
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5659 - acc: 0.7287
 768/1283 [================>.............] - ETA: 0s - loss: 0.5685 - acc: 0.7201
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5682 - acc: 0.7254
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5652 - acc: 0.7256
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5693 - acc: 0.7206
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5685 - acc: 0.7205
1280/1283 [============================>.] - ETA: 0s - loss: 0.5690 - acc: 0.7164
1283/1283 [==============================] - 1s 865us/step - loss: 0.5685 - acc: 0.7171 - val_loss: 0.7109 - val_acc: 0.5764

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5345 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5352 - acc: 0.7708
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5296 - acc: 0.7531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5436 - acc: 0.7388
 576/1283 [============>.................] - ETA: 0s - loss: 0.5444 - acc: 0.7431
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5461 - acc: 0.7358
 768/1283 [================>.............] - ETA: 0s - loss: 0.5483 - acc: 0.7383
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5480 - acc: 0.7404
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5462 - acc: 0.7427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5442 - acc: 0.7461
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5474 - acc: 0.7399
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5526 - acc: 0.7344
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5502 - acc: 0.7327
1280/1283 [============================>.] - ETA: 0s - loss: 0.5521 - acc: 0.7281
1283/1283 [==============================] - 1s 835us/step - loss: 0.5521 - acc: 0.7280 - val_loss: 0.7259 - val_acc: 0.5895

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5461 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.5461 - acc: 0.7578
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5660 - acc: 0.7396
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5555 - acc: 0.7539
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5678 - acc: 0.7406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5494 - acc: 0.7422
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5399 - acc: 0.7500
 576/1283 [============>.................] - ETA: 0s - loss: 0.5529 - acc: 0.7292
 640/1283 [=============>................] - ETA: 0s - loss: 0.5442 - acc: 0.7312
 768/1283 [================>.............] - ETA: 0s - loss: 0.5432 - acc: 0.7383
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5428 - acc: 0.7392
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5428 - acc: 0.7411
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5426 - acc: 0.7417
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5404 - acc: 0.7432
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5379 - acc: 0.7472
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5339 - acc: 0.7500
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5289 - acc: 0.7549
1280/1283 [============================>.] - ETA: 0s - loss: 0.5277 - acc: 0.7523
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5272 - acc: 0.7529 - val_loss: 0.7261 - val_acc: 0.5677

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5634 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5403 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5393 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5339 - acc: 0.7250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5316 - acc: 0.7422
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5232 - acc: 0.7478
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5156 - acc: 0.7617
 576/1283 [============>.................] - ETA: 1s - loss: 0.5161 - acc: 0.7569
 640/1283 [=============>................] - ETA: 1s - loss: 0.5088 - acc: 0.7594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5026 - acc: 0.7642
 768/1283 [================>.............] - ETA: 0s - loss: 0.5064 - acc: 0.7578
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5046 - acc: 0.7584
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5025 - acc: 0.7677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4990 - acc: 0.7715
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4982 - acc: 0.7684
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4975 - acc: 0.7682
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4970 - acc: 0.7714
1280/1283 [============================>.] - ETA: 0s - loss: 0.4941 - acc: 0.7742
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4936 - acc: 0.7747 - val_loss: 0.7545 - val_acc: 0.5764

Epoch 00011: val_acc did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=25
PCA text=100
accuracy=0.5116618075801749
best_valid_accuracy=0.5189504373177842
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:48:25.067656: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 9s - loss: 0.7003 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 3s - loss: 0.6965 - acc: 0.4896
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6936 - acc: 0.5062
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6957 - acc: 0.5026
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6924 - acc: 0.5179
 576/1283 [============>.................] - ETA: 1s - loss: 0.6893 - acc: 0.5330
 640/1283 [=============>................] - ETA: 0s - loss: 0.6883 - acc: 0.5328
 768/1283 [================>.............] - ETA: 0s - loss: 0.6897 - acc: 0.5326
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6909 - acc: 0.5301
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6916 - acc: 0.5271
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6913 - acc: 0.5283
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6933 - acc: 0.5208
1280/1283 [============================>.] - ETA: 0s - loss: 0.6930 - acc: 0.5234
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6929 - acc: 0.5238 - val_loss: 0.7010 - val_acc: 0.4891

Epoch 00001: val_acc improved from -inf to 0.48908, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6538 - acc: 0.6250
 128/1283 [=>............................] - ETA: 0s - loss: 0.6577 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6616 - acc: 0.6172
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6623 - acc: 0.6276
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6701 - acc: 0.5996
 640/1283 [=============>................] - ETA: 0s - loss: 0.6739 - acc: 0.5859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6735 - acc: 0.5881
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6716 - acc: 0.5889
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6707 - acc: 0.5938
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6702 - acc: 0.5928
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6693 - acc: 0.5970
1283/1283 [==============================] - 1s 717us/step - loss: 0.6698 - acc: 0.5916 - val_loss: 0.7028 - val_acc: 0.5284

Epoch 00002: val_acc improved from 0.48908 to 0.52838, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6175 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6430 - acc: 0.6458
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6505 - acc: 0.6211
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6505 - acc: 0.6276
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6494 - acc: 0.6348
 576/1283 [============>.................] - ETA: 0s - loss: 0.6506 - acc: 0.6233
 640/1283 [=============>................] - ETA: 0s - loss: 0.6509 - acc: 0.6203
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6525 - acc: 0.6222
 768/1283 [================>.............] - ETA: 0s - loss: 0.6550 - acc: 0.6198
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6544 - acc: 0.6226
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6528 - acc: 0.6339
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6514 - acc: 0.6344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6514 - acc: 0.6367
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6516 - acc: 0.6388
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6510 - acc: 0.6398
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6503 - acc: 0.6398
1280/1283 [============================>.] - ETA: 0s - loss: 0.6514 - acc: 0.6398
1283/1283 [==============================] - 1s 934us/step - loss: 0.6512 - acc: 0.6399 - val_loss: 0.7030 - val_acc: 0.5415

Epoch 00003: val_acc improved from 0.52838 to 0.54148, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6288 - acc: 0.7031
 128/1283 [=>............................] - ETA: 0s - loss: 0.6476 - acc: 0.6016
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6614 - acc: 0.5885
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6556 - acc: 0.5898
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6554 - acc: 0.5938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6550 - acc: 0.5982
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6491 - acc: 0.6094
 640/1283 [=============>................] - ETA: 0s - loss: 0.6442 - acc: 0.6219
 768/1283 [================>.............] - ETA: 0s - loss: 0.6406 - acc: 0.6302
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6390 - acc: 0.6382
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6397 - acc: 0.6339
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6381 - acc: 0.6396
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6374 - acc: 0.6406
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6362 - acc: 0.6431
1280/1283 [============================>.] - ETA: 0s - loss: 0.6363 - acc: 0.6438
1283/1283 [==============================] - 1s 977us/step - loss: 0.6362 - acc: 0.6438 - val_loss: 0.7108 - val_acc: 0.5371

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5985 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6014 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6023 - acc: 0.6750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6084 - acc: 0.6786
 576/1283 [============>.................] - ETA: 0s - loss: 0.6126 - acc: 0.6788
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6119 - acc: 0.6818
 768/1283 [================>.............] - ETA: 0s - loss: 0.6103 - acc: 0.6901
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6103 - acc: 0.6875
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6093 - acc: 0.6920
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6109 - acc: 0.6854
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6091 - acc: 0.6865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6101 - acc: 0.6875
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6091 - acc: 0.6892
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6108 - acc: 0.6883
1280/1283 [============================>.] - ETA: 0s - loss: 0.6119 - acc: 0.6859
1283/1283 [==============================] - 1s 945us/step - loss: 0.6126 - acc: 0.6859 - val_loss: 0.7223 - val_acc: 0.5240

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6093 - acc: 0.6875
 128/1283 [=>............................] - ETA: 1s - loss: 0.6023 - acc: 0.6797
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6065 - acc: 0.6615
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5988 - acc: 0.6602
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5872 - acc: 0.6844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5934 - acc: 0.6823
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5901 - acc: 0.6855
 576/1283 [============>.................] - ETA: 0s - loss: 0.5879 - acc: 0.6910
 640/1283 [=============>................] - ETA: 0s - loss: 0.5885 - acc: 0.6875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5892 - acc: 0.6861
 768/1283 [================>.............] - ETA: 0s - loss: 0.5848 - acc: 0.6914
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5875 - acc: 0.6911
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5934 - acc: 0.6853
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5930 - acc: 0.6846
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5918 - acc: 0.6875
1280/1283 [============================>.] - ETA: 0s - loss: 0.5919 - acc: 0.6891
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5920 - acc: 0.6882 - val_loss: 0.7330 - val_acc: 0.5240

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5895 - acc: 0.6875
 128/1283 [=>............................] - ETA: 0s - loss: 0.5607 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5733 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5708 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5633 - acc: 0.7500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5594 - acc: 0.7500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5622 - acc: 0.7411
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5681 - acc: 0.7305
 576/1283 [============>.................] - ETA: 0s - loss: 0.5740 - acc: 0.7205
 640/1283 [=============>................] - ETA: 0s - loss: 0.5724 - acc: 0.7234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5767 - acc: 0.7202
 768/1283 [================>.............] - ETA: 0s - loss: 0.5764 - acc: 0.7188
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5723 - acc: 0.7163
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5759 - acc: 0.7109
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5742 - acc: 0.7104
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5764 - acc: 0.7070
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5751 - acc: 0.7086
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5761 - acc: 0.7049
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5769 - acc: 0.7081
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5743 - acc: 0.7108 - val_loss: 0.7447 - val_acc: 0.5109

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5442 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.5358 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5396 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5559 - acc: 0.7219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5582 - acc: 0.7344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5611 - acc: 0.7254
 576/1283 [============>.................] - ETA: 0s - loss: 0.5570 - acc: 0.7222
 640/1283 [=============>................] - ETA: 0s - loss: 0.5542 - acc: 0.7203
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5580 - acc: 0.7116
 768/1283 [================>.............] - ETA: 0s - loss: 0.5541 - acc: 0.7161
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5531 - acc: 0.7163
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5521 - acc: 0.7210
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5497 - acc: 0.7219
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5534 - acc: 0.7188
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5558 - acc: 0.7160
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5505 - acc: 0.7240
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5508 - acc: 0.7270
1280/1283 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.7281
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5488 - acc: 0.7288 - val_loss: 0.7567 - val_acc: 0.4934

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4789 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.5057 - acc: 0.7422
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5097 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5123 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5124 - acc: 0.7562
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5197 - acc: 0.7526
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5138 - acc: 0.7567
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5209 - acc: 0.7461
 576/1283 [============>.................] - ETA: 0s - loss: 0.5193 - acc: 0.7517
 640/1283 [=============>................] - ETA: 0s - loss: 0.5241 - acc: 0.7453
 768/1283 [================>.............] - ETA: 0s - loss: 0.5267 - acc: 0.7435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5269 - acc: 0.7388
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5296 - acc: 0.7354
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5313 - acc: 0.7354
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5340 - acc: 0.7325
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5365 - acc: 0.7283
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5338 - acc: 0.7303
1280/1283 [============================>.] - ETA: 0s - loss: 0.5326 - acc: 0.7305
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5323 - acc: 0.7303 - val_loss: 0.7710 - val_acc: 0.5022

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4532 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.4574 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4825 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4776 - acc: 0.7719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4830 - acc: 0.7760
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4867 - acc: 0.7746
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4856 - acc: 0.7812
 576/1283 [============>.................] - ETA: 0s - loss: 0.4848 - acc: 0.7847
 640/1283 [=============>................] - ETA: 0s - loss: 0.4790 - acc: 0.7922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4769 - acc: 0.7969
 768/1283 [================>.............] - ETA: 0s - loss: 0.4801 - acc: 0.7904
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4937 - acc: 0.7790
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4934 - acc: 0.7793
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4953 - acc: 0.7776
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4947 - acc: 0.7752
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4965 - acc: 0.7738
1280/1283 [============================>.] - ETA: 0s - loss: 0.4959 - acc: 0.7734
1283/1283 [==============================] - 1s 998us/step - loss: 0.4963 - acc: 0.7732 - val_loss: 0.7896 - val_acc: 0.5284

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.4101 - acc: 0.8438
 128/1283 [=>............................] - ETA: 2s - loss: 0.4637 - acc: 0.7578
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4628 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4622 - acc: 0.7578
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4736 - acc: 0.7594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4788 - acc: 0.7545
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4737 - acc: 0.7656
 576/1283 [============>.................] - ETA: 0s - loss: 0.4768 - acc: 0.7691
 640/1283 [=============>................] - ETA: 0s - loss: 0.4840 - acc: 0.7688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4812 - acc: 0.7699
 768/1283 [================>.............] - ETA: 0s - loss: 0.4784 - acc: 0.7682
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4792 - acc: 0.7716
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4800 - acc: 0.7679
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4745 - acc: 0.7760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4750 - acc: 0.7754
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4749 - acc: 0.7743
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4736 - acc: 0.7747
1280/1283 [============================>.] - ETA: 0s - loss: 0.4728 - acc: 0.7742
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4726 - acc: 0.7747 - val_loss: 0.7930 - val_acc: 0.5197

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4749 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.4655 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4483 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4445 - acc: 0.8359
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4517 - acc: 0.8203
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4588 - acc: 0.8125
 576/1283 [============>.................] - ETA: 0s - loss: 0.4567 - acc: 0.8090
 640/1283 [=============>................] - ETA: 0s - loss: 0.4586 - acc: 0.8094
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4527 - acc: 0.8082
 768/1283 [================>.............] - ETA: 0s - loss: 0.4478 - acc: 0.8125
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4434 - acc: 0.8149
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4405 - acc: 0.8125
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4434 - acc: 0.8094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4452 - acc: 0.8027
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4504 - acc: 0.7941
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4531 - acc: 0.7891
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4543 - acc: 0.7878
1280/1283 [============================>.] - ETA: 0s - loss: 0.4589 - acc: 0.7852
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4590 - acc: 0.7849 - val_loss: 0.8265 - val_acc: 0.5240

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.3343 - acc: 0.8750
 128/1283 [=>............................] - ETA: 2s - loss: 0.4102 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 2s - loss: 0.4188 - acc: 0.8073
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4288 - acc: 0.7930
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4168 - acc: 0.7969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4070 - acc: 0.8073
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4064 - acc: 0.8036
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4128 - acc: 0.8008
 576/1283 [============>.................] - ETA: 1s - loss: 0.4171 - acc: 0.7969
 640/1283 [=============>................] - ETA: 1s - loss: 0.4230 - acc: 0.7922
 704/1283 [===============>..............] - ETA: 1s - loss: 0.4244 - acc: 0.7884
 768/1283 [================>.............] - ETA: 0s - loss: 0.4180 - acc: 0.7943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4165 - acc: 0.7957
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4155 - acc: 0.7980
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4180 - acc: 0.7958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4194 - acc: 0.7959
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4227 - acc: 0.7960
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4226 - acc: 0.7977
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4186 - acc: 0.8010
1280/1283 [============================>.] - ETA: 0s - loss: 0.4211 - acc: 0.8023
1283/1283 [==============================] - 2s 2ms/step - loss: 0.4216 - acc: 0.8020 - val_loss: 0.8485 - val_acc: 0.5022

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=30
PCA text=100
accuracy=0.48833819241982507
best_valid_accuracy=0.49271137026239065
