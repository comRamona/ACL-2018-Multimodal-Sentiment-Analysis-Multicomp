/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 13:09:37.774570: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 14s - loss: 0.7355 - acc: 0.5469
 128/1283 [=>............................] - ETA: 7s - loss: 0.7177 - acc: 0.5703 
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7562 - acc: 0.5469
 256/1283 [====>.........................] - ETA: 4s - loss: 0.7388 - acc: 0.5508
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7243 - acc: 0.5563
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7394 - acc: 0.5443
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7350 - acc: 0.5312
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7284 - acc: 0.5371
 576/1283 [============>.................] - ETA: 1s - loss: 0.7242 - acc: 0.5365
 640/1283 [=============>................] - ETA: 1s - loss: 0.7218 - acc: 0.5359
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7188 - acc: 0.5384
 768/1283 [================>.............] - ETA: 1s - loss: 0.7173 - acc: 0.5365
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7154 - acc: 0.5397
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7133 - acc: 0.5446
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7126 - acc: 0.5406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7114 - acc: 0.5430
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7106 - acc: 0.5441
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7090 - acc: 0.5434
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7088 - acc: 0.5378
1280/1283 [============================>.] - ETA: 0s - loss: 0.7070 - acc: 0.5422
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7069 - acc: 0.5425 - val_loss: 0.6939 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6308 - acc: 0.7188
 128/1283 [=>............................] - ETA: 1s - loss: 0.6300 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6325 - acc: 0.6979
 256/1283 [====>.........................] - ETA: 2s - loss: 0.6339 - acc: 0.6758
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6284 - acc: 0.6750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6275 - acc: 0.6745
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6250 - acc: 0.6786
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6280 - acc: 0.6738
 576/1283 [============>.................] - ETA: 1s - loss: 0.6247 - acc: 0.6753
 640/1283 [=============>................] - ETA: 1s - loss: 0.6276 - acc: 0.6703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6294 - acc: 0.6619
 768/1283 [================>.............] - ETA: 0s - loss: 0.6280 - acc: 0.6615
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6252 - acc: 0.6647
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6215 - acc: 0.6629
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6197 - acc: 0.6625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6172 - acc: 0.6650
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6162 - acc: 0.6618
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6140 - acc: 0.6623
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6113 - acc: 0.6645
1280/1283 [============================>.] - ETA: 0s - loss: 0.6149 - acc: 0.6562
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6143 - acc: 0.6571 - val_loss: 0.7014 - val_acc: 0.5633

Epoch 00002: val_acc improved from 0.53712 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.4804 - acc: 0.8125
 128/1283 [=>............................] - ETA: 2s - loss: 0.5034 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 2s - loss: 0.4999 - acc: 0.7760
 256/1283 [====>.........................] - ETA: 2s - loss: 0.4910 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 2s - loss: 0.4976 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 2s - loss: 0.5090 - acc: 0.7474
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4960 - acc: 0.7634
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4953 - acc: 0.7578
 576/1283 [============>.................] - ETA: 1s - loss: 0.4918 - acc: 0.7552
 640/1283 [=============>................] - ETA: 1s - loss: 0.4896 - acc: 0.7516
 704/1283 [===============>..............] - ETA: 1s - loss: 0.4822 - acc: 0.7585
 768/1283 [================>.............] - ETA: 1s - loss: 0.4768 - acc: 0.7617
 832/1283 [==================>...........] - ETA: 1s - loss: 0.4735 - acc: 0.7620
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4766 - acc: 0.7634
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4733 - acc: 0.7677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4701 - acc: 0.7705
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4713 - acc: 0.7693
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4693 - acc: 0.7717
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4676 - acc: 0.7738
1280/1283 [============================>.] - ETA: 0s - loss: 0.4657 - acc: 0.7742
1283/1283 [==============================] - 3s 2ms/step - loss: 0.4664 - acc: 0.7732 - val_loss: 0.7727 - val_acc: 0.6070

Epoch 00003: val_acc improved from 0.56332 to 0.60699, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4287 - acc: 0.7656
 128/1283 [=>............................] - ETA: 2s - loss: 0.3857 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 2s - loss: 0.3610 - acc: 0.8490
 256/1283 [====>.........................] - ETA: 2s - loss: 0.3443 - acc: 0.8555
 320/1283 [======>.......................] - ETA: 2s - loss: 0.3498 - acc: 0.8438
 384/1283 [=======>......................] - ETA: 2s - loss: 0.3522 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 2s - loss: 0.3439 - acc: 0.8482
 512/1283 [==========>...................] - ETA: 2s - loss: 0.3448 - acc: 0.8438
 576/1283 [============>.................] - ETA: 1s - loss: 0.3414 - acc: 0.8438
 640/1283 [=============>................] - ETA: 1s - loss: 0.3357 - acc: 0.8484
 704/1283 [===============>..............] - ETA: 1s - loss: 0.3343 - acc: 0.8466
 768/1283 [================>.............] - ETA: 1s - loss: 0.3254 - acc: 0.8516
 832/1283 [==================>...........] - ETA: 1s - loss: 0.3238 - acc: 0.8558
 896/1283 [===================>..........] - ETA: 1s - loss: 0.3212 - acc: 0.8583
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3215 - acc: 0.8604
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3188 - acc: 0.8604
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3193 - acc: 0.8594
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3158 - acc: 0.8620
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3137 - acc: 0.8660
1280/1283 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.8672
1283/1283 [==============================] - 4s 3ms/step - loss: 0.3128 - acc: 0.8675 - val_loss: 0.8406 - val_acc: 0.6070

Epoch 00004: val_acc improved from 0.60699 to 0.60699, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1765 - acc: 0.9531
 128/1283 [=>............................] - ETA: 3s - loss: 0.1861 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1835 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1715 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 2s - loss: 0.1661 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 2s - loss: 0.1807 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1785 - acc: 0.9420
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1761 - acc: 0.9414
 576/1283 [============>.................] - ETA: 1s - loss: 0.1799 - acc: 0.9358
 640/1283 [=============>................] - ETA: 1s - loss: 0.1843 - acc: 0.9359
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1808 - acc: 0.9361
 768/1283 [================>.............] - ETA: 1s - loss: 0.1823 - acc: 0.9310
 832/1283 [==================>...........] - ETA: 1s - loss: 0.1797 - acc: 0.9327
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1833 - acc: 0.9308
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1843 - acc: 0.9302
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1829 - acc: 0.9336
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1859 - acc: 0.9311
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1823 - acc: 0.9306
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1798 - acc: 0.9309
1280/1283 [============================>.] - ETA: 0s - loss: 0.1809 - acc: 0.9297
1283/1283 [==============================] - 4s 3ms/step - loss: 0.1805 - acc: 0.9299 - val_loss: 1.0156 - val_acc: 0.5677

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.0935 - acc: 0.9531
 128/1283 [=>............................] - ETA: 3s - loss: 0.1056 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 3s - loss: 0.0933 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 3s - loss: 0.1027 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 3s - loss: 0.0943 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 2s - loss: 0.0985 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 2s - loss: 0.0931 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 2s - loss: 0.0932 - acc: 0.9648
 576/1283 [============>.................] - ETA: 2s - loss: 0.0992 - acc: 0.9635
 640/1283 [=============>................] - ETA: 2s - loss: 0.1003 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1043 - acc: 0.9602
 768/1283 [================>.............] - ETA: 1s - loss: 0.1022 - acc: 0.9622
 832/1283 [==================>...........] - ETA: 1s - loss: 0.1039 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 1s - loss: 0.1025 - acc: 0.9587
 960/1283 [=====================>........] - ETA: 1s - loss: 0.1025 - acc: 0.9594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1012 - acc: 0.9590
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1002 - acc: 0.9605
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0983 - acc: 0.9609
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0974 - acc: 0.9622
1280/1283 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9625
1283/1283 [==============================] - 5s 4ms/step - loss: 0.0969 - acc: 0.9626 - val_loss: 1.2633 - val_acc: 0.5983

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.0422 - acc: 0.9844
 128/1283 [=>............................] - ETA: 3s - loss: 0.0421 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 3s - loss: 0.0632 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0671 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 2s - loss: 0.0759 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 2s - loss: 0.0772 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 2s - loss: 0.0742 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 2s - loss: 0.0743 - acc: 0.9648
 576/1283 [============>.................] - ETA: 1s - loss: 0.0739 - acc: 0.9653
 640/1283 [=============>................] - ETA: 1s - loss: 0.0733 - acc: 0.9656
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0721 - acc: 0.9659
 768/1283 [================>.............] - ETA: 1s - loss: 0.0703 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 1s - loss: 0.0695 - acc: 0.9700
 896/1283 [===================>..........] - ETA: 1s - loss: 0.0678 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0673 - acc: 0.9719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0685 - acc: 0.9707
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0677 - acc: 0.9724
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0665 - acc: 0.9731
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0674 - acc: 0.9712
1280/1283 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9688
1283/1283 [==============================] - 4s 3ms/step - loss: 0.0719 - acc: 0.9688 - val_loss: 2.2938 - val_acc: 0.5939

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0664 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.3083 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 2s - loss: 0.2342 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 2s - loss: 0.2274 - acc: 0.9180
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2472 - acc: 0.9062
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2178 - acc: 0.9141
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1977 - acc: 0.9196
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1819 - acc: 0.9297
 576/1283 [============>.................] - ETA: 1s - loss: 0.1861 - acc: 0.9236
 640/1283 [=============>................] - ETA: 1s - loss: 0.2011 - acc: 0.9141
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1902 - acc: 0.9190
 768/1283 [================>.............] - ETA: 1s - loss: 0.1768 - acc: 0.9245
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1672 - acc: 0.9291
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1751 - acc: 0.9241
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1791 - acc: 0.9198
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1738 - acc: 0.9238
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1683 - acc: 0.9265
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1698 - acc: 0.9280
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1792 - acc: 0.9235
1280/1283 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9273
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1732 - acc: 0.9275 - val_loss: 1.5655 - val_acc: 0.5939

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0440 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.1208 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1717 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1973 - acc: 0.9102
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1775 - acc: 0.9187
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1668 - acc: 0.9245
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1538 - acc: 0.9308
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1503 - acc: 0.9336
 576/1283 [============>.................] - ETA: 1s - loss: 0.1467 - acc: 0.9358
 640/1283 [=============>................] - ETA: 1s - loss: 0.1521 - acc: 0.9328
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1874 - acc: 0.9190
 768/1283 [================>.............] - ETA: 1s - loss: 0.1783 - acc: 0.9232
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1725 - acc: 0.9255
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1682 - acc: 0.9297
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1900 - acc: 0.9208
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1895 - acc: 0.9219
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1886 - acc: 0.9228
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1833 - acc: 0.9245
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1774 - acc: 0.9285
1280/1283 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9313
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1734 - acc: 0.9314 - val_loss: 1.8403 - val_acc: 0.5808

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1568 - acc: 0.9688
 128/1283 [=>............................] - ETA: 2s - loss: 0.1509 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1484 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 2s - loss: 0.2020 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1852 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1693 - acc: 0.9349
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1533 - acc: 0.9442
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1394 - acc: 0.9512
 576/1283 [============>.................] - ETA: 1s - loss: 0.1383 - acc: 0.9514
 640/1283 [=============>................] - ETA: 1s - loss: 0.1384 - acc: 0.9516
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1384 - acc: 0.9503
 768/1283 [================>.............] - ETA: 1s - loss: 0.1321 - acc: 0.9531
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1286 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1256 - acc: 0.9531
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1214 - acc: 0.9552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1213 - acc: 0.9561
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1197 - acc: 0.9559
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1177 - acc: 0.9557
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1152 - acc: 0.9564
1280/1283 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9586
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1118 - acc: 0.9587 - val_loss: 1.3959 - val_acc: 0.5939

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0332 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0814 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0709 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0719 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0670 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0624 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0597 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0594 - acc: 0.9785
 576/1283 [============>.................] - ETA: 1s - loss: 0.0599 - acc: 0.9774
 640/1283 [=============>................] - ETA: 1s - loss: 0.0612 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0616 - acc: 0.9730
 768/1283 [================>.............] - ETA: 1s - loss: 0.0581 - acc: 0.9753
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0592 - acc: 0.9748
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0600 - acc: 0.9743
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0580 - acc: 0.9760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0571 - acc: 0.9766
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0559 - acc: 0.9770
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0542 - acc: 0.9783
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0527 - acc: 0.9786
1280/1283 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9773
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0537 - acc: 0.9774 - val_loss: 1.7032 - val_acc: 0.5895

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0526 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0720 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0722 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0595 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 2s - loss: 0.0576 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0517 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0511 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0464 - acc: 0.9863
 576/1283 [============>.................] - ETA: 1s - loss: 0.0458 - acc: 0.9861
 640/1283 [=============>................] - ETA: 1s - loss: 0.0439 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0435 - acc: 0.9872
 768/1283 [================>.............] - ETA: 1s - loss: 0.0450 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0474 - acc: 0.9820
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0472 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0470 - acc: 0.9812
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0476 - acc: 0.9795
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0465 - acc: 0.9807
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0473 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0482 - acc: 0.9778
1280/1283 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9789
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0466 - acc: 0.9790 - val_loss: 1.9245 - val_acc: 0.5633

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0415 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0357 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0378 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0380 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0403 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0382 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0374 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0413 - acc: 0.9844
 576/1283 [============>.................] - ETA: 1s - loss: 0.0389 - acc: 0.9861
 640/1283 [=============>................] - ETA: 1s - loss: 0.0391 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0365 - acc: 0.9858
 768/1283 [================>.............] - ETA: 0s - loss: 0.0381 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0372 - acc: 0.9856
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0373 - acc: 0.9855
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0381 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0374 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0379 - acc: 0.9835
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0393 - acc: 0.9818
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0412 - acc: 0.9794
1280/1283 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9797
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0407 - acc: 0.9797 - val_loss: 2.0828 - val_acc: 0.5590

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0641 - acc: 0.9688
 128/1283 [=>............................] - ETA: 2s - loss: 0.0384 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0317 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0449 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0500 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0467 - acc: 0.9740
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0470 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0469 - acc: 0.9746
 576/1283 [============>.................] - ETA: 1s - loss: 0.0462 - acc: 0.9774
 640/1283 [=============>................] - ETA: 1s - loss: 0.0453 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0428 - acc: 0.9787
 768/1283 [================>.............] - ETA: 0s - loss: 0.0425 - acc: 0.9792
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0431 - acc: 0.9784
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0427 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0414 - acc: 0.9792
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0431 - acc: 0.9785
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0426 - acc: 0.9789
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0416 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0410 - acc: 0.9794
1280/1283 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9789
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0409 - acc: 0.9790 - val_loss: 2.1370 - val_acc: 0.5590

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=3
max_len=25
nodes=100
mode=all
PCA audio=35
PCA visual=45
PCA text=130
accuracy=0.6005830903790087
best_valid_accuracy=0.575801749271137
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 14:04:07.136459: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.7355 - acc: 0.5469
 256/1283 [====>.........................] - ETA: 0s - loss: 0.7389 - acc: 0.5508
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7350 - acc: 0.5312
 640/1283 [=============>................] - ETA: 0s - loss: 0.7216 - acc: 0.5406
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7149 - acc: 0.5457
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7113 - acc: 0.5479
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7086 - acc: 0.5436
1283/1283 [==============================] - 0s 383us/step - loss: 0.7066 - acc: 0.5487 - val_loss: 0.6977 - val_acc: 0.5284

Epoch 00001: val_loss improved from inf to 0.69772, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_3_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6384 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6331 - acc: 0.6562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6216 - acc: 0.6741
 640/1283 [=============>................] - ETA: 0s - loss: 0.6227 - acc: 0.6703
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6217 - acc: 0.6623
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6130 - acc: 0.6670
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6080 - acc: 0.6711
1283/1283 [==============================] - 0s 334us/step - loss: 0.6113 - acc: 0.6641 - val_loss: 0.7056 - val_acc: 0.5546

Epoch 00002: val_loss did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4833 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4901 - acc: 0.7773
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4953 - acc: 0.7612
 640/1283 [=============>................] - ETA: 0s - loss: 0.4842 - acc: 0.7578
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4676 - acc: 0.7692
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4632 - acc: 0.7734
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4641 - acc: 0.7706
1283/1283 [==============================] - 0s 332us/step - loss: 0.4620 - acc: 0.7708 - val_loss: 0.7588 - val_acc: 0.5808

Epoch 00003: val_loss did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4078 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3227 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3257 - acc: 0.8504
 640/1283 [=============>................] - ETA: 0s - loss: 0.3238 - acc: 0.8516
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3169 - acc: 0.8606
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3124 - acc: 0.8643
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3081 - acc: 0.8635
1283/1283 [==============================] - 0s 329us/step - loss: 0.3077 - acc: 0.8636 - val_loss: 0.8437 - val_acc: 0.6026

Epoch 00004: val_loss did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1783 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1727 - acc: 0.9648
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1790 - acc: 0.9442
 640/1283 [=============>................] - ETA: 0s - loss: 0.1865 - acc: 0.9344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1826 - acc: 0.9315
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1864 - acc: 0.9316
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1831 - acc: 0.9301
1283/1283 [==============================] - 0s 328us/step - loss: 0.1838 - acc: 0.9275 - val_loss: 1.0665 - val_acc: 0.5852

Epoch 00005: val_loss did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0938 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1050 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0973 - acc: 0.9621
 640/1283 [=============>................] - ETA: 0s - loss: 0.1066 - acc: 0.9578
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1081 - acc: 0.9543
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1046 - acc: 0.9551
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1015 - acc: 0.9589
1283/1283 [==============================] - 0s 330us/step - loss: 0.1011 - acc: 0.9595 - val_loss: 1.3897 - val_acc: 0.5546

Epoch 00006: val_loss did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0456 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0683 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0741 - acc: 0.9665
 640/1283 [=============>................] - ETA: 0s - loss: 0.0722 - acc: 0.9703
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0697 - acc: 0.9736
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0672 - acc: 0.9736
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0669 - acc: 0.9737
1283/1283 [==============================] - 0s 327us/step - loss: 0.0670 - acc: 0.9735 - val_loss: 1.5586 - val_acc: 0.5983

Epoch 00007: val_loss did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0446 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0512 - acc: 0.9883
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0516 - acc: 0.9821
 640/1283 [=============>................] - ETA: 0s - loss: 0.0512 - acc: 0.9797
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0499 - acc: 0.9784
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0499 - acc: 0.9785
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0506 - acc: 0.9770
1283/1283 [==============================] - 0s 333us/step - loss: 0.0491 - acc: 0.9782 - val_loss: 1.8180 - val_acc: 0.5764

Epoch 00008: val_loss did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0264 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0428 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0422 - acc: 0.9710
 640/1283 [=============>................] - ETA: 0s - loss: 0.0417 - acc: 0.9750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0450 - acc: 0.9724
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0432 - acc: 0.9756
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0431 - acc: 0.9770
1283/1283 [==============================] - 0s 328us/step - loss: 0.0435 - acc: 0.9782 - val_loss: 2.2919 - val_acc: 0.5764

Epoch 00009: val_loss did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0215 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0423 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0395 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0372 - acc: 0.9859
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0422 - acc: 0.9820
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0464 - acc: 0.9805
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0494 - acc: 0.9770
1283/1283 [==============================] - 0s 329us/step - loss: 0.0484 - acc: 0.9774 - val_loss: 2.6879 - val_acc: 0.5415

Epoch 00010: val_loss did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0480 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0713 - acc: 0.9648
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0617 - acc: 0.9710
 640/1283 [=============>................] - ETA: 0s - loss: 0.0645 - acc: 0.9656
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0654 - acc: 0.9663
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0683 - acc: 0.9678
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0656 - acc: 0.9696
1283/1283 [==============================] - 0s 331us/step - loss: 0.0652 - acc: 0.9688 - val_loss: 1.8044 - val_acc: 0.5808

Epoch 00011: val_loss did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=3
max_len=25
nodes=100
mode=all
PCA audio=35
PCA visual=45
PCA text=130
accuracy=0.5918367346938775
best_valid_accuracy=0.5160349854227405
