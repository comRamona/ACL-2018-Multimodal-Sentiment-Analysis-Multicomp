/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 13:09:34.604473: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 14s - loss: 0.9568 - acc: 0.5000
 256/1283 [====>.........................] - ETA: 3s - loss: 0.9446 - acc: 0.4727 
 384/1283 [=======>......................] - ETA: 2s - loss: 0.8682 - acc: 0.4948
 512/1283 [==========>...................] - ETA: 1s - loss: 0.8340 - acc: 0.5117
 640/1283 [=============>................] - ETA: 1s - loss: 0.8040 - acc: 0.5312
 768/1283 [================>.............] - ETA: 0s - loss: 0.7968 - acc: 0.5339
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7927 - acc: 0.5234
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7831 - acc: 0.5292
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7780 - acc: 0.5340
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7711 - acc: 0.5370
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7678 - acc: 0.5362 - val_loss: 0.7585 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5726 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5578 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5674 - acc: 0.6562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5405 - acc: 0.7070
 576/1283 [============>.................] - ETA: 0s - loss: 0.5336 - acc: 0.7101
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5405 - acc: 0.6960
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5276 - acc: 0.7031
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5207 - acc: 0.7165
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5150 - acc: 0.7240
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5126 - acc: 0.7289
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5062 - acc: 0.7344
1283/1283 [==============================] - 1s 643us/step - loss: 0.5009 - acc: 0.7381 - val_loss: 0.7074 - val_acc: 0.6026

Epoch 00002: val_acc improved from 0.54148 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3893 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3950 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3584 - acc: 0.8531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3502 - acc: 0.8638
 576/1283 [============>.................] - ETA: 0s - loss: 0.3492 - acc: 0.8698
 640/1283 [=============>................] - ETA: 0s - loss: 0.3482 - acc: 0.8703
 768/1283 [================>.............] - ETA: 0s - loss: 0.3460 - acc: 0.8711
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3418 - acc: 0.8738
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3368 - acc: 0.8802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3314 - acc: 0.8848
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3281 - acc: 0.8880
1280/1283 [============================>.] - ETA: 0s - loss: 0.3252 - acc: 0.8891
1283/1283 [==============================] - 1s 746us/step - loss: 0.3263 - acc: 0.8878 - val_loss: 0.7079 - val_acc: 0.6332

Epoch 00003: val_acc improved from 0.60262 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2008 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2170 - acc: 0.9740
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2166 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2239 - acc: 0.9609
 640/1283 [=============>................] - ETA: 0s - loss: 0.2252 - acc: 0.9547
 768/1283 [================>.............] - ETA: 0s - loss: 0.2318 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2362 - acc: 0.9464
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2348 - acc: 0.9490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2361 - acc: 0.9453
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2367 - acc: 0.9453
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2367 - acc: 0.9433
1283/1283 [==============================] - 1s 613us/step - loss: 0.2345 - acc: 0.9423 - val_loss: 0.8607 - val_acc: 0.6157

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2274 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2696 - acc: 0.8802
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2568 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2297 - acc: 0.9115
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2157 - acc: 0.9199
 640/1283 [=============>................] - ETA: 0s - loss: 0.2059 - acc: 0.9313
 768/1283 [================>.............] - ETA: 0s - loss: 0.2046 - acc: 0.9297
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1957 - acc: 0.9364
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1956 - acc: 0.9365
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1956 - acc: 0.9366
1280/1283 [============================>.] - ETA: 0s - loss: 0.1942 - acc: 0.9367
1283/1283 [==============================] - 1s 788us/step - loss: 0.1940 - acc: 0.9369 - val_loss: 0.8372 - val_acc: 0.6114

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1438 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1385 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1550 - acc: 0.9648
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1490 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1405 - acc: 0.9727
 640/1283 [=============>................] - ETA: 0s - loss: 0.1378 - acc: 0.9719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1404 - acc: 0.9702
 768/1283 [================>.............] - ETA: 0s - loss: 0.1389 - acc: 0.9701
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1368 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1372 - acc: 0.9677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1372 - acc: 0.9669
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1367 - acc: 0.9653
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1355 - acc: 0.9663
1280/1283 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9672
1283/1283 [==============================] - 1s 997us/step - loss: 0.1336 - acc: 0.9673 - val_loss: 0.8688 - val_acc: 0.6550

Epoch 00006: val_acc improved from 0.63319 to 0.65502, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0861 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0996 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1022 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1007 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0973 - acc: 0.9785
 640/1283 [=============>................] - ETA: 0s - loss: 0.0957 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0952 - acc: 0.9787
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0953 - acc: 0.9796
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0934 - acc: 0.9810
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0938 - acc: 0.9795
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0924 - acc: 0.9807
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0911 - acc: 0.9811
1283/1283 [==============================] - 1s 762us/step - loss: 0.0895 - acc: 0.9821 - val_loss: 0.9612 - val_acc: 0.6376

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0459 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0544 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0661 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0649 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0647 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0650 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0672 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0700 - acc: 0.9826
 640/1283 [=============>................] - ETA: 0s - loss: 0.0689 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0669 - acc: 0.9830
 768/1283 [================>.............] - ETA: 0s - loss: 0.0663 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0660 - acc: 0.9855
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0653 - acc: 0.9865
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0643 - acc: 0.9873
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0646 - acc: 0.9881
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0628 - acc: 0.9885
1280/1283 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9867
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0631 - acc: 0.9867 - val_loss: 1.0180 - val_acc: 0.6463

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0760 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0532 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0519 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0506 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0490 - acc: 0.9922
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0465 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0507 - acc: 0.9891
 768/1283 [================>.............] - ETA: 0s - loss: 0.0520 - acc: 0.9883
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0503 - acc: 0.9888
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0505 - acc: 0.9893
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0492 - acc: 0.9896
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0489 - acc: 0.9901
1283/1283 [==============================] - 1s 778us/step - loss: 0.0485 - acc: 0.9906 - val_loss: 1.0942 - val_acc: 0.6594

Epoch 00009: val_acc improved from 0.65502 to 0.65939, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0258 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0337 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0309 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0379 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0369 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0335 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0323 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0314 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0320 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0320 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0321 - acc: 0.9944
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0328 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0335 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0327 - acc: 0.9936
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0341 - acc: 0.9926
1280/1283 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9922
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0342 - acc: 0.9922 - val_loss: 1.1612 - val_acc: 0.6638

Epoch 00010: val_acc improved from 0.65939 to 0.66376, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_15.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0159 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0183 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0238 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0273 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0295 - acc: 0.9941
 640/1283 [=============>................] - ETA: 0s - loss: 0.0314 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0305 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0295 - acc: 0.9935
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0279 - acc: 0.9944
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0272 - acc: 0.9948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0274 - acc: 0.9951
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0265 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0257 - acc: 0.9957
1280/1283 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9953
1283/1283 [==============================] - 1s 938us/step - loss: 0.0276 - acc: 0.9938 - val_loss: 1.2621 - val_acc: 0.6419

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0128 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0318 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0393 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0514 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0497 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0620 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0574 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0584 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0586 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0598 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0603 - acc: 0.9844
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0611 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0651 - acc: 0.9816
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0635 - acc: 0.9827
1283/1283 [==============================] - 1s 976us/step - loss: 0.0628 - acc: 0.9829 - val_loss: 1.5174 - val_acc: 0.6288

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0669 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.0471 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0407 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0354 - acc: 0.9870
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0465 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0440 - acc: 0.9859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0431 - acc: 0.9858
 768/1283 [================>.............] - ETA: 0s - loss: 0.0417 - acc: 0.9870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0408 - acc: 0.9880
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0424 - acc: 0.9865
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0428 - acc: 0.9863
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0414 - acc: 0.9862
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0406 - acc: 0.9870
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0395 - acc: 0.9877
1280/1283 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9875
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0396 - acc: 0.9875 - val_loss: 1.3145 - val_acc: 0.6288

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0210 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0252 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0298 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0301 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0268 - acc: 0.9961
 640/1283 [=============>................] - ETA: 0s - loss: 0.0250 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0227 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0221 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0215 - acc: 0.9978
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0217 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0223 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0223 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0227 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0230 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9961
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0228 - acc: 0.9961 - val_loss: 1.3510 - val_acc: 0.6332

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0303 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0233 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0204 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0176 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0166 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0169 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0175 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0172 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0168 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0154 - acc: 0.9964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0163 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0159 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0153 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0154 - acc: 0.9965
1280/1283 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9953
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0174 - acc: 0.9953 - val_loss: 1.4974 - val_acc: 0.6332

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0141 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0280 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0315 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0825 - acc: 0.9656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0677 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0609 - acc: 0.9766
 640/1283 [=============>................] - ETA: 0s - loss: 0.0552 - acc: 0.9781
 768/1283 [================>.............] - ETA: 0s - loss: 0.0637 - acc: 0.9779
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0619 - acc: 0.9799
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0568 - acc: 0.9824
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0529 - acc: 0.9835
1280/1283 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9836
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0531 - acc: 0.9836 - val_loss: 1.5025 - val_acc: 0.6550

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0262 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0216 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0192 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0259 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0270 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0323 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0303 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0278 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0283 - acc: 0.9922
 768/1283 [================>.............] - ETA: 0s - loss: 0.0265 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0259 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0256 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0250 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0242 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0240 - acc: 0.9945
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0247 - acc: 0.9939
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0245 - acc: 0.9934
1280/1283 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9938
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0237 - acc: 0.9938 - val_loss: 1.4850 - val_acc: 0.6550

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0107 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0173 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0173 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0193 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0170 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0206 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0181 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0184 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0191 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0176 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0167 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0169 - acc: 0.9978
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0161 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0154 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0154 - acc: 0.9982
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0152 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9977
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0150 - acc: 0.9977 - val_loss: 1.5356 - val_acc: 0.6507

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0086 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0097 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0081 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0096 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0085 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0116 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0102 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0126 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0125 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0122 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0123 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0130 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0130 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0119 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0121 - acc: 0.9957
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0119 - acc: 0.9959
1280/1283 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9961
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 1.5858 - val_acc: 0.6550

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0099 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0089 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0072 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0077 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0085 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0083 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0095 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0091 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0088 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0092 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0086 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0093 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0089 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0088 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0087 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0096 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9977
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0093 - acc: 0.9977 - val_loss: 1.6252 - val_acc: 0.6638

Epoch 00020: val_acc did not improve
Epoch 00020: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=15
nodes=100
mode=VT
PCA audio=35
PCA visual=45
PCA text=130
accuracy=0.5889212827988338
best_valid_accuracy=0.6253644314868805
