/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 20:51:47.738499: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 41s - loss: 0.7030 - acc: 0.5156
 256/1283 [====>.........................] - ETA: 9s - loss: 0.6871 - acc: 0.5664 
 320/1283 [======>.......................] - ETA: 6s - loss: 0.6872 - acc: 0.5687
 448/1283 [=========>....................] - ETA: 4s - loss: 0.6873 - acc: 0.5536
 576/1283 [============>.................] - ETA: 3s - loss: 0.6866 - acc: 0.5434
 704/1283 [===============>..............] - ETA: 2s - loss: 0.6826 - acc: 0.5540
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6796 - acc: 0.5589
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6777 - acc: 0.5677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6772 - acc: 0.5671
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6771 - acc: 0.5650
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6766 - acc: 0.5635 - val_loss: 0.6532 - val_acc: 0.6594

Epoch 00001: val_acc improved from -inf to 0.65939, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6288 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6346 - acc: 0.6458
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6263 - acc: 0.6937
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6305 - acc: 0.6875
 576/1283 [============>.................] - ETA: 0s - loss: 0.6294 - acc: 0.6979
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6285 - acc: 0.6974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6270 - acc: 0.7007
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6248 - acc: 0.7021
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6233 - acc: 0.7022
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6204 - acc: 0.7056
1283/1283 [==============================] - 1s 624us/step - loss: 0.6217 - acc: 0.6999 - val_loss: 0.6087 - val_acc: 0.7074

Epoch 00002: val_acc improved from 0.65939 to 0.70742, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5770 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5565 - acc: 0.7760
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5700 - acc: 0.7469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5684 - acc: 0.7422
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5690 - acc: 0.7383
 640/1283 [=============>................] - ETA: 0s - loss: 0.5661 - acc: 0.7375
 768/1283 [================>.............] - ETA: 0s - loss: 0.5627 - acc: 0.7422
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5633 - acc: 0.7388
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5594 - acc: 0.7441
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5590 - acc: 0.7413
1280/1283 [============================>.] - ETA: 0s - loss: 0.5582 - acc: 0.7391
1283/1283 [==============================] - 1s 602us/step - loss: 0.5592 - acc: 0.7381 - val_loss: 0.5653 - val_acc: 0.7031

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5270 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5328 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5187 - acc: 0.7312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5157 - acc: 0.7411
 576/1283 [============>.................] - ETA: 0s - loss: 0.5117 - acc: 0.7413
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5115 - acc: 0.7415
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5030 - acc: 0.7476
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5012 - acc: 0.7511
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4996 - acc: 0.7521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4971 - acc: 0.7546
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4979 - acc: 0.7552
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4973 - acc: 0.7574
1280/1283 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.7578
1283/1283 [==============================] - 1s 779us/step - loss: 0.4946 - acc: 0.7584 - val_loss: 0.5391 - val_acc: 0.7336

Epoch 00004: val_acc improved from 0.70742 to 0.73362, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5190 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4649 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4310 - acc: 0.7930
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4300 - acc: 0.8031
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4391 - acc: 0.7917
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4376 - acc: 0.7924
 576/1283 [============>.................] - ETA: 0s - loss: 0.4655 - acc: 0.7760
 640/1283 [=============>................] - ETA: 0s - loss: 0.4570 - acc: 0.7828
 768/1283 [================>.............] - ETA: 0s - loss: 0.4678 - acc: 0.7786
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4638 - acc: 0.7746
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4498 - acc: 0.7891
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4483 - acc: 0.7886
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4494 - acc: 0.7911
1280/1283 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.7898
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4509 - acc: 0.7896 - val_loss: 0.5358 - val_acc: 0.7336

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3617 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4173 - acc: 0.8177
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4022 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3965 - acc: 0.8344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3906 - acc: 0.8359
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3988 - acc: 0.8184
 576/1283 [============>.................] - ETA: 0s - loss: 0.4008 - acc: 0.8177
 640/1283 [=============>................] - ETA: 0s - loss: 0.3977 - acc: 0.8203
 768/1283 [================>.............] - ETA: 0s - loss: 0.3932 - acc: 0.8255
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3933 - acc: 0.8269
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3922 - acc: 0.8292
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3896 - acc: 0.8320
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3963 - acc: 0.8263
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3963 - acc: 0.8257
1283/1283 [==============================] - 1s 909us/step - loss: 0.3927 - acc: 0.8277 - val_loss: 0.5515 - val_acc: 0.7336

Epoch 00006: val_acc improved from 0.73362 to 0.73362, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3966 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3887 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3940 - acc: 0.8406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3822 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3812 - acc: 0.8371
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3872 - acc: 0.8359
 576/1283 [============>.................] - ETA: 0s - loss: 0.3802 - acc: 0.8420
 640/1283 [=============>................] - ETA: 0s - loss: 0.3723 - acc: 0.8469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3715 - acc: 0.8494
 768/1283 [================>.............] - ETA: 0s - loss: 0.3690 - acc: 0.8477
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3655 - acc: 0.8486
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3669 - acc: 0.8449
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3658 - acc: 0.8469
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3635 - acc: 0.8477
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3617 - acc: 0.8502
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3642 - acc: 0.8512
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3605 - acc: 0.8542 - val_loss: 0.5649 - val_acc: 0.7293

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3505 - acc: 0.8594
 128/1283 [=>............................] - ETA: 0s - loss: 0.3514 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3338 - acc: 0.8711
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3171 - acc: 0.8828
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3245 - acc: 0.8789
 640/1283 [=============>................] - ETA: 0s - loss: 0.3280 - acc: 0.8781
 768/1283 [================>.............] - ETA: 0s - loss: 0.3272 - acc: 0.8776
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3239 - acc: 0.8786
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3224 - acc: 0.8806
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3305 - acc: 0.8740
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3276 - acc: 0.8750
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3275 - acc: 0.8734
1283/1283 [==============================] - 1s 837us/step - loss: 0.3221 - acc: 0.8761 - val_loss: 0.6085 - val_acc: 0.7162

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2186 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2303 - acc: 0.9271
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2430 - acc: 0.9125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2474 - acc: 0.9141
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2521 - acc: 0.9107
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2615 - acc: 0.9043
 576/1283 [============>.................] - ETA: 0s - loss: 0.2576 - acc: 0.9062
 640/1283 [=============>................] - ETA: 0s - loss: 0.2611 - acc: 0.9062
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2619 - acc: 0.9091
 768/1283 [================>.............] - ETA: 0s - loss: 0.2521 - acc: 0.9128
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2503 - acc: 0.9123
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2503 - acc: 0.9129
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2597 - acc: 0.9072
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2614 - acc: 0.9089
1280/1283 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9086
1283/1283 [==============================] - 1s 847us/step - loss: 0.2572 - acc: 0.9080 - val_loss: 0.6499 - val_acc: 0.6987

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2808 - acc: 0.8906
 128/1283 [=>............................] - ETA: 0s - loss: 0.2476 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2567 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2508 - acc: 0.9141
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2509 - acc: 0.9156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2577 - acc: 0.9062
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2650 - acc: 0.9043
 640/1283 [=============>................] - ETA: 0s - loss: 0.2618 - acc: 0.9031
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2583 - acc: 0.9034
 768/1283 [================>.............] - ETA: 0s - loss: 0.2570 - acc: 0.9049
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2554 - acc: 0.9087
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2543 - acc: 0.9062
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2473 - acc: 0.9092
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2410 - acc: 0.9123
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2372 - acc: 0.9137
1280/1283 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9141
1283/1283 [==============================] - 1s 879us/step - loss: 0.2375 - acc: 0.9127 - val_loss: 0.6771 - val_acc: 0.7118

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1802 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1993 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1914 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1857 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1873 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1834 - acc: 0.9487
 576/1283 [============>.................] - ETA: 0s - loss: 0.1964 - acc: 0.9392
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2014 - acc: 0.9361
 768/1283 [================>.............] - ETA: 0s - loss: 0.2018 - acc: 0.9362
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2042 - acc: 0.9303
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2066 - acc: 0.9308
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2090 - acc: 0.9297
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2146 - acc: 0.9271
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2156 - acc: 0.9268
1280/1283 [============================>.] - ETA: 0s - loss: 0.2158 - acc: 0.9266
1283/1283 [==============================] - 1s 957us/step - loss: 0.2157 - acc: 0.9267 - val_loss: 0.7118 - val_acc: 0.6507

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1800 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1814 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1867 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1829 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1722 - acc: 0.9563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1886 - acc: 0.9464
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1887 - acc: 0.9414
 640/1283 [=============>................] - ETA: 0s - loss: 0.2001 - acc: 0.9328
 768/1283 [================>.............] - ETA: 0s - loss: 0.1917 - acc: 0.9362
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1920 - acc: 0.9319
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1891 - acc: 0.9355
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1887 - acc: 0.9323
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1887 - acc: 0.9326
1280/1283 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9359
1283/1283 [==============================] - 1s 885us/step - loss: 0.1843 - acc: 0.9361 - val_loss: 0.7506 - val_acc: 0.6856

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1131 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1147 - acc: 0.9766
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1442 - acc: 0.9570
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1626 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1529 - acc: 0.9509
 576/1283 [============>.................] - ETA: 0s - loss: 0.1499 - acc: 0.9514
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1513 - acc: 0.9531
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1528 - acc: 0.9507
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1487 - acc: 0.9510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1464 - acc: 0.9522
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1445 - acc: 0.9531
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1435 - acc: 0.9515
1280/1283 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9516
1283/1283 [==============================] - 1s 837us/step - loss: 0.1411 - acc: 0.9517 - val_loss: 0.8075 - val_acc: 0.6812

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1754 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.1194 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1099 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1306 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1301 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1231 - acc: 0.9635
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1196 - acc: 0.9609
 576/1283 [============>.................] - ETA: 0s - loss: 0.1216 - acc: 0.9583
 640/1283 [=============>................] - ETA: 0s - loss: 0.1173 - acc: 0.9609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1174 - acc: 0.9588
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1184 - acc: 0.9615
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1192 - acc: 0.9632
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1167 - acc: 0.9639
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1147 - acc: 0.9635
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1151 - acc: 0.9638
1283/1283 [==============================] - 1s 952us/step - loss: 0.1156 - acc: 0.9641 - val_loss: 0.8496 - val_acc: 0.6638

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0693 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0989 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0926 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0913 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0866 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0833 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0842 - acc: 0.9809
 640/1283 [=============>................] - ETA: 0s - loss: 0.0850 - acc: 0.9797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0904 - acc: 0.9759
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0977 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0942 - acc: 0.9732
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0989 - acc: 0.9698
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0980 - acc: 0.9707
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0947 - acc: 0.9715
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1008 - acc: 0.9663
1283/1283 [==============================] - 1s 969us/step - loss: 0.0983 - acc: 0.9673 - val_loss: 0.9284 - val_acc: 0.6681

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0859 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0856 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0823 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0812 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0799 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.0820 - acc: 0.9774
 640/1283 [=============>................] - ETA: 0s - loss: 0.0785 - acc: 0.9797
 768/1283 [================>.............] - ETA: 0s - loss: 0.0792 - acc: 0.9792
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0770 - acc: 0.9808
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0788 - acc: 0.9802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0793 - acc: 0.9795
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0754 - acc: 0.9818
1280/1283 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9805
1283/1283 [==============================] - 1s 866us/step - loss: 0.0792 - acc: 0.9805 - val_loss: 0.9626 - val_acc: 0.6987

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=70
accuracy=0.673469387755102
best_valid_accuracy=0.6836734693877551
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:20:09.792878: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 30s - loss: 0.6734 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 9s - loss: 0.6875 - acc: 0.5781 
 320/1283 [======>.......................] - ETA: 5s - loss: 0.6882 - acc: 0.5656
 384/1283 [=======>......................] - ETA: 4s - loss: 0.6899 - acc: 0.5469
 448/1283 [=========>....................] - ETA: 3s - loss: 0.6862 - acc: 0.5580
 512/1283 [==========>...................] - ETA: 2s - loss: 0.6867 - acc: 0.5527
 576/1283 [============>.................] - ETA: 2s - loss: 0.6840 - acc: 0.5694
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6824 - acc: 0.5710
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6800 - acc: 0.5805
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6793 - acc: 0.5771
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6766 - acc: 0.5855
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6743 - acc: 0.5938
1280/1283 [============================>.] - ETA: 0s - loss: 0.6733 - acc: 0.5945
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6734 - acc: 0.5939 - val_loss: 0.6523 - val_acc: 0.6507

Epoch 00001: val_acc improved from -inf to 0.65066, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6170 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.6223 - acc: 0.6641
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6209 - acc: 0.6836
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6261 - acc: 0.6771
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6171 - acc: 0.6895
 576/1283 [============>.................] - ETA: 0s - loss: 0.6145 - acc: 0.6944
 640/1283 [=============>................] - ETA: 0s - loss: 0.6154 - acc: 0.6922
 768/1283 [================>.............] - ETA: 0s - loss: 0.6164 - acc: 0.6862
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6142 - acc: 0.6819
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6109 - acc: 0.6924
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6076 - acc: 0.6976
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6075 - acc: 0.6979
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6081 - acc: 0.6974
1280/1283 [============================>.] - ETA: 0s - loss: 0.6084 - acc: 0.6961
1283/1283 [==============================] - 1s 823us/step - loss: 0.6087 - acc: 0.6952 - val_loss: 0.5999 - val_acc: 0.7074

Epoch 00002: val_acc improved from 0.65066 to 0.70742, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5604 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5634 - acc: 0.7344
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5543 - acc: 0.7594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5595 - acc: 0.7448
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5606 - acc: 0.7422
 640/1283 [=============>................] - ETA: 0s - loss: 0.5594 - acc: 0.7375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5601 - acc: 0.7330
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5537 - acc: 0.7368
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5505 - acc: 0.7375
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5479 - acc: 0.7408
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5429 - acc: 0.7525
1280/1283 [============================>.] - ETA: 0s - loss: 0.5435 - acc: 0.7531
1283/1283 [==============================] - 1s 859us/step - loss: 0.5440 - acc: 0.7529 - val_loss: 0.5595 - val_acc: 0.7205

Epoch 00003: val_acc improved from 0.70742 to 0.72052, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5115 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.5039 - acc: 0.7734
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4938 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4975 - acc: 0.7695
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5083 - acc: 0.7760
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5044 - acc: 0.7701
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5024 - acc: 0.7715
 576/1283 [============>.................] - ETA: 0s - loss: 0.5010 - acc: 0.7726
 640/1283 [=============>................] - ETA: 0s - loss: 0.4950 - acc: 0.7750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4904 - acc: 0.7741
 768/1283 [================>.............] - ETA: 0s - loss: 0.4848 - acc: 0.7826
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4877 - acc: 0.7801
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4880 - acc: 0.7803
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4853 - acc: 0.7830
1280/1283 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.7844
1283/1283 [==============================] - 1s 905us/step - loss: 0.4851 - acc: 0.7849 - val_loss: 0.5275 - val_acc: 0.7424

Epoch 00004: val_acc improved from 0.72052 to 0.74236, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4452 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4183 - acc: 0.8229
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4160 - acc: 0.8250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4289 - acc: 0.8125
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4202 - acc: 0.8203
 640/1283 [=============>................] - ETA: 0s - loss: 0.4091 - acc: 0.8328
 768/1283 [================>.............] - ETA: 0s - loss: 0.4119 - acc: 0.8242
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4127 - acc: 0.8197
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4162 - acc: 0.8167
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4159 - acc: 0.8174
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4199 - acc: 0.8180
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4189 - acc: 0.8168
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4131 - acc: 0.8183
1283/1283 [==============================] - 1s 924us/step - loss: 0.4163 - acc: 0.8176 - val_loss: 0.5282 - val_acc: 0.7249

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3607 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3898 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3587 - acc: 0.8789
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3572 - acc: 0.8875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3460 - acc: 0.8932
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3429 - acc: 0.8929
 576/1283 [============>.................] - ETA: 0s - loss: 0.3529 - acc: 0.8715
 640/1283 [=============>................] - ETA: 0s - loss: 0.3626 - acc: 0.8609
 768/1283 [================>.............] - ETA: 0s - loss: 0.3740 - acc: 0.8516
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3746 - acc: 0.8486
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3766 - acc: 0.8460
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3674 - acc: 0.8477
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3681 - acc: 0.8456
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3699 - acc: 0.8472
1280/1283 [============================>.] - ETA: 0s - loss: 0.3731 - acc: 0.8453
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3730 - acc: 0.8457 - val_loss: 0.5322 - val_acc: 0.7205

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2886 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.3064 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3152 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3080 - acc: 0.8984
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2944 - acc: 0.9115
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3041 - acc: 0.8951
 576/1283 [============>.................] - ETA: 0s - loss: 0.3236 - acc: 0.8889
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3242 - acc: 0.8778
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3205 - acc: 0.8750
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3182 - acc: 0.8761
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3173 - acc: 0.8771
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3168 - acc: 0.8770
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3150 - acc: 0.8811
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3187 - acc: 0.8750
1280/1283 [============================>.] - ETA: 0s - loss: 0.3149 - acc: 0.8781
1283/1283 [==============================] - 1s 981us/step - loss: 0.3157 - acc: 0.8776 - val_loss: 0.5473 - val_acc: 0.7205

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4166 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.3669 - acc: 0.8516
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3363 - acc: 0.8711
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3211 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3151 - acc: 0.8817
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3185 - acc: 0.8809
 640/1283 [=============>................] - ETA: 0s - loss: 0.3061 - acc: 0.8844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3074 - acc: 0.8821
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2993 - acc: 0.8882
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2917 - acc: 0.8906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2903 - acc: 0.8926
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2844 - acc: 0.8967
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2851 - acc: 0.8923
1280/1283 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.8938
1283/1283 [==============================] - 1s 923us/step - loss: 0.2843 - acc: 0.8940 - val_loss: 0.5621 - val_acc: 0.7293

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2452 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.2436 - acc: 0.8984
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2296 - acc: 0.8984
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2253 - acc: 0.9031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2278 - acc: 0.9107
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2301 - acc: 0.9102
 576/1283 [============>.................] - ETA: 0s - loss: 0.2303 - acc: 0.9115
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2193 - acc: 0.9176
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2220 - acc: 0.9171
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2188 - acc: 0.9196
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2228 - acc: 0.9170
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2267 - acc: 0.9141
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2300 - acc: 0.9128
1283/1283 [==============================] - 1s 942us/step - loss: 0.2264 - acc: 0.9150 - val_loss: 0.6137 - val_acc: 0.6987

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1511 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2003 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1922 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1885 - acc: 0.9250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1931 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1863 - acc: 0.9286
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1813 - acc: 0.9355
 640/1283 [=============>................] - ETA: 0s - loss: 0.1760 - acc: 0.9375
 768/1283 [================>.............] - ETA: 0s - loss: 0.1820 - acc: 0.9310
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1796 - acc: 0.9330
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1791 - acc: 0.9326
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1775 - acc: 0.9332
1280/1283 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9344
1283/1283 [==============================] - 1s 798us/step - loss: 0.1785 - acc: 0.9345 - val_loss: 0.6540 - val_acc: 0.7118

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1534 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1738 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1366 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1311 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1286 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1270 - acc: 0.9648
 640/1283 [=============>................] - ETA: 0s - loss: 0.1197 - acc: 0.9656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1232 - acc: 0.9659
 768/1283 [================>.............] - ETA: 0s - loss: 0.1242 - acc: 0.9661
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1254 - acc: 0.9651
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1240 - acc: 0.9665
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1244 - acc: 0.9656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1287 - acc: 0.9651
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1311 - acc: 0.9622
1280/1283 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9633
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1306 - acc: 0.9634 - val_loss: 0.7139 - val_acc: 0.7031

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0964 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.0953 - acc: 0.9766
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1121 - acc: 0.9648
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1219 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1159 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1195 - acc: 0.9609
 640/1283 [=============>................] - ETA: 0s - loss: 0.1187 - acc: 0.9609
 768/1283 [================>.............] - ETA: 0s - loss: 0.1081 - acc: 0.9661
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1047 - acc: 0.9675
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1070 - acc: 0.9632
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1137 - acc: 0.9590
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1125 - acc: 0.9596
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1134 - acc: 0.9601
1280/1283 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9609
1283/1283 [==============================] - 1s 889us/step - loss: 0.1117 - acc: 0.9610 - val_loss: 0.7212 - val_acc: 0.7205

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0436 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0742 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0804 - acc: 0.9609
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0887 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0827 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0808 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.0832 - acc: 0.9618
 640/1283 [=============>................] - ETA: 0s - loss: 0.0848 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0825 - acc: 0.9645
 768/1283 [================>.............] - ETA: 0s - loss: 0.0816 - acc: 0.9648
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0814 - acc: 0.9651
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0807 - acc: 0.9665
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0800 - acc: 0.9677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0797 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0793 - acc: 0.9696
1283/1283 [==============================] - 1s 921us/step - loss: 0.0789 - acc: 0.9704 - val_loss: 0.7683 - val_acc: 0.7336

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0628 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1248 - acc: 0.9297
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0840 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0805 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0759 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0728 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0703 - acc: 0.9668
 576/1283 [============>.................] - ETA: 0s - loss: 0.0726 - acc: 0.9670
 640/1283 [=============>................] - ETA: 0s - loss: 0.0704 - acc: 0.9703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0687 - acc: 0.9730
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0671 - acc: 0.9760
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0669 - acc: 0.9766
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0650 - acc: 0.9775
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0624 - acc: 0.9800
1280/1283 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9820
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0604 - acc: 0.9821 - val_loss: 0.7763 - val_acc: 0.7424

Epoch 00014: val_acc improved from 0.74236 to 0.74236, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0409 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0474 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0465 - acc: 0.9883
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0405 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0403 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0448 - acc: 0.9902
 576/1283 [============>.................] - ETA: 0s - loss: 0.0433 - acc: 0.9913
 640/1283 [=============>................] - ETA: 0s - loss: 0.0418 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0403 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0392 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0387 - acc: 0.9928
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0425 - acc: 0.9896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0405 - acc: 0.9899
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0411 - acc: 0.9901
1283/1283 [==============================] - 1s 959us/step - loss: 0.0404 - acc: 0.9906 - val_loss: 0.8239 - val_acc: 0.7380

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0206 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0279 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0288 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0323 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0374 - acc: 0.9902
 576/1283 [============>.................] - ETA: 0s - loss: 0.0347 - acc: 0.9913
 640/1283 [=============>................] - ETA: 0s - loss: 0.0371 - acc: 0.9906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0439 - acc: 0.9872
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0438 - acc: 0.9856
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0427 - acc: 0.9855
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0450 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0436 - acc: 0.9854
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0489 - acc: 0.9816
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0494 - acc: 0.9811
1283/1283 [==============================] - 1s 870us/step - loss: 0.0481 - acc: 0.9821 - val_loss: 0.8542 - val_acc: 0.7336

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0334 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0405 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0381 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0375 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0448 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0424 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0428 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0493 - acc: 0.9826
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0488 - acc: 0.9815
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0470 - acc: 0.9820
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0439 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0444 - acc: 0.9853
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0417 - acc: 0.9868
1280/1283 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9852
1283/1283 [==============================] - 1s 865us/step - loss: 0.0481 - acc: 0.9852 - val_loss: 0.9086 - val_acc: 0.7336

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0726 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0320 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0433 - acc: 0.9883
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0405 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0392 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0355 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0355 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0353 - acc: 0.9915
 768/1283 [================>.............] - ETA: 0s - loss: 0.0356 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0353 - acc: 0.9916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0343 - acc: 0.9922
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0341 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0330 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0340 - acc: 0.9917
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0320 - acc: 0.9926
1280/1283 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9914
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0338 - acc: 0.9914 - val_loss: 0.9679 - val_acc: 0.7074

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0314 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0397 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0302 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0325 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0287 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0292 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0275 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0282 - acc: 0.9943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0299 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0290 - acc: 0.9933
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0274 - acc: 0.9941
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0274 - acc: 0.9931
1280/1283 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9930
1283/1283 [==============================] - 1s 922us/step - loss: 0.0285 - acc: 0.9922 - val_loss: 0.9435 - val_acc: 0.7162

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0109 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0255 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0300 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0417 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0389 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0529 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0638 - acc: 0.9773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0674 - acc: 0.9736
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0680 - acc: 0.9743
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0717 - acc: 0.9727
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0719 - acc: 0.9731
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0718 - acc: 0.9737
1283/1283 [==============================] - 1s 856us/step - loss: 0.0721 - acc: 0.9727 - val_loss: 0.9398 - val_acc: 0.7424

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0841 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0584 - acc: 0.9766
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0449 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0391 - acc: 0.9870
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0370 - acc: 0.9883
 576/1283 [============>.................] - ETA: 0s - loss: 0.0430 - acc: 0.9861
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0398 - acc: 0.9872
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0382 - acc: 0.9880
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0382 - acc: 0.9885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0382 - acc: 0.9883
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0373 - acc: 0.9887
1280/1283 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9898
1283/1283 [==============================] - 1s 867us/step - loss: 0.0345 - acc: 0.9899 - val_loss: 0.9399 - val_acc: 0.7249

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0201 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0215 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0238 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0257 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0253 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0237 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0241 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0231 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0224 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0238 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0241 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0227 - acc: 0.9959
1283/1283 [==============================] - 1s 847us/step - loss: 0.0235 - acc: 0.9953 - val_loss: 0.9695 - val_acc: 0.7293

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0248 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0191 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0169 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0183 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0171 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0179 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0181 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0175 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0166 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0180 - acc: 0.9961
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0177 - acc: 0.9965
1280/1283 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9969
1283/1283 [==============================] - 1s 895us/step - loss: 0.0176 - acc: 0.9969 - val_loss: 1.0085 - val_acc: 0.7205

Epoch 00023: val_acc did not improve
Epoch 24/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0200 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0131 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0128 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0134 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0144 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0144 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0147 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0158 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0145 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0134 - acc: 0.9978
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0138 - acc: 0.9980
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0135 - acc: 0.9983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0134 - acc: 0.9984
1283/1283 [==============================] - 1s 866us/step - loss: 0.0145 - acc: 0.9977 - val_loss: 1.0498 - val_acc: 0.7293

Epoch 00024: val_acc did not improve
Epoch 00024: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=80
accuracy=0.6865889212827988
best_valid_accuracy=0.7011661807580175
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:29:43.976242: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 27s - loss: 0.7047 - acc: 0.4219
 192/1283 [===>..........................] - ETA: 8s - loss: 0.6961 - acc: 0.5104 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.6891 - acc: 0.5281
 448/1283 [=========>....................] - ETA: 3s - loss: 0.6870 - acc: 0.5446
 576/1283 [============>.................] - ETA: 2s - loss: 0.6862 - acc: 0.5503
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6843 - acc: 0.5540
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6850 - acc: 0.5517
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6854 - acc: 0.5525
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6853 - acc: 0.5531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6853 - acc: 0.5537
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6849 - acc: 0.5547
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6834 - acc: 0.5559
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6840 - acc: 0.5526 - val_loss: 0.6594 - val_acc: 0.6550

Epoch 00001: val_acc improved from -inf to 0.65502, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6554 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6434 - acc: 0.6510
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6408 - acc: 0.6680
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6364 - acc: 0.6844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6380 - acc: 0.6745
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6349 - acc: 0.6830
 576/1283 [============>.................] - ETA: 0s - loss: 0.6386 - acc: 0.6632
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6334 - acc: 0.6776
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6309 - acc: 0.6815
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6303 - acc: 0.6802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6312 - acc: 0.6787
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6314 - acc: 0.6719
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6303 - acc: 0.6710
1280/1283 [============================>.] - ETA: 0s - loss: 0.6267 - acc: 0.6742
1283/1283 [==============================] - 1s 802us/step - loss: 0.6264 - acc: 0.6750 - val_loss: 0.6296 - val_acc: 0.6681

Epoch 00002: val_acc improved from 0.65502 to 0.66812, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6383 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6104 - acc: 0.6667
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5884 - acc: 0.7125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5912 - acc: 0.7143
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5891 - acc: 0.7168
 576/1283 [============>.................] - ETA: 0s - loss: 0.5879 - acc: 0.7222
 640/1283 [=============>................] - ETA: 0s - loss: 0.5852 - acc: 0.7219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5815 - acc: 0.7244
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5790 - acc: 0.7260
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5747 - acc: 0.7288
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5729 - acc: 0.7323
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5695 - acc: 0.7289
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5688 - acc: 0.7266
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5716 - acc: 0.7253
1280/1283 [============================>.] - ETA: 0s - loss: 0.5700 - acc: 0.7234
1283/1283 [==============================] - 1s 914us/step - loss: 0.5707 - acc: 0.7225 - val_loss: 0.5871 - val_acc: 0.7162

Epoch 00003: val_acc improved from 0.66812 to 0.71616, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5541 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.5358 - acc: 0.7734
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5213 - acc: 0.7695
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5134 - acc: 0.7688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5280 - acc: 0.7500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5291 - acc: 0.7612
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5270 - acc: 0.7578
 576/1283 [============>.................] - ETA: 0s - loss: 0.5288 - acc: 0.7587
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5269 - acc: 0.7571
 768/1283 [================>.............] - ETA: 0s - loss: 0.5284 - acc: 0.7591
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5253 - acc: 0.7656
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5266 - acc: 0.7634
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5219 - acc: 0.7667
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5138 - acc: 0.7764
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5114 - acc: 0.7803
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5098 - acc: 0.7804
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5094 - acc: 0.7796
1280/1283 [============================>.] - ETA: 0s - loss: 0.5063 - acc: 0.7789
1283/1283 [==============================] - 1s 918us/step - loss: 0.5069 - acc: 0.7779 - val_loss: 0.5634 - val_acc: 0.7249

Epoch 00004: val_acc improved from 0.71616 to 0.72489, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5384 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.4654 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4689 - acc: 0.7891
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4637 - acc: 0.7875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4633 - acc: 0.7943
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4532 - acc: 0.7969
 576/1283 [============>.................] - ETA: 0s - loss: 0.4521 - acc: 0.8003
 640/1283 [=============>................] - ETA: 0s - loss: 0.4607 - acc: 0.7969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4555 - acc: 0.7997
 768/1283 [================>.............] - ETA: 0s - loss: 0.4559 - acc: 0.8008
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4550 - acc: 0.8041
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4587 - acc: 0.8047
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4535 - acc: 0.8073
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4501 - acc: 0.8076
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4527 - acc: 0.8051
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4469 - acc: 0.8090
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4491 - acc: 0.8076
1283/1283 [==============================] - 1s 952us/step - loss: 0.4484 - acc: 0.8090 - val_loss: 0.5617 - val_acc: 0.6900

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3703 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.4198 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4288 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4004 - acc: 0.8156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4012 - acc: 0.8259
 576/1283 [============>.................] - ETA: 0s - loss: 0.3905 - acc: 0.8420
 640/1283 [=============>................] - ETA: 0s - loss: 0.4110 - acc: 0.8328
 768/1283 [================>.............] - ETA: 0s - loss: 0.4049 - acc: 0.8294
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3943 - acc: 0.8353
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3909 - acc: 0.8371
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3937 - acc: 0.8375
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3934 - acc: 0.8364
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3892 - acc: 0.8403
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3877 - acc: 0.8421
1280/1283 [============================>.] - ETA: 0s - loss: 0.3854 - acc: 0.8422
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3856 - acc: 0.8418 - val_loss: 0.5677 - val_acc: 0.6987

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3903 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.3608 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3471 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3327 - acc: 0.8828
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3333 - acc: 0.8812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3379 - acc: 0.8802
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3406 - acc: 0.8770
 640/1283 [=============>................] - ETA: 0s - loss: 0.3371 - acc: 0.8766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3342 - acc: 0.8750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3279 - acc: 0.8786
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3257 - acc: 0.8817
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3205 - acc: 0.8828
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3118 - acc: 0.8854
1280/1283 [============================>.] - ETA: 0s - loss: 0.3152 - acc: 0.8805
1283/1283 [==============================] - 1s 901us/step - loss: 0.3159 - acc: 0.8800 - val_loss: 0.6026 - val_acc: 0.6812

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2438 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2934 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2715 - acc: 0.9115
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2724 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2874 - acc: 0.8969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2773 - acc: 0.9040
 576/1283 [============>.................] - ETA: 0s - loss: 0.2623 - acc: 0.9097
 640/1283 [=============>................] - ETA: 0s - loss: 0.2604 - acc: 0.9078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2635 - acc: 0.9034
 768/1283 [================>.............] - ETA: 0s - loss: 0.2607 - acc: 0.9049
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2565 - acc: 0.9087
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2550 - acc: 0.9107
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2611 - acc: 0.9042
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2698 - acc: 0.9007
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2667 - acc: 0.9028
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2658 - acc: 0.9021
1280/1283 [============================>.] - ETA: 0s - loss: 0.2735 - acc: 0.8992
1283/1283 [==============================] - 1s 974us/step - loss: 0.2742 - acc: 0.8987 - val_loss: 0.6183 - val_acc: 0.6812

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2511 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2537 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2618 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2473 - acc: 0.9094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2469 - acc: 0.9115
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2480 - acc: 0.9082
 576/1283 [============>.................] - ETA: 0s - loss: 0.2437 - acc: 0.9115
 640/1283 [=============>................] - ETA: 0s - loss: 0.2395 - acc: 0.9141
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2415 - acc: 0.9119
 768/1283 [================>.............] - ETA: 0s - loss: 0.2375 - acc: 0.9154
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2386 - acc: 0.9159
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2392 - acc: 0.9141
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2446 - acc: 0.9104
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2368 - acc: 0.9108
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2323 - acc: 0.9128
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2287 - acc: 0.9143 - val_loss: 0.6858 - val_acc: 0.7031

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1492 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1420 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1405 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1433 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1629 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1688 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1674 - acc: 0.9531
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1699 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1728 - acc: 0.9497
 640/1283 [=============>................] - ETA: 0s - loss: 0.1796 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1849 - acc: 0.9418
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1791 - acc: 0.9411
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1788 - acc: 0.9397
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1755 - acc: 0.9406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1719 - acc: 0.9424
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1697 - acc: 0.9449
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1705 - acc: 0.9444
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1712 - acc: 0.9433
1280/1283 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9445
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1703 - acc: 0.9447 - val_loss: 0.7682 - val_acc: 0.6812

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1276 - acc: 0.9531
 128/1283 [=>............................] - ETA: 2s - loss: 0.1452 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1530 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1480 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1446 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1393 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1419 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1340 - acc: 0.9512
 576/1283 [============>.................] - ETA: 1s - loss: 0.1317 - acc: 0.9497
 640/1283 [=============>................] - ETA: 1s - loss: 0.1316 - acc: 0.9516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1288 - acc: 0.9560
 768/1283 [================>.............] - ETA: 0s - loss: 0.1269 - acc: 0.9557
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1265 - acc: 0.9567
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1313 - acc: 0.9542
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1295 - acc: 0.9573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1336 - acc: 0.9561
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1328 - acc: 0.9568
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1348 - acc: 0.9548
1280/1283 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9547
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1361 - acc: 0.9548 - val_loss: 0.7770 - val_acc: 0.6638

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.1252 - acc: 0.9531
 128/1283 [=>............................] - ETA: 2s - loss: 0.1305 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1006 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1049 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1047 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1033 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1020 - acc: 0.9629
 576/1283 [============>.................] - ETA: 1s - loss: 0.1042 - acc: 0.9653
 640/1283 [=============>................] - ETA: 1s - loss: 0.1007 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1078 - acc: 0.9616
 768/1283 [================>.............] - ETA: 0s - loss: 0.1059 - acc: 0.9635
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1010 - acc: 0.9663
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0984 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0968 - acc: 0.9708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0982 - acc: 0.9707
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1006 - acc: 0.9697
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1025 - acc: 0.9679
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1019 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9688
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1011 - acc: 0.9680 - val_loss: 0.8035 - val_acc: 0.6943

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0514 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0585 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0644 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0729 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0720 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0714 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0793 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0800 - acc: 0.9844
 576/1283 [============>.................] - ETA: 1s - loss: 0.0868 - acc: 0.9774
 640/1283 [=============>................] - ETA: 1s - loss: 0.0859 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0836 - acc: 0.9773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0856 - acc: 0.9760
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0854 - acc: 0.9766
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0872 - acc: 0.9760
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0862 - acc: 0.9775
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0886 - acc: 0.9770
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0886 - acc: 0.9757
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0895 - acc: 0.9745
1280/1283 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9727
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0918 - acc: 0.9727 - val_loss: 0.8933 - val_acc: 0.6900

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0802 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0685 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0851 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0808 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0811 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0809 - acc: 0.9740
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0759 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0754 - acc: 0.9785
 576/1283 [============>.................] - ETA: 1s - loss: 0.0723 - acc: 0.9809
 640/1283 [=============>................] - ETA: 1s - loss: 0.0696 - acc: 0.9828
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0674 - acc: 0.9844
 768/1283 [================>.............] - ETA: 0s - loss: 0.0652 - acc: 0.9857
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0665 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0671 - acc: 0.9833
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0650 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0649 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0645 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0648 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0642 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9844
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0630 - acc: 0.9844 - val_loss: 1.0067 - val_acc: 0.6769

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=90
accuracy=0.7011661807580175
best_valid_accuracy=0.6778425655976676
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:43:02.673845: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 32s - loss: 0.6869 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 9s - loss: 0.6977 - acc: 0.5312 
 320/1283 [======>.......................] - ETA: 5s - loss: 0.6972 - acc: 0.5375
 448/1283 [=========>....................] - ETA: 3s - loss: 0.6936 - acc: 0.5513
 576/1283 [============>.................] - ETA: 2s - loss: 0.6944 - acc: 0.5399
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6924 - acc: 0.5369
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6896 - acc: 0.5373
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6863 - acc: 0.5448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6857 - acc: 0.5450
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6846 - acc: 0.5495
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6842 - acc: 0.5502
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6828 - acc: 0.5565 - val_loss: 0.6472 - val_acc: 0.6856

Epoch 00001: val_acc improved from -inf to 0.68559, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6514 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6314 - acc: 0.6823
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6299 - acc: 0.6937
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6271 - acc: 0.7005
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6196 - acc: 0.7207
 640/1283 [=============>................] - ETA: 0s - loss: 0.6193 - acc: 0.7063
 768/1283 [================>.............] - ETA: 0s - loss: 0.6166 - acc: 0.7122
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6186 - acc: 0.6995
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6204 - acc: 0.6931
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6201 - acc: 0.6948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6202 - acc: 0.6924
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6200 - acc: 0.6936
1280/1283 [============================>.] - ETA: 0s - loss: 0.6191 - acc: 0.6922
1283/1283 [==============================] - 1s 910us/step - loss: 0.6190 - acc: 0.6929 - val_loss: 0.6015 - val_acc: 0.7336

Epoch 00002: val_acc improved from 0.68559 to 0.73362, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5584 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5431 - acc: 0.7865
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5408 - acc: 0.7852
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5422 - acc: 0.7844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5378 - acc: 0.7865
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5413 - acc: 0.7790
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5456 - acc: 0.7598
 576/1283 [============>.................] - ETA: 0s - loss: 0.5498 - acc: 0.7500
 640/1283 [=============>................] - ETA: 0s - loss: 0.5514 - acc: 0.7453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5467 - acc: 0.7514
 768/1283 [================>.............] - ETA: 0s - loss: 0.5464 - acc: 0.7526
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5489 - acc: 0.7500
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5424 - acc: 0.7552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5393 - acc: 0.7559
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5382 - acc: 0.7546
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5411 - acc: 0.7509
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5413 - acc: 0.7500
1283/1283 [==============================] - 1s 990us/step - loss: 0.5402 - acc: 0.7521 - val_loss: 0.5517 - val_acc: 0.7467

Epoch 00003: val_acc improved from 0.73362 to 0.74672, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4858 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4810 - acc: 0.7865
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4898 - acc: 0.7891
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4880 - acc: 0.7937
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4855 - acc: 0.7891
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5017 - acc: 0.7746
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4993 - acc: 0.7734
 640/1283 [=============>................] - ETA: 0s - loss: 0.4878 - acc: 0.7781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4861 - acc: 0.7798
 768/1283 [================>.............] - ETA: 0s - loss: 0.4882 - acc: 0.7773
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4851 - acc: 0.7788
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4727 - acc: 0.7879
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4702 - acc: 0.7920
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4697 - acc: 0.7932
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4663 - acc: 0.7934
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4620 - acc: 0.7961
1280/1283 [============================>.] - ETA: 0s - loss: 0.4625 - acc: 0.7922
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4621 - acc: 0.7927 - val_loss: 0.5190 - val_acc: 0.7380

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3293 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3630 - acc: 0.8854
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3780 - acc: 0.8672
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3893 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3883 - acc: 0.8516
 576/1283 [============>.................] - ETA: 0s - loss: 0.3893 - acc: 0.8490
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3970 - acc: 0.8409
 768/1283 [================>.............] - ETA: 0s - loss: 0.3959 - acc: 0.8385
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3965 - acc: 0.8341
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4035 - acc: 0.8281
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3999 - acc: 0.8323
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4003 - acc: 0.8291
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4012 - acc: 0.8290
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4021 - acc: 0.8307
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4008 - acc: 0.8314
1280/1283 [============================>.] - ETA: 0s - loss: 0.3996 - acc: 0.8313
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4004 - acc: 0.8309 - val_loss: 0.5415 - val_acc: 0.7031

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3374 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.3469 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3496 - acc: 0.8698
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3458 - acc: 0.8789
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3266 - acc: 0.8854
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3348 - acc: 0.8789
 576/1283 [============>.................] - ETA: 0s - loss: 0.3431 - acc: 0.8733
 640/1283 [=============>................] - ETA: 0s - loss: 0.3442 - acc: 0.8719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3445 - acc: 0.8693
 768/1283 [================>.............] - ETA: 0s - loss: 0.3461 - acc: 0.8685
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3468 - acc: 0.8654
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3460 - acc: 0.8650
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3413 - acc: 0.8677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3418 - acc: 0.8682
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3379 - acc: 0.8704
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3341 - acc: 0.8724
1280/1283 [============================>.] - ETA: 0s - loss: 0.3331 - acc: 0.8703
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3343 - acc: 0.8691 - val_loss: 0.5537 - val_acc: 0.7249

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3271 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.2770 - acc: 0.8828
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2810 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2861 - acc: 0.8789
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2807 - acc: 0.8854
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2701 - acc: 0.8965
 576/1283 [============>.................] - ETA: 0s - loss: 0.2676 - acc: 0.9028
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2750 - acc: 0.9034
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2755 - acc: 0.9075
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2779 - acc: 0.9074
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2729 - acc: 0.9102
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2682 - acc: 0.9123
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2702 - acc: 0.9120
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2770 - acc: 0.9096 - val_loss: 0.6065 - val_acc: 0.7074

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2630 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2778 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2351 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2085 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2167 - acc: 0.9427
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2242 - acc: 0.9395
 576/1283 [============>.................] - ETA: 0s - loss: 0.2317 - acc: 0.9323
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2323 - acc: 0.9347
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2271 - acc: 0.9375
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2231 - acc: 0.9375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2215 - acc: 0.9365
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2177 - acc: 0.9375
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2185 - acc: 0.9384
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2145 - acc: 0.9391
1280/1283 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9391
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2152 - acc: 0.9392 - val_loss: 0.6031 - val_acc: 0.7249

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1758 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1581 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1440 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1556 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1562 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1540 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1649 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1631 - acc: 0.9492
 576/1283 [============>.................] - ETA: 0s - loss: 0.1671 - acc: 0.9479
 640/1283 [=============>................] - ETA: 0s - loss: 0.1650 - acc: 0.9500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1648 - acc: 0.9489
 768/1283 [================>.............] - ETA: 0s - loss: 0.1674 - acc: 0.9492
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1730 - acc: 0.9435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1732 - acc: 0.9442
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1788 - acc: 0.9427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1757 - acc: 0.9443
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1760 - acc: 0.9430
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1738 - acc: 0.9444
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1707 - acc: 0.9474
1280/1283 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9484
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1694 - acc: 0.9478 - val_loss: 0.6981 - val_acc: 0.6900

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1101 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1342 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1509 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1712 - acc: 0.9297
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1675 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1585 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1687 - acc: 0.9375
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1636 - acc: 0.9453
 576/1283 [============>.................] - ETA: 0s - loss: 0.1652 - acc: 0.9462
 640/1283 [=============>................] - ETA: 0s - loss: 0.1731 - acc: 0.9437
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1695 - acc: 0.9460
 768/1283 [================>.............] - ETA: 0s - loss: 0.1672 - acc: 0.9466
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1625 - acc: 0.9483
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1642 - acc: 0.9498
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1658 - acc: 0.9479
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1647 - acc: 0.9482
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1613 - acc: 0.9494
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1578 - acc: 0.9482
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1566 - acc: 0.9470 - val_loss: 0.6680 - val_acc: 0.7424

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1210 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1036 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1078 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1095 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1030 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1074 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1004 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1024 - acc: 0.9805
 576/1283 [============>.................] - ETA: 0s - loss: 0.1012 - acc: 0.9826
 640/1283 [=============>................] - ETA: 0s - loss: 0.0988 - acc: 0.9828
 768/1283 [================>.............] - ETA: 0s - loss: 0.0993 - acc: 0.9818
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1024 - acc: 0.9796
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1049 - acc: 0.9743
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1058 - acc: 0.9708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1112 - acc: 0.9658
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1137 - acc: 0.9642
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1132 - acc: 0.9653
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1156 - acc: 0.9638
1280/1283 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9633
1283/1283 [==============================] - 1s 994us/step - loss: 0.1169 - acc: 0.9634 - val_loss: 0.7906 - val_acc: 0.6943

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0701 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.1391 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1019 - acc: 0.9648
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0984 - acc: 0.9661
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0953 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0918 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0957 - acc: 0.9659
 768/1283 [================>.............] - ETA: 0s - loss: 0.0931 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0940 - acc: 0.9700
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0904 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0900 - acc: 0.9729
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0881 - acc: 0.9746
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0861 - acc: 0.9748
1280/1283 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9750
1283/1283 [==============================] - 1s 865us/step - loss: 0.0867 - acc: 0.9743 - val_loss: 0.7632 - val_acc: 0.7074

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0586 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0806 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0683 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0683 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0718 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0690 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0698 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0642 - acc: 0.9878
 640/1283 [=============>................] - ETA: 0s - loss: 0.0616 - acc: 0.9891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0611 - acc: 0.9901
 768/1283 [================>.............] - ETA: 0s - loss: 0.0592 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0616 - acc: 0.9892
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0604 - acc: 0.9888
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0585 - acc: 0.9896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0602 - acc: 0.9883
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0661 - acc: 0.9852
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0660 - acc: 0.9852
1283/1283 [==============================] - 1s 948us/step - loss: 0.0656 - acc: 0.9852 - val_loss: 0.8244 - val_acc: 0.7249

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6909620991253644
best_valid_accuracy=0.6588921282798834
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:51:10.938728: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 14s - loss: 0.7087 - acc: 0.4844
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6909 - acc: 0.5234 
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6916 - acc: 0.5104
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6870 - acc: 0.5371
 640/1283 [=============>................] - ETA: 1s - loss: 0.6849 - acc: 0.5453
 768/1283 [================>.............] - ETA: 0s - loss: 0.6851 - acc: 0.5469
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6833 - acc: 0.5502
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6834 - acc: 0.5508
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6820 - acc: 0.5547
1280/1283 [============================>.] - ETA: 0s - loss: 0.6813 - acc: 0.5563
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6813 - acc: 0.5557 - val_loss: 0.6600 - val_acc: 0.6157

Epoch 00001: val_acc improved from -inf to 0.61572, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5918 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6315 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6268 - acc: 0.6992
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6341 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6298 - acc: 0.6953
 640/1283 [=============>................] - ETA: 0s - loss: 0.6270 - acc: 0.6953
 768/1283 [================>.............] - ETA: 0s - loss: 0.6266 - acc: 0.6979
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6229 - acc: 0.6975
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6214 - acc: 0.6973
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6194 - acc: 0.6953
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6184 - acc: 0.6933
1280/1283 [============================>.] - ETA: 0s - loss: 0.6189 - acc: 0.6914
1283/1283 [==============================] - 1s 636us/step - loss: 0.6191 - acc: 0.6906 - val_loss: 0.6246 - val_acc: 0.6900

Epoch 00002: val_acc improved from 0.61572 to 0.68996, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6099 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5755 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5755 - acc: 0.7469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5702 - acc: 0.7578
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5683 - acc: 0.7522
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5665 - acc: 0.7539
 576/1283 [============>.................] - ETA: 0s - loss: 0.5710 - acc: 0.7483
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5676 - acc: 0.7500
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5649 - acc: 0.7524
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5613 - acc: 0.7490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5606 - acc: 0.7520
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5540 - acc: 0.7613
1280/1283 [============================>.] - ETA: 0s - loss: 0.5514 - acc: 0.7641
1283/1283 [==============================] - 1s 865us/step - loss: 0.5519 - acc: 0.7631 - val_loss: 0.5868 - val_acc: 0.7074

Epoch 00003: val_acc improved from 0.68996 to 0.70742, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5536 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4994 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4939 - acc: 0.8125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4978 - acc: 0.8058
 576/1283 [============>.................] - ETA: 0s - loss: 0.4907 - acc: 0.8056
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4878 - acc: 0.8040
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4799 - acc: 0.8065
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4844 - acc: 0.8010
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4797 - acc: 0.8033
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4762 - acc: 0.8043
1283/1283 [==============================] - 1s 611us/step - loss: 0.4794 - acc: 0.7997 - val_loss: 0.5511 - val_acc: 0.7205

Epoch 00004: val_acc improved from 0.70742 to 0.72052, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4606 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4264 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4356 - acc: 0.8250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4360 - acc: 0.8307
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4345 - acc: 0.8281
 640/1283 [=============>................] - ETA: 0s - loss: 0.4429 - acc: 0.8187
 768/1283 [================>.............] - ETA: 0s - loss: 0.4267 - acc: 0.8320
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4221 - acc: 0.8353
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4163 - acc: 0.8375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4158 - acc: 0.8379
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4145 - acc: 0.8359
1280/1283 [============================>.] - ETA: 0s - loss: 0.4124 - acc: 0.8328
1283/1283 [==============================] - 1s 852us/step - loss: 0.4131 - acc: 0.8316 - val_loss: 0.5381 - val_acc: 0.7293

Epoch 00005: val_acc improved from 0.72052 to 0.72926, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3620 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3954 - acc: 0.8333
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3783 - acc: 0.8469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3641 - acc: 0.8527
 576/1283 [============>.................] - ETA: 0s - loss: 0.3685 - acc: 0.8490
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3656 - acc: 0.8509
 768/1283 [================>.............] - ETA: 0s - loss: 0.3690 - acc: 0.8503
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3632 - acc: 0.8534
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3635 - acc: 0.8527
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3609 - acc: 0.8552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3614 - acc: 0.8555
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3608 - acc: 0.8539
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3564 - acc: 0.8569
1280/1283 [============================>.] - ETA: 0s - loss: 0.3545 - acc: 0.8562
1283/1283 [==============================] - 1s 855us/step - loss: 0.3547 - acc: 0.8558 - val_loss: 0.5624 - val_acc: 0.6943

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3235 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.3429 - acc: 0.8672
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3062 - acc: 0.8867
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3029 - acc: 0.8938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3049 - acc: 0.8880
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2972 - acc: 0.8951
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2964 - acc: 0.8906
 576/1283 [============>.................] - ETA: 0s - loss: 0.2969 - acc: 0.8872
 640/1283 [=============>................] - ETA: 0s - loss: 0.2945 - acc: 0.8891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2980 - acc: 0.8849
 768/1283 [================>.............] - ETA: 0s - loss: 0.2941 - acc: 0.8893
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2934 - acc: 0.8894
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2897 - acc: 0.8940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2882 - acc: 0.8938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2930 - acc: 0.8916
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2921 - acc: 0.8924
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2948 - acc: 0.8931
1280/1283 [============================>.] - ETA: 0s - loss: 0.2910 - acc: 0.8938
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2910 - acc: 0.8932 - val_loss: 0.5650 - val_acc: 0.7162

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2068 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.2280 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2122 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2143 - acc: 0.9336
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2207 - acc: 0.9313
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2158 - acc: 0.9297
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2192 - acc: 0.9219
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2175 - acc: 0.9199
 576/1283 [============>.................] - ETA: 0s - loss: 0.2107 - acc: 0.9253
 640/1283 [=============>................] - ETA: 0s - loss: 0.2153 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2108 - acc: 0.9276
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2249 - acc: 0.9207
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2259 - acc: 0.9219
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2220 - acc: 0.9260
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2227 - acc: 0.9258
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2207 - acc: 0.9274
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2236 - acc: 0.9253
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2242 - acc: 0.9252
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2290 - acc: 0.9213 - val_loss: 0.6013 - val_acc: 0.7293

Epoch 00008: val_acc improved from 0.72926 to 0.72926, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1681 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.1783 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2089 - acc: 0.9271
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1960 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1856 - acc: 0.9406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1804 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1801 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1749 - acc: 0.9492
 576/1283 [============>.................] - ETA: 0s - loss: 0.1741 - acc: 0.9462
 640/1283 [=============>................] - ETA: 0s - loss: 0.1828 - acc: 0.9391
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1840 - acc: 0.9332
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1793 - acc: 0.9363
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1806 - acc: 0.9330
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1777 - acc: 0.9365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1784 - acc: 0.9375
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1771 - acc: 0.9384
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1767 - acc: 0.9392
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1791 - acc: 0.9391
1280/1283 [============================>.] - ETA: 0s - loss: 0.1791 - acc: 0.9406
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1794 - acc: 0.9400 - val_loss: 0.6693 - val_acc: 0.7031

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1383 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1520 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1421 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1366 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1490 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1593 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1633 - acc: 0.9497
 640/1283 [=============>................] - ETA: 0s - loss: 0.1594 - acc: 0.9500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1554 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1574 - acc: 0.9505
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1591 - acc: 0.9509
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1577 - acc: 0.9510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1538 - acc: 0.9541
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1508 - acc: 0.9550
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1528 - acc: 0.9531
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1501 - acc: 0.9531
1280/1283 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9523
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1509 - acc: 0.9525 - val_loss: 0.7163 - val_acc: 0.7336

Epoch 00010: val_acc improved from 0.72926 to 0.73362, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0734 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0774 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0898 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0967 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0851 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0827 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0842 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0864 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0943 - acc: 0.9792
 640/1283 [=============>................] - ETA: 0s - loss: 0.0933 - acc: 0.9797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0943 - acc: 0.9801
 768/1283 [================>.............] - ETA: 0s - loss: 0.0967 - acc: 0.9766
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0969 - acc: 0.9772
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1014 - acc: 0.9743
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1005 - acc: 0.9750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1022 - acc: 0.9756
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1019 - acc: 0.9752
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0995 - acc: 0.9766
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0999 - acc: 0.9778
1280/1283 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9789
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0980 - acc: 0.9790 - val_loss: 0.7980 - val_acc: 0.6943

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0665 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0739 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0807 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0838 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0786 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0744 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0742 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0748 - acc: 0.9863
 576/1283 [============>.................] - ETA: 1s - loss: 0.0740 - acc: 0.9878
 640/1283 [=============>................] - ETA: 1s - loss: 0.0756 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0749 - acc: 0.9886
 768/1283 [================>.............] - ETA: 0s - loss: 0.0750 - acc: 0.9870
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0772 - acc: 0.9856
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0770 - acc: 0.9855
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0773 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0772 - acc: 0.9844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0742 - acc: 0.9853
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0732 - acc: 0.9852
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0734 - acc: 0.9860
1280/1283 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9859
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0736 - acc: 0.9860 - val_loss: 0.9041 - val_acc: 0.6856

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0585 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0436 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0511 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0431 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0394 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0428 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0419 - acc: 0.9941
 576/1283 [============>.................] - ETA: 1s - loss: 0.0438 - acc: 0.9931
 640/1283 [=============>................] - ETA: 1s - loss: 0.0428 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0445 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0443 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0442 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0475 - acc: 0.9911
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0474 - acc: 0.9917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0475 - acc: 0.9922
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0483 - acc: 0.9917
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0494 - acc: 0.9905
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0484 - acc: 0.9910
1280/1283 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9898
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0499 - acc: 0.9899 - val_loss: 0.9927 - val_acc: 0.6856

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0311 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0281 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0323 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0365 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0371 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0389 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0394 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0367 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0374 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0371 - acc: 0.9915
 768/1283 [================>.............] - ETA: 0s - loss: 0.0383 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0381 - acc: 0.9904
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0385 - acc: 0.9911
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0377 - acc: 0.9917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0373 - acc: 0.9922
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0376 - acc: 0.9926
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0372 - acc: 0.9922
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0381 - acc: 0.9918
1280/1283 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9922
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0375 - acc: 0.9922 - val_loss: 1.0644 - val_acc: 0.6943

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.0165 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0187 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0180 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0184 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 2s - loss: 0.0176 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0188 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0187 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0185 - acc: 0.9980
 576/1283 [============>.................] - ETA: 1s - loss: 0.0189 - acc: 0.9983
 640/1283 [=============>................] - ETA: 1s - loss: 0.0202 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0212 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0212 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0206 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0208 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0212 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0236 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0231 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0236 - acc: 0.9983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0235 - acc: 0.9984
1280/1283 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9984
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0230 - acc: 0.9984 - val_loss: 1.1646 - val_acc: 0.6856

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0103 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0182 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0181 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0386 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0377 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0360 - acc: 0.9911
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0346 - acc: 0.9902
 640/1283 [=============>................] - ETA: 0s - loss: 0.0343 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0329 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0397 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0389 - acc: 0.9916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0372 - acc: 0.9922
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0365 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0354 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0384 - acc: 0.9908
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0378 - acc: 0.9913
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0378 - acc: 0.9910
1280/1283 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9891
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0409 - acc: 0.9891 - val_loss: 1.2282 - val_acc: 0.6900

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0245 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0320 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0274 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0237 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0215 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0210 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0209 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0196 - acc: 0.9961
 576/1283 [============>.................] - ETA: 1s - loss: 0.0200 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0235 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0249 - acc: 0.9929
 768/1283 [================>.............] - ETA: 0s - loss: 0.0265 - acc: 0.9922
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0255 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0248 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0240 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0236 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0246 - acc: 0.9926
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0254 - acc: 0.9934
1280/1283 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9938
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0248 - acc: 0.9938 - val_loss: 1.2454 - val_acc: 0.6856

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0188 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0165 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0163 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0161 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0202 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0178 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0170 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0162 - acc: 0.9980
 576/1283 [============>.................] - ETA: 1s - loss: 0.0158 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0153 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0154 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0158 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0164 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0159 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0156 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0162 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0160 - acc: 0.9991
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0157 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0158 - acc: 0.9992
1280/1283 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9992
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0197 - acc: 0.9969 - val_loss: 1.2837 - val_acc: 0.6900

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0201 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0283 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0240 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0220 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0308 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0510 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0718 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0933 - acc: 0.9668
 576/1283 [============>.................] - ETA: 0s - loss: 0.0952 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.0930 - acc: 0.9656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0893 - acc: 0.9673
 768/1283 [================>.............] - ETA: 0s - loss: 0.0841 - acc: 0.9701
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0804 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0775 - acc: 0.9732
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0746 - acc: 0.9750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0731 - acc: 0.9756
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0744 - acc: 0.9743
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0714 - acc: 0.9757
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0699 - acc: 0.9762
1280/1283 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9750
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0750 - acc: 0.9727 - val_loss: 1.0458 - val_acc: 0.6725

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0500 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0375 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0364 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0323 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0320 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0377 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0400 - acc: 0.9866
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0428 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0489 - acc: 0.9844
 640/1283 [=============>................] - ETA: 0s - loss: 0.0493 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0499 - acc: 0.9858
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0634 - acc: 0.9820
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0647 - acc: 0.9810
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0666 - acc: 0.9802
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0824 - acc: 0.9733
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0902 - acc: 0.9714
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0935 - acc: 0.9688
1280/1283 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9688
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0929 - acc: 0.9688 - val_loss: 1.0634 - val_acc: 0.6376

Epoch 00020: val_acc did not improve
Epoch 00020: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=110
accuracy=0.6938775510204082
best_valid_accuracy=0.6953352769679301
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:08:56.878193: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 16s - loss: 0.7085 - acc: 0.4844
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6963 - acc: 0.5234 
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6959 - acc: 0.5026
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6940 - acc: 0.5117
 640/1283 [=============>................] - ETA: 1s - loss: 0.6917 - acc: 0.5141
 768/1283 [================>.............] - ETA: 0s - loss: 0.6884 - acc: 0.5221
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6889 - acc: 0.5301
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6881 - acc: 0.5333
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6872 - acc: 0.5414
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6863 - acc: 0.5444
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6859 - acc: 0.5440 - val_loss: 0.6664 - val_acc: 0.6070

Epoch 00001: val_acc improved from -inf to 0.60699, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6274 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6333 - acc: 0.6667
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6389 - acc: 0.6719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6391 - acc: 0.6674
 576/1283 [============>.................] - ETA: 0s - loss: 0.6369 - acc: 0.6806
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6402 - acc: 0.6690
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6361 - acc: 0.6791
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6323 - acc: 0.6844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6304 - acc: 0.6875
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6297 - acc: 0.6858
1280/1283 [============================>.] - ETA: 0s - loss: 0.6283 - acc: 0.6859
1283/1283 [==============================] - 1s 687us/step - loss: 0.6279 - acc: 0.6867 - val_loss: 0.6319 - val_acc: 0.6769

Epoch 00002: val_acc improved from 0.60699 to 0.67686, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5523 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5761 - acc: 0.7708
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5799 - acc: 0.7500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5752 - acc: 0.7552
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5749 - acc: 0.7500
 576/1283 [============>.................] - ETA: 0s - loss: 0.5767 - acc: 0.7378
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5714 - acc: 0.7443
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5703 - acc: 0.7332
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5682 - acc: 0.7365
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5672 - acc: 0.7399
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5690 - acc: 0.7393
1283/1283 [==============================] - 1s 701us/step - loss: 0.5699 - acc: 0.7350 - val_loss: 0.5910 - val_acc: 0.7074

Epoch 00003: val_acc improved from 0.67686 to 0.70742, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5459 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5447 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5248 - acc: 0.8063
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5147 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5104 - acc: 0.7988
 640/1283 [=============>................] - ETA: 0s - loss: 0.5017 - acc: 0.8047
 768/1283 [================>.............] - ETA: 0s - loss: 0.4917 - acc: 0.8151
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4942 - acc: 0.8125
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4906 - acc: 0.8154
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4921 - acc: 0.8142
1280/1283 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8117
1283/1283 [==============================] - 1s 673us/step - loss: 0.4900 - acc: 0.8114 - val_loss: 0.5533 - val_acc: 0.7162

Epoch 00004: val_acc improved from 0.70742 to 0.71616, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3897 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4088 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4503 - acc: 0.8125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4305 - acc: 0.8259
 576/1283 [============>.................] - ETA: 0s - loss: 0.4278 - acc: 0.8194
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4235 - acc: 0.8253
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4252 - acc: 0.8233
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4228 - acc: 0.8250
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4242 - acc: 0.8244
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4183 - acc: 0.8306
1280/1283 [============================>.] - ETA: 0s - loss: 0.4158 - acc: 0.8305
1283/1283 [==============================] - 1s 706us/step - loss: 0.4162 - acc: 0.8301 - val_loss: 0.5534 - val_acc: 0.7424

Epoch 00005: val_acc improved from 0.71616 to 0.74236, saving model to classification_logs//lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3968 - acc: 0.8125
 128/1283 [=>............................] - ETA: 0s - loss: 0.3396 - acc: 0.8672
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3545 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3675 - acc: 0.8562
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3668 - acc: 0.8571
 576/1283 [============>.................] - ETA: 0s - loss: 0.3443 - acc: 0.8733
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3491 - acc: 0.8736
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3496 - acc: 0.8738
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3457 - acc: 0.8729
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3454 - acc: 0.8730
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3418 - acc: 0.8741
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3382 - acc: 0.8775
1283/1283 [==============================] - 1s 785us/step - loss: 0.3340 - acc: 0.8784 - val_loss: 0.5425 - val_acc: 0.7293

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2897 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2608 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2736 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2886 - acc: 0.9040
 576/1283 [============>.................] - ETA: 0s - loss: 0.2770 - acc: 0.9080
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2745 - acc: 0.9077
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2767 - acc: 0.9050
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2714 - acc: 0.9062
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2697 - acc: 0.9062
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2693 - acc: 0.9072
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2642 - acc: 0.9099
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2601 - acc: 0.9132
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2597 - acc: 0.9128
1280/1283 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.9125
1283/1283 [==============================] - 1s 910us/step - loss: 0.2607 - acc: 0.9119 - val_loss: 0.5994 - val_acc: 0.7118

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2315 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1759 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1707 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1714 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1706 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1865 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1945 - acc: 0.9509
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1875 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.1906 - acc: 0.9531
 640/1283 [=============>................] - ETA: 0s - loss: 0.1911 - acc: 0.9516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1960 - acc: 0.9489
 768/1283 [================>.............] - ETA: 0s - loss: 0.1980 - acc: 0.9479
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2041 - acc: 0.9447
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2014 - acc: 0.9453
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2017 - acc: 0.9427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2006 - acc: 0.9443
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1991 - acc: 0.9467
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1997 - acc: 0.9449
1280/1283 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9422
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2012 - acc: 0.9415 - val_loss: 0.6306 - val_acc: 0.6769

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2119 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1829 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1762 - acc: 0.9414
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1688 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1690 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1610 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1708 - acc: 0.9434
 576/1283 [============>.................] - ETA: 0s - loss: 0.1654 - acc: 0.9479
 640/1283 [=============>................] - ETA: 0s - loss: 0.1680 - acc: 0.9484
 768/1283 [================>.............] - ETA: 0s - loss: 0.1652 - acc: 0.9505
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1625 - acc: 0.9507
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1627 - acc: 0.9498
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1641 - acc: 0.9469
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1627 - acc: 0.9482
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1618 - acc: 0.9494
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1588 - acc: 0.9505
1280/1283 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9492
1283/1283 [==============================] - 1s 952us/step - loss: 0.1595 - acc: 0.9493 - val_loss: 0.6700 - val_acc: 0.6900

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1041 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1097 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0998 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0955 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0960 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0933 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1021 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1011 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.1027 - acc: 0.9757
 640/1283 [=============>................] - ETA: 0s - loss: 0.1030 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1079 - acc: 0.9759
 768/1283 [================>.............] - ETA: 0s - loss: 0.1082 - acc: 0.9766
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1126 - acc: 0.9748
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1106 - acc: 0.9766
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1080 - acc: 0.9771
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1120 - acc: 0.9746
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1165 - acc: 0.9706
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1144 - acc: 0.9714
1280/1283 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9711
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1118 - acc: 0.9712 - val_loss: 0.7445 - val_acc: 0.7162

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1023 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0825 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0885 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0780 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0731 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0772 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0763 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0730 - acc: 0.9785
 576/1283 [============>.................] - ETA: 0s - loss: 0.0698 - acc: 0.9792
 640/1283 [=============>................] - ETA: 0s - loss: 0.0718 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0715 - acc: 0.9787
 768/1283 [================>.............] - ETA: 0s - loss: 0.0694 - acc: 0.9805
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0687 - acc: 0.9808
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0667 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0694 - acc: 0.9802
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0689 - acc: 0.9805
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0677 - acc: 0.9816
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0698 - acc: 0.9809
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0733 - acc: 0.9786
1280/1283 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9789
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0732 - acc: 0.9790 - val_loss: 0.8310 - val_acc: 0.6856

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0484 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0336 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0403 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0405 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0400 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0438 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0423 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0411 - acc: 0.9931
 640/1283 [=============>................] - ETA: 0s - loss: 0.0438 - acc: 0.9906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0440 - acc: 0.9901
 768/1283 [================>.............] - ETA: 0s - loss: 0.0441 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0434 - acc: 0.9916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0441 - acc: 0.9911
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0445 - acc: 0.9906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0448 - acc: 0.9902
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0452 - acc: 0.9899
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0464 - acc: 0.9896
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0467 - acc: 0.9893
1280/1283 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9898
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0461 - acc: 0.9899 - val_loss: 0.9405 - val_acc: 0.6769

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0272 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0257 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0262 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0249 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0246 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0233 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0273 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0272 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0270 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0276 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0282 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0279 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0274 - acc: 0.9944
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0267 - acc: 0.9948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0271 - acc: 0.9951
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0279 - acc: 0.9945
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0281 - acc: 0.9948
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0291 - acc: 0.9942
1280/1283 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9945
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0287 - acc: 0.9945 - val_loss: 1.0084 - val_acc: 0.6856

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0108 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0216 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0268 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0244 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0228 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0224 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0216 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0210 - acc: 0.9948
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0204 - acc: 0.9952
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0199 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0196 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0194 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0194 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0193 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0188 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9969
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0191 - acc: 0.9969 - val_loss: 1.0464 - val_acc: 0.6769

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0113 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0108 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0114 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0148 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0137 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0142 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0136 - acc: 0.9980
 576/1283 [============>.................] - ETA: 1s - loss: 0.0138 - acc: 0.9983
 640/1283 [=============>................] - ETA: 1s - loss: 0.0148 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0144 - acc: 0.9972
 768/1283 [================>.............] - ETA: 0s - loss: 0.0137 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0135 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0141 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0138 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0142 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0151 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0154 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0157 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9969
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0153 - acc: 0.9969 - val_loss: 1.1223 - val_acc: 0.6856

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=120
accuracy=0.6865889212827988
best_valid_accuracy=0.6720116618075802
