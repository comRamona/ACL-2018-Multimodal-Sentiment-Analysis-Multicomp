/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:24:12.244162: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.6695 - acc: 0.6406
 128/1283 [=>............................] - ETA: 6s - loss: 0.7326 - acc: 0.5625 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.7637 - acc: 0.5417
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7484 - acc: 0.5750
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7467 - acc: 0.5446
 576/1283 [============>.................] - ETA: 1s - loss: 0.7631 - acc: 0.5417
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7507 - acc: 0.5412
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7426 - acc: 0.5445
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7366 - acc: 0.5427
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7326 - acc: 0.5450
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7319 - acc: 0.5378
1280/1283 [============================>.] - ETA: 0s - loss: 0.7291 - acc: 0.5391
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7293 - acc: 0.5386 - val_loss: 0.7138 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5418 - acc: 0.7344
 128/1283 [=>............................] - ETA: 0s - loss: 0.5576 - acc: 0.7109
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5665 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5706 - acc: 0.7438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5837 - acc: 0.7098
 576/1283 [============>.................] - ETA: 0s - loss: 0.5882 - acc: 0.7031
 640/1283 [=============>................] - ETA: 0s - loss: 0.5858 - acc: 0.7078
 768/1283 [================>.............] - ETA: 0s - loss: 0.5798 - acc: 0.7096
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5764 - acc: 0.7132
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5743 - acc: 0.7109
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5710 - acc: 0.7101
1280/1283 [============================>.] - ETA: 0s - loss: 0.5675 - acc: 0.7094
1283/1283 [==============================] - 1s 711us/step - loss: 0.5674 - acc: 0.7093 - val_loss: 0.7682 - val_acc: 0.5459

Epoch 00002: val_acc improved from 0.53712 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5233 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4920 - acc: 0.7917
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4765 - acc: 0.7937
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4681 - acc: 0.8103
 576/1283 [============>.................] - ETA: 0s - loss: 0.4606 - acc: 0.8229
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4525 - acc: 0.8224
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4557 - acc: 0.8101
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4477 - acc: 0.8187
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4441 - acc: 0.8171
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4452 - acc: 0.8125
1283/1283 [==============================] - 1s 628us/step - loss: 0.4417 - acc: 0.8161 - val_loss: 0.7524 - val_acc: 0.5590

Epoch 00003: val_acc improved from 0.54585 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2593 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.3116 - acc: 0.8984
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3407 - acc: 0.8711
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3442 - acc: 0.8688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3401 - acc: 0.8672
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3439 - acc: 0.8616
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3481 - acc: 0.8594
 576/1283 [============>.................] - ETA: 0s - loss: 0.3541 - acc: 0.8542
 640/1283 [=============>................] - ETA: 0s - loss: 0.3553 - acc: 0.8531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3593 - acc: 0.8438
 768/1283 [================>.............] - ETA: 0s - loss: 0.3657 - acc: 0.8372
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3705 - acc: 0.8304
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3663 - acc: 0.8281
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3615 - acc: 0.8299
1280/1283 [============================>.] - ETA: 0s - loss: 0.3599 - acc: 0.8289
1283/1283 [==============================] - 1s 861us/step - loss: 0.3608 - acc: 0.8277 - val_loss: 0.8354 - val_acc: 0.5764

Epoch 00004: val_acc improved from 0.55895 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2581 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2841 - acc: 0.8542
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3447 - acc: 0.8086
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3528 - acc: 0.8031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3484 - acc: 0.8099
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3309 - acc: 0.8418
 640/1283 [=============>................] - ETA: 0s - loss: 0.3324 - acc: 0.8406
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3247 - acc: 0.8452
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3155 - acc: 0.8486
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3150 - acc: 0.8490
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3147 - acc: 0.8511
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3117 - acc: 0.8569
1280/1283 [============================>.] - ETA: 0s - loss: 0.3100 - acc: 0.8578
1283/1283 [==============================] - 1s 891us/step - loss: 0.3101 - acc: 0.8574 - val_loss: 0.8191 - val_acc: 0.6288

Epoch 00005: val_acc improved from 0.57642 to 0.62882, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2021 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2026 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2396 - acc: 0.8875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2536 - acc: 0.8705
 576/1283 [============>.................] - ETA: 0s - loss: 0.2469 - acc: 0.8802
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2372 - acc: 0.8920
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2414 - acc: 0.8918
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2422 - acc: 0.8958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2400 - acc: 0.8943
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2378 - acc: 0.8931
1283/1283 [==============================] - 1s 690us/step - loss: 0.2372 - acc: 0.8956 - val_loss: 0.9053 - val_acc: 0.6114

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1737 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1907 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1926 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1796 - acc: 0.9427
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1791 - acc: 0.9414
 576/1283 [============>.................] - ETA: 0s - loss: 0.1738 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1762 - acc: 0.9418
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1782 - acc: 0.9375
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1761 - acc: 0.9375
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1722 - acc: 0.9384
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1742 - acc: 0.9367
1283/1283 [==============================] - 1s 681us/step - loss: 0.1771 - acc: 0.9345 - val_loss: 1.1020 - val_acc: 0.5983

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1540 - acc: 0.9219
 128/1283 [=>............................] - ETA: 0s - loss: 0.1579 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1741 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1638 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1628 - acc: 0.9442
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1626 - acc: 0.9414
 640/1283 [=============>................] - ETA: 0s - loss: 0.1618 - acc: 0.9375
 768/1283 [================>.............] - ETA: 0s - loss: 0.1574 - acc: 0.9388
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1566 - acc: 0.9375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1619 - acc: 0.9326
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1567 - acc: 0.9366
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1569 - acc: 0.9350
1280/1283 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9359
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1578 - acc: 0.9361 - val_loss: 1.1318 - val_acc: 0.5939

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0892 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0952 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1237 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1167 - acc: 0.9492
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1189 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1166 - acc: 0.9479
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1198 - acc: 0.9453
 576/1283 [============>.................] - ETA: 0s - loss: 0.1236 - acc: 0.9427
 640/1283 [=============>................] - ETA: 0s - loss: 0.1288 - acc: 0.9406
 768/1283 [================>.............] - ETA: 0s - loss: 0.1251 - acc: 0.9401
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1195 - acc: 0.9475
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1207 - acc: 0.9469
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1178 - acc: 0.9504
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1190 - acc: 0.9498
1280/1283 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9469
1283/1283 [==============================] - 1s 894us/step - loss: 0.1233 - acc: 0.9470 - val_loss: 1.2421 - val_acc: 0.5852

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1369 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1132 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1107 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1125 - acc: 0.9479
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1107 - acc: 0.9453
 640/1283 [=============>................] - ETA: 0s - loss: 0.1060 - acc: 0.9516
 768/1283 [================>.............] - ETA: 0s - loss: 0.1009 - acc: 0.9557
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1050 - acc: 0.9520
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1018 - acc: 0.9561
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1052 - acc: 0.9540
1280/1283 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9547
1283/1283 [==============================] - 1s 618us/step - loss: 0.1033 - acc: 0.9548 - val_loss: 1.4252 - val_acc: 0.5808

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1257 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1205 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1122 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0983 - acc: 0.9576
 576/1283 [============>.................] - ETA: 0s - loss: 0.0924 - acc: 0.9601
 640/1283 [=============>................] - ETA: 0s - loss: 0.0908 - acc: 0.9609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0910 - acc: 0.9616
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0932 - acc: 0.9627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0912 - acc: 0.9635
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0945 - acc: 0.9605
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0911 - acc: 0.9613
1283/1283 [==============================] - 1s 689us/step - loss: 0.0905 - acc: 0.9610 - val_loss: 1.4848 - val_acc: 0.5895

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0911 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0604 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0730 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0683 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0705 - acc: 0.9727
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0751 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0754 - acc: 0.9675
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0809 - acc: 0.9615
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0812 - acc: 0.9623
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0828 - acc: 0.9622
1280/1283 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9609
1283/1283 [==============================] - 1s 646us/step - loss: 0.0821 - acc: 0.9610 - val_loss: 1.5827 - val_acc: 0.5895

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0825 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0947 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0927 - acc: 0.9570
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0885 - acc: 0.9635
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0878 - acc: 0.9609
 640/1283 [=============>................] - ETA: 0s - loss: 0.0824 - acc: 0.9641
 768/1283 [================>.............] - ETA: 0s - loss: 0.0828 - acc: 0.9622
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0817 - acc: 0.9609
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0841 - acc: 0.9590
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0891 - acc: 0.9583
1280/1283 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9594
1283/1283 [==============================] - 1s 606us/step - loss: 0.0891 - acc: 0.9595 - val_loss: 1.7245 - val_acc: 0.5764

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0622 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0689 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0656 - acc: 0.9727
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0665 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0640 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0687 - acc: 0.9730
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0643 - acc: 0.9760
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0720 - acc: 0.9708
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0732 - acc: 0.9688
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0745 - acc: 0.9679
1280/1283 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9641
1283/1283 [==============================] - 1s 590us/step - loss: 0.0772 - acc: 0.9641 - val_loss: 1.6985 - val_acc: 0.5677

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0687 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.0713 - acc: 0.9609
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0807 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0662 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0655 - acc: 0.9707
 640/1283 [=============>................] - ETA: 0s - loss: 0.0688 - acc: 0.9672
 768/1283 [================>.............] - ETA: 0s - loss: 0.0655 - acc: 0.9701
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0713 - acc: 0.9643
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0701 - acc: 0.9658
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0668 - acc: 0.9688
1280/1283 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9672
1283/1283 [==============================] - 1s 641us/step - loss: 0.0699 - acc: 0.9673 - val_loss: 1.8499 - val_acc: 0.5764

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5874635568513119
best_valid_accuracy=0.5816326530612245
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:29:43.061119: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.7451 - acc: 0.5312
 128/1283 [=>............................] - ETA: 4s - loss: 0.8516 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 3s - loss: 0.8463 - acc: 0.4896
 320/1283 [======>.......................] - ETA: 2s - loss: 0.8131 - acc: 0.4938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.8193 - acc: 0.4792
 448/1283 [=========>....................] - ETA: 1s - loss: 0.8046 - acc: 0.4777
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7949 - acc: 0.4961
 576/1283 [============>.................] - ETA: 1s - loss: 0.7890 - acc: 0.4913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7730 - acc: 0.5014
 768/1283 [================>.............] - ETA: 0s - loss: 0.7683 - acc: 0.5026
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7629 - acc: 0.5084
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7576 - acc: 0.5123
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7495 - acc: 0.5205
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7445 - acc: 0.5248
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7426 - acc: 0.5226
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7367 - acc: 0.5288
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7360 - acc: 0.5300 - val_loss: 0.7265 - val_acc: 0.5153

Epoch 00001: val_acc improved from -inf to 0.51528, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6034 - acc: 0.5938
 128/1283 [=>............................] - ETA: 0s - loss: 0.6045 - acc: 0.6016
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6070 - acc: 0.6289
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6077 - acc: 0.6250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5963 - acc: 0.6429
 576/1283 [============>.................] - ETA: 0s - loss: 0.5921 - acc: 0.6545
 640/1283 [=============>................] - ETA: 0s - loss: 0.5930 - acc: 0.6547
 768/1283 [================>.............] - ETA: 0s - loss: 0.5870 - acc: 0.6641
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5888 - acc: 0.6674
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5843 - acc: 0.6826
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5831 - acc: 0.6875
1280/1283 [============================>.] - ETA: 0s - loss: 0.5812 - acc: 0.6883
1283/1283 [==============================] - 1s 829us/step - loss: 0.5813 - acc: 0.6882 - val_loss: 0.6950 - val_acc: 0.5939

Epoch 00002: val_acc improved from 0.51528 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5025 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5150 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5110 - acc: 0.7695
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5122 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5092 - acc: 0.7682
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5133 - acc: 0.7480
 576/1283 [============>.................] - ETA: 0s - loss: 0.5079 - acc: 0.7465
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5028 - acc: 0.7429
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4963 - acc: 0.7500
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4989 - acc: 0.7479
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4918 - acc: 0.7583
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4881 - acc: 0.7623
1280/1283 [============================>.] - ETA: 0s - loss: 0.4880 - acc: 0.7602
1283/1283 [==============================] - 1s 740us/step - loss: 0.4884 - acc: 0.7599 - val_loss: 0.7129 - val_acc: 0.6026

Epoch 00003: val_acc improved from 0.59389 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3707 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.3831 - acc: 0.8828
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3737 - acc: 0.8633
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3719 - acc: 0.8719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3621 - acc: 0.8705
 576/1283 [============>.................] - ETA: 0s - loss: 0.3624 - acc: 0.8715
 640/1283 [=============>................] - ETA: 0s - loss: 0.3599 - acc: 0.8781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3662 - acc: 0.8679
 768/1283 [================>.............] - ETA: 0s - loss: 0.3673 - acc: 0.8672
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3671 - acc: 0.8678
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3657 - acc: 0.8667
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3627 - acc: 0.8682
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3624 - acc: 0.8686
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3639 - acc: 0.8646
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3677 - acc: 0.8610
1280/1283 [============================>.] - ETA: 0s - loss: 0.3653 - acc: 0.8609
1283/1283 [==============================] - 1s 989us/step - loss: 0.3654 - acc: 0.8605 - val_loss: 0.8245 - val_acc: 0.5983

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2840 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.2893 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2907 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2918 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2927 - acc: 0.8839
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2941 - acc: 0.8848
 640/1283 [=============>................] - ETA: 0s - loss: 0.2844 - acc: 0.8953
 768/1283 [================>.............] - ETA: 0s - loss: 0.2877 - acc: 0.8919
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2878 - acc: 0.8954
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2893 - acc: 0.8929
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2935 - acc: 0.8896
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2928 - acc: 0.8872
1280/1283 [============================>.] - ETA: 0s - loss: 0.2876 - acc: 0.8883
1283/1283 [==============================] - 1s 971us/step - loss: 0.2873 - acc: 0.8885 - val_loss: 1.0407 - val_acc: 0.6157

Epoch 00005: val_acc improved from 0.60262 to 0.61572, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2289 - acc: 0.8594
 128/1283 [=>............................] - ETA: 0s - loss: 0.2265 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2435 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2422 - acc: 0.8984
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2256 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2274 - acc: 0.9018
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2282 - acc: 0.9043
 576/1283 [============>.................] - ETA: 0s - loss: 0.2266 - acc: 0.9080
 640/1283 [=============>................] - ETA: 0s - loss: 0.2263 - acc: 0.9078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2214 - acc: 0.9105
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2154 - acc: 0.9111
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2137 - acc: 0.9129
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2141 - acc: 0.9125
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2146 - acc: 0.9121
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2152 - acc: 0.9099
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2094 - acc: 0.9161
1280/1283 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9187
1283/1283 [==============================] - 1s 966us/step - loss: 0.2083 - acc: 0.9174 - val_loss: 1.2652 - val_acc: 0.5808

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2245 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3066 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2946 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2804 - acc: 0.8500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2846 - acc: 0.8490
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2828 - acc: 0.8504
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2905 - acc: 0.8516
 640/1283 [=============>................] - ETA: 0s - loss: 0.2841 - acc: 0.8500
 768/1283 [================>.............] - ETA: 0s - loss: 0.2691 - acc: 0.8646
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2688 - acc: 0.8690
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2689 - acc: 0.8650
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2688 - acc: 0.8721
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2628 - acc: 0.8759
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2598 - acc: 0.8759
1280/1283 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.8789
1283/1283 [==============================] - 1s 893us/step - loss: 0.2583 - acc: 0.8784 - val_loss: 1.1089 - val_acc: 0.5633

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2114 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.1890 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1798 - acc: 0.9271
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1743 - acc: 0.9336
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1690 - acc: 0.9406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1669 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1645 - acc: 0.9375
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1631 - acc: 0.9395
 640/1283 [=============>................] - ETA: 0s - loss: 0.1690 - acc: 0.9297
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1689 - acc: 0.9347
 768/1283 [================>.............] - ETA: 0s - loss: 0.1652 - acc: 0.9362
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1631 - acc: 0.9386
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1598 - acc: 0.9406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1615 - acc: 0.9404
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1627 - acc: 0.9366
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1597 - acc: 0.9384
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1596 - acc: 0.9391
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1613 - acc: 0.9369 - val_loss: 1.2098 - val_acc: 0.5677

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1402 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.1690 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1461 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1284 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1273 - acc: 0.9487
 576/1283 [============>.................] - ETA: 0s - loss: 0.1325 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1288 - acc: 0.9531
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1286 - acc: 0.9495
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1248 - acc: 0.9531
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1218 - acc: 0.9540
1283/1283 [==============================] - 1s 641us/step - loss: 0.1230 - acc: 0.9540 - val_loss: 1.3679 - val_acc: 0.5852

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1791 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1297 - acc: 0.9414
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1160 - acc: 0.9509
 576/1283 [============>.................] - ETA: 0s - loss: 0.1148 - acc: 0.9514
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1100 - acc: 0.9560
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1086 - acc: 0.9554
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1060 - acc: 0.9561
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1063 - acc: 0.9557
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1073 - acc: 0.9564
1280/1283 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9586
1283/1283 [==============================] - 1s 589us/step - loss: 0.1049 - acc: 0.9587 - val_loss: 1.4987 - val_acc: 0.5546

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0773 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0891 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0833 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0884 - acc: 0.9635
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0878 - acc: 0.9645
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0922 - acc: 0.9621
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0918 - acc: 0.9632
1280/1283 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9641
1283/1283 [==============================] - 1s 485us/step - loss: 0.0902 - acc: 0.9634 - val_loss: 1.6131 - val_acc: 0.5546

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0828 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0811 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0817 - acc: 0.9656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0821 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.0880 - acc: 0.9618
 768/1283 [================>.............] - ETA: 0s - loss: 0.0863 - acc: 0.9622
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0827 - acc: 0.9654
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0817 - acc: 0.9648
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0837 - acc: 0.9644
1280/1283 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9625
1283/1283 [==============================] - 1s 589us/step - loss: 0.0858 - acc: 0.9626 - val_loss: 1.6906 - val_acc: 0.5633

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1019 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0810 - acc: 0.9570
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0756 - acc: 0.9621
 576/1283 [============>.................] - ETA: 0s - loss: 0.0744 - acc: 0.9653
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0823 - acc: 0.9631
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0819 - acc: 0.9632
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0786 - acc: 0.9642
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0792 - acc: 0.9638
1283/1283 [==============================] - 1s 575us/step - loss: 0.0778 - acc: 0.9641 - val_loss: 1.8054 - val_acc: 0.5502

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0472 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0685 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0629 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0663 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.0717 - acc: 0.9705
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0721 - acc: 0.9688
 768/1283 [================>.............] - ETA: 0s - loss: 0.0739 - acc: 0.9674
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0729 - acc: 0.9665
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0743 - acc: 0.9656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0736 - acc: 0.9669
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0745 - acc: 0.9638
1283/1283 [==============================] - 1s 814us/step - loss: 0.0730 - acc: 0.9649 - val_loss: 1.8631 - val_acc: 0.5546

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0741 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.0763 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0795 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0695 - acc: 0.9727
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0709 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0666 - acc: 0.9727
 640/1283 [=============>................] - ETA: 0s - loss: 0.0703 - acc: 0.9688
 768/1283 [================>.............] - ETA: 0s - loss: 0.0650 - acc: 0.9727
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0677 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0692 - acc: 0.9688
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0661 - acc: 0.9705
1280/1283 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9672
1283/1283 [==============================] - 1s 659us/step - loss: 0.0679 - acc: 0.9673 - val_loss: 1.9620 - val_acc: 0.5415

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=110
accuracy=0.607871720116618
best_valid_accuracy=0.6209912536443148
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:41:48.166428: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.7846 - acc: 0.3594
 128/1283 [=>............................] - ETA: 3s - loss: 0.8810 - acc: 0.4844
 192/1283 [===>..........................] - ETA: 2s - loss: 0.8961 - acc: 0.4896
 256/1283 [====>.........................] - ETA: 2s - loss: 0.8468 - acc: 0.5039
 320/1283 [======>.......................] - ETA: 1s - loss: 0.8131 - acc: 0.5094
 384/1283 [=======>......................] - ETA: 1s - loss: 0.8360 - acc: 0.5156
 448/1283 [=========>....................] - ETA: 1s - loss: 0.8779 - acc: 0.5112
 512/1283 [==========>...................] - ETA: 1s - loss: 0.8724 - acc: 0.5078
 576/1283 [============>.................] - ETA: 1s - loss: 0.8488 - acc: 0.5174
 640/1283 [=============>................] - ETA: 0s - loss: 0.8380 - acc: 0.5203
 704/1283 [===============>..............] - ETA: 0s - loss: 0.8310 - acc: 0.5185
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8242 - acc: 0.5192
 896/1283 [===================>..........] - ETA: 0s - loss: 0.8180 - acc: 0.5212
 960/1283 [=====================>........] - ETA: 0s - loss: 0.8143 - acc: 0.5177
1024/1283 [======================>.......] - ETA: 0s - loss: 0.8084 - acc: 0.5195
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7946 - acc: 0.5252
1280/1283 [============================>.] - ETA: 0s - loss: 0.7831 - acc: 0.5328
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7830 - acc: 0.5316 - val_loss: 0.7333 - val_acc: 0.5197

Epoch 00001: val_acc improved from -inf to 0.51965, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6396 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.6377 - acc: 0.6328
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6302 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6263 - acc: 0.6367
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6251 - acc: 0.6406
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6210 - acc: 0.6582
 640/1283 [=============>................] - ETA: 0s - loss: 0.6203 - acc: 0.6703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6208 - acc: 0.6776
 768/1283 [================>.............] - ETA: 0s - loss: 0.6188 - acc: 0.6862
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6189 - acc: 0.6875
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6169 - acc: 0.6897
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6178 - acc: 0.6846
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6118 - acc: 0.6936
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6093 - acc: 0.6982
1283/1283 [==============================] - 1s 959us/step - loss: 0.6080 - acc: 0.6984 - val_loss: 0.7601 - val_acc: 0.5415

Epoch 00002: val_acc improved from 0.51965 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5504 - acc: 0.7656
 128/1283 [=>............................] - ETA: 1s - loss: 0.5198 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5216 - acc: 0.7917
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5150 - acc: 0.7969
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5139 - acc: 0.7906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5164 - acc: 0.7786
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5175 - acc: 0.7723
 576/1283 [============>.................] - ETA: 0s - loss: 0.5155 - acc: 0.7674
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5153 - acc: 0.7656
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5046 - acc: 0.7764
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4995 - acc: 0.7792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4994 - acc: 0.7757
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4996 - acc: 0.7717
1280/1283 [============================>.] - ETA: 0s - loss: 0.5001 - acc: 0.7695
1283/1283 [==============================] - 1s 863us/step - loss: 0.5002 - acc: 0.7693 - val_loss: 0.7353 - val_acc: 0.5284

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3753 - acc: 0.8594
 128/1283 [=>............................] - ETA: 0s - loss: 0.3609 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3583 - acc: 0.8542
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3594 - acc: 0.8516
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3603 - acc: 0.8542
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3670 - acc: 0.8457
 640/1283 [=============>................] - ETA: 0s - loss: 0.3693 - acc: 0.8453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3818 - acc: 0.8338
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3761 - acc: 0.8389
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3702 - acc: 0.8438
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3688 - acc: 0.8465
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3682 - acc: 0.8481
1280/1283 [============================>.] - ETA: 0s - loss: 0.3686 - acc: 0.8438
1283/1283 [==============================] - 1s 892us/step - loss: 0.3681 - acc: 0.8441 - val_loss: 0.7921 - val_acc: 0.5459

Epoch 00004: val_acc improved from 0.54148 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3172 - acc: 0.8594
 128/1283 [=>............................] - ETA: 0s - loss: 0.2756 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2811 - acc: 0.8789
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2719 - acc: 0.8880
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2669 - acc: 0.8884
 576/1283 [============>.................] - ETA: 0s - loss: 0.2624 - acc: 0.8976
 640/1283 [=============>................] - ETA: 0s - loss: 0.2563 - acc: 0.9016
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2598 - acc: 0.8991
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2558 - acc: 0.9038
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2576 - acc: 0.8979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2609 - acc: 0.8934
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2582 - acc: 0.8923
1283/1283 [==============================] - 1s 879us/step - loss: 0.2591 - acc: 0.8901 - val_loss: 0.8796 - val_acc: 0.5764

Epoch 00005: val_acc improved from 0.54585 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2423 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.2109 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1989 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1968 - acc: 0.9297
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2081 - acc: 0.9141
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2064 - acc: 0.9107
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1983 - acc: 0.9160
 576/1283 [============>.................] - ETA: 0s - loss: 0.1945 - acc: 0.9184
 640/1283 [=============>................] - ETA: 0s - loss: 0.2077 - acc: 0.9062
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2056 - acc: 0.9091
 768/1283 [================>.............] - ETA: 0s - loss: 0.2056 - acc: 0.9128
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2016 - acc: 0.9152
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1989 - acc: 0.9177
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1938 - acc: 0.9219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1900 - acc: 0.9253
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1902 - acc: 0.9243
1280/1283 [============================>.] - ETA: 0s - loss: 0.1888 - acc: 0.9250
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1884 - acc: 0.9252 - val_loss: 1.0447 - val_acc: 0.5328

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1014 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1294 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1258 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1359 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1325 - acc: 0.9505
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1441 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1415 - acc: 0.9492
 640/1283 [=============>................] - ETA: 0s - loss: 0.1360 - acc: 0.9516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1345 - acc: 0.9517
 768/1283 [================>.............] - ETA: 0s - loss: 0.1366 - acc: 0.9505
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1342 - acc: 0.9519
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1292 - acc: 0.9552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1295 - acc: 0.9541
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1328 - acc: 0.9522
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1355 - acc: 0.9523
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1365 - acc: 0.9507
1280/1283 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9508
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1352 - acc: 0.9501 - val_loss: 1.3032 - val_acc: 0.5590

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0853 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0999 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1009 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1214 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1112 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1120 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1153 - acc: 0.9551
 576/1283 [============>.................] - ETA: 0s - loss: 0.1154 - acc: 0.9549
 640/1283 [=============>................] - ETA: 0s - loss: 0.1135 - acc: 0.9578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1127 - acc: 0.9588
 768/1283 [================>.............] - ETA: 0s - loss: 0.1159 - acc: 0.9557
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1187 - acc: 0.9519
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1143 - acc: 0.9554
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1132 - acc: 0.9552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1177 - acc: 0.9541
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1167 - acc: 0.9540
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1212 - acc: 0.9505
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1222 - acc: 0.9482
1280/1283 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9461
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1240 - acc: 0.9462 - val_loss: 1.3655 - val_acc: 0.5590

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0892 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0959 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0940 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1127 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1043 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1133 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1110 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1129 - acc: 0.9473
 576/1283 [============>.................] - ETA: 0s - loss: 0.1173 - acc: 0.9427
 640/1283 [=============>................] - ETA: 0s - loss: 0.1162 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1166 - acc: 0.9446
 768/1283 [================>.............] - ETA: 0s - loss: 0.1135 - acc: 0.9466
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1140 - acc: 0.9471
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1114 - acc: 0.9498
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1100 - acc: 0.9502
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1117 - acc: 0.9497
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1105 - acc: 0.9507
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1075 - acc: 0.9532 - val_loss: 1.6077 - val_acc: 0.5633

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1138 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.1314 - acc: 0.9297
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1231 - acc: 0.9414
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1117 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1063 - acc: 0.9505
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0977 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.0960 - acc: 0.9601
 640/1283 [=============>................] - ETA: 0s - loss: 0.0951 - acc: 0.9594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0932 - acc: 0.9616
 768/1283 [================>.............] - ETA: 0s - loss: 0.0943 - acc: 0.9583
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0939 - acc: 0.9579
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0929 - acc: 0.9576
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0886 - acc: 0.9604
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0860 - acc: 0.9629
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0866 - acc: 0.9623
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0864 - acc: 0.9627
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0887 - acc: 0.9622
1280/1283 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9633
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0867 - acc: 0.9634 - val_loss: 1.6834 - val_acc: 0.5459

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0821 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1039 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0882 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0917 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0919 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0870 - acc: 0.9509
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0819 - acc: 0.9531
 576/1283 [============>.................] - ETA: 0s - loss: 0.0818 - acc: 0.9514
 640/1283 [=============>................] - ETA: 0s - loss: 0.0767 - acc: 0.9563
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0758 - acc: 0.9588
 768/1283 [================>.............] - ETA: 0s - loss: 0.0729 - acc: 0.9622
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0764 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0717 - acc: 0.9621
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0712 - acc: 0.9625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0714 - acc: 0.9639
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0711 - acc: 0.9642
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0739 - acc: 0.9635
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0727 - acc: 0.9655
1280/1283 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9641
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0752 - acc: 0.9641 - val_loss: 1.8071 - val_acc: 0.5371

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0572 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0410 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0516 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0584 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0520 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0617 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0648 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0672 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0639 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0648 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0642 - acc: 0.9708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0622 - acc: 0.9717
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0668 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0681 - acc: 0.9688
1280/1283 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9664
1283/1283 [==============================] - 1s 995us/step - loss: 0.0708 - acc: 0.9665 - val_loss: 1.8572 - val_acc: 0.5502

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1601 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.1245 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0976 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0914 - acc: 0.9492
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0807 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0796 - acc: 0.9576
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0774 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.0707 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.0735 - acc: 0.9594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0704 - acc: 0.9631
 768/1283 [================>.............] - ETA: 0s - loss: 0.0736 - acc: 0.9596
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0729 - acc: 0.9603
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0771 - acc: 0.9587
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0745 - acc: 0.9604
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0738 - acc: 0.9619
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0717 - acc: 0.9632
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0703 - acc: 0.9644
1280/1283 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9656
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0684 - acc: 0.9649 - val_loss: 2.0663 - val_acc: 0.5459

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0492 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0660 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0921 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1050 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1012 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1055 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.1003 - acc: 0.9601
 640/1283 [=============>................] - ETA: 0s - loss: 0.1101 - acc: 0.9578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1097 - acc: 0.9588
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1155 - acc: 0.9555
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1096 - acc: 0.9594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1100 - acc: 0.9586
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1119 - acc: 0.9564
1280/1283 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9500
1283/1283 [==============================] - 1s 857us/step - loss: 0.1220 - acc: 0.9501 - val_loss: 2.2653 - val_acc: 0.5371

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2049 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1155 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1245 - acc: 0.9344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1185 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1161 - acc: 0.9397
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1071 - acc: 0.9453
 640/1283 [=============>................] - ETA: 0s - loss: 0.0975 - acc: 0.9547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1015 - acc: 0.9517
 768/1283 [================>.............] - ETA: 0s - loss: 0.0972 - acc: 0.9557
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0952 - acc: 0.9576
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1028 - acc: 0.9552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1028 - acc: 0.9541
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1019 - acc: 0.9550
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1054 - acc: 0.9523
1283/1283 [==============================] - 1s 844us/step - loss: 0.1051 - acc: 0.9517 - val_loss: 1.9212 - val_acc: 0.5240

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=120
accuracy=0.5116618075801749
best_valid_accuracy=0.5714285714285714
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:53:21.493083: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.6970 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 2s - loss: 0.7609 - acc: 0.5365
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7624 - acc: 0.5234
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7646 - acc: 0.5281
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7520 - acc: 0.5365
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7704 - acc: 0.5195
 576/1283 [============>.................] - ETA: 1s - loss: 0.7621 - acc: 0.5226
 640/1283 [=============>................] - ETA: 0s - loss: 0.7546 - acc: 0.5344
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7489 - acc: 0.5312
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7390 - acc: 0.5421
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7361 - acc: 0.5446
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7333 - acc: 0.5417
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7278 - acc: 0.5496
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7268 - acc: 0.5460
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7284 - acc: 0.5403
1280/1283 [============================>.] - ETA: 0s - loss: 0.7245 - acc: 0.5437
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7246 - acc: 0.5433 - val_loss: 0.7097 - val_acc: 0.5633

Epoch 00001: val_acc improved from -inf to 0.56332, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5735 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.5762 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5682 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5774 - acc: 0.7625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5743 - acc: 0.7604
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5710 - acc: 0.7612
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5639 - acc: 0.7695
 576/1283 [============>.................] - ETA: 0s - loss: 0.5653 - acc: 0.7587
 640/1283 [=============>................] - ETA: 0s - loss: 0.5629 - acc: 0.7625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5624 - acc: 0.7599
 768/1283 [================>.............] - ETA: 0s - loss: 0.5608 - acc: 0.7604
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5576 - acc: 0.7620
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5553 - acc: 0.7531
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5548 - acc: 0.7482
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5540 - acc: 0.7508
1280/1283 [============================>.] - ETA: 0s - loss: 0.5538 - acc: 0.7523
1283/1283 [==============================] - 1s 980us/step - loss: 0.5541 - acc: 0.7514 - val_loss: 0.7303 - val_acc: 0.5590

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4523 - acc: 0.7500
 128/1283 [=>............................] - ETA: 0s - loss: 0.4761 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4708 - acc: 0.7708
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4585 - acc: 0.8008
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4508 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4456 - acc: 0.8151
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4434 - acc: 0.8170
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4402 - acc: 0.8262
 640/1283 [=============>................] - ETA: 0s - loss: 0.4324 - acc: 0.8344
 768/1283 [================>.............] - ETA: 0s - loss: 0.4270 - acc: 0.8451
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4285 - acc: 0.8413
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4211 - acc: 0.8460
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4228 - acc: 0.8406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4204 - acc: 0.8438
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4181 - acc: 0.8438
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4172 - acc: 0.8429
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4194 - acc: 0.8355
1283/1283 [==============================] - 1s 953us/step - loss: 0.4184 - acc: 0.8348 - val_loss: 0.8467 - val_acc: 0.5895

Epoch 00003: val_acc improved from 0.56332 to 0.58952, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3492 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3654 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3455 - acc: 0.8633
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3317 - acc: 0.8724
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3331 - acc: 0.8728
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3352 - acc: 0.8633
 576/1283 [============>.................] - ETA: 0s - loss: 0.3321 - acc: 0.8628
 640/1283 [=============>................] - ETA: 0s - loss: 0.3349 - acc: 0.8547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3277 - acc: 0.8608
 768/1283 [================>.............] - ETA: 0s - loss: 0.3269 - acc: 0.8659
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3195 - acc: 0.8672
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3173 - acc: 0.8729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3116 - acc: 0.8741
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3097 - acc: 0.8775
1280/1283 [============================>.] - ETA: 0s - loss: 0.3088 - acc: 0.8758
1283/1283 [==============================] - 1s 984us/step - loss: 0.3083 - acc: 0.8761 - val_loss: 0.8357 - val_acc: 0.5677

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2434 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.2380 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2306 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2143 - acc: 0.9323
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2198 - acc: 0.9219
 640/1283 [=============>................] - ETA: 0s - loss: 0.2192 - acc: 0.9187
 768/1283 [================>.............] - ETA: 0s - loss: 0.2169 - acc: 0.9206
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2150 - acc: 0.9174
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2137 - acc: 0.9177
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2135 - acc: 0.9180
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2155 - acc: 0.9141
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2155 - acc: 0.9137
1280/1283 [============================>.] - ETA: 0s - loss: 0.2185 - acc: 0.9109
1283/1283 [==============================] - 1s 833us/step - loss: 0.2191 - acc: 0.9104 - val_loss: 1.0803 - val_acc: 0.5764

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1695 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1810 - acc: 0.9115
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1845 - acc: 0.9141
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1845 - acc: 0.9125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1768 - acc: 0.9174
 576/1283 [============>.................] - ETA: 0s - loss: 0.1798 - acc: 0.9219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1769 - acc: 0.9247
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1728 - acc: 0.9279
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1732 - acc: 0.9292
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1715 - acc: 0.9274
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1702 - acc: 0.9276
1283/1283 [==============================] - 1s 736us/step - loss: 0.1749 - acc: 0.9267 - val_loss: 1.1867 - val_acc: 0.5808

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1604 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1610 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1665 - acc: 0.9344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1452 - acc: 0.9420
 576/1283 [============>.................] - ETA: 0s - loss: 0.1386 - acc: 0.9444
 640/1283 [=============>................] - ETA: 0s - loss: 0.1388 - acc: 0.9422
 768/1283 [================>.............] - ETA: 0s - loss: 0.1375 - acc: 0.9440
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1395 - acc: 0.9431
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1365 - acc: 0.9448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1313 - acc: 0.9494
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1276 - acc: 0.9507
1280/1283 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9516
1283/1283 [==============================] - 1s 853us/step - loss: 0.1260 - acc: 0.9517 - val_loss: 1.3502 - val_acc: 0.5590

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0733 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1124 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1056 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1061 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1091 - acc: 0.9554
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1115 - acc: 0.9512
 576/1283 [============>.................] - ETA: 0s - loss: 0.1063 - acc: 0.9549
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1036 - acc: 0.9588
 768/1283 [================>.............] - ETA: 0s - loss: 0.0984 - acc: 0.9622
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0973 - acc: 0.9627
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0987 - acc: 0.9609
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0964 - acc: 0.9619
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0957 - acc: 0.9623
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0960 - acc: 0.9627
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0956 - acc: 0.9630
1280/1283 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9602
1283/1283 [==============================] - 1s 929us/step - loss: 0.0990 - acc: 0.9595 - val_loss: 1.4389 - val_acc: 0.5677

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0446 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0588 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0903 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0914 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0938 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0943 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0919 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0907 - acc: 0.9590
 640/1283 [=============>................] - ETA: 0s - loss: 0.0907 - acc: 0.9594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0961 - acc: 0.9545
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0982 - acc: 0.9531
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0968 - acc: 0.9552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0957 - acc: 0.9570
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0947 - acc: 0.9577
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0943 - acc: 0.9566
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0959 - acc: 0.9548
1280/1283 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9563
1283/1283 [==============================] - 1s 948us/step - loss: 0.0935 - acc: 0.9564 - val_loss: 1.5314 - val_acc: 0.5328

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0549 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0725 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0729 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0738 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0701 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0717 - acc: 0.9732
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0686 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.0715 - acc: 0.9705
 640/1283 [=============>................] - ETA: 0s - loss: 0.0783 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0817 - acc: 0.9659
 768/1283 [================>.............] - ETA: 0s - loss: 0.0797 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0795 - acc: 0.9675
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0798 - acc: 0.9676
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0805 - acc: 0.9667
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0812 - acc: 0.9660
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0862 - acc: 0.9618
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0873 - acc: 0.9613
1283/1283 [==============================] - 1s 926us/step - loss: 0.0876 - acc: 0.9618 - val_loss: 1.6615 - val_acc: 0.5415

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1121 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0828 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0823 - acc: 0.9570
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0792 - acc: 0.9661
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0769 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0745 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0769 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0782 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0782 - acc: 0.9675
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0744 - acc: 0.9699
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0764 - acc: 0.9677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0737 - acc: 0.9697
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0790 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0790 - acc: 0.9679
1280/1283 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9625
1283/1283 [==============================] - 1s 884us/step - loss: 0.0812 - acc: 0.9626 - val_loss: 1.8020 - val_acc: 0.5764

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0268 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0732 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0698 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0725 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0704 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0666 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0727 - acc: 0.9627
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0767 - acc: 0.9621
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0756 - acc: 0.9619
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0724 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0709 - acc: 0.9663
1280/1283 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9664
1283/1283 [==============================] - 1s 860us/step - loss: 0.0719 - acc: 0.9665 - val_loss: 1.7185 - val_acc: 0.5633

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0333 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0512 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0623 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0646 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0616 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0645 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0627 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0653 - acc: 0.9668
 576/1283 [============>.................] - ETA: 0s - loss: 0.0652 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0701 - acc: 0.9616
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0753 - acc: 0.9627
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0701 - acc: 0.9654
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0686 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0696 - acc: 0.9670
1280/1283 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9664
1283/1283 [==============================] - 1s 846us/step - loss: 0.0699 - acc: 0.9665 - val_loss: 1.9763 - val_acc: 0.5328

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=10
PCA visual=30
PCA text=130
accuracy=0.5349854227405247
best_valid_accuracy=0.6107871720116618
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 00:10:56.221743: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 18s - loss: 0.9340 - acc: 0.3906
 128/1283 [=>............................] - ETA: 9s - loss: 0.9379 - acc: 0.4219 
 256/1283 [====>.........................] - ETA: 4s - loss: 0.8271 - acc: 0.5078
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7943 - acc: 0.5219
 384/1283 [=======>......................] - ETA: 3s - loss: 0.8102 - acc: 0.5026
 448/1283 [=========>....................] - ETA: 2s - loss: 0.8021 - acc: 0.5022
 576/1283 [============>.................] - ETA: 1s - loss: 0.7785 - acc: 0.5069
 640/1283 [=============>................] - ETA: 1s - loss: 0.7734 - acc: 0.4984
 768/1283 [================>.............] - ETA: 1s - loss: 0.7595 - acc: 0.5078
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7573 - acc: 0.5011
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7506 - acc: 0.5073
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7421 - acc: 0.5156
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7379 - acc: 0.5217
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7341 - acc: 0.5271
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7306 - acc: 0.5323 - val_loss: 0.7110 - val_acc: 0.4934

Epoch 00001: val_acc improved from -inf to 0.49345, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5707 - acc: 0.7188
 128/1283 [=>............................] - ETA: 1s - loss: 0.5792 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5874 - acc: 0.6667
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5778 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5785 - acc: 0.6813
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5827 - acc: 0.6693
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5913 - acc: 0.6562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5846 - acc: 0.6699
 640/1283 [=============>................] - ETA: 0s - loss: 0.5789 - acc: 0.6766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5786 - acc: 0.6776
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5789 - acc: 0.6779
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5777 - acc: 0.6786
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5782 - acc: 0.6758
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5769 - acc: 0.6814
1280/1283 [============================>.] - ETA: 0s - loss: 0.5757 - acc: 0.6828
1283/1283 [==============================] - 1s 902us/step - loss: 0.5755 - acc: 0.6828 - val_loss: 0.7491 - val_acc: 0.5240

Epoch 00002: val_acc improved from 0.49345 to 0.52402, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4995 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.4861 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4683 - acc: 0.8229
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4697 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4749 - acc: 0.8156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4759 - acc: 0.8099
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4705 - acc: 0.8125
 640/1283 [=============>................] - ETA: 0s - loss: 0.4669 - acc: 0.8078
 768/1283 [================>.............] - ETA: 0s - loss: 0.4710 - acc: 0.7995
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4691 - acc: 0.8025
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4692 - acc: 0.8021
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4670 - acc: 0.8037
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4622 - acc: 0.8051
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4605 - acc: 0.8038
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4590 - acc: 0.8043
1280/1283 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8063
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4566 - acc: 0.8059 - val_loss: 0.7927 - val_acc: 0.5109

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3607 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3392 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3517 - acc: 0.8516
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3512 - acc: 0.8625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3583 - acc: 0.8490
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3670 - acc: 0.8259
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3730 - acc: 0.8203
 576/1283 [============>.................] - ETA: 0s - loss: 0.3749 - acc: 0.8142
 640/1283 [=============>................] - ETA: 0s - loss: 0.3739 - acc: 0.8187
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3703 - acc: 0.8210
 768/1283 [================>.............] - ETA: 0s - loss: 0.3734 - acc: 0.8177
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3687 - acc: 0.8221
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3649 - acc: 0.8304
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3702 - acc: 0.8260
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3678 - acc: 0.8271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3669 - acc: 0.8300
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3674 - acc: 0.8307
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3687 - acc: 0.8306
1280/1283 [============================>.] - ETA: 0s - loss: 0.3677 - acc: 0.8297
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3680 - acc: 0.8293 - val_loss: 0.9530 - val_acc: 0.6026

Epoch 00004: val_acc improved from 0.52402 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3586 - acc: 0.8125
 128/1283 [=>............................] - ETA: 0s - loss: 0.4180 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3966 - acc: 0.8047
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3797 - acc: 0.8187
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3541 - acc: 0.8359
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3477 - acc: 0.8393
 576/1283 [============>.................] - ETA: 0s - loss: 0.3308 - acc: 0.8455
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3208 - acc: 0.8494
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3190 - acc: 0.8510
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3204 - acc: 0.8490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3157 - acc: 0.8516
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3127 - acc: 0.8516
1280/1283 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8492
1283/1283 [==============================] - 1s 783us/step - loss: 0.3161 - acc: 0.8488 - val_loss: 0.8848 - val_acc: 0.5633

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2483 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2643 - acc: 0.8854
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2760 - acc: 0.8828
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2772 - acc: 0.8812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2659 - acc: 0.8929
 576/1283 [============>.................] - ETA: 0s - loss: 0.2661 - acc: 0.8854
 640/1283 [=============>................] - ETA: 0s - loss: 0.2612 - acc: 0.8875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2605 - acc: 0.8864
 768/1283 [================>.............] - ETA: 0s - loss: 0.2594 - acc: 0.8867
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2533 - acc: 0.8906
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2507 - acc: 0.8917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2485 - acc: 0.8965
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2464 - acc: 0.8980
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2423 - acc: 0.9019
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2423 - acc: 0.9021
1280/1283 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9016
1283/1283 [==============================] - 1s 987us/step - loss: 0.2449 - acc: 0.9010 - val_loss: 1.0228 - val_acc: 0.5590

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1534 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1769 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1847 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1889 - acc: 0.9406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1865 - acc: 0.9401
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1860 - acc: 0.9316
 640/1283 [=============>................] - ETA: 0s - loss: 0.1914 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1933 - acc: 0.9219
 768/1283 [================>.............] - ETA: 0s - loss: 0.1959 - acc: 0.9219
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1921 - acc: 0.9263
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1884 - acc: 0.9281
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1879 - acc: 0.9297
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1908 - acc: 0.9265
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1887 - acc: 0.9271
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1864 - acc: 0.9285
1280/1283 [============================>.] - ETA: 0s - loss: 0.1879 - acc: 0.9266
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1876 - acc: 0.9267 - val_loss: 1.3183 - val_acc: 0.5546

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1170 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1156 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1206 - acc: 0.9648
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1239 - acc: 0.9609
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1415 - acc: 0.9492
 640/1283 [=============>................] - ETA: 0s - loss: 0.1420 - acc: 0.9484
 768/1283 [================>.............] - ETA: 0s - loss: 0.1449 - acc: 0.9427
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1545 - acc: 0.9353
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1520 - acc: 0.9375
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1479 - acc: 0.9384
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1470 - acc: 0.9391
1280/1283 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9398
1283/1283 [==============================] - 1s 772us/step - loss: 0.1458 - acc: 0.9400 - val_loss: 1.3978 - val_acc: 0.5546

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0941 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1049 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1184 - acc: 0.9609
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1423 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1451 - acc: 0.9420
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1423 - acc: 0.9434
 576/1283 [============>.................] - ETA: 0s - loss: 0.1379 - acc: 0.9479
 640/1283 [=============>................] - ETA: 0s - loss: 0.1376 - acc: 0.9500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1396 - acc: 0.9489
 768/1283 [================>.............] - ETA: 0s - loss: 0.1378 - acc: 0.9531
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1372 - acc: 0.9519
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1375 - acc: 0.9510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1334 - acc: 0.9531
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1281 - acc: 0.9559
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1289 - acc: 0.9540
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1259 - acc: 0.9556
1280/1283 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9563
1283/1283 [==============================] - 1s 982us/step - loss: 0.1249 - acc: 0.9564 - val_loss: 1.6456 - val_acc: 0.5633

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1002 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1057 - acc: 0.9609
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0983 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0893 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0917 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0899 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.1025 - acc: 0.9705
 640/1283 [=============>................] - ETA: 0s - loss: 0.0999 - acc: 0.9703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0970 - acc: 0.9702
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0984 - acc: 0.9651
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1025 - acc: 0.9632
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1012 - acc: 0.9615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1011 - acc: 0.9619
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1007 - acc: 0.9614
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1030 - acc: 0.9609
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1028 - acc: 0.9597
1283/1283 [==============================] - 1s 958us/step - loss: 0.1027 - acc: 0.9579 - val_loss: 1.7262 - val_acc: 0.5764

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0441 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0867 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0857 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0981 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0889 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0930 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0916 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0939 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.0912 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.0909 - acc: 0.9609
 768/1283 [================>.............] - ETA: 0s - loss: 0.0888 - acc: 0.9635
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0886 - acc: 0.9651
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0924 - acc: 0.9632
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0885 - acc: 0.9646
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0872 - acc: 0.9642
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0848 - acc: 0.9663
1280/1283 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9648
1283/1283 [==============================] - 1s 952us/step - loss: 0.0847 - acc: 0.9649 - val_loss: 1.8082 - val_acc: 0.5633

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0704 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0818 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0805 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0792 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0752 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0707 - acc: 0.9732
 576/1283 [============>.................] - ETA: 0s - loss: 0.0679 - acc: 0.9740
 640/1283 [=============>................] - ETA: 0s - loss: 0.0733 - acc: 0.9703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0757 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0702 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0745 - acc: 0.9676
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0773 - acc: 0.9656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0766 - acc: 0.9658
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0754 - acc: 0.9669
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0749 - acc: 0.9670
1280/1283 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9680
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0753 - acc: 0.9680 - val_loss: 2.0033 - val_acc: 0.5371

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0523 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0646 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0772 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0808 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0823 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0801 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0792 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0783 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.0743 - acc: 0.9653
 640/1283 [=============>................] - ETA: 0s - loss: 0.0772 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0787 - acc: 0.9616
 768/1283 [================>.............] - ETA: 0s - loss: 0.0787 - acc: 0.9635
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0782 - acc: 0.9639
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0819 - acc: 0.9609
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0792 - acc: 0.9625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0795 - acc: 0.9629
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0748 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0751 - acc: 0.9638
1280/1283 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9625
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0837 - acc: 0.9626 - val_loss: 2.2126 - val_acc: 0.5284

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0552 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0468 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0628 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0808 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0842 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0746 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0730 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.0807 - acc: 0.9601
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0755 - acc: 0.9616
 768/1283 [================>.............] - ETA: 0s - loss: 0.0715 - acc: 0.9648
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0725 - acc: 0.9639
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0733 - acc: 0.9632
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0717 - acc: 0.9646
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0725 - acc: 0.9648
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0707 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0725 - acc: 0.9630
1280/1283 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9648
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0719 - acc: 0.9649 - val_loss: 2.2347 - val_acc: 0.5328

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=10
PCA visual=30
PCA text=140
accuracy=0.5612244897959183
best_valid_accuracy=0.5903790087463557
