/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 13:18:13.349460: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.6821 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 3s - loss: 0.7752 - acc: 0.4948 
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7739 - acc: 0.4961
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7788 - acc: 0.4844
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7738 - acc: 0.4870
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7595 - acc: 0.4978
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7559 - acc: 0.4922
 576/1283 [============>.................] - ETA: 1s - loss: 0.7487 - acc: 0.4913
 640/1283 [=============>................] - ETA: 1s - loss: 0.7457 - acc: 0.5016
 768/1283 [================>.............] - ETA: 0s - loss: 0.7429 - acc: 0.5026
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7384 - acc: 0.5036
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7382 - acc: 0.5033
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7340 - acc: 0.5094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7270 - acc: 0.5205
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7294 - acc: 0.5175
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7294 - acc: 0.5148
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7250 - acc: 0.5230
1280/1283 [============================>.] - ETA: 0s - loss: 0.7223 - acc: 0.5258
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7221 - acc: 0.5261 - val_loss: 0.7552 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6265 - acc: 0.6094
 128/1283 [=>............................] - ETA: 1s - loss: 0.6317 - acc: 0.6016
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6110 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6237 - acc: 0.6172
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6149 - acc: 0.6375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6075 - acc: 0.6484
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6042 - acc: 0.6518
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5987 - acc: 0.6562
 576/1283 [============>.................] - ETA: 0s - loss: 0.5895 - acc: 0.6667
 640/1283 [=============>................] - ETA: 0s - loss: 0.5886 - acc: 0.6625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5881 - acc: 0.6577
 768/1283 [================>.............] - ETA: 0s - loss: 0.5784 - acc: 0.6706
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5751 - acc: 0.6755
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5702 - acc: 0.6875
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5633 - acc: 0.6990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5594 - acc: 0.7021
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5551 - acc: 0.7068
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5535 - acc: 0.7083
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5511 - acc: 0.7089
1280/1283 [============================>.] - ETA: 0s - loss: 0.5470 - acc: 0.7102
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5469 - acc: 0.7101 - val_loss: 0.6861 - val_acc: 0.6245

Epoch 00002: val_acc improved from 0.52838 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4082 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3856 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3809 - acc: 0.8789
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3793 - acc: 0.8812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3766 - acc: 0.8776
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3807 - acc: 0.8705
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3871 - acc: 0.8574
 576/1283 [============>.................] - ETA: 0s - loss: 0.3883 - acc: 0.8455
 640/1283 [=============>................] - ETA: 0s - loss: 0.3852 - acc: 0.8484
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3792 - acc: 0.8537
 768/1283 [================>.............] - ETA: 0s - loss: 0.3801 - acc: 0.8516
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3790 - acc: 0.8486
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3703 - acc: 0.8538
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3671 - acc: 0.8573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3644 - acc: 0.8584
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3612 - acc: 0.8594
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3617 - acc: 0.8602
1280/1283 [============================>.] - ETA: 0s - loss: 0.3590 - acc: 0.8609
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3594 - acc: 0.8605 - val_loss: 0.8190 - val_acc: 0.6594

Epoch 00003: val_acc improved from 0.62445 to 0.65939, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2367 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2827 - acc: 0.8802
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2753 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2639 - acc: 0.8812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2527 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2550 - acc: 0.8951
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2779 - acc: 0.8789
 576/1283 [============>.................] - ETA: 0s - loss: 0.2761 - acc: 0.8819
 640/1283 [=============>................] - ETA: 0s - loss: 0.2717 - acc: 0.8844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2637 - acc: 0.8906
 768/1283 [================>.............] - ETA: 0s - loss: 0.2608 - acc: 0.8945
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2561 - acc: 0.8990
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2631 - acc: 0.8951
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2634 - acc: 0.8958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2560 - acc: 0.9017
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2519 - acc: 0.9028
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2520 - acc: 0.9021
1280/1283 [============================>.] - ETA: 0s - loss: 0.2513 - acc: 0.9023
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2513 - acc: 0.9026 - val_loss: 0.9025 - val_acc: 0.6288

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1766 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.1727 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1724 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1643 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1661 - acc: 0.9500
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1551 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1607 - acc: 0.9509
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1636 - acc: 0.9512
 576/1283 [============>.................] - ETA: 0s - loss: 0.1637 - acc: 0.9462
 640/1283 [=============>................] - ETA: 0s - loss: 0.1560 - acc: 0.9516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1533 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1548 - acc: 0.9505
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1511 - acc: 0.9543
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1497 - acc: 0.9531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1506 - acc: 0.9492
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1505 - acc: 0.9494
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1481 - acc: 0.9505
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1468 - acc: 0.9507
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1467 - acc: 0.9501 - val_loss: 0.9306 - val_acc: 0.6812

Epoch 00005: val_acc improved from 0.65939 to 0.68122, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0811 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0971 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1014 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0980 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0975 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0883 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0909 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0862 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0847 - acc: 0.9809
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0848 - acc: 0.9815
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0805 - acc: 0.9832
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0789 - acc: 0.9833
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0811 - acc: 0.9825
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0803 - acc: 0.9803
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0792 - acc: 0.9805 - val_loss: 1.0299 - val_acc: 0.6812

Epoch 00006: val_acc improved from 0.68122 to 0.68122, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0363 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0437 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0464 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0483 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0484 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0450 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0483 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0485 - acc: 0.9872
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0492 - acc: 0.9856
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0482 - acc: 0.9865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0478 - acc: 0.9871
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0493 - acc: 0.9852
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0500 - acc: 0.9852
1280/1283 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9859
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0499 - acc: 0.9860 - val_loss: 1.1756 - val_acc: 0.6638

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0451 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0395 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0340 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0303 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0354 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0373 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0359 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0377 - acc: 0.9883
 576/1283 [============>.................] - ETA: 0s - loss: 0.0389 - acc: 0.9878
 640/1283 [=============>................] - ETA: 0s - loss: 0.0403 - acc: 0.9859
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0389 - acc: 0.9872
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0379 - acc: 0.9880
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0373 - acc: 0.9877
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0365 - acc: 0.9885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0378 - acc: 0.9873
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0377 - acc: 0.9881
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0370 - acc: 0.9887
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0359 - acc: 0.9893
1280/1283 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9898
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0351 - acc: 0.9899 - val_loss: 1.3395 - val_acc: 0.6507

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0275 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0256 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0256 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0236 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0244 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0223 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0208 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0197 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0203 - acc: 0.9972
 768/1283 [================>.............] - ETA: 0s - loss: 0.0212 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0204 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0196 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0197 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0195 - acc: 0.9972
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0202 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9961
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0209 - acc: 0.9961 - val_loss: 1.3633 - val_acc: 0.6856

Epoch 00009: val_acc improved from 0.68122 to 0.68559, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0209 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0256 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0198 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0158 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0181 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0158 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0165 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0157 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0147 - acc: 0.9953
 768/1283 [================>.............] - ETA: 0s - loss: 0.0148 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0142 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0138 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0142 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0136 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0138 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0135 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9961
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0143 - acc: 0.9961 - val_loss: 1.4479 - val_acc: 0.6987

Epoch 00010: val_acc improved from 0.68559 to 0.69869, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0293 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0195 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0143 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0117 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0108 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0096 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0092 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0113 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0108 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0118 - acc: 0.9972
 768/1283 [================>.............] - ETA: 0s - loss: 0.0114 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0114 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0119 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0114 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0114 - acc: 0.9974
1280/1283 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9969
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0118 - acc: 0.9969 - val_loss: 1.7401 - val_acc: 0.6507

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0137 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0720 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0994 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0788 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0646 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0590 - acc: 0.9818
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0826 - acc: 0.9668
 576/1283 [============>.................] - ETA: 0s - loss: 0.0843 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0765 - acc: 0.9688
 768/1283 [================>.............] - ETA: 0s - loss: 0.0855 - acc: 0.9661
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0824 - acc: 0.9663
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0811 - acc: 0.9676
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0767 - acc: 0.9698
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0729 - acc: 0.9717
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0688 - acc: 0.9731
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0668 - acc: 0.9745
1280/1283 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9742
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0656 - acc: 0.9743 - val_loss: 1.7101 - val_acc: 0.6201

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0292 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0294 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0272 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0257 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0222 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0200 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0205 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0199 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0200 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0337 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0327 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0335 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0340 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0327 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0392 - acc: 0.9936
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0388 - acc: 0.9939
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0376 - acc: 0.9942
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0377 - acc: 0.9938 - val_loss: 1.5296 - val_acc: 0.6288

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0108 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0085 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0151 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0131 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0178 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0230 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0223 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0209 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0194 - acc: 0.9953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0179 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0182 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0191 - acc: 0.9964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0184 - acc: 0.9969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0180 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0174 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0174 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9969
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0170 - acc: 0.9969 - val_loss: 1.6278 - val_acc: 0.6288

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0142 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0100 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0122 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0133 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0124 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0116 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0113 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0110 - acc: 0.9961
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0107 - acc: 0.9964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0106 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0100 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0106 - acc: 0.9965
1280/1283 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9961
1283/1283 [==============================] - 1s 937us/step - loss: 0.0114 - acc: 0.9961 - val_loss: 1.7322 - val_acc: 0.6376

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0032 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0068 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0125 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0103 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0114 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0100 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0100 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0096 - acc: 0.9972
 768/1283 [================>.............] - ETA: 0s - loss: 0.0098 - acc: 0.9961
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0088 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0080 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0076 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0073 - acc: 0.9975
1283/1283 [==============================] - 1s 798us/step - loss: 0.0084 - acc: 0.9961 - val_loss: 1.7813 - val_acc: 0.6332

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0021 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0027 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0046 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0043 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0039 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0045 - acc: 0.9987
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0066 - acc: 0.9978
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0074 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0076 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0074 - acc: 0.9967
1283/1283 [==============================] - 1s 828us/step - loss: 0.0072 - acc: 0.9969 - val_loss: 1.8488 - val_acc: 0.6245

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0082 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0080 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0066 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0063 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0057 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0050 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0053 - acc: 0.9979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0060 - acc: 0.9972
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0058 - acc: 0.9975
1283/1283 [==============================] - 1s 667us/step - loss: 0.0063 - acc: 0.9969 - val_loss: 1.9035 - val_acc: 0.6288

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0027 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0057 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0046 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0059 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0052 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0050 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0048 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0045 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0058 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0061 - acc: 0.9982
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0060 - acc: 0.9984
1283/1283 [==============================] - 1s 841us/step - loss: 0.0064 - acc: 0.9977 - val_loss: 1.9796 - val_acc: 0.6245

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 5.4904e-04 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 6.7791e-04 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 9.1483e-04 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0053 - acc: 0.9974    
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0051 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0045 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0072 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0076 - acc: 0.9952
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0068 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0071 - acc: 0.9954
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0064 - acc: 0.9959
1280/1283 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9961
1283/1283 [==============================] - 1s 742us/step - loss: 0.0061 - acc: 0.9961 - val_loss: 2.0121 - val_acc: 0.6245

Epoch 00020: val_acc did not improve
Epoch 00020: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=15
nodes=100
mode=VT
PCA audio=35
PCA visual=45
PCA text=130
accuracy=0.619533527696793
best_valid_accuracy=0.6501457725947521
