/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:12:28.941069: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 22s - loss: 0.7016 - acc: 0.4688
 192/1283 [===>..........................] - ETA: 7s - loss: 0.6960 - acc: 0.5104 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.6950 - acc: 0.5094
 448/1283 [=========>....................] - ETA: 2s - loss: 0.6923 - acc: 0.5223
 512/1283 [==========>...................] - ETA: 2s - loss: 0.6927 - acc: 0.5137
 640/1283 [=============>................] - ETA: 1s - loss: 0.6938 - acc: 0.5094
 768/1283 [================>.............] - ETA: 1s - loss: 0.6968 - acc: 0.4922
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6947 - acc: 0.5033
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6947 - acc: 0.5039
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6943 - acc: 0.5055
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6923 - acc: 0.5164
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6919 - acc: 0.5214 - val_loss: 0.6820 - val_acc: 0.5546

Epoch 00001: val_acc improved from -inf to 0.55459, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6907 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6935 - acc: 0.5208
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6935 - acc: 0.5312
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6929 - acc: 0.5312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6900 - acc: 0.5491
 576/1283 [============>.................] - ETA: 0s - loss: 0.6886 - acc: 0.5451
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6872 - acc: 0.5497
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6846 - acc: 0.5673
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6822 - acc: 0.5729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6807 - acc: 0.5800
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6789 - acc: 0.5842
1280/1283 [============================>.] - ETA: 0s - loss: 0.6792 - acc: 0.5813
1283/1283 [==============================] - 1s 703us/step - loss: 0.6790 - acc: 0.5822 - val_loss: 0.6821 - val_acc: 0.5328

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6694 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6603 - acc: 0.6641
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6662 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6618 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6636 - acc: 0.6344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6680 - acc: 0.6146
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6717 - acc: 0.6027
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6700 - acc: 0.6055
 576/1283 [============>.................] - ETA: 0s - loss: 0.6676 - acc: 0.6128
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6697 - acc: 0.6037
 768/1283 [================>.............] - ETA: 0s - loss: 0.6696 - acc: 0.6068
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6692 - acc: 0.6034
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6698 - acc: 0.6049
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6690 - acc: 0.6052
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6697 - acc: 0.6016
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6689 - acc: 0.6048
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6695 - acc: 0.6042
1280/1283 [============================>.] - ETA: 0s - loss: 0.6679 - acc: 0.6062
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6674 - acc: 0.6072 - val_loss: 0.6837 - val_acc: 0.5415

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6734 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6706 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6543 - acc: 0.6219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6585 - acc: 0.6094
 576/1283 [============>.................] - ETA: 0s - loss: 0.6606 - acc: 0.6042
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6642 - acc: 0.5938
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6642 - acc: 0.5950
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6665 - acc: 0.5938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6650 - acc: 0.5996
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6666 - acc: 0.5929
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6639 - acc: 0.5987
1280/1283 [============================>.] - ETA: 0s - loss: 0.6637 - acc: 0.5992
1283/1283 [==============================] - 1s 795us/step - loss: 0.6634 - acc: 0.5994 - val_loss: 0.6842 - val_acc: 0.5895

Epoch 00004: val_acc improved from 0.55459 to 0.58952, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6463 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6640 - acc: 0.6198
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6775 - acc: 0.5898
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6652 - acc: 0.6125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6608 - acc: 0.6276
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6599 - acc: 0.6295
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6579 - acc: 0.6328
 640/1283 [=============>................] - ETA: 0s - loss: 0.6539 - acc: 0.6281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6590 - acc: 0.6165
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6553 - acc: 0.6250
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6559 - acc: 0.6239
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6563 - acc: 0.6188
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6584 - acc: 0.6143
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6585 - acc: 0.6149
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6590 - acc: 0.6155
1280/1283 [============================>.] - ETA: 0s - loss: 0.6584 - acc: 0.6195
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6582 - acc: 0.6196 - val_loss: 0.6800 - val_acc: 0.5895

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6419 - acc: 0.6250
 128/1283 [=>............................] - ETA: 1s - loss: 0.6375 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6513 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6488 - acc: 0.6289
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6506 - acc: 0.6344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6460 - acc: 0.6354
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6413 - acc: 0.6540
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6477 - acc: 0.6445
 576/1283 [============>.................] - ETA: 0s - loss: 0.6484 - acc: 0.6476
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6493 - acc: 0.6378
 768/1283 [================>.............] - ETA: 0s - loss: 0.6462 - acc: 0.6393
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6477 - acc: 0.6334
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6472 - acc: 0.6317
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6489 - acc: 0.6270
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6495 - acc: 0.6268
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6510 - acc: 0.6250
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6526 - acc: 0.6234
1280/1283 [============================>.] - ETA: 0s - loss: 0.6527 - acc: 0.6234
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6524 - acc: 0.6235 - val_loss: 0.6828 - val_acc: 0.5983

Epoch 00006: val_acc improved from 0.58952 to 0.59825, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5972 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6054 - acc: 0.6927
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6287 - acc: 0.6687
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6342 - acc: 0.6585
 576/1283 [============>.................] - ETA: 0s - loss: 0.6289 - acc: 0.6632
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6366 - acc: 0.6520
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6395 - acc: 0.6478
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6399 - acc: 0.6448
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6419 - acc: 0.6436
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6437 - acc: 0.6406
1280/1283 [============================>.] - ETA: 0s - loss: 0.6458 - acc: 0.6336
1283/1283 [==============================] - 1s 713us/step - loss: 0.6459 - acc: 0.6337 - val_loss: 0.6806 - val_acc: 0.6026

Epoch 00007: val_acc improved from 0.59825 to 0.60262, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6621 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6408 - acc: 0.6406
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6529 - acc: 0.6250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6586 - acc: 0.6205
 576/1283 [============>.................] - ETA: 0s - loss: 0.6457 - acc: 0.6458
 640/1283 [=============>................] - ETA: 0s - loss: 0.6516 - acc: 0.6297
 768/1283 [================>.............] - ETA: 0s - loss: 0.6554 - acc: 0.6185
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6563 - acc: 0.6178
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6522 - acc: 0.6250
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6454 - acc: 0.6314
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6415 - acc: 0.6373
1283/1283 [==============================] - 1s 777us/step - loss: 0.6370 - acc: 0.6430 - val_loss: 0.6823 - val_acc: 0.5939

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6113 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6392 - acc: 0.6562
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6206 - acc: 0.6758
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6328 - acc: 0.6589
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6265 - acc: 0.6660
 576/1283 [============>.................] - ETA: 0s - loss: 0.6223 - acc: 0.6719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6202 - acc: 0.6733
 768/1283 [================>.............] - ETA: 0s - loss: 0.6254 - acc: 0.6719
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6277 - acc: 0.6629
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6272 - acc: 0.6611
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6245 - acc: 0.6627
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6256 - acc: 0.6615
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6289 - acc: 0.6571
1283/1283 [==============================] - 1s 749us/step - loss: 0.6281 - acc: 0.6586 - val_loss: 0.6869 - val_acc: 0.5852

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6615 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6226 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6267 - acc: 0.6719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6175 - acc: 0.6786
 576/1283 [============>.................] - ETA: 0s - loss: 0.6231 - acc: 0.6632
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6244 - acc: 0.6591
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6260 - acc: 0.6562
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6255 - acc: 0.6607
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6245 - acc: 0.6582
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6263 - acc: 0.6553
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6213 - acc: 0.6606
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6209 - acc: 0.6587
1280/1283 [============================>.] - ETA: 0s - loss: 0.6196 - acc: 0.6617
1283/1283 [==============================] - 1s 864us/step - loss: 0.6206 - acc: 0.6610 - val_loss: 0.6934 - val_acc: 0.5764

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6102 - acc: 0.7188
 128/1283 [=>............................] - ETA: 1s - loss: 0.6046 - acc: 0.6953
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6019 - acc: 0.6992
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6262 - acc: 0.6641
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6291 - acc: 0.6543
 640/1283 [=============>................] - ETA: 0s - loss: 0.6244 - acc: 0.6625
 768/1283 [================>.............] - ETA: 0s - loss: 0.6330 - acc: 0.6497
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6321 - acc: 0.6514
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6305 - acc: 0.6500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6284 - acc: 0.6543
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6281 - acc: 0.6493
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6250 - acc: 0.6530
1283/1283 [==============================] - 1s 757us/step - loss: 0.6245 - acc: 0.6563 - val_loss: 0.6922 - val_acc: 0.5808

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6194 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6198 - acc: 0.6302
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6181 - acc: 0.6375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6215 - acc: 0.6339
 576/1283 [============>.................] - ETA: 0s - loss: 0.6223 - acc: 0.6389
 640/1283 [=============>................] - ETA: 0s - loss: 0.6180 - acc: 0.6500
 768/1283 [================>.............] - ETA: 0s - loss: 0.6121 - acc: 0.6667
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6160 - acc: 0.6611
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6121 - acc: 0.6698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6116 - acc: 0.6728
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6097 - acc: 0.6793
1283/1283 [==============================] - 1s 787us/step - loss: 0.6099 - acc: 0.6773 - val_loss: 0.6901 - val_acc: 0.6026

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6188 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.6236 - acc: 0.6172
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6138 - acc: 0.6602
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6035 - acc: 0.6687
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6150 - acc: 0.6641
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6153 - acc: 0.6674
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6174 - acc: 0.6641
 576/1283 [============>.................] - ETA: 0s - loss: 0.6156 - acc: 0.6597
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6039 - acc: 0.6648
 768/1283 [================>.............] - ETA: 0s - loss: 0.6015 - acc: 0.6654
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5991 - acc: 0.6707
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5986 - acc: 0.6719
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6015 - acc: 0.6687
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5961 - acc: 0.6777
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5982 - acc: 0.6737
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5973 - acc: 0.6776
1280/1283 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.6711
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6023 - acc: 0.6703 - val_loss: 0.7002 - val_acc: 0.5764

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5865 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5785 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5898 - acc: 0.6875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5893 - acc: 0.6830
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5971 - acc: 0.6758
 576/1283 [============>.................] - ETA: 0s - loss: 0.5875 - acc: 0.6840
 640/1283 [=============>................] - ETA: 0s - loss: 0.5857 - acc: 0.6891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5873 - acc: 0.6903
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5911 - acc: 0.6887
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5938 - acc: 0.6844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5938 - acc: 0.6836
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5953 - acc: 0.6801
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5953 - acc: 0.6801
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5918 - acc: 0.6820 - val_loss: 0.7016 - val_acc: 0.5590

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5689 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5499 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5499 - acc: 0.7469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5478 - acc: 0.7500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5631 - acc: 0.7305
 576/1283 [============>.................] - ETA: 0s - loss: 0.5606 - acc: 0.7257
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5676 - acc: 0.7074
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5730 - acc: 0.7055
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5760 - acc: 0.7000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5777 - acc: 0.6949
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5816 - acc: 0.6941
1283/1283 [==============================] - 1s 797us/step - loss: 0.5798 - acc: 0.6952 - val_loss: 0.6968 - val_acc: 0.5939

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5170 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5277 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5449 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5473 - acc: 0.7375
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5566 - acc: 0.7292
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5634 - acc: 0.7299
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5666 - acc: 0.7246
 576/1283 [============>.................] - ETA: 0s - loss: 0.5728 - acc: 0.7170
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5744 - acc: 0.7131
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5754 - acc: 0.7103
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5734 - acc: 0.7109
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5716 - acc: 0.7125
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5741 - acc: 0.7105
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5730 - acc: 0.7072
1280/1283 [============================>.] - ETA: 0s - loss: 0.5717 - acc: 0.7086
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5712 - acc: 0.7093 - val_loss: 0.6921 - val_acc: 0.6026

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4962 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5543 - acc: 0.7109
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5590 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5501 - acc: 0.7344
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5581 - acc: 0.7219
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5499 - acc: 0.7266
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5558 - acc: 0.7232
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5620 - acc: 0.7188
 576/1283 [============>.................] - ETA: 1s - loss: 0.5636 - acc: 0.7153
 640/1283 [=============>................] - ETA: 1s - loss: 0.5614 - acc: 0.7172
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5590 - acc: 0.7173
 768/1283 [================>.............] - ETA: 0s - loss: 0.5537 - acc: 0.7240
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5544 - acc: 0.7199
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5560 - acc: 0.7178
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5580 - acc: 0.7151
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5599 - acc: 0.7101
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5600 - acc: 0.7105
1280/1283 [============================>.] - ETA: 0s - loss: 0.5593 - acc: 0.7094
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5594 - acc: 0.7093 - val_loss: 0.7057 - val_acc: 0.5808

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5262390670553936
best_valid_accuracy=0.5087463556851312
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:21:09.602747: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 15s - loss: 0.7224 - acc: 0.3125
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6984 - acc: 0.4492 
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6957 - acc: 0.4714
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6950 - acc: 0.4922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6927 - acc: 0.5014
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6914 - acc: 0.5134
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6906 - acc: 0.5119
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6905 - acc: 0.5156
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6917 - acc: 0.5129 - val_loss: 0.6890 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6727 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6784 - acc: 0.6016
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6741 - acc: 0.5990
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6669 - acc: 0.6270
 640/1283 [=============>................] - ETA: 0s - loss: 0.6682 - acc: 0.6266
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6678 - acc: 0.6238
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6713 - acc: 0.6104
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6704 - acc: 0.6121
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6736 - acc: 0.6069
1283/1283 [==============================] - 1s 471us/step - loss: 0.6736 - acc: 0.6025 - val_loss: 0.6826 - val_acc: 0.5415

Epoch 00002: val_acc improved from 0.53712 to 0.54148, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6243 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6508 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6531 - acc: 0.6302
 576/1283 [============>.................] - ETA: 0s - loss: 0.6558 - acc: 0.6128
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6609 - acc: 0.5980
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6630 - acc: 0.5925
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6624 - acc: 0.5979
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6619 - acc: 0.5990
1280/1283 [============================>.] - ETA: 0s - loss: 0.6606 - acc: 0.6023
1283/1283 [==============================] - 1s 452us/step - loss: 0.6608 - acc: 0.6017 - val_loss: 0.6817 - val_acc: 0.5459

Epoch 00003: val_acc improved from 0.54148 to 0.54585, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6611 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6577 - acc: 0.5521
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6576 - acc: 0.5687
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6524 - acc: 0.5915
 576/1283 [============>.................] - ETA: 0s - loss: 0.6509 - acc: 0.6042
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6514 - acc: 0.6122
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6538 - acc: 0.6046
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6567 - acc: 0.6016
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6552 - acc: 0.6076
1280/1283 [============================>.] - ETA: 0s - loss: 0.6535 - acc: 0.6133
1283/1283 [==============================] - 1s 516us/step - loss: 0.6538 - acc: 0.6126 - val_loss: 0.6828 - val_acc: 0.5502

Epoch 00004: val_acc improved from 0.54585 to 0.55022, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6420 - acc: 0.6094
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6586 - acc: 0.5977
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6445 - acc: 0.6354
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6491 - acc: 0.6270
 640/1283 [=============>................] - ETA: 0s - loss: 0.6440 - acc: 0.6297
 768/1283 [================>.............] - ETA: 0s - loss: 0.6484 - acc: 0.6263
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6498 - acc: 0.6205
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6483 - acc: 0.6201
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6440 - acc: 0.6328
1283/1283 [==============================] - 1s 473us/step - loss: 0.6442 - acc: 0.6321 - val_loss: 0.6837 - val_acc: 0.5721

Epoch 00005: val_acc improved from 0.55022 to 0.57205, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6390 - acc: 0.6250
 128/1283 [=>............................] - ETA: 0s - loss: 0.6318 - acc: 0.6641
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6188 - acc: 0.6797
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6312 - acc: 0.6667
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6346 - acc: 0.6562
 640/1283 [=============>................] - ETA: 0s - loss: 0.6340 - acc: 0.6547
 768/1283 [================>.............] - ETA: 0s - loss: 0.6307 - acc: 0.6589
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6290 - acc: 0.6596
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6275 - acc: 0.6572
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6302 - acc: 0.6510
1280/1283 [============================>.] - ETA: 0s - loss: 0.6313 - acc: 0.6484
1283/1283 [==============================] - 1s 608us/step - loss: 0.6313 - acc: 0.6477 - val_loss: 0.6951 - val_acc: 0.5284

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6348 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6279 - acc: 0.6289
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6192 - acc: 0.6432
 576/1283 [============>.................] - ETA: 0s - loss: 0.6117 - acc: 0.6528
 768/1283 [================>.............] - ETA: 0s - loss: 0.6098 - acc: 0.6523
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6190 - acc: 0.6479
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6199 - acc: 0.6502
1280/1283 [============================>.] - ETA: 0s - loss: 0.6217 - acc: 0.6484
1283/1283 [==============================] - 1s 491us/step - loss: 0.6217 - acc: 0.6477 - val_loss: 0.6891 - val_acc: 0.5502

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6139 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6150 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5986 - acc: 0.6906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6063 - acc: 0.6719
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6177 - acc: 0.6523
 640/1283 [=============>................] - ETA: 0s - loss: 0.6207 - acc: 0.6469
 768/1283 [================>.............] - ETA: 0s - loss: 0.6205 - acc: 0.6432
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6205 - acc: 0.6451
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6174 - acc: 0.6510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6143 - acc: 0.6517
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6102 - acc: 0.6571
1283/1283 [==============================] - 1s 791us/step - loss: 0.6098 - acc: 0.6610 - val_loss: 0.6940 - val_acc: 0.5459

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6001 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5718 - acc: 0.7396
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5792 - acc: 0.7227
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5847 - acc: 0.7057
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5872 - acc: 0.7012
 576/1283 [============>.................] - ETA: 0s - loss: 0.5899 - acc: 0.6979
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5956 - acc: 0.6875
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6009 - acc: 0.6875
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5987 - acc: 0.6875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5993 - acc: 0.6875
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5998 - acc: 0.6797
1280/1283 [============================>.] - ETA: 0s - loss: 0.6005 - acc: 0.6758
1283/1283 [==============================] - 1s 751us/step - loss: 0.6005 - acc: 0.6758 - val_loss: 0.6962 - val_acc: 0.5240

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5671 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5983 - acc: 0.6667
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5991 - acc: 0.6602
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5907 - acc: 0.6562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5783 - acc: 0.6719
 640/1283 [=============>................] - ETA: 0s - loss: 0.5825 - acc: 0.6750
 768/1283 [================>.............] - ETA: 0s - loss: 0.5812 - acc: 0.6797
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5798 - acc: 0.6815
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5854 - acc: 0.6792
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5850 - acc: 0.6797
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5861 - acc: 0.6771
1280/1283 [============================>.] - ETA: 0s - loss: 0.5873 - acc: 0.6742
1283/1283 [==============================] - 1s 696us/step - loss: 0.5867 - acc: 0.6750 - val_loss: 0.7064 - val_acc: 0.5197

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5463 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5792 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5844 - acc: 0.6781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5684 - acc: 0.7054
 576/1283 [============>.................] - ETA: 0s - loss: 0.5590 - acc: 0.7083
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5522 - acc: 0.7159
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5558 - acc: 0.7103
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5636 - acc: 0.7010
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5667 - acc: 0.6976
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5719 - acc: 0.6957
1283/1283 [==============================] - 1s 703us/step - loss: 0.5721 - acc: 0.6952 - val_loss: 0.7154 - val_acc: 0.5328

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5648 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5601 - acc: 0.7135
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5442 - acc: 0.7344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5573 - acc: 0.7083
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5513 - acc: 0.7090
 640/1283 [=============>................] - ETA: 0s - loss: 0.5529 - acc: 0.7094
 768/1283 [================>.............] - ETA: 0s - loss: 0.5524 - acc: 0.7174
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5563 - acc: 0.7132
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5574 - acc: 0.7148
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5594 - acc: 0.7161
1280/1283 [============================>.] - ETA: 0s - loss: 0.5564 - acc: 0.7180
1283/1283 [==============================] - 1s 709us/step - loss: 0.5568 - acc: 0.7171 - val_loss: 0.7068 - val_acc: 0.5415

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5937 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5690 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5347 - acc: 0.7438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5279 - acc: 0.7567
 576/1283 [============>.................] - ETA: 0s - loss: 0.5385 - acc: 0.7431
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5365 - acc: 0.7472
 768/1283 [================>.............] - ETA: 0s - loss: 0.5348 - acc: 0.7487
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5335 - acc: 0.7444
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5343 - acc: 0.7432
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5377 - acc: 0.7353
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5416 - acc: 0.7319
1283/1283 [==============================] - 1s 702us/step - loss: 0.5402 - acc: 0.7319 - val_loss: 0.7232 - val_acc: 0.5066

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5661 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5327 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5228 - acc: 0.7500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5355 - acc: 0.7344
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5503 - acc: 0.7227
 576/1283 [============>.................] - ETA: 0s - loss: 0.5473 - acc: 0.7292
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5468 - acc: 0.7273
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5382 - acc: 0.7356
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5351 - acc: 0.7344
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5367 - acc: 0.7279
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5339 - acc: 0.7286
1280/1283 [============================>.] - ETA: 0s - loss: 0.5277 - acc: 0.7375
1283/1283 [==============================] - 1s 765us/step - loss: 0.5279 - acc: 0.7373 - val_loss: 0.7217 - val_acc: 0.5371

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4795 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5086 - acc: 0.7292
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4986 - acc: 0.7531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4954 - acc: 0.7589
 576/1283 [============>.................] - ETA: 0s - loss: 0.5015 - acc: 0.7535
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5093 - acc: 0.7372
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5065 - acc: 0.7368
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5083 - acc: 0.7366
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5123 - acc: 0.7334
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5112 - acc: 0.7326
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5130 - acc: 0.7294
1283/1283 [==============================] - 1s 739us/step - loss: 0.5121 - acc: 0.7319 - val_loss: 0.7437 - val_acc: 0.5371

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=15
PCA text=100
accuracy=0.4839650145772595
best_valid_accuracy=0.5131195335276968
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:30:02.661449: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 28s - loss: 0.7005 - acc: 0.4219
 192/1283 [===>..........................] - ETA: 8s - loss: 0.7081 - acc: 0.4427 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.7020 - acc: 0.4844
 448/1283 [=========>....................] - ETA: 3s - loss: 0.7004 - acc: 0.4844
 576/1283 [============>.................] - ETA: 2s - loss: 0.6986 - acc: 0.4965
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6980 - acc: 0.4957
 832/1283 [==================>...........] - ETA: 1s - loss: 0.6970 - acc: 0.4940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6968 - acc: 0.5042
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6965 - acc: 0.5037
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6951 - acc: 0.5099
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6944 - acc: 0.5144 - val_loss: 0.6865 - val_acc: 0.5633

Epoch 00001: val_acc improved from -inf to 0.56332, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6684 - acc: 0.6562
 128/1283 [=>............................] - ETA: 1s - loss: 0.6711 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6716 - acc: 0.6094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6705 - acc: 0.6120
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6715 - acc: 0.5996
 576/1283 [============>.................] - ETA: 0s - loss: 0.6726 - acc: 0.5972
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6724 - acc: 0.5980
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6705 - acc: 0.6046
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6727 - acc: 0.5969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6724 - acc: 0.5910
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6703 - acc: 0.5987
1283/1283 [==============================] - 1s 770us/step - loss: 0.6731 - acc: 0.5900 - val_loss: 0.6853 - val_acc: 0.5895

Epoch 00002: val_acc improved from 0.56332 to 0.58952, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6346 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6561 - acc: 0.6302
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6584 - acc: 0.6133
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6545 - acc: 0.6312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6565 - acc: 0.6272
 576/1283 [============>.................] - ETA: 0s - loss: 0.6618 - acc: 0.6128
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6628 - acc: 0.6094
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6629 - acc: 0.6049
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6632 - acc: 0.6055
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6626 - acc: 0.6076
1280/1283 [============================>.] - ETA: 0s - loss: 0.6623 - acc: 0.6117
1283/1283 [==============================] - 1s 746us/step - loss: 0.6616 - acc: 0.6126 - val_loss: 0.6835 - val_acc: 0.5852

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6573 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6492 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6553 - acc: 0.6250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6557 - acc: 0.6138
 576/1283 [============>.................] - ETA: 0s - loss: 0.6521 - acc: 0.6198
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6497 - acc: 0.6278
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6512 - acc: 0.6238
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6521 - acc: 0.6240
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6515 - acc: 0.6232
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6456 - acc: 0.6357
1283/1283 [==============================] - 1s 743us/step - loss: 0.6458 - acc: 0.6313 - val_loss: 0.6820 - val_acc: 0.5808

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6319 - acc: 0.6094
 128/1283 [=>............................] - ETA: 0s - loss: 0.6142 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6065 - acc: 0.7083
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6182 - acc: 0.6875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6139 - acc: 0.6797
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6253 - acc: 0.6621
 640/1283 [=============>................] - ETA: 0s - loss: 0.6282 - acc: 0.6625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6302 - acc: 0.6577
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6299 - acc: 0.6599
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6277 - acc: 0.6646
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6352 - acc: 0.6544
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6325 - acc: 0.6604
1280/1283 [============================>.] - ETA: 0s - loss: 0.6343 - acc: 0.6562
1283/1283 [==============================] - 1s 865us/step - loss: 0.6342 - acc: 0.6563 - val_loss: 0.6862 - val_acc: 0.5677

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6181 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6297 - acc: 0.6302
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6235 - acc: 0.6445
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6147 - acc: 0.6667
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6211 - acc: 0.6607
 576/1283 [============>.................] - ETA: 0s - loss: 0.6171 - acc: 0.6632
 640/1283 [=============>................] - ETA: 0s - loss: 0.6130 - acc: 0.6672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6225 - acc: 0.6577
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6237 - acc: 0.6526
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6192 - acc: 0.6596
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6164 - acc: 0.6641
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6171 - acc: 0.6627
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6172 - acc: 0.6620
1280/1283 [============================>.] - ETA: 0s - loss: 0.6156 - acc: 0.6648
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6155 - acc: 0.6648 - val_loss: 0.6869 - val_acc: 0.5895

Epoch 00006: val_acc improved from 0.58952 to 0.58952, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5885 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5953 - acc: 0.6979
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5924 - acc: 0.7063
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5982 - acc: 0.6964
 576/1283 [============>.................] - ETA: 0s - loss: 0.6009 - acc: 0.6927
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5991 - acc: 0.6903
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6023 - acc: 0.6887
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5995 - acc: 0.6897
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5999 - acc: 0.6865
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5969 - acc: 0.6895
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5959 - acc: 0.6921
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5964 - acc: 0.6918
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5978 - acc: 0.6900
1280/1283 [============================>.] - ETA: 0s - loss: 0.5953 - acc: 0.6945
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5955 - acc: 0.6945 - val_loss: 0.6967 - val_acc: 0.5852

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5952 - acc: 0.7188
 128/1283 [=>............................] - ETA: 1s - loss: 0.5798 - acc: 0.7266
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5868 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5872 - acc: 0.7125
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5846 - acc: 0.7161
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5797 - acc: 0.7210
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5819 - acc: 0.7207
 640/1283 [=============>................] - ETA: 0s - loss: 0.5782 - acc: 0.7219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5797 - acc: 0.7116
 768/1283 [================>.............] - ETA: 0s - loss: 0.5750 - acc: 0.7148
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5711 - acc: 0.7224
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5733 - acc: 0.7176
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5753 - acc: 0.7080
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5729 - acc: 0.7092
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5771 - acc: 0.7015
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5787 - acc: 0.6984 - val_loss: 0.7126 - val_acc: 0.5764

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.5056 - acc: 0.7500
 128/1283 [=>............................] - ETA: 2s - loss: 0.5134 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5213 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5301 - acc: 0.7617
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5369 - acc: 0.7500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5509 - acc: 0.7285
 640/1283 [=============>................] - ETA: 0s - loss: 0.5460 - acc: 0.7250
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5477 - acc: 0.7216
 768/1283 [================>.............] - ETA: 0s - loss: 0.5490 - acc: 0.7266
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5488 - acc: 0.7260
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5484 - acc: 0.7266
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5537 - acc: 0.7227
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5543 - acc: 0.7215
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5526 - acc: 0.7248
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5523 - acc: 0.7253
1280/1283 [============================>.] - ETA: 0s - loss: 0.5546 - acc: 0.7227
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5560 - acc: 0.7210 - val_loss: 0.7183 - val_acc: 0.5502

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5293 - acc: 0.7188
 128/1283 [=>............................] - ETA: 1s - loss: 0.5409 - acc: 0.7109
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5496 - acc: 0.7083
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5318 - acc: 0.7375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5443 - acc: 0.7165
 576/1283 [============>.................] - ETA: 0s - loss: 0.5345 - acc: 0.7326
 640/1283 [=============>................] - ETA: 0s - loss: 0.5373 - acc: 0.7297
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5390 - acc: 0.7273
 768/1283 [================>.............] - ETA: 0s - loss: 0.5411 - acc: 0.7201
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5420 - acc: 0.7236
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5367 - acc: 0.7333
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5372 - acc: 0.7344
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5416 - acc: 0.7326
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5455 - acc: 0.7319
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5465 - acc: 0.7272 - val_loss: 0.7189 - val_acc: 0.5633

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5007 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5188 - acc: 0.7865
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5153 - acc: 0.7781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5225 - acc: 0.7567
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5262 - acc: 0.7559
 576/1283 [============>.................] - ETA: 0s - loss: 0.5280 - acc: 0.7552
 640/1283 [=============>................] - ETA: 0s - loss: 0.5308 - acc: 0.7516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5303 - acc: 0.7514
 768/1283 [================>.............] - ETA: 0s - loss: 0.5299 - acc: 0.7487
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5296 - acc: 0.7488
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5284 - acc: 0.7500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5274 - acc: 0.7529
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5294 - acc: 0.7509
1280/1283 [============================>.] - ETA: 0s - loss: 0.5291 - acc: 0.7477
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5295 - acc: 0.7467 - val_loss: 0.7285 - val_acc: 0.5677

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5440 - acc: 0.7188
 128/1283 [=>............................] - ETA: 1s - loss: 0.5292 - acc: 0.7266
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5145 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5116 - acc: 0.7594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5035 - acc: 0.7656
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4946 - acc: 0.7734
 576/1283 [============>.................] - ETA: 0s - loss: 0.4970 - acc: 0.7674
 640/1283 [=============>................] - ETA: 0s - loss: 0.4883 - acc: 0.7781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4979 - acc: 0.7685
 768/1283 [================>.............] - ETA: 0s - loss: 0.4936 - acc: 0.7721
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4924 - acc: 0.7728
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4870 - acc: 0.7768
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4853 - acc: 0.7750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4863 - acc: 0.7744
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4883 - acc: 0.7721
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4911 - acc: 0.7706
1280/1283 [============================>.] - ETA: 0s - loss: 0.4899 - acc: 0.7727
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4902 - acc: 0.7724 - val_loss: 0.7617 - val_acc: 0.5721

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4932 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5025 - acc: 0.7266
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4825 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4710 - acc: 0.7773
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4530 - acc: 0.8000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4526 - acc: 0.7995
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4598 - acc: 0.7946
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4625 - acc: 0.7891
 576/1283 [============>.................] - ETA: 0s - loss: 0.4687 - acc: 0.7847
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4740 - acc: 0.7756
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4730 - acc: 0.7692
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4720 - acc: 0.7712
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4689 - acc: 0.7760
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4690 - acc: 0.7776
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4688 - acc: 0.7769
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4698 - acc: 0.7780
1280/1283 [============================>.] - ETA: 0s - loss: 0.4712 - acc: 0.7781
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4707 - acc: 0.7786 - val_loss: 0.7880 - val_acc: 0.5764

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3979 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4470 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4299 - acc: 0.8250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4237 - acc: 0.8281
 576/1283 [============>.................] - ETA: 0s - loss: 0.4307 - acc: 0.8212
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4230 - acc: 0.8239
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4303 - acc: 0.8149
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4300 - acc: 0.8125
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4343 - acc: 0.8061
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4319 - acc: 0.8073
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4401 - acc: 0.8035
1280/1283 [============================>.] - ETA: 0s - loss: 0.4454 - acc: 0.7969
1283/1283 [==============================] - 1s 869us/step - loss: 0.4463 - acc: 0.7958 - val_loss: 0.8334 - val_acc: 0.5677

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3989 - acc: 0.7656
 128/1283 [=>............................] - ETA: 1s - loss: 0.4203 - acc: 0.7891
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4059 - acc: 0.7930
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4206 - acc: 0.7906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4132 - acc: 0.8080
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4174 - acc: 0.8086
 576/1283 [============>.................] - ETA: 0s - loss: 0.4163 - acc: 0.8090
 640/1283 [=============>................] - ETA: 0s - loss: 0.4182 - acc: 0.8078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4136 - acc: 0.8153
 768/1283 [================>.............] - ETA: 0s - loss: 0.4206 - acc: 0.8112
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4167 - acc: 0.8147
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4280 - acc: 0.8047
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4299 - acc: 0.8030
1280/1283 [============================>.] - ETA: 0s - loss: 0.4231 - acc: 0.8047
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4230 - acc: 0.8051 - val_loss: 0.8496 - val_acc: 0.5415

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3332 - acc: 0.8906
 128/1283 [=>............................] - ETA: 1s - loss: 0.3831 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3781 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3800 - acc: 0.8398
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3729 - acc: 0.8469
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3694 - acc: 0.8490
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3699 - acc: 0.8482
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3661 - acc: 0.8535
 576/1283 [============>.................] - ETA: 0s - loss: 0.3733 - acc: 0.8507
 640/1283 [=============>................] - ETA: 0s - loss: 0.3751 - acc: 0.8453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3775 - acc: 0.8395
 768/1283 [================>.............] - ETA: 0s - loss: 0.3824 - acc: 0.8333
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3844 - acc: 0.8317
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3888 - acc: 0.8315
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3809 - acc: 0.8375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3883 - acc: 0.8301
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3919 - acc: 0.8254
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3947 - acc: 0.8212
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3904 - acc: 0.8232
1280/1283 [============================>.] - ETA: 0s - loss: 0.3873 - acc: 0.8281
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3884 - acc: 0.8277 - val_loss: 0.9200 - val_acc: 0.5590

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=20
PCA text=100
accuracy=0.48542274052478135
best_valid_accuracy=0.49854227405247814
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:38:23.974500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 20s - loss: 0.7086 - acc: 0.3438
 192/1283 [===>..........................] - ETA: 6s - loss: 0.6993 - acc: 0.4531 
 320/1283 [======>.......................] - ETA: 3s - loss: 0.6961 - acc: 0.4906
 448/1283 [=========>....................] - ETA: 2s - loss: 0.6933 - acc: 0.5134
 576/1283 [============>.................] - ETA: 1s - loss: 0.6924 - acc: 0.5156
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6897 - acc: 0.5369
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6905 - acc: 0.5337
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6911 - acc: 0.5354
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6894 - acc: 0.5441
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6887 - acc: 0.5444
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6885 - acc: 0.5472 - val_loss: 0.6834 - val_acc: 0.5764

Epoch 00001: val_acc improved from -inf to 0.57642, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6626 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6585 - acc: 0.5885
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6588 - acc: 0.6094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6631 - acc: 0.6094
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6629 - acc: 0.6113
 576/1283 [============>.................] - ETA: 0s - loss: 0.6606 - acc: 0.6163
 640/1283 [=============>................] - ETA: 0s - loss: 0.6624 - acc: 0.6094
 768/1283 [================>.............] - ETA: 0s - loss: 0.6658 - acc: 0.6016
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6666 - acc: 0.5971
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6655 - acc: 0.5957
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6655 - acc: 0.5955
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6645 - acc: 0.5987
1283/1283 [==============================] - 1s 775us/step - loss: 0.6649 - acc: 0.5963 - val_loss: 0.6819 - val_acc: 0.5764

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6620 - acc: 0.5781
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6398 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6310 - acc: 0.6469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6366 - acc: 0.6451
 576/1283 [============>.................] - ETA: 0s - loss: 0.6370 - acc: 0.6476
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6357 - acc: 0.6520
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6400 - acc: 0.6442
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6407 - acc: 0.6458
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6446 - acc: 0.6406
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6436 - acc: 0.6390
1283/1283 [==============================] - 1s 544us/step - loss: 0.6434 - acc: 0.6391 - val_loss: 0.6806 - val_acc: 0.5808

Epoch 00003: val_acc improved from 0.57642 to 0.58079, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6069 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6304 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6312 - acc: 0.6594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6286 - acc: 0.6629
 576/1283 [============>.................] - ETA: 0s - loss: 0.6257 - acc: 0.6632
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6375 - acc: 0.6392
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6314 - acc: 0.6502
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6328 - acc: 0.6490
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6259 - acc: 0.6599
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6240 - acc: 0.6587
1283/1283 [==============================] - 1s 517us/step - loss: 0.6255 - acc: 0.6539 - val_loss: 0.6839 - val_acc: 0.5546

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5791 - acc: 0.7969
 128/1283 [=>............................] - ETA: 0s - loss: 0.6176 - acc: 0.7422
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6150 - acc: 0.7109
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6139 - acc: 0.6979
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6149 - acc: 0.6855
 640/1283 [=============>................] - ETA: 0s - loss: 0.6092 - acc: 0.6891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6124 - acc: 0.6847
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6140 - acc: 0.6791
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6098 - acc: 0.6808
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6118 - acc: 0.6777
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6088 - acc: 0.6780
1280/1283 [============================>.] - ETA: 0s - loss: 0.6081 - acc: 0.6797
1283/1283 [==============================] - 1s 641us/step - loss: 0.6087 - acc: 0.6781 - val_loss: 0.6918 - val_acc: 0.5459

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5875 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5755 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5881 - acc: 0.6969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5828 - acc: 0.7121
 576/1283 [============>.................] - ETA: 0s - loss: 0.5919 - acc: 0.6944
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5893 - acc: 0.7088
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5869 - acc: 0.7043
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5782 - acc: 0.7158
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5858 - acc: 0.7066
1283/1283 [==============================] - 1s 504us/step - loss: 0.5908 - acc: 0.6960 - val_loss: 0.6960 - val_acc: 0.5721

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5878 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5741 - acc: 0.7292
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5525 - acc: 0.7474
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5621 - acc: 0.7285
 640/1283 [=============>................] - ETA: 0s - loss: 0.5663 - acc: 0.7203
 768/1283 [================>.............] - ETA: 0s - loss: 0.5726 - acc: 0.7174
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5797 - acc: 0.6998
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5825 - acc: 0.7002
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5776 - acc: 0.7031
1280/1283 [============================>.] - ETA: 0s - loss: 0.5809 - acc: 0.7008
1283/1283 [==============================] - 1s 546us/step - loss: 0.5808 - acc: 0.7007 - val_loss: 0.6980 - val_acc: 0.5546

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5408 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5609 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5599 - acc: 0.7156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5569 - acc: 0.7188
 576/1283 [============>.................] - ETA: 0s - loss: 0.5524 - acc: 0.7222
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5594 - acc: 0.7159
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5626 - acc: 0.7103
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5624 - acc: 0.7167
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5669 - acc: 0.7142
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5680 - acc: 0.7127
1280/1283 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7148
1283/1283 [==============================] - 1s 695us/step - loss: 0.5659 - acc: 0.7140 - val_loss: 0.7187 - val_acc: 0.5328

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4980 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5291 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5360 - acc: 0.7344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5428 - acc: 0.7240
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5371 - acc: 0.7411
 576/1283 [============>.................] - ETA: 0s - loss: 0.5362 - acc: 0.7465
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5396 - acc: 0.7358
 768/1283 [================>.............] - ETA: 0s - loss: 0.5418 - acc: 0.7344
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5375 - acc: 0.7411
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5367 - acc: 0.7417
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5409 - acc: 0.7381
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5445 - acc: 0.7336
1283/1283 [==============================] - 1s 844us/step - loss: 0.5426 - acc: 0.7358 - val_loss: 0.7197 - val_acc: 0.5328

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6018 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5210 - acc: 0.7760
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5207 - acc: 0.7688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5210 - acc: 0.7656
 576/1283 [============>.................] - ETA: 0s - loss: 0.5260 - acc: 0.7587
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5320 - acc: 0.7543
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5290 - acc: 0.7536
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5259 - acc: 0.7567
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5285 - acc: 0.7529
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5241 - acc: 0.7517
1280/1283 [============================>.] - ETA: 0s - loss: 0.5207 - acc: 0.7562
1283/1283 [==============================] - 1s 724us/step - loss: 0.5207 - acc: 0.7568 - val_loss: 0.7453 - val_acc: 0.5328

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4894 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.4662 - acc: 0.8359
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4935 - acc: 0.8047
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4950 - acc: 0.7969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4804 - acc: 0.8099
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4781 - acc: 0.8125
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4906 - acc: 0.7988
 576/1283 [============>.................] - ETA: 0s - loss: 0.4881 - acc: 0.7986
 640/1283 [=============>................] - ETA: 0s - loss: 0.4879 - acc: 0.7891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4845 - acc: 0.7926
 768/1283 [================>.............] - ETA: 0s - loss: 0.4806 - acc: 0.7891
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4751 - acc: 0.7945
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4760 - acc: 0.7924
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4803 - acc: 0.7906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4880 - acc: 0.7842
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4897 - acc: 0.7858
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4895 - acc: 0.7865
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4918 - acc: 0.7780
1283/1283 [==============================] - 2s 2ms/step - loss: 0.4954 - acc: 0.7740 - val_loss: 0.7961 - val_acc: 0.5284

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4586 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4216 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4394 - acc: 0.8073
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4571 - acc: 0.8086
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4581 - acc: 0.8031
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4573 - acc: 0.8099
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4690 - acc: 0.7969
 640/1283 [=============>................] - ETA: 0s - loss: 0.4718 - acc: 0.7906
 768/1283 [================>.............] - ETA: 0s - loss: 0.4733 - acc: 0.7904
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4737 - acc: 0.7891
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4727 - acc: 0.7885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4700 - acc: 0.7930
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4726 - acc: 0.7914
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4729 - acc: 0.7943
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4692 - acc: 0.7977
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4705 - acc: 0.7958 - val_loss: 0.7899 - val_acc: 0.5371

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3963 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.3947 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3872 - acc: 0.8646
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3987 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4169 - acc: 0.8219
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4243 - acc: 0.8013
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4284 - acc: 0.7949
 640/1283 [=============>................] - ETA: 0s - loss: 0.4327 - acc: 0.8000
 768/1283 [================>.............] - ETA: 0s - loss: 0.4432 - acc: 0.7943
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4492 - acc: 0.7879
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4465 - acc: 0.7900
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4506 - acc: 0.7856
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4501 - acc: 0.7854
1280/1283 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.7859
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4490 - acc: 0.7857 - val_loss: 0.8431 - val_acc: 0.5284

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=25
PCA text=100
accuracy=0.4956268221574344
best_valid_accuracy=0.5043731778425656
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 18:48:25.139855: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 9s - loss: 0.6964 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 3s - loss: 0.6949 - acc: 0.5000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6976 - acc: 0.4969
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6986 - acc: 0.4978
 576/1283 [============>.................] - ETA: 0s - loss: 0.6973 - acc: 0.5052
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6971 - acc: 0.5057
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6925 - acc: 0.5240
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6924 - acc: 0.5302
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6914 - acc: 0.5377
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6920 - acc: 0.5345
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6924 - acc: 0.5331 - val_loss: 0.6965 - val_acc: 0.5415

Epoch 00001: val_acc improved from -inf to 0.54148, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6507 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6725 - acc: 0.5885
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6708 - acc: 0.5969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6678 - acc: 0.5960
 576/1283 [============>.................] - ETA: 0s - loss: 0.6681 - acc: 0.6024
 640/1283 [=============>................] - ETA: 0s - loss: 0.6671 - acc: 0.6062
 768/1283 [================>.............] - ETA: 0s - loss: 0.6657 - acc: 0.6159
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6659 - acc: 0.6127
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6643 - acc: 0.6123
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6651 - acc: 0.6094
1280/1283 [============================>.] - ETA: 0s - loss: 0.6637 - acc: 0.6109
1283/1283 [==============================] - 1s 611us/step - loss: 0.6637 - acc: 0.6103 - val_loss: 0.6997 - val_acc: 0.5590

Epoch 00002: val_acc improved from 0.54148 to 0.55895, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6573 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6422 - acc: 0.6823
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6432 - acc: 0.6469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6459 - acc: 0.6362
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6459 - acc: 0.6406
 576/1283 [============>.................] - ETA: 0s - loss: 0.6413 - acc: 0.6493
 640/1283 [=============>................] - ETA: 0s - loss: 0.6422 - acc: 0.6391
 768/1283 [================>.............] - ETA: 0s - loss: 0.6400 - acc: 0.6471
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6380 - acc: 0.6526
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6392 - acc: 0.6469
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6372 - acc: 0.6494
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6380 - acc: 0.6461
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6406 - acc: 0.6423
1283/1283 [==============================] - 1s 781us/step - loss: 0.6406 - acc: 0.6422 - val_loss: 0.7086 - val_acc: 0.5502

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6603 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6264 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6282 - acc: 0.6602
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6144 - acc: 0.6849
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6228 - acc: 0.6641
 640/1283 [=============>................] - ETA: 0s - loss: 0.6254 - acc: 0.6516
 768/1283 [================>.............] - ETA: 0s - loss: 0.6272 - acc: 0.6497
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6246 - acc: 0.6484
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6243 - acc: 0.6494
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6233 - acc: 0.6507
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6183 - acc: 0.6620
1280/1283 [============================>.] - ETA: 0s - loss: 0.6179 - acc: 0.6641
1283/1283 [==============================] - 1s 693us/step - loss: 0.6179 - acc: 0.6641 - val_loss: 0.7101 - val_acc: 0.5153

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6064 - acc: 0.6562
 128/1283 [=>............................] - ETA: 0s - loss: 0.6203 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6149 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6073 - acc: 0.6656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6094 - acc: 0.6607
 576/1283 [============>.................] - ETA: 0s - loss: 0.6091 - acc: 0.6632
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6120 - acc: 0.6491
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6077 - acc: 0.6562
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6055 - acc: 0.6629
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6067 - acc: 0.6641
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6069 - acc: 0.6641
1280/1283 [============================>.] - ETA: 0s - loss: 0.6042 - acc: 0.6703
1283/1283 [==============================] - 1s 824us/step - loss: 0.6047 - acc: 0.6695 - val_loss: 0.7207 - val_acc: 0.5284

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6271 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6136 - acc: 0.6510
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5919 - acc: 0.6844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5833 - acc: 0.6853
 576/1283 [============>.................] - ETA: 0s - loss: 0.5825 - acc: 0.6840
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5819 - acc: 0.6960
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5791 - acc: 0.6995
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5800 - acc: 0.6958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5838 - acc: 0.6930
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5818 - acc: 0.6941
1283/1283 [==============================] - 1s 596us/step - loss: 0.5871 - acc: 0.6890 - val_loss: 0.7230 - val_acc: 0.5153

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5503 - acc: 0.7812
 128/1283 [=>............................] - ETA: 0s - loss: 0.5499 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5974 - acc: 0.7070
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5876 - acc: 0.7125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5809 - acc: 0.7165
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5724 - acc: 0.7227
 640/1283 [=============>................] - ETA: 0s - loss: 0.5722 - acc: 0.7234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5727 - acc: 0.7188
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5679 - acc: 0.7296
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5688 - acc: 0.7254
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5718 - acc: 0.7168
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5729 - acc: 0.7170
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5712 - acc: 0.7188
1283/1283 [==============================] - 1s 850us/step - loss: 0.5703 - acc: 0.7178 - val_loss: 0.7263 - val_acc: 0.5502

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4772 - acc: 0.7969
 128/1283 [=>............................] - ETA: 0s - loss: 0.4759 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5111 - acc: 0.7852
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5097 - acc: 0.7875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5164 - acc: 0.7879
 576/1283 [============>.................] - ETA: 0s - loss: 0.5247 - acc: 0.7778
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5325 - acc: 0.7699
 768/1283 [================>.............] - ETA: 0s - loss: 0.5324 - acc: 0.7669
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5281 - acc: 0.7704
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5375 - acc: 0.7573
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5366 - acc: 0.7509
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5366 - acc: 0.7467
1280/1283 [============================>.] - ETA: 0s - loss: 0.5419 - acc: 0.7430
1283/1283 [==============================] - 1s 839us/step - loss: 0.5422 - acc: 0.7428 - val_loss: 0.7364 - val_acc: 0.5459

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5009 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4949 - acc: 0.7292
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5167 - acc: 0.7305
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5342 - acc: 0.7125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5208 - acc: 0.7161
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5266 - acc: 0.7168
 640/1283 [=============>................] - ETA: 0s - loss: 0.5207 - acc: 0.7297
 768/1283 [================>.............] - ETA: 0s - loss: 0.5258 - acc: 0.7383
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5210 - acc: 0.7422
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5200 - acc: 0.7448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5153 - acc: 0.7491
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5196 - acc: 0.7467
1280/1283 [============================>.] - ETA: 0s - loss: 0.5160 - acc: 0.7531
1283/1283 [==============================] - 1s 869us/step - loss: 0.5163 - acc: 0.7529 - val_loss: 0.7499 - val_acc: 0.5590

Epoch 00009: val_acc improved from 0.55895 to 0.55895, saving model to classification_logs//lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_lstm_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5154 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4639 - acc: 0.7917
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5016 - acc: 0.7625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5074 - acc: 0.7630
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4980 - acc: 0.7676
 640/1283 [=============>................] - ETA: 0s - loss: 0.4954 - acc: 0.7750
 768/1283 [================>.............] - ETA: 0s - loss: 0.4939 - acc: 0.7760
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4930 - acc: 0.7752
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4933 - acc: 0.7771
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4930 - acc: 0.7767
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4912 - acc: 0.7755
1283/1283 [==============================] - 1s 791us/step - loss: 0.4901 - acc: 0.7763 - val_loss: 0.7694 - val_acc: 0.5502

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4921 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.4625 - acc: 0.7891
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4508 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4510 - acc: 0.8094
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4502 - acc: 0.8099
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4466 - acc: 0.8125
 576/1283 [============>.................] - ETA: 0s - loss: 0.4536 - acc: 0.8073
 640/1283 [=============>................] - ETA: 0s - loss: 0.4447 - acc: 0.8141
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4366 - acc: 0.8210
 768/1283 [================>.............] - ETA: 0s - loss: 0.4407 - acc: 0.8151
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4402 - acc: 0.8161
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4421 - acc: 0.8136
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4435 - acc: 0.8125
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4496 - acc: 0.8076
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4507 - acc: 0.8051
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4496 - acc: 0.8073
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4540 - acc: 0.8035
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4551 - acc: 0.8020 - val_loss: 0.8154 - val_acc: 0.5284

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3833 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.3983 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3998 - acc: 0.8646
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4091 - acc: 0.8555
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4185 - acc: 0.8344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3999 - acc: 0.8571
 576/1283 [============>.................] - ETA: 0s - loss: 0.4091 - acc: 0.8455
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4052 - acc: 0.8438
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4111 - acc: 0.8353
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4148 - acc: 0.8302
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4141 - acc: 0.8290
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4099 - acc: 0.8322
1283/1283 [==============================] - 1s 911us/step - loss: 0.4105 - acc: 0.8309 - val_loss: 0.8171 - val_acc: 0.5459

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4479 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3852 - acc: 0.8229
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4011 - acc: 0.8219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3949 - acc: 0.8229
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3954 - acc: 0.8304
 576/1283 [============>.................] - ETA: 0s - loss: 0.3838 - acc: 0.8472
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3840 - acc: 0.8409
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3822 - acc: 0.8389
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3750 - acc: 0.8427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3800 - acc: 0.8418
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3814 - acc: 0.8420
1280/1283 [============================>.] - ETA: 0s - loss: 0.3806 - acc: 0.8422
1283/1283 [==============================] - 1s 788us/step - loss: 0.3807 - acc: 0.8426 - val_loss: 0.8666 - val_acc: 0.5066

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3284 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3091 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3055 - acc: 0.8781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3258 - acc: 0.8661
 576/1283 [============>.................] - ETA: 0s - loss: 0.3296 - acc: 0.8611
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3417 - acc: 0.8565
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3381 - acc: 0.8594
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3432 - acc: 0.8573
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3417 - acc: 0.8557
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3424 - acc: 0.8561
1283/1283 [==============================] - 1s 810us/step - loss: 0.3425 - acc: 0.8574 - val_loss: 0.9340 - val_acc: 0.5066

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3064 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3069 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2882 - acc: 0.9156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3084 - acc: 0.8951
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3152 - acc: 0.8906
 576/1283 [============>.................] - ETA: 0s - loss: 0.3179 - acc: 0.8872
 640/1283 [=============>................] - ETA: 0s - loss: 0.3319 - acc: 0.8797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3452 - acc: 0.8764
 768/1283 [================>.............] - ETA: 0s - loss: 0.3560 - acc: 0.8672
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3560 - acc: 0.8666
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3580 - acc: 0.8635
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3598 - acc: 0.8633
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3558 - acc: 0.8646
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3533 - acc: 0.8651
1280/1283 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.8617
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3597 - acc: 0.8605 - val_loss: 0.9100 - val_acc: 0.5109

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3155 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.3025 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2899 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3035 - acc: 0.8984
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3179 - acc: 0.8781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3141 - acc: 0.8828
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3135 - acc: 0.8809
 640/1283 [=============>................] - ETA: 0s - loss: 0.3314 - acc: 0.8594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3352 - acc: 0.8551
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3306 - acc: 0.8642
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3284 - acc: 0.8672
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3284 - acc: 0.8656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3253 - acc: 0.8691
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3248 - acc: 0.8704
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3246 - acc: 0.8733
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3244 - acc: 0.8742
1280/1283 [============================>.] - ETA: 0s - loss: 0.3236 - acc: 0.8750
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3231 - acc: 0.8753 - val_loss: 0.8651 - val_acc: 0.5240

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3569 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.3392 - acc: 0.8672
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3188 - acc: 0.8633
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3076 - acc: 0.8781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2915 - acc: 0.8839
 576/1283 [============>.................] - ETA: 0s - loss: 0.2843 - acc: 0.8889
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2815 - acc: 0.8920
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2742 - acc: 0.8990
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2750 - acc: 0.8969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2729 - acc: 0.8998
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2769 - acc: 0.8958
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2784 - acc: 0.8939
1283/1283 [==============================] - 1s 902us/step - loss: 0.2874 - acc: 0.8893 - val_loss: 0.9545 - val_acc: 0.5284

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2489 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.2463 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2563 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2379 - acc: 0.9313
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2498 - acc: 0.9174
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2445 - acc: 0.9238
 576/1283 [============>.................] - ETA: 0s - loss: 0.2435 - acc: 0.9219
 640/1283 [=============>................] - ETA: 0s - loss: 0.2502 - acc: 0.9141
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2444 - acc: 0.9190
 768/1283 [================>.............] - ETA: 0s - loss: 0.2400 - acc: 0.9219
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2395 - acc: 0.9207
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2400 - acc: 0.9185
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2403 - acc: 0.9167
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2468 - acc: 0.9141
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2495 - acc: 0.9145
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2499 - acc: 0.9137
1280/1283 [============================>.] - ETA: 0s - loss: 0.2459 - acc: 0.9156
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2458 - acc: 0.9158 - val_loss: 1.0091 - val_acc: 0.5371

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1531 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1677 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1673 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1811 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1840 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1899 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1879 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1953 - acc: 0.9492
 640/1283 [=============>................] - ETA: 0s - loss: 0.2005 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2025 - acc: 0.9418
 768/1283 [================>.............] - ETA: 0s - loss: 0.2016 - acc: 0.9414
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2039 - acc: 0.9411
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2056 - acc: 0.9420
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2033 - acc: 0.9427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1998 - acc: 0.9453
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1994 - acc: 0.9449
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2025 - acc: 0.9427
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2057 - acc: 0.9416
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2068 - acc: 0.9400 - val_loss: 1.1327 - val_acc: 0.5240

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
nodes=100
mode=A
PCA audio=30
PCA visual=30
PCA text=100
accuracy=0.5043731778425656
best_valid_accuracy=0.5116618075801749
