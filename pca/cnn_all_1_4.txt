/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 13:01:23.736440: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.7807 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 1s - loss: 0.8035 - acc: 0.5990
 256/1283 [====>.........................] - ETA: 1s - loss: 0.8104 - acc: 0.6055
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7890 - acc: 0.6000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7792 - acc: 0.5964
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7695 - acc: 0.6027
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7499 - acc: 0.6094
 576/1283 [============>.................] - ETA: 0s - loss: 0.7456 - acc: 0.6181
 640/1283 [=============>................] - ETA: 0s - loss: 0.7264 - acc: 0.6312
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7355 - acc: 0.6250
 768/1283 [================>.............] - ETA: 0s - loss: 0.7407 - acc: 0.6172
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7421 - acc: 0.6118
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7432 - acc: 0.6027
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7411 - acc: 0.5977
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7368 - acc: 0.6020
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7299 - acc: 0.6050
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7282 - acc: 0.6044
1280/1283 [============================>.] - ETA: 0s - loss: 0.7220 - acc: 0.6086
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7222 - acc: 0.6080 - val_loss: 0.7030 - val_acc: 0.5590

Epoch 00001: val_acc improved from -inf to 0.55895, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4769 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.4112 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4482 - acc: 0.8229
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4478 - acc: 0.7969
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4296 - acc: 0.8187
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4336 - acc: 0.8125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4364 - acc: 0.8125
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4296 - acc: 0.8242
 576/1283 [============>.................] - ETA: 0s - loss: 0.4286 - acc: 0.8194
 640/1283 [=============>................] - ETA: 0s - loss: 0.4214 - acc: 0.8266
 768/1283 [================>.............] - ETA: 0s - loss: 0.4156 - acc: 0.8320
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4059 - acc: 0.8426
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3982 - acc: 0.8479
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3954 - acc: 0.8467
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3956 - acc: 0.8456
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3980 - acc: 0.8403
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3919 - acc: 0.8438
1280/1283 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8453
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3893 - acc: 0.8449 - val_loss: 0.8331 - val_acc: 0.5764

Epoch 00002: val_acc improved from 0.55895 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3172 - acc: 0.8594
 128/1283 [=>............................] - ETA: 0s - loss: 0.3587 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3573 - acc: 0.8021
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3357 - acc: 0.8242
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3134 - acc: 0.8469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3065 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3112 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3047 - acc: 0.8672
 640/1283 [=============>................] - ETA: 0s - loss: 0.2959 - acc: 0.8734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2912 - acc: 0.8764
 768/1283 [================>.............] - ETA: 0s - loss: 0.2876 - acc: 0.8815
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2794 - acc: 0.8817
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2667 - acc: 0.8906
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2595 - acc: 0.8932
1280/1283 [============================>.] - ETA: 0s - loss: 0.2537 - acc: 0.8977
1283/1283 [==============================] - 1s 908us/step - loss: 0.2535 - acc: 0.8979 - val_loss: 0.8477 - val_acc: 0.6201

Epoch 00003: val_acc improved from 0.57642 to 0.62009, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1583 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.1749 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1561 - acc: 0.9492
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1453 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1408 - acc: 0.9621
 576/1283 [============>.................] - ETA: 0s - loss: 0.1314 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1308 - acc: 0.9659
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1253 - acc: 0.9675
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1214 - acc: 0.9698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1244 - acc: 0.9669
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1226 - acc: 0.9663
1283/1283 [==============================] - 1s 778us/step - loss: 0.1212 - acc: 0.9665 - val_loss: 0.9137 - val_acc: 0.6507

Epoch 00004: val_acc improved from 0.62009 to 0.65066, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0770 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0784 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0686 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0663 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0637 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0630 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0608 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0592 - acc: 0.9979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0593 - acc: 0.9963
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0583 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0575 - acc: 0.9967
1283/1283 [==============================] - 1s 803us/step - loss: 0.0584 - acc: 0.9953 - val_loss: 1.0160 - val_acc: 0.6419

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0322 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0314 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0310 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0309 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0320 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0310 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0306 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0300 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0292 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0294 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0293 - acc: 0.9982
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0289 - acc: 0.9984
1283/1283 [==============================] - 1s 779us/step - loss: 0.0281 - acc: 0.9984 - val_loss: 1.1520 - val_acc: 0.6376

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0139 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0177 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0176 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0179 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0180 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0179 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0169 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0174 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0170 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0163 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 1.0000
1283/1283 [==============================] - 1s 777us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 1.2197 - val_acc: 0.6245

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0069 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0097 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0113 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0108 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0108 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0108 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0101 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0104 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0103 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0101 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0101 - acc: 1.0000
1283/1283 [==============================] - 1s 816us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 1.2198 - val_acc: 0.6288

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0064 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0067 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0065 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0064 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0064 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0063 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 1.0000
1283/1283 [==============================] - 1s 777us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.3050 - val_acc: 0.6419

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0037 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0048 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0087 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0097 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0088 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0085 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0079 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0076 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0075 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0074 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0073 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 1.0000
1283/1283 [==============================] - 1s 677us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 1.3125 - val_acc: 0.6201

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0044 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0041 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0040 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0039 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0040 - acc: 1.0000
1283/1283 [==============================] - 1s 595us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.3901 - val_acc: 0.6288

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0024 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0022 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0025 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0025 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0026 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0026 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0025 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0026 - acc: 1.0000
1283/1283 [==============================] - 1s 539us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.4254 - val_acc: 0.6376

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0022 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0019 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0021 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0019 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0020 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0020 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0019 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 1.0000
1283/1283 [==============================] - 1s 501us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.4574 - val_acc: 0.6245

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0010 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0019 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0019 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0017 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0016 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0016 - acc: 1.0000
1283/1283 [==============================] - 1s 547us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.4914 - val_acc: 0.6245

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=30
nodes=100
mode=all
PCA audio=35
PCA visual=45
PCA text=130
accuracy=0.6545189504373178
best_valid_accuracy=0.641399416909621
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 13:56:57.108370: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 29s - loss: 0.7807 - acc: 0.5469
 128/1283 [=>............................] - ETA: 15s - loss: 0.7925 - acc: 0.6016
 192/1283 [===>..........................] - ETA: 10s - loss: 0.8035 - acc: 0.5990
 256/1283 [====>.........................] - ETA: 8s - loss: 0.8104 - acc: 0.6055 
 320/1283 [======>.......................] - ETA: 6s - loss: 0.7890 - acc: 0.6000
 384/1283 [=======>......................] - ETA: 5s - loss: 0.7792 - acc: 0.5964
 448/1283 [=========>....................] - ETA: 5s - loss: 0.7695 - acc: 0.6027
 512/1283 [==========>...................] - ETA: 4s - loss: 0.7499 - acc: 0.6094
 576/1283 [============>.................] - ETA: 3s - loss: 0.7456 - acc: 0.6181
 640/1283 [=============>................] - ETA: 3s - loss: 0.7264 - acc: 0.6312
 704/1283 [===============>..............] - ETA: 2s - loss: 0.7355 - acc: 0.6250
 768/1283 [================>.............] - ETA: 2s - loss: 0.7407 - acc: 0.6172
 832/1283 [==================>...........] - ETA: 2s - loss: 0.7421 - acc: 0.6118
 896/1283 [===================>..........] - ETA: 1s - loss: 0.7432 - acc: 0.6027
 960/1283 [=====================>........] - ETA: 1s - loss: 0.7432 - acc: 0.6010
1024/1283 [======================>.......] - ETA: 1s - loss: 0.7411 - acc: 0.5967
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7368 - acc: 0.6011
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7299 - acc: 0.6042
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7282 - acc: 0.6036
1280/1283 [============================>.] - ETA: 0s - loss: 0.7220 - acc: 0.6078
1283/1283 [==============================] - 6s 5ms/step - loss: 0.7222 - acc: 0.6072 - val_loss: 0.7030 - val_acc: 0.5590

Epoch 00001: val_loss improved from inf to 0.70297, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4770 - acc: 0.8594
 128/1283 [=>............................] - ETA: 2s - loss: 0.4111 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 2s - loss: 0.4480 - acc: 0.8229
 256/1283 [====>.........................] - ETA: 2s - loss: 0.4470 - acc: 0.8008
 320/1283 [======>.......................] - ETA: 2s - loss: 0.4292 - acc: 0.8219
 384/1283 [=======>......................] - ETA: 2s - loss: 0.4333 - acc: 0.8099
 448/1283 [=========>....................] - ETA: 2s - loss: 0.4358 - acc: 0.8103
 512/1283 [==========>...................] - ETA: 2s - loss: 0.4288 - acc: 0.8203
 576/1283 [============>.................] - ETA: 2s - loss: 0.4278 - acc: 0.8160
 640/1283 [=============>................] - ETA: 2s - loss: 0.4205 - acc: 0.8234
 704/1283 [===============>..............] - ETA: 2s - loss: 0.4196 - acc: 0.8224
 768/1283 [================>.............] - ETA: 1s - loss: 0.4144 - acc: 0.8307
 832/1283 [==================>...........] - ETA: 1s - loss: 0.4117 - acc: 0.8353
 896/1283 [===================>..........] - ETA: 1s - loss: 0.4049 - acc: 0.8415
 960/1283 [=====================>........] - ETA: 1s - loss: 0.3972 - acc: 0.8479
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3942 - acc: 0.8477
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3943 - acc: 0.8465
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3968 - acc: 0.8411
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3906 - acc: 0.8446
1280/1283 [============================>.] - ETA: 0s - loss: 0.3880 - acc: 0.8461
1283/1283 [==============================] - 5s 4ms/step - loss: 0.3880 - acc: 0.8457 - val_loss: 0.8374 - val_acc: 0.5808

Epoch 00002: val_loss did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.3182 - acc: 0.8594
 128/1283 [=>............................] - ETA: 3s - loss: 0.3604 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 3s - loss: 0.3585 - acc: 0.8021
 256/1283 [====>.........................] - ETA: 3s - loss: 0.3365 - acc: 0.8203
 320/1283 [======>.......................] - ETA: 3s - loss: 0.3137 - acc: 0.8438
 384/1283 [=======>......................] - ETA: 2s - loss: 0.3064 - acc: 0.8568
 448/1283 [=========>....................] - ETA: 2s - loss: 0.3110 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 2s - loss: 0.3043 - acc: 0.8691
 576/1283 [============>.................] - ETA: 2s - loss: 0.3003 - acc: 0.8698
 640/1283 [=============>................] - ETA: 2s - loss: 0.2947 - acc: 0.8750
 704/1283 [===============>..............] - ETA: 2s - loss: 0.2900 - acc: 0.8778
 768/1283 [================>.............] - ETA: 1s - loss: 0.2867 - acc: 0.8828
 832/1283 [==================>...........] - ETA: 1s - loss: 0.2842 - acc: 0.8834
 896/1283 [===================>..........] - ETA: 1s - loss: 0.2781 - acc: 0.8850
 960/1283 [=====================>........] - ETA: 1s - loss: 0.2717 - acc: 0.8896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2656 - acc: 0.8926
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2603 - acc: 0.8943
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2585 - acc: 0.8950
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2570 - acc: 0.8956
1280/1283 [============================>.] - ETA: 0s - loss: 0.2523 - acc: 0.8992
1283/1283 [==============================] - 5s 4ms/step - loss: 0.2521 - acc: 0.8995 - val_loss: 0.8465 - val_acc: 0.6288

Epoch 00003: val_loss did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.1557 - acc: 0.9844
 128/1283 [=>............................] - ETA: 4s - loss: 0.1717 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 3s - loss: 0.1491 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 3s - loss: 0.1541 - acc: 0.9492
 320/1283 [======>.......................] - ETA: 3s - loss: 0.1399 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 2s - loss: 0.1429 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 2s - loss: 0.1386 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 2s - loss: 0.1326 - acc: 0.9648
 576/1283 [============>.................] - ETA: 2s - loss: 0.1305 - acc: 0.9688
 640/1283 [=============>................] - ETA: 1s - loss: 0.1303 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1301 - acc: 0.9673
 768/1283 [================>.............] - ETA: 1s - loss: 0.1265 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 1s - loss: 0.1252 - acc: 0.9688
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1230 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1214 - acc: 0.9708
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1220 - acc: 0.9697
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1244 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1225 - acc: 0.9679
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1228 - acc: 0.9671
1280/1283 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9672
1283/1283 [==============================] - 4s 3ms/step - loss: 0.1216 - acc: 0.9673 - val_loss: 0.9071 - val_acc: 0.6507

Epoch 00004: val_loss did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.0785 - acc: 1.0000
 128/1283 [=>............................] - ETA: 4s - loss: 0.0884 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 3s - loss: 0.0807 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 3s - loss: 0.0743 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 3s - loss: 0.0705 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 3s - loss: 0.0694 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 3s - loss: 0.0677 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 2s - loss: 0.0671 - acc: 0.9961
 576/1283 [============>.................] - ETA: 2s - loss: 0.0653 - acc: 0.9965
 640/1283 [=============>................] - ETA: 2s - loss: 0.0647 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 2s - loss: 0.0647 - acc: 0.9972
 768/1283 [================>.............] - ETA: 1s - loss: 0.0625 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 1s - loss: 0.0626 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 1s - loss: 0.0617 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 1s - loss: 0.0609 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0604 - acc: 0.9961
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0610 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0600 - acc: 0.9957
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0590 - acc: 0.9959
1280/1283 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9945
1283/1283 [==============================] - 4s 3ms/step - loss: 0.0600 - acc: 0.9945 - val_loss: 1.0056 - val_acc: 0.6332

Epoch 00005: val_loss did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.0329 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0359 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0322 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0345 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 2s - loss: 0.0320 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 2s - loss: 0.0326 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 2s - loss: 0.0317 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0328 - acc: 0.9980
 576/1283 [============>.................] - ETA: 1s - loss: 0.0323 - acc: 0.9983
 640/1283 [=============>................] - ETA: 1s - loss: 0.0319 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0315 - acc: 0.9986
 768/1283 [================>.............] - ETA: 1s - loss: 0.0316 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 1s - loss: 0.0309 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 1s - loss: 0.0299 - acc: 0.9978
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0299 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0301 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0300 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0300 - acc: 0.9983
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0295 - acc: 0.9984
1280/1283 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9984
1283/1283 [==============================] - 4s 3ms/step - loss: 0.0287 - acc: 0.9984 - val_loss: 1.1560 - val_acc: 0.6376

Epoch 00006: val_loss did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0134 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0135 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0176 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0168 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0177 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0189 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0180 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0187 - acc: 1.0000
 576/1283 [============>.................] - ETA: 1s - loss: 0.0182 - acc: 1.0000
 640/1283 [=============>................] - ETA: 1s - loss: 0.0183 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0181 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0178 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0170 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0175 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0176 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0171 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0170 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0164 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0163 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 1.0000
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 1.2151 - val_acc: 0.6288

Epoch 00007: val_loss did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0068 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0088 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0101 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0115 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0115 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0110 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0107 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0110 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0109 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0110 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0103 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0102 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0104 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0102 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0103 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0102 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 1.0000
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.2224 - val_acc: 0.6332

Epoch 00008: val_loss did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0042 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0051 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0055 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0056 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0060 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0059 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0063 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0066 - acc: 1.0000
 576/1283 [============>.................] - ETA: 1s - loss: 0.0065 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0067 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0068 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0067 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0065 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0064 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0065 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0065 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0064 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0062 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 1.0000
1283/1283 [==============================] - 2s 2ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.3038 - val_acc: 0.6376

Epoch 00009: val_loss did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0038 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0052 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0093 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0098 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0101 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0106 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0097 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0094 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0090 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0087 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0084 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0084 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0081 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0080 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0079 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0079 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0077 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0075 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0074 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 1.0000
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.3153 - val_acc: 0.6332

Epoch 00010: val_loss did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0037 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0047 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0046 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0043 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0041 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0040 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0039 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0041 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0041 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0040 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0041 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0041 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 1.0000
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.3909 - val_acc: 0.6376

Epoch 00011: val_loss did not improve
Epoch 00011: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=30
nodes=100
mode=all
PCA audio=35
PCA visual=45
PCA text=130
accuracy=0.6501457725947521
best_valid_accuracy=0.597667638483965
