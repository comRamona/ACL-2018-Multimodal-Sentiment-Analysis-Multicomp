/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:48:16.730424: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 14s - loss: 0.6957 - acc: 0.5312
 128/1283 [=>............................] - ETA: 7s - loss: 0.6993 - acc: 0.5156 
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7017 - acc: 0.5365
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6929 - acc: 0.5586
 320/1283 [======>.......................] - ETA: 3s - loss: 0.6894 - acc: 0.5719
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6897 - acc: 0.5677
 512/1283 [==========>...................] - ETA: 2s - loss: 0.6989 - acc: 0.5605
 576/1283 [============>.................] - ETA: 1s - loss: 0.7008 - acc: 0.5625
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7028 - acc: 0.5526
 768/1283 [================>.............] - ETA: 1s - loss: 0.7051 - acc: 0.5482
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7014 - acc: 0.5491
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7024 - acc: 0.5420
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6997 - acc: 0.5434
1280/1283 [============================>.] - ETA: 0s - loss: 0.6985 - acc: 0.5437
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6983 - acc: 0.5448 - val_loss: 0.6906 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6547 - acc: 0.5781
 128/1283 [=>............................] - ETA: 1s - loss: 0.6468 - acc: 0.6172
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6445 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6461 - acc: 0.6276
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6519 - acc: 0.6191
 576/1283 [============>.................] - ETA: 0s - loss: 0.6501 - acc: 0.6319
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6519 - acc: 0.6293
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6486 - acc: 0.6339
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6506 - acc: 0.6270
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6486 - acc: 0.6293
1280/1283 [============================>.] - ETA: 0s - loss: 0.6496 - acc: 0.6258
1283/1283 [==============================] - 1s 935us/step - loss: 0.6500 - acc: 0.6243 - val_loss: 0.7148 - val_acc: 0.5415

Epoch 00002: val_acc improved from 0.52838 to 0.54148, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.7055 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6700 - acc: 0.5781
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6369 - acc: 0.6188
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6356 - acc: 0.6138
 576/1283 [============>.................] - ETA: 0s - loss: 0.6310 - acc: 0.6337
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6227 - acc: 0.6491
 768/1283 [================>.............] - ETA: 0s - loss: 0.6239 - acc: 0.6484
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6242 - acc: 0.6454
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6234 - acc: 0.6500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6242 - acc: 0.6507
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6247 - acc: 0.6488
1283/1283 [==============================] - 1s 744us/step - loss: 0.6201 - acc: 0.6586 - val_loss: 0.7114 - val_acc: 0.5633

Epoch 00003: val_acc improved from 0.54148 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5647 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6105 - acc: 0.6523
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6236 - acc: 0.6250
 576/1283 [============>.................] - ETA: 0s - loss: 0.6259 - acc: 0.6233
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6263 - acc: 0.6236
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6197 - acc: 0.6382
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6191 - acc: 0.6406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6162 - acc: 0.6445
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6116 - acc: 0.6489
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6102 - acc: 0.6528
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6103 - acc: 0.6554
1280/1283 [============================>.] - ETA: 0s - loss: 0.6092 - acc: 0.6555
1283/1283 [==============================] - 1s 861us/step - loss: 0.6094 - acc: 0.6547 - val_loss: 0.6980 - val_acc: 0.5590

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4953 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5781 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6141 - acc: 0.6250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5932 - acc: 0.6629
 576/1283 [============>.................] - ETA: 0s - loss: 0.5883 - acc: 0.6615
 640/1283 [=============>................] - ETA: 0s - loss: 0.5848 - acc: 0.6687
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5830 - acc: 0.6733
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5780 - acc: 0.6803
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5744 - acc: 0.6875
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5697 - acc: 0.6976
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5682 - acc: 0.6998
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5669 - acc: 0.7023 - val_loss: 0.6741 - val_acc: 0.6332

Epoch 00005: val_acc improved from 0.56332 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4763 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4949 - acc: 0.8073
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4857 - acc: 0.8164
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5066 - acc: 0.7875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5084 - acc: 0.7768
 576/1283 [============>.................] - ETA: 0s - loss: 0.5109 - acc: 0.7743
 640/1283 [=============>................] - ETA: 0s - loss: 0.5033 - acc: 0.7812
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5010 - acc: 0.7784
 768/1283 [================>.............] - ETA: 0s - loss: 0.4952 - acc: 0.7826
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4947 - acc: 0.7800
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4979 - acc: 0.7757
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5050 - acc: 0.7666
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5076 - acc: 0.7578
1280/1283 [============================>.] - ETA: 0s - loss: 0.5124 - acc: 0.7492
1283/1283 [==============================] - 1s 959us/step - loss: 0.5123 - acc: 0.7498 - val_loss: 0.7968 - val_acc: 0.5939

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5704 - acc: 0.6719
 128/1283 [=>............................] - ETA: 0s - loss: 0.5771 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5682 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6360 - acc: 0.6523
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6221 - acc: 0.6531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5805 - acc: 0.6875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5765 - acc: 0.6895
 576/1283 [============>.................] - ETA: 0s - loss: 0.5711 - acc: 0.6910
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5701 - acc: 0.6932
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5588 - acc: 0.7055
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5552 - acc: 0.7087
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5484 - acc: 0.7109
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5460 - acc: 0.7105
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5457 - acc: 0.7092
1280/1283 [============================>.] - ETA: 0s - loss: 0.5463 - acc: 0.7086
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5463 - acc: 0.7093 - val_loss: 0.7435 - val_acc: 0.5721

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5084 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5521 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5772 - acc: 0.6667
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5788 - acc: 0.6523
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5728 - acc: 0.6625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5655 - acc: 0.6667
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5612 - acc: 0.6763
 576/1283 [============>.................] - ETA: 1s - loss: 0.5418 - acc: 0.7066
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5333 - acc: 0.7188
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5345 - acc: 0.7151
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5283 - acc: 0.7178
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5216 - acc: 0.7222
1280/1283 [============================>.] - ETA: 0s - loss: 0.5173 - acc: 0.7273
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5174 - acc: 0.7272 - val_loss: 0.7096 - val_acc: 0.5764

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4138 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4348 - acc: 0.7969
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4252 - acc: 0.8063
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4264 - acc: 0.8058
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4304 - acc: 0.8027
 576/1283 [============>.................] - ETA: 0s - loss: 0.4338 - acc: 0.7986
 640/1283 [=============>................] - ETA: 0s - loss: 0.4328 - acc: 0.7984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4296 - acc: 0.7997
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4337 - acc: 0.7957
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4340 - acc: 0.7948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4291 - acc: 0.7996
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4275 - acc: 0.7985
1280/1283 [============================>.] - ETA: 0s - loss: 0.4313 - acc: 0.7945
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4315 - acc: 0.7942 - val_loss: 0.7112 - val_acc: 0.5939

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3846 - acc: 0.8438
 128/1283 [=>............................] - ETA: 0s - loss: 0.3840 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3872 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3774 - acc: 0.8344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3842 - acc: 0.8281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3823 - acc: 0.8304
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3813 - acc: 0.8301
 576/1283 [============>.................] - ETA: 1s - loss: 0.3759 - acc: 0.8316
 640/1283 [=============>................] - ETA: 0s - loss: 0.3773 - acc: 0.8281
 768/1283 [================>.............] - ETA: 0s - loss: 0.3807 - acc: 0.8255
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3856 - acc: 0.8233
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3855 - acc: 0.8259
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3812 - acc: 0.8281
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3831 - acc: 0.8235
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3802 - acc: 0.8264
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3781 - acc: 0.8298
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3765 - acc: 0.8324 - val_loss: 0.7708 - val_acc: 0.5983

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3686 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3461 - acc: 0.8542
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3169 - acc: 0.8688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3289 - acc: 0.8568
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3205 - acc: 0.8616
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3338 - acc: 0.8496
 576/1283 [============>.................] - ETA: 0s - loss: 0.3296 - acc: 0.8524
 640/1283 [=============>................] - ETA: 0s - loss: 0.3270 - acc: 0.8500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3214 - acc: 0.8565
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3204 - acc: 0.8630
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3189 - acc: 0.8646
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3275 - acc: 0.8603
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3271 - acc: 0.8585
1280/1283 [============================>.] - ETA: 0s - loss: 0.3242 - acc: 0.8625
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3242 - acc: 0.8620 - val_loss: 0.8346 - val_acc: 0.5677

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2566 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.3011 - acc: 0.8828
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3340 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3204 - acc: 0.8656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3194 - acc: 0.8616
 576/1283 [============>.................] - ETA: 0s - loss: 0.3244 - acc: 0.8611
 640/1283 [=============>................] - ETA: 0s - loss: 0.3212 - acc: 0.8609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3180 - acc: 0.8622
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3127 - acc: 0.8678
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3207 - acc: 0.8571
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3214 - acc: 0.8604
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3224 - acc: 0.8594
1280/1283 [============================>.] - ETA: 0s - loss: 0.3205 - acc: 0.8609
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3213 - acc: 0.8597 - val_loss: 0.8875 - val_acc: 0.5983

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2764 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.2943 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3230 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3247 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3272 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3245 - acc: 0.8616
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3241 - acc: 0.8613
 640/1283 [=============>................] - ETA: 0s - loss: 0.3319 - acc: 0.8547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3286 - acc: 0.8551
 768/1283 [================>.............] - ETA: 0s - loss: 0.3198 - acc: 0.8581
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3273 - acc: 0.8558
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3271 - acc: 0.8549
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3289 - acc: 0.8531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3322 - acc: 0.8496
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3322 - acc: 0.8520
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3315 - acc: 0.8495
1280/1283 [============================>.] - ETA: 0s - loss: 0.3287 - acc: 0.8523
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3283 - acc: 0.8527 - val_loss: 0.9527 - val_acc: 0.5852

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.2351 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2640 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2612 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2696 - acc: 0.9062
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2609 - acc: 0.9141
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2565 - acc: 0.9174
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2573 - acc: 0.9199
 576/1283 [============>.................] - ETA: 1s - loss: 0.2618 - acc: 0.9132
 640/1283 [=============>................] - ETA: 0s - loss: 0.2601 - acc: 0.9109
 768/1283 [================>.............] - ETA: 0s - loss: 0.2646 - acc: 0.9049
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2626 - acc: 0.9038
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2640 - acc: 0.9007
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2650 - acc: 0.8979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2619 - acc: 0.8984
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2648 - acc: 0.8943
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2695 - acc: 0.8906
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2731 - acc: 0.8882
1280/1283 [============================>.] - ETA: 0s - loss: 0.2750 - acc: 0.8867
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2744 - acc: 0.8870 - val_loss: 0.9338 - val_acc: 0.6026

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2284 - acc: 0.9219
 128/1283 [=>............................] - ETA: 3s - loss: 0.2189 - acc: 0.9297
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2381 - acc: 0.9023
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2264 - acc: 0.9089
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2196 - acc: 0.9152
 576/1283 [============>.................] - ETA: 0s - loss: 0.2186 - acc: 0.9167
 640/1283 [=============>................] - ETA: 0s - loss: 0.2245 - acc: 0.9125
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2195 - acc: 0.9176
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2239 - acc: 0.9159
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2308 - acc: 0.9107
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2286 - acc: 0.9125
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2264 - acc: 0.9173
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2264 - acc: 0.9175
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2271 - acc: 0.9153
1280/1283 [============================>.] - ETA: 0s - loss: 0.2252 - acc: 0.9180
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2252 - acc: 0.9182 - val_loss: 1.0453 - val_acc: 0.5546

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5306122448979592
best_valid_accuracy=0.5145772594752187
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:56:08.111878: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.7099 - acc: 0.4062
 128/1283 [=>............................] - ETA: 4s - loss: 0.7579 - acc: 0.4766
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7371 - acc: 0.4883
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7295 - acc: 0.5078
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7202 - acc: 0.5215
 640/1283 [=============>................] - ETA: 0s - loss: 0.7170 - acc: 0.5328
 768/1283 [================>.............] - ETA: 0s - loss: 0.7190 - acc: 0.5208
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7145 - acc: 0.5234
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7125 - acc: 0.5281
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7120 - acc: 0.5264
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7107 - acc: 0.5276
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7095 - acc: 0.5304
1280/1283 [============================>.] - ETA: 0s - loss: 0.7077 - acc: 0.5375
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7078 - acc: 0.5370 - val_loss: 0.6865 - val_acc: 0.5808

Epoch 00001: val_acc improved from -inf to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.6286 - acc: 0.7188
 128/1283 [=>............................] - ETA: 1s - loss: 0.6427 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6447 - acc: 0.6719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6438 - acc: 0.6473
 576/1283 [============>.................] - ETA: 0s - loss: 0.6465 - acc: 0.6476
 640/1283 [=============>................] - ETA: 0s - loss: 0.6490 - acc: 0.6375
 768/1283 [================>.............] - ETA: 0s - loss: 0.6468 - acc: 0.6445
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6481 - acc: 0.6451
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6483 - acc: 0.6387
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6454 - acc: 0.6372
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6463 - acc: 0.6316
1283/1283 [==============================] - 1s 815us/step - loss: 0.6468 - acc: 0.6321 - val_loss: 0.7010 - val_acc: 0.5284

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6033 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6159 - acc: 0.6758
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6074 - acc: 0.6927
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6084 - acc: 0.6964
 576/1283 [============>.................] - ETA: 0s - loss: 0.6013 - acc: 0.7049
 640/1283 [=============>................] - ETA: 0s - loss: 0.6024 - acc: 0.7031
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5999 - acc: 0.7045
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6027 - acc: 0.6995
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6026 - acc: 0.6975
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6004 - acc: 0.6982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5970 - acc: 0.7005
1280/1283 [============================>.] - ETA: 0s - loss: 0.5991 - acc: 0.6945
1283/1283 [==============================] - 1s 785us/step - loss: 0.5991 - acc: 0.6945 - val_loss: 0.6927 - val_acc: 0.5764

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5644 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5459 - acc: 0.7708
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5470 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5547 - acc: 0.7500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5510 - acc: 0.7441
 640/1283 [=============>................] - ETA: 0s - loss: 0.5503 - acc: 0.7469
 768/1283 [================>.............] - ETA: 0s - loss: 0.5500 - acc: 0.7448
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5528 - acc: 0.7455
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5536 - acc: 0.7383
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5541 - acc: 0.7370
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5567 - acc: 0.7311
1283/1283 [==============================] - 1s 917us/step - loss: 0.5571 - acc: 0.7311 - val_loss: 0.7324 - val_acc: 0.5721

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5916 - acc: 0.6406
 128/1283 [=>............................] - ETA: 0s - loss: 0.5473 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5367 - acc: 0.6979
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5338 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5353 - acc: 0.7031
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5266 - acc: 0.7143
 576/1283 [============>.................] - ETA: 0s - loss: 0.5243 - acc: 0.7240
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5254 - acc: 0.7244
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5213 - acc: 0.7308
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5223 - acc: 0.7271
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5235 - acc: 0.7270
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5275 - acc: 0.7286
1283/1283 [==============================] - 1s 876us/step - loss: 0.5256 - acc: 0.7319 - val_loss: 0.7037 - val_acc: 0.5939

Epoch 00005: val_acc improved from 0.58079 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4117 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4494 - acc: 0.8177
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4761 - acc: 0.7930
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4639 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4611 - acc: 0.8047
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4537 - acc: 0.8008
 576/1283 [============>.................] - ETA: 0s - loss: 0.4543 - acc: 0.7969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4585 - acc: 0.7955
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4489 - acc: 0.8053
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4507 - acc: 0.8010
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4521 - acc: 0.7979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4537 - acc: 0.7969
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4534 - acc: 0.7995
1280/1283 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.7937
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4557 - acc: 0.7942 - val_loss: 0.7527 - val_acc: 0.5764

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4433 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4555 - acc: 0.7734
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4516 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4376 - acc: 0.8047
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4314 - acc: 0.8156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4251 - acc: 0.8229
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4263 - acc: 0.8192
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4211 - acc: 0.8184
 640/1283 [=============>................] - ETA: 0s - loss: 0.4157 - acc: 0.8187
 768/1283 [================>.............] - ETA: 0s - loss: 0.4126 - acc: 0.8203
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4157 - acc: 0.8173
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4163 - acc: 0.8136
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4147 - acc: 0.8153
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4093 - acc: 0.8174
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4088 - acc: 0.8168 - val_loss: 0.8009 - val_acc: 0.5721

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3965 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3444 - acc: 0.8802
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3399 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3623 - acc: 0.8460
 576/1283 [============>.................] - ETA: 0s - loss: 0.3570 - acc: 0.8490
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3550 - acc: 0.8466
 768/1283 [================>.............] - ETA: 0s - loss: 0.3507 - acc: 0.8516
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3467 - acc: 0.8594
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3475 - acc: 0.8571
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3522 - acc: 0.8525
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3493 - acc: 0.8577
1283/1283 [==============================] - 1s 792us/step - loss: 0.3463 - acc: 0.8597 - val_loss: 0.7966 - val_acc: 0.5852

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2582 - acc: 0.9688
 128/1283 [=>............................] - ETA: 2s - loss: 0.2639 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2673 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2722 - acc: 0.9187
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2744 - acc: 0.9089
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2791 - acc: 0.9004
 576/1283 [============>.................] - ETA: 0s - loss: 0.2792 - acc: 0.8993
 640/1283 [=============>................] - ETA: 0s - loss: 0.2820 - acc: 0.9000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2795 - acc: 0.9006
 768/1283 [================>.............] - ETA: 0s - loss: 0.2835 - acc: 0.8958
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2895 - acc: 0.8930
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2871 - acc: 0.8969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2907 - acc: 0.8888
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2893 - acc: 0.8880
1280/1283 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.8867
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2906 - acc: 0.8862 - val_loss: 0.9459 - val_acc: 0.5852

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.2909 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3314 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3011 - acc: 0.8750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3058 - acc: 0.8672
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3015 - acc: 0.8638
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3031 - acc: 0.8633
 576/1283 [============>.................] - ETA: 0s - loss: 0.2973 - acc: 0.8663
 640/1283 [=============>................] - ETA: 0s - loss: 0.2939 - acc: 0.8688
 768/1283 [================>.............] - ETA: 0s - loss: 0.2887 - acc: 0.8737
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2893 - acc: 0.8761
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2846 - acc: 0.8760
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2819 - acc: 0.8778
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2812 - acc: 0.8783
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2814 - acc: 0.8761 - val_loss: 0.9606 - val_acc: 0.5852

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2237 - acc: 0.8906
 128/1283 [=>............................] - ETA: 2s - loss: 0.2099 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2146 - acc: 0.9141
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2182 - acc: 0.9115
 576/1283 [============>.................] - ETA: 0s - loss: 0.2238 - acc: 0.9132
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2282 - acc: 0.9162
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2256 - acc: 0.9171
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2251 - acc: 0.9187
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2253 - acc: 0.9182
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2250 - acc: 0.9186
1280/1283 [============================>.] - ETA: 0s - loss: 0.2244 - acc: 0.9187
1283/1283 [==============================] - 1s 919us/step - loss: 0.2262 - acc: 0.9174 - val_loss: 1.0640 - val_acc: 0.5677

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2711 - acc: 0.8906
 128/1283 [=>............................] - ETA: 2s - loss: 0.2331 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2149 - acc: 0.9258
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2109 - acc: 0.9245
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2099 - acc: 0.9180
 576/1283 [============>.................] - ETA: 0s - loss: 0.2056 - acc: 0.9219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2112 - acc: 0.9162
 768/1283 [================>.............] - ETA: 0s - loss: 0.2103 - acc: 0.9167
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2222 - acc: 0.9107
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2219 - acc: 0.9125
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2244 - acc: 0.9082
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2261 - acc: 0.9062
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2278 - acc: 0.9038
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2251 - acc: 0.9057 - val_loss: 1.0728 - val_acc: 0.5895

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1995 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1806 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1867 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2013 - acc: 0.9250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1876 - acc: 0.9330
 576/1283 [============>.................] - ETA: 0s - loss: 0.1926 - acc: 0.9288
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1849 - acc: 0.9332
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1833 - acc: 0.9327
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1845 - acc: 0.9308
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1852 - acc: 0.9292
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1871 - acc: 0.9277
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1853 - acc: 0.9292
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1828 - acc: 0.9314
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1845 - acc: 0.9301
1280/1283 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9320
1283/1283 [==============================] - 1s 968us/step - loss: 0.1825 - acc: 0.9322 - val_loss: 1.0381 - val_acc: 0.5459

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1505 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1600 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1518 - acc: 0.9609
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1373 - acc: 0.9661
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1402 - acc: 0.9590
 640/1283 [=============>................] - ETA: 0s - loss: 0.1406 - acc: 0.9594
 768/1283 [================>.............] - ETA: 0s - loss: 0.1424 - acc: 0.9583
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1412 - acc: 0.9554
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1412 - acc: 0.9542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1407 - acc: 0.9540
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1416 - acc: 0.9531
1280/1283 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9531
1283/1283 [==============================] - 1s 853us/step - loss: 0.1412 - acc: 0.9532 - val_loss: 1.1662 - val_acc: 0.5590

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1026 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1164 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1200 - acc: 0.9656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1317 - acc: 0.9554
 576/1283 [============>.................] - ETA: 0s - loss: 0.1271 - acc: 0.9549
 640/1283 [=============>................] - ETA: 0s - loss: 0.1294 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1265 - acc: 0.9557
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1235 - acc: 0.9576
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1232 - acc: 0.9590
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1199 - acc: 0.9609
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1196 - acc: 0.9597
1280/1283 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9609
1283/1283 [==============================] - 1s 879us/step - loss: 0.1181 - acc: 0.9610 - val_loss: 1.3806 - val_acc: 0.5459

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=15
PCA text=100
accuracy=0.4868804664723032
best_valid_accuracy=0.49271137026239065
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:09:09.147250: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.7813 - acc: 0.5000
 192/1283 [===>..........................] - ETA: 2s - loss: 0.7432 - acc: 0.5156
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7441 - acc: 0.5094
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7459 - acc: 0.5045
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7416 - acc: 0.5059
 640/1283 [=============>................] - ETA: 0s - loss: 0.7377 - acc: 0.5109
 768/1283 [================>.............] - ETA: 0s - loss: 0.7326 - acc: 0.5091
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7228 - acc: 0.5279
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7248 - acc: 0.5250
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7227 - acc: 0.5184
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7199 - acc: 0.5189
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7186 - acc: 0.5191 - val_loss: 0.6989 - val_acc: 0.4672

Epoch 00001: val_acc improved from -inf to 0.46725, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6596 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6608 - acc: 0.6615
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6553 - acc: 0.6836
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6527 - acc: 0.6813
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6506 - acc: 0.6849
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6549 - acc: 0.6777
 576/1283 [============>.................] - ETA: 0s - loss: 0.6528 - acc: 0.6892
 640/1283 [=============>................] - ETA: 0s - loss: 0.6495 - acc: 0.6969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6493 - acc: 0.6918
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6478 - acc: 0.6767
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6486 - acc: 0.6698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6492 - acc: 0.6654
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6481 - acc: 0.6562
1280/1283 [============================>.] - ETA: 0s - loss: 0.6471 - acc: 0.6570
1283/1283 [==============================] - 1s 999us/step - loss: 0.6471 - acc: 0.6571 - val_loss: 0.7008 - val_acc: 0.5590

Epoch 00002: val_acc improved from 0.46725 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6263 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6186 - acc: 0.6667
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6028 - acc: 0.6797
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6134 - acc: 0.6594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6149 - acc: 0.6607
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6110 - acc: 0.6680
 640/1283 [=============>................] - ETA: 0s - loss: 0.6184 - acc: 0.6625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6182 - acc: 0.6591
 768/1283 [================>.............] - ETA: 0s - loss: 0.6143 - acc: 0.6628
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6140 - acc: 0.6647
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6172 - acc: 0.6574
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6190 - acc: 0.6533
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6159 - acc: 0.6589
1280/1283 [============================>.] - ETA: 0s - loss: 0.6105 - acc: 0.6664
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6103 - acc: 0.6664 - val_loss: 0.7110 - val_acc: 0.5677

Epoch 00003: val_acc improved from 0.55895 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5476 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5421 - acc: 0.7604
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5410 - acc: 0.7719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5386 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5418 - acc: 0.7589
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5524 - acc: 0.7441
 576/1283 [============>.................] - ETA: 0s - loss: 0.5489 - acc: 0.7465
 640/1283 [=============>................] - ETA: 0s - loss: 0.5544 - acc: 0.7422
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5528 - acc: 0.7443
 768/1283 [================>.............] - ETA: 0s - loss: 0.5521 - acc: 0.7435
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5539 - acc: 0.7388
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5555 - acc: 0.7365
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5576 - acc: 0.7325
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5538 - acc: 0.7368
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5566 - acc: 0.7327 - val_loss: 0.6900 - val_acc: 0.6157

Epoch 00004: val_acc improved from 0.56769 to 0.61572, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.4517 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4634 - acc: 0.8047
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4765 - acc: 0.8086
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4863 - acc: 0.7891
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4856 - acc: 0.7910
 576/1283 [============>.................] - ETA: 0s - loss: 0.4910 - acc: 0.7882
 640/1283 [=============>................] - ETA: 0s - loss: 0.4848 - acc: 0.7953
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4851 - acc: 0.7926
 768/1283 [================>.............] - ETA: 0s - loss: 0.4754 - acc: 0.7995
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4811 - acc: 0.7924
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4775 - acc: 0.7927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4843 - acc: 0.7842
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4884 - acc: 0.7767
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4873 - acc: 0.7760
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4907 - acc: 0.7706
1280/1283 [============================>.] - ETA: 0s - loss: 0.4883 - acc: 0.7734
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4882 - acc: 0.7732 - val_loss: 0.6909 - val_acc: 0.6376

Epoch 00005: val_acc improved from 0.61572 to 0.63755, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3962 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4315 - acc: 0.8073
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4120 - acc: 0.8469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4165 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4128 - acc: 0.8415
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4188 - acc: 0.8301
 576/1283 [============>.................] - ETA: 0s - loss: 0.4213 - acc: 0.8264
 640/1283 [=============>................] - ETA: 0s - loss: 0.4173 - acc: 0.8281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4149 - acc: 0.8281
 768/1283 [================>.............] - ETA: 0s - loss: 0.4165 - acc: 0.8242
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4173 - acc: 0.8245
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4249 - acc: 0.8170
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4278 - acc: 0.8125
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4280 - acc: 0.8125
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4285 - acc: 0.8107
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4323 - acc: 0.8056
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4334 - acc: 0.8051
1280/1283 [============================>.] - ETA: 0s - loss: 0.4337 - acc: 0.8023
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4333 - acc: 0.8028 - val_loss: 0.7019 - val_acc: 0.6026

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3713 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.3663 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3432 - acc: 0.8698
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3412 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3427 - acc: 0.8688
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3633 - acc: 0.8464
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3537 - acc: 0.8571
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3602 - acc: 0.8457
 576/1283 [============>.................] - ETA: 0s - loss: 0.3592 - acc: 0.8490
 640/1283 [=============>................] - ETA: 0s - loss: 0.3530 - acc: 0.8547
 768/1283 [================>.............] - ETA: 0s - loss: 0.3578 - acc: 0.8490
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3602 - acc: 0.8522
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3579 - acc: 0.8538
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3612 - acc: 0.8510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3593 - acc: 0.8525
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3564 - acc: 0.8548
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3539 - acc: 0.8542
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3543 - acc: 0.8577
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3546 - acc: 0.8574 - val_loss: 0.7145 - val_acc: 0.6288

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3034 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2920 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3111 - acc: 0.8781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3301 - acc: 0.8571
 576/1283 [============>.................] - ETA: 0s - loss: 0.3214 - acc: 0.8681
 640/1283 [=============>................] - ETA: 0s - loss: 0.3225 - acc: 0.8672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3202 - acc: 0.8679
 768/1283 [================>.............] - ETA: 0s - loss: 0.3233 - acc: 0.8646
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3196 - acc: 0.8678
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3187 - acc: 0.8672
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3163 - acc: 0.8677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3139 - acc: 0.8711
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3169 - acc: 0.8658
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3186 - acc: 0.8637
1280/1283 [============================>.] - ETA: 0s - loss: 0.3128 - acc: 0.8680
1283/1283 [==============================] - 1s 985us/step - loss: 0.3139 - acc: 0.8675 - val_loss: 0.8287 - val_acc: 0.6070

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.3077 - acc: 0.8281
 128/1283 [=>............................] - ETA: 2s - loss: 0.3601 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3434 - acc: 0.8177
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3350 - acc: 0.8203
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3226 - acc: 0.8344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3060 - acc: 0.8542
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3109 - acc: 0.8504
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3091 - acc: 0.8516
 576/1283 [============>.................] - ETA: 0s - loss: 0.3073 - acc: 0.8524
 640/1283 [=============>................] - ETA: 0s - loss: 0.3020 - acc: 0.8578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3020 - acc: 0.8565
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2936 - acc: 0.8642
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2901 - acc: 0.8708
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2931 - acc: 0.8704
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2916 - acc: 0.8783
1280/1283 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.8797
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2895 - acc: 0.8800 - val_loss: 0.8765 - val_acc: 0.6114

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2314 - acc: 0.9062
 128/1283 [=>............................] - ETA: 1s - loss: 0.2109 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 2s - loss: 0.2033 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2112 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2067 - acc: 0.9219
 640/1283 [=============>................] - ETA: 0s - loss: 0.2083 - acc: 0.9234
 768/1283 [================>.............] - ETA: 0s - loss: 0.2102 - acc: 0.9232
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2077 - acc: 0.9263
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2078 - acc: 0.9248
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2063 - acc: 0.9265
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2049 - acc: 0.9262
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2037 - acc: 0.9260
1280/1283 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9258
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2025 - acc: 0.9260 - val_loss: 0.9348 - val_acc: 0.6288

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2018 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1856 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1822 - acc: 0.9492
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1759 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1963 - acc: 0.9297
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2044 - acc: 0.9196
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2161 - acc: 0.9121
 576/1283 [============>.................] - ETA: 0s - loss: 0.2139 - acc: 0.9132
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2108 - acc: 0.9162
 768/1283 [================>.............] - ETA: 0s - loss: 0.2135 - acc: 0.9154
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2117 - acc: 0.9171
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2148 - acc: 0.9129
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2172 - acc: 0.9094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2175 - acc: 0.9082
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2184 - acc: 0.9097
1280/1283 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9164
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2114 - acc: 0.9150 - val_loss: 0.9874 - val_acc: 0.6026

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1935 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.1928 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1851 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1861 - acc: 0.9156
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1993 - acc: 0.9082
 576/1283 [============>.................] - ETA: 0s - loss: 0.2000 - acc: 0.9080
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1996 - acc: 0.9091
 768/1283 [================>.............] - ETA: 0s - loss: 0.1991 - acc: 0.9128
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1960 - acc: 0.9135
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1902 - acc: 0.9174
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1883 - acc: 0.9167
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1882 - acc: 0.9180
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1855 - acc: 0.9210
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1871 - acc: 0.9211
1283/1283 [==============================] - 1s 911us/step - loss: 0.1865 - acc: 0.9205 - val_loss: 0.9618 - val_acc: 0.6201

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1358 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1462 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1465 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1511 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1433 - acc: 0.9442
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1373 - acc: 0.9492
 576/1283 [============>.................] - ETA: 0s - loss: 0.1315 - acc: 0.9531
 640/1283 [=============>................] - ETA: 0s - loss: 0.1314 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1315 - acc: 0.9518
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1345 - acc: 0.9487
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1370 - acc: 0.9463
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1344 - acc: 0.9470
1280/1283 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9492
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1338 - acc: 0.9493 - val_loss: 1.0228 - val_acc: 0.6114

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1868 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1648 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1504 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1583 - acc: 0.9375
 576/1283 [============>.................] - ETA: 0s - loss: 0.1706 - acc: 0.9288
 640/1283 [=============>................] - ETA: 0s - loss: 0.1745 - acc: 0.9266
 768/1283 [================>.............] - ETA: 0s - loss: 0.1715 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1700 - acc: 0.9315
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1702 - acc: 0.9297
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1674 - acc: 0.9323
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1668 - acc: 0.9326
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1653 - acc: 0.9338
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1648 - acc: 0.9340
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1629 - acc: 0.9359
1280/1283 [============================>.] - ETA: 0s - loss: 0.1621 - acc: 0.9359
1283/1283 [==============================] - 1s 832us/step - loss: 0.1619 - acc: 0.9361 - val_loss: 1.0867 - val_acc: 0.5983

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0633 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0979 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1081 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1140 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 2s - loss: 0.1222 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1157 - acc: 0.9621
 576/1283 [============>.................] - ETA: 0s - loss: 0.1170 - acc: 0.9653
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1151 - acc: 0.9659
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1167 - acc: 0.9651
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1127 - acc: 0.9658
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1126 - acc: 0.9653
1280/1283 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9633
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1149 - acc: 0.9634 - val_loss: 1.1010 - val_acc: 0.5939

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=20
PCA text=100
accuracy=0.5102040816326531
best_valid_accuracy=0.5131195335276968
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:19:32.496083: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.7065 - acc: 0.5469
 192/1283 [===>..........................] - ETA: 1s - loss: 0.7271 - acc: 0.4948
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7303 - acc: 0.4813
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7160 - acc: 0.5022
 576/1283 [============>.................] - ETA: 0s - loss: 0.7147 - acc: 0.4931
 768/1283 [================>.............] - ETA: 0s - loss: 0.7076 - acc: 0.5065
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7033 - acc: 0.5219
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7035 - acc: 0.5193
1280/1283 [============================>.] - ETA: 0s - loss: 0.7003 - acc: 0.5266
1283/1283 [==============================] - 1s 694us/step - loss: 0.6999 - acc: 0.5277 - val_loss: 0.7122 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6262 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6256 - acc: 0.6367
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6299 - acc: 0.6205
 576/1283 [============>.................] - ETA: 0s - loss: 0.6309 - acc: 0.6163
 768/1283 [================>.............] - ETA: 0s - loss: 0.6214 - acc: 0.6419
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6184 - acc: 0.6521
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6181 - acc: 0.6546
1283/1283 [==============================] - 0s 332us/step - loss: 0.6201 - acc: 0.6493 - val_loss: 0.7022 - val_acc: 0.5240

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5730 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5697 - acc: 0.7305
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5648 - acc: 0.7366
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5638 - acc: 0.7244
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5614 - acc: 0.7271
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5604 - acc: 0.7278
1283/1283 [==============================] - 0s 310us/step - loss: 0.5614 - acc: 0.7241 - val_loss: 0.7272 - val_acc: 0.5197

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4666 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4916 - acc: 0.7875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4892 - acc: 0.7793
 768/1283 [================>.............] - ETA: 0s - loss: 0.4923 - acc: 0.7826
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4860 - acc: 0.7891
1280/1283 [============================>.] - ETA: 0s - loss: 0.4850 - acc: 0.7875
1283/1283 [==============================] - 0s 268us/step - loss: 0.4844 - acc: 0.7880 - val_loss: 0.7734 - val_acc: 0.5764

Epoch 00004: val_acc improved from 0.52838 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4330 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4406 - acc: 0.7891
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4146 - acc: 0.8237
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4172 - acc: 0.8168
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4152 - acc: 0.8170
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4197 - acc: 0.8134
1280/1283 [============================>.] - ETA: 0s - loss: 0.4232 - acc: 0.8102
1283/1283 [==============================] - 0s 322us/step - loss: 0.4230 - acc: 0.8106 - val_loss: 1.0575 - val_acc: 0.4585

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5172 - acc: 0.7500
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4995 - acc: 0.7312
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4706 - acc: 0.7480
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4538 - acc: 0.7642
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4346 - acc: 0.7875
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4242 - acc: 0.7952
1283/1283 [==============================] - 0s 279us/step - loss: 0.4272 - acc: 0.7935 - val_loss: 0.7992 - val_acc: 0.6026

Epoch 00006: val_acc improved from 0.57642 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3091 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3121 - acc: 0.8750
 576/1283 [============>.................] - ETA: 0s - loss: 0.3263 - acc: 0.8663
 768/1283 [================>.............] - ETA: 0s - loss: 0.3221 - acc: 0.8633
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3166 - acc: 0.8677
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3122 - acc: 0.8724
1283/1283 [==============================] - 0s 336us/step - loss: 0.3119 - acc: 0.8737 - val_loss: 0.9952 - val_acc: 0.5852

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3771 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3814 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3597 - acc: 0.8170
 640/1283 [=============>................] - ETA: 0s - loss: 0.3522 - acc: 0.8234
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3357 - acc: 0.8365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3198 - acc: 0.8535
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3138 - acc: 0.8585
1283/1283 [==============================] - 0s 337us/step - loss: 0.3156 - acc: 0.8550 - val_loss: 0.9841 - val_acc: 0.5764

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2680 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2736 - acc: 0.8854
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2607 - acc: 0.9036
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2526 - acc: 0.9043
 640/1283 [=============>................] - ETA: 0s - loss: 0.2517 - acc: 0.9016
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2570 - acc: 0.8978
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2553 - acc: 0.8975
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2484 - acc: 0.9010
1280/1283 [============================>.] - ETA: 0s - loss: 0.2476 - acc: 0.9016
1283/1283 [==============================] - 1s 446us/step - loss: 0.2473 - acc: 0.9018 - val_loss: 0.9470 - val_acc: 0.5939

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2049 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1690 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1740 - acc: 0.9487
 640/1283 [=============>................] - ETA: 0s - loss: 0.1791 - acc: 0.9453
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1818 - acc: 0.9423
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1850 - acc: 0.9404
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1859 - acc: 0.9367
1283/1283 [==============================] - 0s 348us/step - loss: 0.1862 - acc: 0.9361 - val_loss: 1.2138 - val_acc: 0.5197

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2056 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2014 - acc: 0.9023
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1833 - acc: 0.9129
 640/1283 [=============>................] - ETA: 0s - loss: 0.1758 - acc: 0.9219
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1745 - acc: 0.9267
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1750 - acc: 0.9248
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1740 - acc: 0.9262
1283/1283 [==============================] - 0s 365us/step - loss: 0.1731 - acc: 0.9275 - val_loss: 1.1239 - val_acc: 0.5852

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1394 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1651 - acc: 0.9297
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1593 - acc: 0.9420
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1735 - acc: 0.9347
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1639 - acc: 0.9386
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1613 - acc: 0.9395
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1547 - acc: 0.9449
1283/1283 [==============================] - 0s 322us/step - loss: 0.1544 - acc: 0.9431 - val_loss: 1.3260 - val_acc: 0.5721

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1749 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1317 - acc: 0.9406
 576/1283 [============>.................] - ETA: 0s - loss: 0.1283 - acc: 0.9479
 768/1283 [================>.............] - ETA: 0s - loss: 0.1229 - acc: 0.9505
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1181 - acc: 0.9570
1280/1283 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9563
1283/1283 [==============================] - 0s 284us/step - loss: 0.1202 - acc: 0.9556 - val_loss: 1.3110 - val_acc: 0.5633

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1194 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2249 - acc: 0.8828
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1874 - acc: 0.9107
 640/1283 [=============>................] - ETA: 0s - loss: 0.2050 - acc: 0.9031
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1908 - acc: 0.9129
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1843 - acc: 0.9194
1283/1283 [==============================] - 0s 263us/step - loss: 0.1826 - acc: 0.9189 - val_loss: 1.2559 - val_acc: 0.5109

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1226 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1235 - acc: 0.9570
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1143 - acc: 0.9598
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1181 - acc: 0.9631
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1110 - acc: 0.9635
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1132 - acc: 0.9627
1283/1283 [==============================] - 0s 269us/step - loss: 0.1115 - acc: 0.9626 - val_loss: 1.3860 - val_acc: 0.5459

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0687 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0882 - acc: 0.9727
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0905 - acc: 0.9710
 640/1283 [=============>................] - ETA: 0s - loss: 0.0922 - acc: 0.9688
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0941 - acc: 0.9688
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0931 - acc: 0.9679
1283/1283 [==============================] - 0s 278us/step - loss: 0.0913 - acc: 0.9673 - val_loss: 1.5995 - val_acc: 0.5546

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=25
PCA text=100
accuracy=0.4970845481049563
best_valid_accuracy=0.4868804664723032
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:24:08.421316: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.7775 - acc: 0.3438
 128/1283 [=>............................] - ETA: 3s - loss: 0.8037 - acc: 0.3750
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7628 - acc: 0.4609
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7383 - acc: 0.4922
 512/1283 [==========>...................] - ETA: 0s - loss: 0.7283 - acc: 0.5098
 576/1283 [============>.................] - ETA: 0s - loss: 0.7221 - acc: 0.5208
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7156 - acc: 0.5298
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7169 - acc: 0.5240
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7153 - acc: 0.5260
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7125 - acc: 0.5312
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7116 - acc: 0.5278
1280/1283 [============================>.] - ETA: 0s - loss: 0.7101 - acc: 0.5258
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7102 - acc: 0.5246 - val_loss: 0.6910 - val_acc: 0.5109

Epoch 00001: val_acc improved from -inf to 0.51092, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6208 - acc: 0.7344
 128/1283 [=>............................] - ETA: 0s - loss: 0.6215 - acc: 0.7266
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6318 - acc: 0.6836
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6321 - acc: 0.6849
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6341 - acc: 0.6777
 640/1283 [=============>................] - ETA: 0s - loss: 0.6323 - acc: 0.6766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6297 - acc: 0.6804
 768/1283 [================>.............] - ETA: 0s - loss: 0.6274 - acc: 0.6784
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6248 - acc: 0.6830
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6239 - acc: 0.6797
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6231 - acc: 0.6727
1283/1283 [==============================] - 1s 622us/step - loss: 0.6225 - acc: 0.6664 - val_loss: 0.7350 - val_acc: 0.4891

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5386 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5475 - acc: 0.7292
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5639 - acc: 0.7156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5604 - acc: 0.7165
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5527 - acc: 0.7363
 640/1283 [=============>................] - ETA: 0s - loss: 0.5642 - acc: 0.7188
 768/1283 [================>.............] - ETA: 0s - loss: 0.5694 - acc: 0.7148
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5675 - acc: 0.7165
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5644 - acc: 0.7188
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5626 - acc: 0.7188
1280/1283 [============================>.] - ETA: 0s - loss: 0.5619 - acc: 0.7180
1283/1283 [==============================] - 1s 677us/step - loss: 0.5617 - acc: 0.7178 - val_loss: 0.7893 - val_acc: 0.4934

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5745 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5930 - acc: 0.6302
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5755 - acc: 0.6594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5616 - acc: 0.6719
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5509 - acc: 0.6875
 640/1283 [=============>................] - ETA: 0s - loss: 0.5503 - acc: 0.6844
 768/1283 [================>.............] - ETA: 0s - loss: 0.5477 - acc: 0.6927
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5392 - acc: 0.7098
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5312 - acc: 0.7227
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5325 - acc: 0.7179
1280/1283 [============================>.] - ETA: 0s - loss: 0.5251 - acc: 0.7328
1283/1283 [==============================] - 1s 563us/step - loss: 0.5250 - acc: 0.7334 - val_loss: 0.7513 - val_acc: 0.5066

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4589 - acc: 0.8125
 128/1283 [=>............................] - ETA: 0s - loss: 0.4883 - acc: 0.7891
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4670 - acc: 0.8164
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4536 - acc: 0.8099
 576/1283 [============>.................] - ETA: 0s - loss: 0.4515 - acc: 0.8160
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4501 - acc: 0.8139
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4458 - acc: 0.8161
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4480 - acc: 0.8094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4442 - acc: 0.8096
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4456 - acc: 0.8090
1280/1283 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8109
1283/1283 [==============================] - 1s 640us/step - loss: 0.4407 - acc: 0.8106 - val_loss: 0.8290 - val_acc: 0.5109

Epoch 00005: val_acc improved from 0.51092 to 0.51092, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3892 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3504 - acc: 0.8646
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3655 - acc: 0.8469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3595 - acc: 0.8549
 576/1283 [============>.................] - ETA: 0s - loss: 0.3664 - acc: 0.8524
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3602 - acc: 0.8594
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3526 - acc: 0.8666
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3610 - acc: 0.8555
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3607 - acc: 0.8561
1283/1283 [==============================] - 1s 643us/step - loss: 0.3650 - acc: 0.8511 - val_loss: 0.7995 - val_acc: 0.5502

Epoch 00006: val_acc improved from 0.51092 to 0.55022, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3387 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3215 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3012 - acc: 0.8969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3049 - acc: 0.8884
 576/1283 [============>.................] - ETA: 0s - loss: 0.3020 - acc: 0.8906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2940 - acc: 0.8949
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2943 - acc: 0.8894
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2985 - acc: 0.8854
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2984 - acc: 0.8842
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2961 - acc: 0.8849
1283/1283 [==============================] - 1s 558us/step - loss: 0.3001 - acc: 0.8807 - val_loss: 0.8560 - val_acc: 0.5764

Epoch 00007: val_acc improved from 0.55022 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2353 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2693 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2785 - acc: 0.8945
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2753 - acc: 0.8938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2677 - acc: 0.9010
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2801 - acc: 0.8906
 640/1283 [=============>................] - ETA: 0s - loss: 0.2709 - acc: 0.8938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2709 - acc: 0.8949
 768/1283 [================>.............] - ETA: 0s - loss: 0.2780 - acc: 0.8893
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2736 - acc: 0.8906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2754 - acc: 0.8828
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2743 - acc: 0.8828
1280/1283 [============================>.] - ETA: 0s - loss: 0.2719 - acc: 0.8875
1283/1283 [==============================] - 1s 678us/step - loss: 0.2717 - acc: 0.8878 - val_loss: 0.9547 - val_acc: 0.5721

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2389 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2101 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2077 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1950 - acc: 0.9330
 576/1283 [============>.................] - ETA: 0s - loss: 0.1936 - acc: 0.9236
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2004 - acc: 0.9205
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1973 - acc: 0.9267
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2025 - acc: 0.9240
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2074 - acc: 0.9182
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2014 - acc: 0.9227
1280/1283 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9234
1283/1283 [==============================] - 1s 527us/step - loss: 0.2014 - acc: 0.9236 - val_loss: 1.0007 - val_acc: 0.5590

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1489 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1599 - acc: 0.9414
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1556 - acc: 0.9479
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1585 - acc: 0.9434
 640/1283 [=============>................] - ETA: 0s - loss: 0.1577 - acc: 0.9437
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1586 - acc: 0.9460
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1601 - acc: 0.9459
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1640 - acc: 0.9437
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1619 - acc: 0.9421
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1632 - acc: 0.9400
1283/1283 [==============================] - 1s 649us/step - loss: 0.1614 - acc: 0.9408 - val_loss: 1.1073 - val_acc: 0.5415

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1393 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1398 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1518 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1468 - acc: 0.9479
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1428 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1478 - acc: 0.9389
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1397 - acc: 0.9435
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1402 - acc: 0.9437
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1413 - acc: 0.9439
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1371 - acc: 0.9457
1283/1283 [==============================] - 1s 600us/step - loss: 0.1397 - acc: 0.9447 - val_loss: 1.1895 - val_acc: 0.5808

Epoch 00011: val_acc improved from 0.57642 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1755 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2362 - acc: 0.8984
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2154 - acc: 0.9062
 576/1283 [============>.................] - ETA: 0s - loss: 0.2349 - acc: 0.8941
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2243 - acc: 0.9020
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2297 - acc: 0.9026
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2294 - acc: 0.8984
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2218 - acc: 0.9054
1280/1283 [============================>.] - ETA: 0s - loss: 0.2188 - acc: 0.9070
1283/1283 [==============================] - 1s 446us/step - loss: 0.2189 - acc: 0.9065 - val_loss: 1.1620 - val_acc: 0.5197

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0774 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1168 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1483 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1536 - acc: 0.9375
 576/1283 [============>.................] - ETA: 0s - loss: 0.1486 - acc: 0.9410
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1485 - acc: 0.9432
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1517 - acc: 0.9423
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1448 - acc: 0.9473
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1458 - acc: 0.9465
1283/1283 [==============================] - 1s 464us/step - loss: 0.1447 - acc: 0.9478 - val_loss: 1.1706 - val_acc: 0.5808

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1024 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1051 - acc: 0.9570
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1066 - acc: 0.9629
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1003 - acc: 0.9645
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0949 - acc: 0.9676
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0987 - acc: 0.9635
1283/1283 [==============================] - 0s 325us/step - loss: 0.0957 - acc: 0.9649 - val_loss: 1.1822 - val_acc: 0.5633

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0593 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0746 - acc: 0.9896
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0694 - acc: 0.9870
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0763 - acc: 0.9785
 640/1283 [=============>................] - ETA: 0s - loss: 0.0748 - acc: 0.9781
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0720 - acc: 0.9784
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0717 - acc: 0.9781
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0755 - acc: 0.9733
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0756 - acc: 0.9729
1280/1283 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9734
1283/1283 [==============================] - 1s 639us/step - loss: 0.0755 - acc: 0.9735 - val_loss: 1.2608 - val_acc: 0.5546

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0886 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1008 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0782 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0706 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.0687 - acc: 0.9792
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0661 - acc: 0.9801
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0683 - acc: 0.9796
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0702 - acc: 0.9760
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0663 - acc: 0.9770
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0666 - acc: 0.9770
1283/1283 [==============================] - 1s 527us/step - loss: 0.0668 - acc: 0.9758 - val_loss: 1.3691 - val_acc: 0.5546

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0794 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0620 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0620 - acc: 0.9799
 640/1283 [=============>................] - ETA: 0s - loss: 0.0617 - acc: 0.9812
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0622 - acc: 0.9766
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0602 - acc: 0.9779
1280/1283 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9766
1283/1283 [==============================] - 0s 310us/step - loss: 0.0607 - acc: 0.9766 - val_loss: 1.4066 - val_acc: 0.5677

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0592 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0596 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0577 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0572 - acc: 0.9809
 768/1283 [================>.............] - ETA: 0s - loss: 0.0582 - acc: 0.9792
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0572 - acc: 0.9777
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0553 - acc: 0.9789
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0560 - acc: 0.9786
1283/1283 [==============================] - 1s 436us/step - loss: 0.0571 - acc: 0.9782 - val_loss: 1.5159 - val_acc: 0.5764

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0178 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0713 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0773 - acc: 0.9661
 576/1283 [============>.................] - ETA: 0s - loss: 0.0819 - acc: 0.9670
 768/1283 [================>.............] - ETA: 0s - loss: 0.0993 - acc: 0.9596
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0999 - acc: 0.9598
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0956 - acc: 0.9623
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0930 - acc: 0.9630
1283/1283 [==============================] - 1s 441us/step - loss: 0.0915 - acc: 0.9641 - val_loss: 1.3512 - val_acc: 0.5721

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0611 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0480 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0509 - acc: 0.9792
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0585 - acc: 0.9746
 640/1283 [=============>................] - ETA: 0s - loss: 0.0609 - acc: 0.9750
 768/1283 [================>.............] - ETA: 0s - loss: 0.0662 - acc: 0.9727
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0657 - acc: 0.9740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0646 - acc: 0.9743
1280/1283 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9750
1283/1283 [==============================] - 1s 438us/step - loss: 0.0637 - acc: 0.9751 - val_loss: 1.4904 - val_acc: 0.5677

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0787 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0613 - acc: 0.9740
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0581 - acc: 0.9740
 576/1283 [============>.................] - ETA: 0s - loss: 0.0595 - acc: 0.9705
 768/1283 [================>.............] - ETA: 0s - loss: 0.0579 - acc: 0.9740
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0541 - acc: 0.9781
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0535 - acc: 0.9792
1283/1283 [==============================] - 0s 364us/step - loss: 0.0537 - acc: 0.9797 - val_loss: 1.6013 - val_acc: 0.5764

Epoch 00021: val_acc did not improve
Epoch 00021: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=30
PCA text=100
accuracy=0.5043731778425656
best_valid_accuracy=0.5116618075801749
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:45:10.397475: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 6s - loss: 0.7176 - acc: 0.4062
 256/1283 [====>.........................] - ETA: 1s - loss: 0.7112 - acc: 0.5352
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7492 - acc: 0.5067
 640/1283 [=============>................] - ETA: 0s - loss: 0.7504 - acc: 0.5000
 768/1283 [================>.............] - ETA: 0s - loss: 0.7405 - acc: 0.5039
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7346 - acc: 0.5089
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7248 - acc: 0.5230
1280/1283 [============================>.] - ETA: 0s - loss: 0.7184 - acc: 0.5320
1283/1283 [==============================] - 1s 721us/step - loss: 0.7186 - acc: 0.5308 - val_loss: 0.6990 - val_acc: 0.5109

Epoch 00001: val_acc improved from -inf to 0.51092, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6862 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6657 - acc: 0.5833
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6517 - acc: 0.6068
 576/1283 [============>.................] - ETA: 0s - loss: 0.6455 - acc: 0.6406
 640/1283 [=============>................] - ETA: 0s - loss: 0.6426 - acc: 0.6484
 768/1283 [================>.............] - ETA: 0s - loss: 0.6460 - acc: 0.6328
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6401 - acc: 0.6469
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6365 - acc: 0.6498
1280/1283 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.6539
1283/1283 [==============================] - 1s 645us/step - loss: 0.6331 - acc: 0.6547 - val_loss: 0.7263 - val_acc: 0.5197

Epoch 00002: val_acc improved from 0.51092 to 0.51965, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6302 - acc: 0.5938
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5774 - acc: 0.6680
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5772 - acc: 0.6830
 640/1283 [=============>................] - ETA: 0s - loss: 0.5856 - acc: 0.6750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5774 - acc: 0.6875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5829 - acc: 0.6777
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5793 - acc: 0.6832
1283/1283 [==============================] - 0s 367us/step - loss: 0.5817 - acc: 0.6820 - val_loss: 0.8014 - val_acc: 0.4760

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5591 - acc: 0.6875
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5316 - acc: 0.7406
 640/1283 [=============>................] - ETA: 0s - loss: 0.5198 - acc: 0.7578
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5097 - acc: 0.7781
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5142 - acc: 0.7697
1283/1283 [==============================] - 0s 219us/step - loss: 0.5125 - acc: 0.7708 - val_loss: 0.7642 - val_acc: 0.4978

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4413 - acc: 0.8594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4224 - acc: 0.8411
 640/1283 [=============>................] - ETA: 0s - loss: 0.4242 - acc: 0.8391
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4252 - acc: 0.8315
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4087 - acc: 0.8380
1283/1283 [==============================] - 0s 215us/step - loss: 0.4101 - acc: 0.8371 - val_loss: 0.8244 - val_acc: 0.5066

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3915 - acc: 0.8125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3878 - acc: 0.8151
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3587 - acc: 0.8395
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3509 - acc: 0.8477
1283/1283 [==============================] - 0s 209us/step - loss: 0.3452 - acc: 0.8504 - val_loss: 0.8974 - val_acc: 0.5153

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2158 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2727 - acc: 0.9062
 640/1283 [=============>................] - ETA: 0s - loss: 0.2757 - acc: 0.9000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2746 - acc: 0.8938
1280/1283 [============================>.] - ETA: 0s - loss: 0.2815 - acc: 0.8898
1283/1283 [==============================] - 0s 204us/step - loss: 0.2810 - acc: 0.8901 - val_loss: 0.9759 - val_acc: 0.5240

Epoch 00007: val_acc improved from 0.51965 to 0.52402, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1829 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2122 - acc: 0.9297
 640/1283 [=============>................] - ETA: 0s - loss: 0.2084 - acc: 0.9297
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2082 - acc: 0.9275
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2015 - acc: 0.9320
1283/1283 [==============================] - 0s 254us/step - loss: 0.2081 - acc: 0.9267 - val_loss: 1.1234 - val_acc: 0.5197

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1218 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1577 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1543 - acc: 0.9598
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1653 - acc: 0.9460
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1679 - acc: 0.9417
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1707 - acc: 0.9367
1283/1283 [==============================] - 0s 273us/step - loss: 0.1686 - acc: 0.9376 - val_loss: 1.1897 - val_acc: 0.5109

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1583 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1401 - acc: 0.9500
 576/1283 [============>.................] - ETA: 0s - loss: 0.1469 - acc: 0.9462
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1472 - acc: 0.9423
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1450 - acc: 0.9439
1280/1283 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9445
1283/1283 [==============================] - 0s 256us/step - loss: 0.1445 - acc: 0.9439 - val_loss: 1.4490 - val_acc: 0.5459

Epoch 00010: val_acc improved from 0.52402 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2040 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1607 - acc: 0.9336
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1590 - acc: 0.9375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1510 - acc: 0.9418
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1537 - acc: 0.9353
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1450 - acc: 0.9412
1280/1283 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9422
1283/1283 [==============================] - 0s 310us/step - loss: 0.1401 - acc: 0.9423 - val_loss: 1.5570 - val_acc: 0.5459

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1163 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1393 - acc: 0.9344
 640/1283 [=============>................] - ETA: 0s - loss: 0.1281 - acc: 0.9516
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1239 - acc: 0.9531
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1216 - acc: 0.9549
1283/1283 [==============================] - 0s 250us/step - loss: 0.1190 - acc: 0.9579 - val_loss: 1.4349 - val_acc: 0.5284

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0939 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0854 - acc: 0.9781
 576/1283 [============>.................] - ETA: 0s - loss: 0.0792 - acc: 0.9792
 768/1283 [================>.............] - ETA: 0s - loss: 0.0864 - acc: 0.9674
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0871 - acc: 0.9678
1280/1283 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9688
1283/1283 [==============================] - 0s 274us/step - loss: 0.0859 - acc: 0.9688 - val_loss: 1.4531 - val_acc: 0.5590

Epoch 00013: val_acc improved from 0.54585 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0621 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0693 - acc: 0.9750
 576/1283 [============>.................] - ETA: 0s - loss: 0.0663 - acc: 0.9740
 768/1283 [================>.............] - ETA: 0s - loss: 0.0627 - acc: 0.9766
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0671 - acc: 0.9756
1280/1283 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9750
1283/1283 [==============================] - 0s 269us/step - loss: 0.0671 - acc: 0.9751 - val_loss: 1.4630 - val_acc: 0.5371

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0439 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0688 - acc: 0.9688
 640/1283 [=============>................] - ETA: 0s - loss: 0.0706 - acc: 0.9719
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0634 - acc: 0.9760
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0597 - acc: 0.9786
1283/1283 [==============================] - 0s 240us/step - loss: 0.0588 - acc: 0.9790 - val_loss: 1.5734 - val_acc: 0.5284

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0447 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0550 - acc: 0.9750
 576/1283 [============>.................] - ETA: 0s - loss: 0.0597 - acc: 0.9705
 768/1283 [================>.............] - ETA: 0s - loss: 0.0537 - acc: 0.9753
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0511 - acc: 0.9771
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0520 - acc: 0.9783
1283/1283 [==============================] - 0s 287us/step - loss: 0.0536 - acc: 0.9782 - val_loss: 1.6706 - val_acc: 0.5109

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0684 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1028 - acc: 0.9563
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0912 - acc: 0.9609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0901 - acc: 0.9602
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0948 - acc: 0.9583
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0938 - acc: 0.9583
1283/1283 [==============================] - 0s 292us/step - loss: 0.0958 - acc: 0.9564 - val_loss: 1.6270 - val_acc: 0.5328

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0649 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0675 - acc: 0.9719
 576/1283 [============>.................] - ETA: 0s - loss: 0.0583 - acc: 0.9774
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0620 - acc: 0.9748
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0683 - acc: 0.9688
1280/1283 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9727
1283/1283 [==============================] - 0s 286us/step - loss: 0.0655 - acc: 0.9727 - val_loss: 1.8048 - val_acc: 0.5415

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0560 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0405 - acc: 0.9906
 576/1283 [============>.................] - ETA: 0s - loss: 0.0416 - acc: 0.9913
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0556 - acc: 0.9820
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0600 - acc: 0.9779
1283/1283 [==============================] - 0s 253us/step - loss: 0.0622 - acc: 0.9758 - val_loss: 1.8463 - val_acc: 0.5197

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0742 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0448 - acc: 0.9781
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0478 - acc: 0.9824
 768/1283 [================>.............] - ETA: 0s - loss: 0.0529 - acc: 0.9779
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0509 - acc: 0.9795
1280/1283 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9797
1283/1283 [==============================] - 0s 243us/step - loss: 0.0494 - acc: 0.9797 - val_loss: 1.7936 - val_acc: 0.5153

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0559 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0554 - acc: 0.9792
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0419 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0434 - acc: 0.9814
1280/1283 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9797
1283/1283 [==============================] - 0s 216us/step - loss: 0.0445 - acc: 0.9797 - val_loss: 1.9590 - val_acc: 0.5197

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0769 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0558 - acc: 0.9750
 576/1283 [============>.................] - ETA: 0s - loss: 0.0470 - acc: 0.9774
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0452 - acc: 0.9771
1280/1283 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9797
1283/1283 [==============================] - 0s 201us/step - loss: 0.0449 - acc: 0.9790 - val_loss: 2.0043 - val_acc: 0.5109

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0241 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0624 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.0656 - acc: 0.9594
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0644 - acc: 0.9635
1280/1283 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9648
1283/1283 [==============================] - 0s 212us/step - loss: 0.0654 - acc: 0.9649 - val_loss: 2.0171 - val_acc: 0.5415

Epoch 00023: val_acc did not improve
Epoch 00023: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=A
PCA audio=30
PCA visual=35
PCA text=100
accuracy=0.49854227405247814
best_valid_accuracy=0.4897959183673469
