/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:24:30.882999: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.6695 - acc: 0.6406
 128/1283 [=>............................] - ETA: 4s - loss: 0.7326 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 3s - loss: 0.7637 - acc: 0.5417
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7532 - acc: 0.5625
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7484 - acc: 0.5750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7500 - acc: 0.5651
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7633 - acc: 0.5391
 640/1283 [=============>................] - ETA: 0s - loss: 0.7560 - acc: 0.5375
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7510 - acc: 0.5398
 768/1283 [================>.............] - ETA: 0s - loss: 0.7504 - acc: 0.5352
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7418 - acc: 0.5357
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7364 - acc: 0.5371
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7321 - acc: 0.5382
1280/1283 [============================>.] - ETA: 0s - loss: 0.7295 - acc: 0.5352
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7297 - acc: 0.5347 - val_loss: 0.7187 - val_acc: 0.5066

Epoch 00001: val_acc improved from -inf to 0.50655, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5445 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5705 - acc: 0.7344
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5730 - acc: 0.7375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5838 - acc: 0.7121
 576/1283 [============>.................] - ETA: 0s - loss: 0.5878 - acc: 0.7083
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5837 - acc: 0.7045
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5771 - acc: 0.7200
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5739 - acc: 0.7198
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5724 - acc: 0.7169
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5704 - acc: 0.7089
1283/1283 [==============================] - 1s 678us/step - loss: 0.5675 - acc: 0.7124 - val_loss: 0.7647 - val_acc: 0.5459

Epoch 00002: val_acc improved from 0.50655 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5200 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4915 - acc: 0.7760
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4761 - acc: 0.7875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4692 - acc: 0.8058
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4658 - acc: 0.8145
 640/1283 [=============>................] - ETA: 0s - loss: 0.4550 - acc: 0.8187
 768/1283 [================>.............] - ETA: 0s - loss: 0.4539 - acc: 0.8138
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4537 - acc: 0.8058
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4477 - acc: 0.8115
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4473 - acc: 0.8056
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4463 - acc: 0.8067
1280/1283 [============================>.] - ETA: 0s - loss: 0.4426 - acc: 0.8102
1283/1283 [==============================] - 1s 748us/step - loss: 0.4428 - acc: 0.8106 - val_loss: 0.7654 - val_acc: 0.5633

Epoch 00003: val_acc improved from 0.54585 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2574 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.3132 - acc: 0.8984
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3383 - acc: 0.8789
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3384 - acc: 0.8698
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3419 - acc: 0.8661
 576/1283 [============>.................] - ETA: 0s - loss: 0.3516 - acc: 0.8594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3577 - acc: 0.8480
 768/1283 [================>.............] - ETA: 0s - loss: 0.3641 - acc: 0.8424
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3688 - acc: 0.8359
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3655 - acc: 0.8330
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3602 - acc: 0.8359
1280/1283 [============================>.] - ETA: 0s - loss: 0.3595 - acc: 0.8352
1283/1283 [==============================] - 1s 691us/step - loss: 0.3605 - acc: 0.8340 - val_loss: 0.8476 - val_acc: 0.5983

Epoch 00004: val_acc improved from 0.56332 to 0.59825, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2552 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2837 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3593 - acc: 0.8031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3488 - acc: 0.8237
 576/1283 [============>.................] - ETA: 0s - loss: 0.3367 - acc: 0.8351
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3294 - acc: 0.8423
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3202 - acc: 0.8462
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3201 - acc: 0.8458
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3190 - acc: 0.8502
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3160 - acc: 0.8544
1283/1283 [==============================] - 1s 568us/step - loss: 0.3147 - acc: 0.8542 - val_loss: 0.8294 - val_acc: 0.6026

Epoch 00005: val_acc improved from 0.59825 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2086 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2068 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2446 - acc: 0.8938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2563 - acc: 0.8750
 576/1283 [============>.................] - ETA: 0s - loss: 0.2508 - acc: 0.8802
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2415 - acc: 0.8878
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2448 - acc: 0.8894
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2446 - acc: 0.8917
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2413 - acc: 0.8906
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2378 - acc: 0.8931
1283/1283 [==============================] - 1s 630us/step - loss: 0.2375 - acc: 0.8948 - val_loss: 0.9118 - val_acc: 0.6114

Epoch 00006: val_acc improved from 0.60262 to 0.61135, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1659 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1880 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1943 - acc: 0.9313
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1847 - acc: 0.9353
 576/1283 [============>.................] - ETA: 0s - loss: 0.1760 - acc: 0.9392
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1779 - acc: 0.9347
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1797 - acc: 0.9327
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1774 - acc: 0.9292
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1730 - acc: 0.9301
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1748 - acc: 0.9293
1283/1283 [==============================] - 1s 673us/step - loss: 0.1776 - acc: 0.9275 - val_loss: 1.1203 - val_acc: 0.5895

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1582 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1819 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1632 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1602 - acc: 0.9464
 576/1283 [============>.................] - ETA: 0s - loss: 0.1585 - acc: 0.9462
 768/1283 [================>.............] - ETA: 0s - loss: 0.1539 - acc: 0.9440
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1533 - acc: 0.9420
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1585 - acc: 0.9375
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1536 - acc: 0.9410
1280/1283 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9406
1283/1283 [==============================] - 1s 549us/step - loss: 0.1549 - acc: 0.9408 - val_loss: 1.1314 - val_acc: 0.5939

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0873 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1190 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1156 - acc: 0.9500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1149 - acc: 0.9509
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1178 - acc: 0.9512
 640/1283 [=============>................] - ETA: 0s - loss: 0.1272 - acc: 0.9453
 768/1283 [================>.............] - ETA: 0s - loss: 0.1237 - acc: 0.9453
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1196 - acc: 0.9495
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1196 - acc: 0.9510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1169 - acc: 0.9540
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1181 - acc: 0.9531
1283/1283 [==============================] - 1s 733us/step - loss: 0.1222 - acc: 0.9501 - val_loss: 1.2383 - val_acc: 0.5939

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1361 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.1144 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1198 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1100 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1148 - acc: 0.9397
 576/1283 [============>.................] - ETA: 0s - loss: 0.1093 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1032 - acc: 0.9503
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1070 - acc: 0.9471
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1015 - acc: 0.9521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1036 - acc: 0.9522
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1042 - acc: 0.9531
1283/1283 [==============================] - 1s 665us/step - loss: 0.1028 - acc: 0.9540 - val_loss: 1.4126 - val_acc: 0.5852

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1223 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1180 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1100 - acc: 0.9437
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0969 - acc: 0.9554
 576/1283 [============>.................] - ETA: 0s - loss: 0.0911 - acc: 0.9583
 640/1283 [=============>................] - ETA: 0s - loss: 0.0898 - acc: 0.9594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0897 - acc: 0.9602
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0927 - acc: 0.9603
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0902 - acc: 0.9615
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0939 - acc: 0.9577
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0910 - acc: 0.9589
1283/1283 [==============================] - 1s 689us/step - loss: 0.0904 - acc: 0.9587 - val_loss: 1.4667 - val_acc: 0.6070

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0915 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.0628 - acc: 0.9766
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0730 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0704 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0668 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.0731 - acc: 0.9705
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0750 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0755 - acc: 0.9651
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0811 - acc: 0.9604
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0815 - acc: 0.9614
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0852 - acc: 0.9601
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0831 - acc: 0.9613
1283/1283 [==============================] - 1s 765us/step - loss: 0.0824 - acc: 0.9602 - val_loss: 1.6147 - val_acc: 0.5764

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0791 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0881 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0823 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0858 - acc: 0.9576
 576/1283 [============>.................] - ETA: 0s - loss: 0.0815 - acc: 0.9618
 640/1283 [=============>................] - ETA: 0s - loss: 0.0785 - acc: 0.9641
 768/1283 [================>.............] - ETA: 0s - loss: 0.0774 - acc: 0.9635
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0777 - acc: 0.9621
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0798 - acc: 0.9600
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0807 - acc: 0.9622
1283/1283 [==============================] - 1s 593us/step - loss: 0.0842 - acc: 0.9610 - val_loss: 1.8509 - val_acc: 0.5852

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0624 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0729 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0698 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0638 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.0700 - acc: 0.9722
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0684 - acc: 0.9730
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0648 - acc: 0.9748
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0725 - acc: 0.9698
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0724 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0747 - acc: 0.9679
1283/1283 [==============================] - 1s 549us/step - loss: 0.0766 - acc: 0.9649 - val_loss: 1.7583 - val_acc: 0.5677

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0715 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0827 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0771 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0658 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0715 - acc: 0.9653
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0667 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0667 - acc: 0.9700
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0702 - acc: 0.9668
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0680 - acc: 0.9679
1283/1283 [==============================] - 1s 519us/step - loss: 0.0687 - acc: 0.9680 - val_loss: 1.8496 - val_acc: 0.5895

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0715 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0684 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0599 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0602 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.0653 - acc: 0.9618
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0601 - acc: 0.9645
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0593 - acc: 0.9663
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0583 - acc: 0.9677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0609 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0664 - acc: 0.9663
1283/1283 [==============================] - 1s 487us/step - loss: 0.0644 - acc: 0.9673 - val_loss: 1.8883 - val_acc: 0.5852

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5903790087463557
best_valid_accuracy=0.5539358600583091
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:29:07.814348: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 22s - loss: 0.7451 - acc: 0.5312
 128/1283 [=>............................] - ETA: 11s - loss: 0.8485 - acc: 0.5156
 256/1283 [====>.........................] - ETA: 5s - loss: 0.8225 - acc: 0.4961 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.8106 - acc: 0.4906
 448/1283 [=========>....................] - ETA: 2s - loss: 0.8018 - acc: 0.4732
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7918 - acc: 0.4844
 640/1283 [=============>................] - ETA: 1s - loss: 0.7770 - acc: 0.4953
 768/1283 [================>.............] - ETA: 1s - loss: 0.7648 - acc: 0.4987
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7543 - acc: 0.5112
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7499 - acc: 0.5188
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7412 - acc: 0.5257
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7337 - acc: 0.5304
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7338 - acc: 0.5308 - val_loss: 0.7216 - val_acc: 0.5328

Epoch 00001: val_acc improved from -inf to 0.53275, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5916 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5987 - acc: 0.6250
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6062 - acc: 0.6367
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6045 - acc: 0.6328
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5998 - acc: 0.6387
 640/1283 [=============>................] - ETA: 0s - loss: 0.5978 - acc: 0.6469
 768/1283 [================>.............] - ETA: 0s - loss: 0.5924 - acc: 0.6602
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5953 - acc: 0.6587
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5943 - acc: 0.6677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5916 - acc: 0.6857
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5903 - acc: 0.6867
1280/1283 [============================>.] - ETA: 0s - loss: 0.5887 - acc: 0.6875
1283/1283 [==============================] - 1s 717us/step - loss: 0.5889 - acc: 0.6867 - val_loss: 0.6794 - val_acc: 0.6026

Epoch 00002: val_acc improved from 0.53275 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4947 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5002 - acc: 0.7865
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5094 - acc: 0.7750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5099 - acc: 0.7746
 576/1283 [============>.................] - ETA: 0s - loss: 0.5073 - acc: 0.7622
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5053 - acc: 0.7543
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4979 - acc: 0.7596
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4991 - acc: 0.7583
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4963 - acc: 0.7617
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4935 - acc: 0.7665
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4903 - acc: 0.7697
1283/1283 [==============================] - 1s 694us/step - loss: 0.4904 - acc: 0.7670 - val_loss: 0.7070 - val_acc: 0.6026

Epoch 00003: val_acc improved from 0.60262 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3745 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3825 - acc: 0.8490
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3775 - acc: 0.8516
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3725 - acc: 0.8542
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3664 - acc: 0.8613
 576/1283 [============>.................] - ETA: 0s - loss: 0.3676 - acc: 0.8611
 640/1283 [=============>................] - ETA: 0s - loss: 0.3647 - acc: 0.8656
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3709 - acc: 0.8565
 768/1283 [================>.............] - ETA: 0s - loss: 0.3722 - acc: 0.8568
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3725 - acc: 0.8594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3661 - acc: 0.8643
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3674 - acc: 0.8602
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3712 - acc: 0.8561
1280/1283 [============================>.] - ETA: 0s - loss: 0.3686 - acc: 0.8562
1283/1283 [==============================] - 1s 924us/step - loss: 0.3686 - acc: 0.8566 - val_loss: 0.8322 - val_acc: 0.5764

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2852 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.2973 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3044 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2947 - acc: 0.8945
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2919 - acc: 0.8828
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2992 - acc: 0.8770
 640/1283 [=============>................] - ETA: 0s - loss: 0.2894 - acc: 0.8875
 768/1283 [================>.............] - ETA: 0s - loss: 0.2920 - acc: 0.8867
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2929 - acc: 0.8873
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2962 - acc: 0.8867
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2951 - acc: 0.8842
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2916 - acc: 0.8832
1283/1283 [==============================] - 1s 766us/step - loss: 0.2893 - acc: 0.8839 - val_loss: 1.0523 - val_acc: 0.5895

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2163 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2350 - acc: 0.9115
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2219 - acc: 0.9187
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2223 - acc: 0.9115
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2270 - acc: 0.9102
 576/1283 [============>.................] - ETA: 0s - loss: 0.2268 - acc: 0.9115
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2212 - acc: 0.9148
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2153 - acc: 0.9123
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2132 - acc: 0.9156
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2146 - acc: 0.9136
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2090 - acc: 0.9178
1283/1283 [==============================] - 1s 648us/step - loss: 0.2075 - acc: 0.9197 - val_loss: 1.2877 - val_acc: 0.5721

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2402 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2831 - acc: 0.8359
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2748 - acc: 0.8516
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2743 - acc: 0.8527
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2776 - acc: 0.8555
 640/1283 [=============>................] - ETA: 0s - loss: 0.2698 - acc: 0.8609
 768/1283 [================>.............] - ETA: 0s - loss: 0.2576 - acc: 0.8724
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2548 - acc: 0.8772
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2559 - acc: 0.8799
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2483 - acc: 0.8837
1280/1283 [============================>.] - ETA: 0s - loss: 0.2462 - acc: 0.8852
1283/1283 [==============================] - 1s 692us/step - loss: 0.2462 - acc: 0.8846 - val_loss: 1.1017 - val_acc: 0.5764

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1869 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1613 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1555 - acc: 0.9344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1512 - acc: 0.9330
 640/1283 [=============>................] - ETA: 0s - loss: 0.1570 - acc: 0.9297
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1558 - acc: 0.9347
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1513 - acc: 0.9375
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1481 - acc: 0.9396
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1490 - acc: 0.9395
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1478 - acc: 0.9375
1280/1283 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9367
1283/1283 [==============================] - 1s 664us/step - loss: 0.1507 - acc: 0.9369 - val_loss: 1.2386 - val_acc: 0.5852

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1364 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.1620 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1228 - acc: 0.9500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1222 - acc: 0.9442
 576/1283 [============>.................] - ETA: 0s - loss: 0.1266 - acc: 0.9444
 640/1283 [=============>................] - ETA: 0s - loss: 0.1232 - acc: 0.9484
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1228 - acc: 0.9517
 768/1283 [================>.............] - ETA: 0s - loss: 0.1198 - acc: 0.9531
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1236 - acc: 0.9483
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1223 - acc: 0.9509
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1184 - acc: 0.9531
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1149 - acc: 0.9539
1280/1283 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9531
1283/1283 [==============================] - 1s 730us/step - loss: 0.1180 - acc: 0.9532 - val_loss: 1.3478 - val_acc: 0.5983

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1714 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1315 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1220 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1164 - acc: 0.9509
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1156 - acc: 0.9512
 640/1283 [=============>................] - ETA: 0s - loss: 0.1122 - acc: 0.9531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1093 - acc: 0.9560
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1071 - acc: 0.9579
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1051 - acc: 0.9573
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1066 - acc: 0.9557
1280/1283 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9578
1283/1283 [==============================] - 1s 635us/step - loss: 0.1054 - acc: 0.9579 - val_loss: 1.4674 - val_acc: 0.5633

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0793 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0950 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0803 - acc: 0.9625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0820 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0900 - acc: 0.9570
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0866 - acc: 0.9616
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0900 - acc: 0.9579
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0905 - acc: 0.9587
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0925 - acc: 0.9563
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0906 - acc: 0.9586
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0888 - acc: 0.9597
1283/1283 [==============================] - 1s 649us/step - loss: 0.0888 - acc: 0.9610 - val_loss: 1.5779 - val_acc: 0.5808

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0808 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.0792 - acc: 0.9609
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0786 - acc: 0.9648
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0753 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0841 - acc: 0.9668
 576/1283 [============>.................] - ETA: 0s - loss: 0.0861 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.0817 - acc: 0.9656
 768/1283 [================>.............] - ETA: 0s - loss: 0.0853 - acc: 0.9635
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0811 - acc: 0.9676
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0805 - acc: 0.9668
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0827 - acc: 0.9661
1280/1283 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9641
1283/1283 [==============================] - 1s 699us/step - loss: 0.0850 - acc: 0.9641 - val_loss: 1.6295 - val_acc: 0.5633

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1057 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.0992 - acc: 0.9453
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0834 - acc: 0.9570
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0758 - acc: 0.9635
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0758 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.0745 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0814 - acc: 0.9645
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0800 - acc: 0.9651
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0796 - acc: 0.9646
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0767 - acc: 0.9668
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0771 - acc: 0.9661
1280/1283 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9656
1283/1283 [==============================] - 1s 749us/step - loss: 0.0768 - acc: 0.9657 - val_loss: 1.7475 - val_acc: 0.5502

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=110
accuracy=0.5830903790087464
best_valid_accuracy=0.532069970845481
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:41:57.693755: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 10s - loss: 0.7846 - acc: 0.3594
 128/1283 [=>............................] - ETA: 7s - loss: 0.8810 - acc: 0.4844 /afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.110790). Check your callbacks.
  % delta_t_median)

 192/1283 [===>..........................] - ETA: 5s - loss: 0.9020 - acc: 0.4896
 256/1283 [====>.........................] - ETA: 4s - loss: 0.8534 - acc: 0.5078
 320/1283 [======>.......................] - ETA: 3s - loss: 0.8184 - acc: 0.5156
 384/1283 [=======>......................] - ETA: 2s - loss: 0.8428 - acc: 0.5208
 448/1283 [=========>....................] - ETA: 2s - loss: 0.8862 - acc: 0.5112
 512/1283 [==========>...................] - ETA: 2s - loss: 0.8813 - acc: 0.5117
 576/1283 [============>.................] - ETA: 1s - loss: 0.8564 - acc: 0.5226
 640/1283 [=============>................] - ETA: 1s - loss: 0.8457 - acc: 0.5250
 704/1283 [===============>..............] - ETA: 1s - loss: 0.8375 - acc: 0.5227
 768/1283 [================>.............] - ETA: 1s - loss: 0.8274 - acc: 0.5247
 832/1283 [==================>...........] - ETA: 0s - loss: 0.8306 - acc: 0.5180
 896/1283 [===================>..........] - ETA: 0s - loss: 0.8244 - acc: 0.5212
 960/1283 [=====================>........] - ETA: 0s - loss: 0.8204 - acc: 0.5188
1024/1283 [======================>.......] - ETA: 0s - loss: 0.8147 - acc: 0.5195
1088/1283 [========================>.....] - ETA: 0s - loss: 0.8076 - acc: 0.5211
1152/1283 [=========================>....] - ETA: 0s - loss: 0.8007 - acc: 0.5217
1280/1283 [============================>.] - ETA: 0s - loss: 0.7887 - acc: 0.5305
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7886 - acc: 0.5292 - val_loss: 0.7347 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6434 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6340 - acc: 0.6146
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6301 - acc: 0.6250
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6274 - acc: 0.6219
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6277 - acc: 0.6354
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6244 - acc: 0.6621
 576/1283 [============>.................] - ETA: 0s - loss: 0.6251 - acc: 0.6701
 640/1283 [=============>................] - ETA: 0s - loss: 0.6243 - acc: 0.6766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6235 - acc: 0.6875
 768/1283 [================>.............] - ETA: 0s - loss: 0.6211 - acc: 0.6966
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6219 - acc: 0.6959
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6196 - acc: 0.6964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6214 - acc: 0.6917
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6213 - acc: 0.6885
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6184 - acc: 0.6921
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6130 - acc: 0.7007
1280/1283 [============================>.] - ETA: 0s - loss: 0.6114 - acc: 0.7008
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6112 - acc: 0.7007 - val_loss: 0.7599 - val_acc: 0.5546

Epoch 00002: val_acc improved from 0.52838 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5614 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.5371 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5393 - acc: 0.7760
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5303 - acc: 0.7812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5311 - acc: 0.7734
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5300 - acc: 0.7679
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5289 - acc: 0.7539
 640/1283 [=============>................] - ETA: 0s - loss: 0.5268 - acc: 0.7625
 768/1283 [================>.............] - ETA: 0s - loss: 0.5217 - acc: 0.7643
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5120 - acc: 0.7723
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5115 - acc: 0.7695
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5123 - acc: 0.7656
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5119 - acc: 0.7656
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5114 - acc: 0.7656
1280/1283 [============================>.] - ETA: 0s - loss: 0.5123 - acc: 0.7633
1283/1283 [==============================] - 1s 975us/step - loss: 0.5123 - acc: 0.7631 - val_loss: 0.7439 - val_acc: 0.5240

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3992 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.3819 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3791 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3773 - acc: 0.8477
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3805 - acc: 0.8469
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3728 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3855 - acc: 0.8527
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3824 - acc: 0.8457
 640/1283 [=============>................] - ETA: 0s - loss: 0.3838 - acc: 0.8500
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3939 - acc: 0.8395
 768/1283 [================>.............] - ETA: 0s - loss: 0.3923 - acc: 0.8411
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3878 - acc: 0.8438
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3851 - acc: 0.8449
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3801 - acc: 0.8486
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3799 - acc: 0.8483
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3793 - acc: 0.8462
1280/1283 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8422
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3792 - acc: 0.8426 - val_loss: 0.7886 - val_acc: 0.5328

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3187 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.2766 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2977 - acc: 0.8646
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2851 - acc: 0.8711
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2806 - acc: 0.8719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2708 - acc: 0.8795
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2681 - acc: 0.8867
 576/1283 [============>.................] - ETA: 0s - loss: 0.2688 - acc: 0.8889
 640/1283 [=============>................] - ETA: 0s - loss: 0.2629 - acc: 0.8938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2663 - acc: 0.8920
 768/1283 [================>.............] - ETA: 0s - loss: 0.2625 - acc: 0.8971
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2627 - acc: 0.8978
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2625 - acc: 0.8962
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2639 - acc: 0.8948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2666 - acc: 0.8915
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2677 - acc: 0.8898
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2633 - acc: 0.8914
1280/1283 [============================>.] - ETA: 0s - loss: 0.2653 - acc: 0.8883
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2649 - acc: 0.8885 - val_loss: 0.8865 - val_acc: 0.5764

Epoch 00005: val_acc improved from 0.55459 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2490 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.2234 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2113 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2104 - acc: 0.9250
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2182 - acc: 0.9141
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2155 - acc: 0.9107
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2065 - acc: 0.9160
 576/1283 [============>.................] - ETA: 0s - loss: 0.2026 - acc: 0.9184
 640/1283 [=============>................] - ETA: 0s - loss: 0.2155 - acc: 0.9062
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2132 - acc: 0.9091
 768/1283 [================>.............] - ETA: 0s - loss: 0.2121 - acc: 0.9128
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2101 - acc: 0.9147
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2078 - acc: 0.9163
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2051 - acc: 0.9187
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2032 - acc: 0.9180
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2001 - acc: 0.9219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1962 - acc: 0.9253
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1966 - acc: 0.9235
1280/1283 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9242
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1947 - acc: 0.9244 - val_loss: 1.0525 - val_acc: 0.5415

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1052 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1226 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1413 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1376 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1496 - acc: 0.9420
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1469 - acc: 0.9434
 576/1283 [============>.................] - ETA: 0s - loss: 0.1384 - acc: 0.9479
 640/1283 [=============>................] - ETA: 0s - loss: 0.1399 - acc: 0.9469
 768/1283 [================>.............] - ETA: 0s - loss: 0.1404 - acc: 0.9466
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1365 - acc: 0.9498
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1333 - acc: 0.9531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1336 - acc: 0.9521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1366 - acc: 0.9494
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1394 - acc: 0.9497
1280/1283 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9492
1283/1283 [==============================] - 1s 913us/step - loss: 0.1393 - acc: 0.9486 - val_loss: 1.3117 - val_acc: 0.5633

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0879 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.1037 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1254 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1122 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1165 - acc: 0.9609
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1209 - acc: 0.9551
 576/1283 [============>.................] - ETA: 0s - loss: 0.1199 - acc: 0.9566
 640/1283 [=============>................] - ETA: 0s - loss: 0.1185 - acc: 0.9594
 768/1283 [================>.............] - ETA: 0s - loss: 0.1210 - acc: 0.9544
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1240 - acc: 0.9495
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1182 - acc: 0.9531
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1220 - acc: 0.9522
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1273 - acc: 0.9457
1283/1283 [==============================] - 1s 811us/step - loss: 0.1287 - acc: 0.9447 - val_loss: 1.4108 - val_acc: 0.5590

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0956 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1128 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1066 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1114 - acc: 0.9563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1168 - acc: 0.9464
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1186 - acc: 0.9453
 640/1283 [=============>................] - ETA: 0s - loss: 0.1214 - acc: 0.9406
 768/1283 [================>.............] - ETA: 0s - loss: 0.1177 - acc: 0.9440
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1175 - acc: 0.9459
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1132 - acc: 0.9490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1129 - acc: 0.9482
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1144 - acc: 0.9479
1280/1283 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9508
1283/1283 [==============================] - 1s 919us/step - loss: 0.1105 - acc: 0.9509 - val_loss: 1.5369 - val_acc: 0.5677

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1147 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1346 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1128 - acc: 0.9469
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0990 - acc: 0.9576
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0988 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.0972 - acc: 0.9601
 640/1283 [=============>................] - ETA: 0s - loss: 0.0967 - acc: 0.9594
 768/1283 [================>.............] - ETA: 0s - loss: 0.0961 - acc: 0.9583
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0960 - acc: 0.9579
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0948 - acc: 0.9576
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0879 - acc: 0.9619
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0881 - acc: 0.9614
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0881 - acc: 0.9618
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0906 - acc: 0.9597
1280/1283 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9609
1283/1283 [==============================] - 1s 981us/step - loss: 0.0887 - acc: 0.9610 - val_loss: 1.7029 - val_acc: 0.5415

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0870 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0932 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0889 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0934 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0938 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0889 - acc: 0.9509
 576/1283 [============>.................] - ETA: 0s - loss: 0.0838 - acc: 0.9514
 640/1283 [=============>................] - ETA: 0s - loss: 0.0783 - acc: 0.9563
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0771 - acc: 0.9588
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0780 - acc: 0.9591
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0733 - acc: 0.9621
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0728 - acc: 0.9625
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0724 - acc: 0.9642
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0739 - acc: 0.9655
1283/1283 [==============================] - 1s 967us/step - loss: 0.0765 - acc: 0.9641 - val_loss: 1.8084 - val_acc: 0.5328

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0573 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0519 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0522 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0568 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0627 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0662 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0680 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0644 - acc: 0.9712
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0654 - acc: 0.9710
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0648 - acc: 0.9708
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0673 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0662 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9656
1283/1283 [==============================] - 1s 839us/step - loss: 0.0715 - acc: 0.9657 - val_loss: 1.8655 - val_acc: 0.5415

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1571 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.1227 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0965 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0906 - acc: 0.9492
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0920 - acc: 0.9500
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0788 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0767 - acc: 0.9609
 576/1283 [============>.................] - ETA: 0s - loss: 0.0701 - acc: 0.9653
 640/1283 [=============>................] - ETA: 0s - loss: 0.0730 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0700 - acc: 0.9659
 768/1283 [================>.............] - ETA: 0s - loss: 0.0732 - acc: 0.9622
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0727 - acc: 0.9627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0745 - acc: 0.9625
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0717 - acc: 0.9651
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0704 - acc: 0.9661
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0687 - acc: 0.9671
1280/1283 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9672
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0685 - acc: 0.9673 - val_loss: 2.0004 - val_acc: 0.5546

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0520 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0543 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0814 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0820 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0835 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.0853 - acc: 0.9656
 768/1283 [================>.............] - ETA: 0s - loss: 0.0868 - acc: 0.9661
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0857 - acc: 0.9654
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0822 - acc: 0.9668
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0824 - acc: 0.9661
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0841 - acc: 0.9646
1280/1283 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9617
1283/1283 [==============================] - 1s 805us/step - loss: 0.0880 - acc: 0.9618 - val_loss: 2.0651 - val_acc: 0.5284

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1144 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.0913 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0830 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0884 - acc: 0.9594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0870 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0878 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.0788 - acc: 0.9653
 640/1283 [=============>................] - ETA: 0s - loss: 0.0736 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0775 - acc: 0.9645
 768/1283 [================>.............] - ETA: 0s - loss: 0.0745 - acc: 0.9674
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0733 - acc: 0.9676
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0735 - acc: 0.9658
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0789 - acc: 0.9635
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0796 - acc: 0.9622
1280/1283 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9617
1283/1283 [==============================] - 1s 886us/step - loss: 0.0796 - acc: 0.9610 - val_loss: 2.1055 - val_acc: 0.5240

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=30
PCA visual=10
PCA text=120
accuracy=0.5262390670553936
best_valid_accuracy=0.5670553935860059
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 23:53:15.535695: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 12s - loss: 0.6970 - acc: 0.5312
 128/1283 [=>............................] - ETA: 6s - loss: 0.7667 - acc: 0.5625 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.7609 - acc: 0.5365
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7624 - acc: 0.5234
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7517 - acc: 0.5365
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7631 - acc: 0.5268
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7707 - acc: 0.5195
 576/1283 [============>.................] - ETA: 1s - loss: 0.7625 - acc: 0.5226
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7482 - acc: 0.5327
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7385 - acc: 0.5433
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7330 - acc: 0.5427
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7278 - acc: 0.5506
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7287 - acc: 0.5403
1280/1283 [============================>.] - ETA: 0s - loss: 0.7248 - acc: 0.5406
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7248 - acc: 0.5409 - val_loss: 0.7100 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5700 - acc: 0.7656
 128/1283 [=>............................] - ETA: 0s - loss: 0.5768 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5812 - acc: 0.7422
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5769 - acc: 0.7500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5667 - acc: 0.7656
 576/1283 [============>.................] - ETA: 0s - loss: 0.5689 - acc: 0.7552
 640/1283 [=============>................] - ETA: 0s - loss: 0.5655 - acc: 0.7578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5647 - acc: 0.7557
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5591 - acc: 0.7584
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5560 - acc: 0.7510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5535 - acc: 0.7461
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5550 - acc: 0.7472
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5528 - acc: 0.7533
1280/1283 [============================>.] - ETA: 0s - loss: 0.5520 - acc: 0.7555
1283/1283 [==============================] - 1s 770us/step - loss: 0.5523 - acc: 0.7545 - val_loss: 0.7359 - val_acc: 0.5677

Epoch 00002: val_acc improved from 0.55022 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4573 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4721 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4602 - acc: 0.7930
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4445 - acc: 0.8177
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4401 - acc: 0.8242
 640/1283 [=============>................] - ETA: 0s - loss: 0.4325 - acc: 0.8344
 768/1283 [================>.............] - ETA: 0s - loss: 0.4261 - acc: 0.8451
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4192 - acc: 0.8504
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4178 - acc: 0.8486
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4151 - acc: 0.8474
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4163 - acc: 0.8413
1280/1283 [============================>.] - ETA: 0s - loss: 0.4153 - acc: 0.8406
1283/1283 [==============================] - 1s 753us/step - loss: 0.4154 - acc: 0.8402 - val_loss: 0.8492 - val_acc: 0.5895

Epoch 00003: val_acc improved from 0.56769 to 0.58952, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3543 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3754 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3497 - acc: 0.8531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3425 - acc: 0.8594
 576/1283 [============>.................] - ETA: 0s - loss: 0.3417 - acc: 0.8490
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3357 - acc: 0.8494
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3325 - acc: 0.8546
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3226 - acc: 0.8623
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3185 - acc: 0.8655
1280/1283 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.8664
1283/1283 [==============================] - 1s 612us/step - loss: 0.3154 - acc: 0.8667 - val_loss: 0.8338 - val_acc: 0.5633

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2562 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2393 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2374 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2222 - acc: 0.9323
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2282 - acc: 0.9263
 576/1283 [============>.................] - ETA: 0s - loss: 0.2263 - acc: 0.9219
 640/1283 [=============>................] - ETA: 0s - loss: 0.2263 - acc: 0.9187
 768/1283 [================>.............] - ETA: 0s - loss: 0.2227 - acc: 0.9219
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2197 - acc: 0.9219
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2191 - acc: 0.9198
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2230 - acc: 0.9145
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2202 - acc: 0.9137
1283/1283 [==============================] - 1s 711us/step - loss: 0.2235 - acc: 0.9104 - val_loss: 1.0498 - val_acc: 0.5852

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1718 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1756 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1805 - acc: 0.9156
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1745 - acc: 0.9196
 576/1283 [============>.................] - ETA: 0s - loss: 0.1767 - acc: 0.9236
 640/1283 [=============>................] - ETA: 0s - loss: 0.1750 - acc: 0.9250
 768/1283 [================>.............] - ETA: 0s - loss: 0.1711 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1700 - acc: 0.9291
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1701 - acc: 0.9302
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1686 - acc: 0.9292
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1660 - acc: 0.9314
1280/1283 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9281
1283/1283 [==============================] - 1s 775us/step - loss: 0.1721 - acc: 0.9283 - val_loss: 1.1761 - val_acc: 0.5721

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1580 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1622 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1797 - acc: 0.9258
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1539 - acc: 0.9401
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1434 - acc: 0.9395
 640/1283 [=============>................] - ETA: 0s - loss: 0.1384 - acc: 0.9391
 768/1283 [================>.............] - ETA: 0s - loss: 0.1379 - acc: 0.9401
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1402 - acc: 0.9397
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1342 - acc: 0.9443
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1285 - acc: 0.9479
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1282 - acc: 0.9474
1280/1283 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9484
1283/1283 [==============================] - 1s 692us/step - loss: 0.1269 - acc: 0.9486 - val_loss: 1.3446 - val_acc: 0.5590

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0746 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1145 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1063 - acc: 0.9563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1095 - acc: 0.9554
 576/1283 [============>.................] - ETA: 0s - loss: 0.1076 - acc: 0.9549
 640/1283 [=============>................] - ETA: 0s - loss: 0.1043 - acc: 0.9578
 768/1283 [================>.............] - ETA: 0s - loss: 0.0994 - acc: 0.9635
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0985 - acc: 0.9639
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0996 - acc: 0.9621
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1001 - acc: 0.9604
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0963 - acc: 0.9632
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0961 - acc: 0.9638
1280/1283 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9602
1283/1283 [==============================] - 1s 834us/step - loss: 0.0996 - acc: 0.9602 - val_loss: 1.4489 - val_acc: 0.5546

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0434 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0576 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0909 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0908 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0929 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0912 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0899 - acc: 0.9609
 640/1283 [=============>................] - ETA: 0s - loss: 0.0902 - acc: 0.9609
 768/1283 [================>.............] - ETA: 0s - loss: 0.0959 - acc: 0.9570
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1009 - acc: 0.9531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0960 - acc: 0.9570
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0956 - acc: 0.9575
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0972 - acc: 0.9564
1280/1283 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9578
1283/1283 [==============================] - 1s 840us/step - loss: 0.0947 - acc: 0.9579 - val_loss: 1.5108 - val_acc: 0.5284

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0522 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0650 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0725 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0745 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0754 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0713 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0726 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0695 - acc: 0.9766
 576/1283 [============>.................] - ETA: 0s - loss: 0.0715 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.0757 - acc: 0.9703
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0786 - acc: 0.9673
 768/1283 [================>.............] - ETA: 0s - loss: 0.0772 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0773 - acc: 0.9700
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0787 - acc: 0.9677
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0793 - acc: 0.9668
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0798 - acc: 0.9669
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0842 - acc: 0.9635
1280/1283 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9625
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0870 - acc: 0.9626 - val_loss: 1.6443 - val_acc: 0.5415

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1127 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0849 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0905 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0794 - acc: 0.9661
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0801 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.0772 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0793 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0780 - acc: 0.9675
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0771 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0750 - acc: 0.9707
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0792 - acc: 0.9688
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0792 - acc: 0.9671
1280/1283 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9633
1283/1283 [==============================] - 1s 813us/step - loss: 0.0822 - acc: 0.9634 - val_loss: 1.7375 - val_acc: 0.5852

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0262 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0721 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0679 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0683 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0737 - acc: 0.9648
 576/1283 [============>.................] - ETA: 0s - loss: 0.0695 - acc: 0.9653
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0662 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0723 - acc: 0.9603
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0754 - acc: 0.9594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0749 - acc: 0.9600
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0713 - acc: 0.9627
1280/1283 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9648
1283/1283 [==============================] - 1s 720us/step - loss: 0.0704 - acc: 0.9649 - val_loss: 1.7236 - val_acc: 0.5764

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0335 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0613 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0619 - acc: 0.9656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0635 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0660 - acc: 0.9629
 640/1283 [=============>................] - ETA: 0s - loss: 0.0707 - acc: 0.9578
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0705 - acc: 0.9588
 768/1283 [================>.............] - ETA: 0s - loss: 0.0741 - acc: 0.9596
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0761 - acc: 0.9603
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0720 - acc: 0.9635
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0694 - acc: 0.9648
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0693 - acc: 0.9651
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0711 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0720 - acc: 0.9638
1283/1283 [==============================] - 1s 834us/step - loss: 0.0713 - acc: 0.9641 - val_loss: 2.0260 - val_acc: 0.5633

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=10
PCA visual=30
PCA text=130
accuracy=0.5510204081632653
best_valid_accuracy=0.6064139941690962
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 00:11:15.433550: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 21s - loss: 0.9340 - acc: 0.3906
 128/1283 [=>............................] - ETA: 10s - loss: 0.9379 - acc: 0.4219
 256/1283 [====>.........................] - ETA: 5s - loss: 0.8274 - acc: 0.5078 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.7946 - acc: 0.5219
 384/1283 [=======>......................] - ETA: 3s - loss: 0.8103 - acc: 0.5026
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7870 - acc: 0.5059
 576/1283 [============>.................] - ETA: 2s - loss: 0.7783 - acc: 0.5069
 640/1283 [=============>................] - ETA: 1s - loss: 0.7730 - acc: 0.4984
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7634 - acc: 0.5071
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7593 - acc: 0.5036
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7572 - acc: 0.5033
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7505 - acc: 0.5094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7468 - acc: 0.5107
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7419 - acc: 0.5175
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7376 - acc: 0.5226
1280/1283 [============================>.] - ETA: 0s - loss: 0.7304 - acc: 0.5328
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7303 - acc: 0.5331 - val_loss: 0.7123 - val_acc: 0.5022

Epoch 00001: val_acc improved from -inf to 0.50218, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5726 - acc: 0.6719
 128/1283 [=>............................] - ETA: 1s - loss: 0.5801 - acc: 0.6797
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5890 - acc: 0.6510
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5789 - acc: 0.6758
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5784 - acc: 0.6750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5816 - acc: 0.6693
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5895 - acc: 0.6585
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5822 - acc: 0.6738
 576/1283 [============>.................] - ETA: 0s - loss: 0.5762 - acc: 0.6788
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5741 - acc: 0.6861
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5755 - acc: 0.6863
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5745 - acc: 0.6853
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5740 - acc: 0.6846
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5733 - acc: 0.6875
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5725 - acc: 0.6867
1280/1283 [============================>.] - ETA: 0s - loss: 0.5715 - acc: 0.6875
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5713 - acc: 0.6875 - val_loss: 0.7579 - val_acc: 0.5197

Epoch 00002: val_acc improved from 0.50218 to 0.51965, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4989 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.4902 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4669 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4661 - acc: 0.8398
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4702 - acc: 0.8156
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4705 - acc: 0.8151
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4663 - acc: 0.8192
 576/1283 [============>.................] - ETA: 0s - loss: 0.4652 - acc: 0.8125
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4637 - acc: 0.8082
 768/1283 [================>.............] - ETA: 0s - loss: 0.4681 - acc: 0.8034
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4681 - acc: 0.8047
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4681 - acc: 0.8052
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4602 - acc: 0.8107
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4578 - acc: 0.8084
1280/1283 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.8102
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4551 - acc: 0.8098 - val_loss: 0.8022 - val_acc: 0.5240

Epoch 00003: val_acc improved from 0.51965 to 0.52402, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3655 - acc: 0.8438
 128/1283 [=>............................] - ETA: 1s - loss: 0.3378 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3456 - acc: 0.8490
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3575 - acc: 0.8469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3638 - acc: 0.8307
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3818 - acc: 0.8086
 640/1283 [=============>................] - ETA: 0s - loss: 0.3822 - acc: 0.8063
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3783 - acc: 0.8097
 768/1283 [================>.............] - ETA: 0s - loss: 0.3810 - acc: 0.8073
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3753 - acc: 0.8137
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3749 - acc: 0.8177
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3703 - acc: 0.8235
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3703 - acc: 0.8238
1280/1283 [============================>.] - ETA: 0s - loss: 0.3692 - acc: 0.8250
1283/1283 [==============================] - 1s 822us/step - loss: 0.3694 - acc: 0.8246 - val_loss: 0.9132 - val_acc: 0.5764

Epoch 00004: val_acc improved from 0.52402 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_T_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3367 - acc: 0.8125
 128/1283 [=>............................] - ETA: 1s - loss: 0.3718 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3754 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3705 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3621 - acc: 0.8375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3408 - acc: 0.8516
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3326 - acc: 0.8549
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3183 - acc: 0.8633
 640/1283 [=============>................] - ETA: 0s - loss: 0.3124 - acc: 0.8625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3098 - acc: 0.8608
 768/1283 [================>.............] - ETA: 0s - loss: 0.3113 - acc: 0.8594
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3090 - acc: 0.8594
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3041 - acc: 0.8627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3094 - acc: 0.8615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3050 - acc: 0.8623
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3067 - acc: 0.8603
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3047 - acc: 0.8628
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3045 - acc: 0.8635
1280/1283 [============================>.] - ETA: 0s - loss: 0.3073 - acc: 0.8602
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3073 - acc: 0.8597 - val_loss: 0.9004 - val_acc: 0.5677

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2467 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2472 - acc: 0.8984
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2554 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2511 - acc: 0.9023
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2474 - acc: 0.8958
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2442 - acc: 0.8951
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2396 - acc: 0.8945
 576/1283 [============>.................] - ETA: 0s - loss: 0.2453 - acc: 0.8906
 640/1283 [=============>................] - ETA: 0s - loss: 0.2406 - acc: 0.8938
 768/1283 [================>.............] - ETA: 0s - loss: 0.2394 - acc: 0.8906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2363 - acc: 0.8942
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2322 - acc: 0.8958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2308 - acc: 0.8984
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2251 - acc: 0.9062
1280/1283 [============================>.] - ETA: 0s - loss: 0.2285 - acc: 0.9070
1283/1283 [==============================] - 1s 952us/step - loss: 0.2291 - acc: 0.9065 - val_loss: 1.0627 - val_acc: 0.5240

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1431 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1682 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1778 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1757 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1815 - acc: 0.9353
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1771 - acc: 0.9355
 576/1283 [============>.................] - ETA: 0s - loss: 0.1826 - acc: 0.9306
 640/1283 [=============>................] - ETA: 0s - loss: 0.1843 - acc: 0.9266
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1862 - acc: 0.9247
 768/1283 [================>.............] - ETA: 0s - loss: 0.1879 - acc: 0.9258
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1866 - acc: 0.9267
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1840 - acc: 0.9297
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1804 - acc: 0.9313
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1805 - acc: 0.9316
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1812 - acc: 0.9297
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1791 - acc: 0.9317
1280/1283 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9289
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1813 - acc: 0.9291 - val_loss: 1.3240 - val_acc: 0.5546

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1058 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.0924 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1111 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1167 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1217 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1304 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1364 - acc: 0.9473
 576/1283 [============>.................] - ETA: 0s - loss: 0.1331 - acc: 0.9514
 640/1283 [=============>................] - ETA: 0s - loss: 0.1356 - acc: 0.9469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1391 - acc: 0.9432
 768/1283 [================>.............] - ETA: 0s - loss: 0.1395 - acc: 0.9414
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1495 - acc: 0.9327
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1469 - acc: 0.9353
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1447 - acc: 0.9375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1435 - acc: 0.9365
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1414 - acc: 0.9375
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1410 - acc: 0.9383
1280/1283 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9391
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1402 - acc: 0.9392 - val_loss: 1.4836 - val_acc: 0.5502

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0890 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1103 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1355 - acc: 0.9500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1447 - acc: 0.9401
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1419 - acc: 0.9395
 576/1283 [============>.................] - ETA: 0s - loss: 0.1383 - acc: 0.9427
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1437 - acc: 0.9403
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1395 - acc: 0.9435
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1388 - acc: 0.9437
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1299 - acc: 0.9485
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1266 - acc: 0.9490
1283/1283 [==============================] - 1s 853us/step - loss: 0.1254 - acc: 0.9501 - val_loss: 1.6494 - val_acc: 0.5721

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0957 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.1052 - acc: 0.9609
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1048 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0940 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0950 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1026 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.1028 - acc: 0.9705
 640/1283 [=============>................] - ETA: 0s - loss: 0.0996 - acc: 0.9703
 768/1283 [================>.............] - ETA: 0s - loss: 0.0963 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0985 - acc: 0.9651
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1030 - acc: 0.9632
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1024 - acc: 0.9615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1026 - acc: 0.9619
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1023 - acc: 0.9614
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1043 - acc: 0.9618
1280/1283 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9609
1283/1283 [==============================] - 1s 992us/step - loss: 0.1041 - acc: 0.9602 - val_loss: 1.8123 - val_acc: 0.5633

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0391 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0820 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0812 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0861 - acc: 0.9656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0895 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0912 - acc: 0.9609
 576/1283 [============>.................] - ETA: 0s - loss: 0.0889 - acc: 0.9653
 640/1283 [=============>................] - ETA: 0s - loss: 0.0888 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0866 - acc: 0.9631
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0869 - acc: 0.9651
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0866 - acc: 0.9646
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0886 - acc: 0.9619
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0853 - acc: 0.9642
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0833 - acc: 0.9644
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0826 - acc: 0.9663
1280/1283 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9656
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0825 - acc: 0.9657 - val_loss: 1.9164 - val_acc: 0.5459

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0685 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0636 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0784 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0757 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0761 - acc: 0.9719
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0725 - acc: 0.9740
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0680 - acc: 0.9754
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0678 - acc: 0.9746
 576/1283 [============>.................] - ETA: 0s - loss: 0.0655 - acc: 0.9757
 640/1283 [=============>................] - ETA: 0s - loss: 0.0710 - acc: 0.9719
 768/1283 [================>.............] - ETA: 0s - loss: 0.0698 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0683 - acc: 0.9724
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0726 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0754 - acc: 0.9656
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0733 - acc: 0.9669
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0728 - acc: 0.9670
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0741 - acc: 0.9671
1280/1283 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9680
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0730 - acc: 0.9680 - val_loss: 2.0552 - val_acc: 0.5459

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0501 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0740 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0774 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0744 - acc: 0.9609
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0730 - acc: 0.9629
 640/1283 [=============>................] - ETA: 0s - loss: 0.0721 - acc: 0.9609
 768/1283 [================>.............] - ETA: 0s - loss: 0.0729 - acc: 0.9622
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0723 - acc: 0.9627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0743 - acc: 0.9615
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0721 - acc: 0.9632
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0699 - acc: 0.9638
1280/1283 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9625
1283/1283 [==============================] - 1s 742us/step - loss: 0.0744 - acc: 0.9626 - val_loss: 2.2731 - val_acc: 0.5328

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0532 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0461 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0612 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0795 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0830 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0730 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0717 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.0706 - acc: 0.9618
 640/1283 [=============>................] - ETA: 0s - loss: 0.0697 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0674 - acc: 0.9645
 768/1283 [================>.............] - ETA: 0s - loss: 0.0642 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0657 - acc: 0.9663
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0675 - acc: 0.9654
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0666 - acc: 0.9667
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0683 - acc: 0.9658
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0717 - acc: 0.9632
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0684 - acc: 0.9653
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0702 - acc: 0.9638
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0696 - acc: 0.9657 - val_loss: 2.3863 - val_acc: 0.5371

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=25
nodes=100
mode=T
PCA audio=10
PCA visual=30
PCA text=140
accuracy=0.532069970845481
best_valid_accuracy=0.5860058309037901
