/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:48:32.292370: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 26s - loss: 0.7218 - acc: 0.5000
 192/1283 [===>..........................] - ETA: 8s - loss: 0.7479 - acc: 0.5104 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.7279 - acc: 0.5281
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7463 - acc: 0.5268
 576/1283 [============>.................] - ETA: 2s - loss: 0.7484 - acc: 0.5330
 640/1283 [=============>................] - ETA: 1s - loss: 0.7416 - acc: 0.5375
 768/1283 [================>.............] - ETA: 1s - loss: 0.7423 - acc: 0.5286
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7351 - acc: 0.5223
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7316 - acc: 0.5264
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7251 - acc: 0.5330
1280/1283 [============================>.] - ETA: 0s - loss: 0.7251 - acc: 0.5258
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7249 - acc: 0.5261 - val_loss: 0.6889 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.6710 - acc: 0.5312
 128/1283 [=>............................] - ETA: 2s - loss: 0.6714 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 2s - loss: 0.6601 - acc: 0.5781
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6546 - acc: 0.5969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6574 - acc: 0.6004
 576/1283 [============>.................] - ETA: 0s - loss: 0.6588 - acc: 0.5955
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6588 - acc: 0.5980
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6597 - acc: 0.5986
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6624 - acc: 0.6010
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6619 - acc: 0.6039
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6619 - acc: 0.6024
1280/1283 [============================>.] - ETA: 0s - loss: 0.6675 - acc: 0.5938
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6679 - acc: 0.5931 - val_loss: 0.6821 - val_acc: 0.5677

Epoch 00002: val_acc improved from 0.53712 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6497 - acc: 0.5781
 128/1283 [=>............................] - ETA: 1s - loss: 0.6397 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6388 - acc: 0.6406
 256/1283 [====>.........................] - ETA: 2s - loss: 0.6392 - acc: 0.6406
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6353 - acc: 0.6536
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6301 - acc: 0.6602
 576/1283 [============>.................] - ETA: 0s - loss: 0.6313 - acc: 0.6580
 640/1283 [=============>................] - ETA: 0s - loss: 0.6311 - acc: 0.6594
 768/1283 [================>.............] - ETA: 0s - loss: 0.6327 - acc: 0.6484
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6305 - acc: 0.6484
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6327 - acc: 0.6438
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6317 - acc: 0.6445
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6316 - acc: 0.6425
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6328 - acc: 0.6389
1280/1283 [============================>.] - ETA: 0s - loss: 0.6373 - acc: 0.6273
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6370 - acc: 0.6274 - val_loss: 0.6944 - val_acc: 0.5764

Epoch 00003: val_acc improved from 0.56769 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5976 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.6325 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6175 - acc: 0.6680
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6213 - acc: 0.6667
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6234 - acc: 0.6621
 576/1283 [============>.................] - ETA: 0s - loss: 0.6219 - acc: 0.6701
 640/1283 [=============>................] - ETA: 0s - loss: 0.6194 - acc: 0.6750
 768/1283 [================>.............] - ETA: 0s - loss: 0.6254 - acc: 0.6628
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6231 - acc: 0.6629
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6196 - acc: 0.6641
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6150 - acc: 0.6701
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6130 - acc: 0.6735
1280/1283 [============================>.] - ETA: 0s - loss: 0.6116 - acc: 0.6742
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6115 - acc: 0.6742 - val_loss: 0.6727 - val_acc: 0.5895

Epoch 00004: val_acc improved from 0.57642 to 0.58952, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6143 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5841 - acc: 0.6979
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6014 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 1s - loss: 0.6045 - acc: 0.6656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5981 - acc: 0.6696
 576/1283 [============>.................] - ETA: 0s - loss: 0.5842 - acc: 0.6875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5869 - acc: 0.6818
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5830 - acc: 0.6863
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5882 - acc: 0.6844
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5880 - acc: 0.6857
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5858 - acc: 0.6892
1280/1283 [============================>.] - ETA: 0s - loss: 0.5884 - acc: 0.6875
1283/1283 [==============================] - 1s 833us/step - loss: 0.5883 - acc: 0.6875 - val_loss: 0.6889 - val_acc: 0.6026

Epoch 00005: val_acc improved from 0.58952 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4989 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5336 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5531 - acc: 0.7344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5625 - acc: 0.7135
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5692 - acc: 0.7090
 640/1283 [=============>................] - ETA: 0s - loss: 0.5598 - acc: 0.7219
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5583 - acc: 0.7259
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5599 - acc: 0.7200
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5580 - acc: 0.7188
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5610 - acc: 0.7142
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5613 - acc: 0.7109
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5604 - acc: 0.7105
1283/1283 [==============================] - 1s 731us/step - loss: 0.5606 - acc: 0.7132 - val_loss: 0.7091 - val_acc: 0.6070

Epoch 00006: val_acc improved from 0.60262 to 0.60699, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5461 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4869 - acc: 0.7865
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5099 - acc: 0.7406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5220 - acc: 0.7388
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5179 - acc: 0.7441
 640/1283 [=============>................] - ETA: 0s - loss: 0.5180 - acc: 0.7422
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5194 - acc: 0.7415
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5246 - acc: 0.7416
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5223 - acc: 0.7510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5260 - acc: 0.7472
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5240 - acc: 0.7484
1283/1283 [==============================] - 1s 656us/step - loss: 0.5268 - acc: 0.7451 - val_loss: 0.7336 - val_acc: 0.5939

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5423 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5097 - acc: 0.7396
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5078 - acc: 0.7312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5093 - acc: 0.7299
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5001 - acc: 0.7480
 640/1283 [=============>................] - ETA: 0s - loss: 0.5021 - acc: 0.7500
 768/1283 [================>.............] - ETA: 0s - loss: 0.5026 - acc: 0.7474
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4990 - acc: 0.7567
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5009 - acc: 0.7588
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5063 - acc: 0.7526
1280/1283 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.7508
1283/1283 [==============================] - 1s 919us/step - loss: 0.5043 - acc: 0.7514 - val_loss: 0.7199 - val_acc: 0.6026

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4427 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4649 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4768 - acc: 0.7656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4680 - acc: 0.7656
 576/1283 [============>.................] - ETA: 0s - loss: 0.4584 - acc: 0.7934
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4574 - acc: 0.7926
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4499 - acc: 0.7993
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4534 - acc: 0.7937
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4496 - acc: 0.7960
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4497 - acc: 0.7952
1280/1283 [============================>.] - ETA: 0s - loss: 0.4511 - acc: 0.7906
1283/1283 [==============================] - 1s 771us/step - loss: 0.4508 - acc: 0.7911 - val_loss: 0.7468 - val_acc: 0.6157

Epoch 00009: val_acc improved from 0.60699 to 0.61572, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4868 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4397 - acc: 0.8073
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4203 - acc: 0.8187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4257 - acc: 0.8147
 576/1283 [============>.................] - ETA: 0s - loss: 0.4257 - acc: 0.8090
 768/1283 [================>.............] - ETA: 0s - loss: 0.4227 - acc: 0.8138
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4190 - acc: 0.8125
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4178 - acc: 0.8125
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4176 - acc: 0.8135
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4200 - acc: 0.8107
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4244 - acc: 0.8067
1283/1283 [==============================] - 1s 837us/step - loss: 0.4235 - acc: 0.8090 - val_loss: 0.7558 - val_acc: 0.5677

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3748 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3608 - acc: 0.8698
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3620 - acc: 0.8711
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3749 - acc: 0.8542
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3712 - acc: 0.8516
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3803 - acc: 0.8395
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3910 - acc: 0.8293
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3913 - acc: 0.8208
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3915 - acc: 0.8223
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4004 - acc: 0.8143
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4057 - acc: 0.8100
1283/1283 [==============================] - 1s 903us/step - loss: 0.4024 - acc: 0.8145 - val_loss: 0.8228 - val_acc: 0.6114

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3091 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3474 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3528 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3650 - acc: 0.8281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3630 - acc: 0.8393
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3681 - acc: 0.8379
 576/1283 [============>.................] - ETA: 0s - loss: 0.3664 - acc: 0.8420
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3722 - acc: 0.8381
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3659 - acc: 0.8401
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3727 - acc: 0.8313
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3694 - acc: 0.8346
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3707 - acc: 0.8342
1280/1283 [============================>.] - ETA: 0s - loss: 0.3730 - acc: 0.8305
1283/1283 [==============================] - 1s 896us/step - loss: 0.3725 - acc: 0.8309 - val_loss: 0.8764 - val_acc: 0.5328

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3673 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.3756 - acc: 0.8047
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3688 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3584 - acc: 0.8375
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3464 - acc: 0.8464
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3691 - acc: 0.8281
 640/1283 [=============>................] - ETA: 0s - loss: 0.3641 - acc: 0.8344
 768/1283 [================>.............] - ETA: 0s - loss: 0.3558 - acc: 0.8438
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3564 - acc: 0.8460
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3516 - acc: 0.8486
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3516 - acc: 0.8464
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3488 - acc: 0.8495
1280/1283 [============================>.] - ETA: 0s - loss: 0.3490 - acc: 0.8484
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3521 - acc: 0.8472 - val_loss: 0.9280 - val_acc: 0.5983

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3267 - acc: 0.8281
 128/1283 [=>............................] - ETA: 0s - loss: 0.3329 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3347 - acc: 0.8333
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3258 - acc: 0.8500
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3288 - acc: 0.8594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3341 - acc: 0.8549
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3302 - acc: 0.8613
 640/1283 [=============>................] - ETA: 0s - loss: 0.3398 - acc: 0.8531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3429 - acc: 0.8523
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3380 - acc: 0.8570
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3349 - acc: 0.8583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3311 - acc: 0.8612
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3333 - acc: 0.8627
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3336 - acc: 0.8605 - val_loss: 0.8934 - val_acc: 0.5721

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.3560 - acc: 0.8438
 128/1283 [=>............................] - ETA: 2s - loss: 0.3698 - acc: 0.8047
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3801 - acc: 0.8021
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3794 - acc: 0.8187
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3599 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3598 - acc: 0.8393
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3505 - acc: 0.8516
 640/1283 [=============>................] - ETA: 0s - loss: 0.3437 - acc: 0.8516
 768/1283 [================>.............] - ETA: 0s - loss: 0.3395 - acc: 0.8503
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3317 - acc: 0.8571
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3352 - acc: 0.8555
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3314 - acc: 0.8576
1280/1283 [============================>.] - ETA: 0s - loss: 0.3253 - acc: 0.8625
1283/1283 [==============================] - 1s 981us/step - loss: 0.3261 - acc: 0.8620 - val_loss: 0.9362 - val_acc: 0.5677

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2600 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2419 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2544 - acc: 0.9258
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2544 - acc: 0.9281
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2532 - acc: 0.9245
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2663 - acc: 0.9141
 576/1283 [============>.................] - ETA: 0s - loss: 0.2673 - acc: 0.9115
 640/1283 [=============>................] - ETA: 0s - loss: 0.2631 - acc: 0.9141
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2651 - acc: 0.9105
 768/1283 [================>.............] - ETA: 0s - loss: 0.2711 - acc: 0.9036
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2713 - acc: 0.9029
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2730 - acc: 0.9021
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2713 - acc: 0.9007
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2745 - acc: 0.8988
1280/1283 [============================>.] - ETA: 0s - loss: 0.2733 - acc: 0.9000
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2733 - acc: 0.9002 - val_loss: 0.9151 - val_acc: 0.5721

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2593 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.2668 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2590 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2658 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2682 - acc: 0.9031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2691 - acc: 0.9010
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2592 - acc: 0.9040
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2597 - acc: 0.9023
 640/1283 [=============>................] - ETA: 0s - loss: 0.2563 - acc: 0.9062
 768/1283 [================>.............] - ETA: 0s - loss: 0.2584 - acc: 0.9062
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2519 - acc: 0.9118
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2470 - acc: 0.9150
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2456 - acc: 0.9132
1280/1283 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9164
1283/1283 [==============================] - 1s 837us/step - loss: 0.2444 - acc: 0.9166 - val_loss: 0.9816 - val_acc: 0.5895

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2331 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.2217 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2270 - acc: 0.9141
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2175 - acc: 0.9271
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2193 - acc: 0.9219
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2136 - acc: 0.9258
 576/1283 [============>.................] - ETA: 0s - loss: 0.2209 - acc: 0.9184
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2260 - acc: 0.9219
 768/1283 [================>.............] - ETA: 0s - loss: 0.2240 - acc: 0.9258
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2164 - acc: 0.9330
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2167 - acc: 0.9292
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2171 - acc: 0.9287
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2209 - acc: 0.9246
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2208 - acc: 0.9252
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2192 - acc: 0.9260 - val_loss: 1.0180 - val_acc: 0.5764

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1755 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1963 - acc: 0.9167
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1996 - acc: 0.9156
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1949 - acc: 0.9297
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1896 - acc: 0.9315
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1856 - acc: 0.9375
1283/1283 [==============================] - 0s 330us/step - loss: 0.1879 - acc: 0.9376 - val_loss: 1.0980 - val_acc: 0.5939

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5553935860058309
best_valid_accuracy=0.5466472303206997
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:56:09.149147: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 9s - loss: 0.8203 - acc: 0.3750
 192/1283 [===>..........................] - ETA: 4s - loss: 0.7888 - acc: 0.5000
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7604 - acc: 0.5094
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7413 - acc: 0.5179
 640/1283 [=============>................] - ETA: 0s - loss: 0.7265 - acc: 0.5234
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7158 - acc: 0.5481
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7117 - acc: 0.5490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7084 - acc: 0.5547
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7035 - acc: 0.5634
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7039 - acc: 0.5592
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7037 - acc: 0.5573 - val_loss: 0.7045 - val_acc: 0.5153

Epoch 00001: val_acc improved from -inf to 0.51528, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6491 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6484 - acc: 0.6302
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6321 - acc: 0.6641
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6395 - acc: 0.6380
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6437 - acc: 0.6183
 640/1283 [=============>................] - ETA: 0s - loss: 0.6440 - acc: 0.6172
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6382 - acc: 0.6310
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6350 - acc: 0.6426
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6368 - acc: 0.6423
1283/1283 [==============================] - 1s 666us/step - loss: 0.6330 - acc: 0.6485 - val_loss: 0.7174 - val_acc: 0.5328

Epoch 00002: val_acc improved from 0.51528 to 0.53275, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.5799 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5718 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5873 - acc: 0.6781
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5928 - acc: 0.6797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5857 - acc: 0.6932
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5925 - acc: 0.6803
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5922 - acc: 0.6792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5935 - acc: 0.6783
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5947 - acc: 0.6753
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5955 - acc: 0.6735
1283/1283 [==============================] - 1s 853us/step - loss: 0.5948 - acc: 0.6750 - val_loss: 0.7005 - val_acc: 0.5590

Epoch 00003: val_acc improved from 0.53275 to 0.55895, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5322 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.5586 - acc: 0.7109
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5464 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5505 - acc: 0.7281
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5686 - acc: 0.7031
 576/1283 [============>.................] - ETA: 0s - loss: 0.5605 - acc: 0.7135
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5658 - acc: 0.7060
 768/1283 [================>.............] - ETA: 0s - loss: 0.5616 - acc: 0.7122
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5571 - acc: 0.7163
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5534 - acc: 0.7199
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5554 - acc: 0.7167
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5498 - acc: 0.7215
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5533 - acc: 0.7188
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5595 - acc: 0.7122
1280/1283 [============================>.] - ETA: 0s - loss: 0.5601 - acc: 0.7133
1283/1283 [==============================] - 1s 1ms/step - loss: 0.5599 - acc: 0.7140 - val_loss: 0.7111 - val_acc: 0.5764

Epoch 00004: val_acc improved from 0.55895 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5194 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4995 - acc: 0.7656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5142 - acc: 0.7474
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5056 - acc: 0.7539
 640/1283 [=============>................] - ETA: 0s - loss: 0.5051 - acc: 0.7609
 768/1283 [================>.............] - ETA: 0s - loss: 0.5087 - acc: 0.7526
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5102 - acc: 0.7489
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5129 - acc: 0.7461
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5127 - acc: 0.7482
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5154 - acc: 0.7434
1283/1283 [==============================] - 1s 871us/step - loss: 0.5185 - acc: 0.7405 - val_loss: 0.7191 - val_acc: 0.5939

Epoch 00005: val_acc improved from 0.57642 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4950 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4837 - acc: 0.7734
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4598 - acc: 0.7943
 576/1283 [============>.................] - ETA: 0s - loss: 0.4632 - acc: 0.7899
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4588 - acc: 0.7940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4626 - acc: 0.7913
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4617 - acc: 0.7906
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4614 - acc: 0.7920
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4676 - acc: 0.7865
1280/1283 [============================>.] - ETA: 0s - loss: 0.4698 - acc: 0.7828
1283/1283 [==============================] - 1s 687us/step - loss: 0.4700 - acc: 0.7825 - val_loss: 0.7236 - val_acc: 0.5939

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4098 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4157 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4250 - acc: 0.8219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4249 - acc: 0.8177
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4242 - acc: 0.8192
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4279 - acc: 0.8242
 640/1283 [=============>................] - ETA: 0s - loss: 0.4362 - acc: 0.8125
 768/1283 [================>.............] - ETA: 0s - loss: 0.4394 - acc: 0.8112
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4401 - acc: 0.8136
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4389 - acc: 0.8105
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4376 - acc: 0.8125
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4367 - acc: 0.8084
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4344 - acc: 0.8114 - val_loss: 0.8210 - val_acc: 0.5852

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4519 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3970 - acc: 0.8177
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4012 - acc: 0.8094
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3938 - acc: 0.8262
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3919 - acc: 0.8310
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3804 - acc: 0.8438
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3837 - acc: 0.8396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3843 - acc: 0.8428
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3877 - acc: 0.8421
1280/1283 [============================>.] - ETA: 0s - loss: 0.3904 - acc: 0.8367
1283/1283 [==============================] - 1s 683us/step - loss: 0.3904 - acc: 0.8363 - val_loss: 0.7888 - val_acc: 0.5808

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3393 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3349 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3469 - acc: 0.8638
 640/1283 [=============>................] - ETA: 0s - loss: 0.3555 - acc: 0.8469
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3542 - acc: 0.8534
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3538 - acc: 0.8535
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3524 - acc: 0.8529
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3512 - acc: 0.8533
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3487 - acc: 0.8553
1283/1283 [==============================] - 1s 605us/step - loss: 0.3466 - acc: 0.8566 - val_loss: 0.8029 - val_acc: 0.6114

Epoch 00009: val_acc improved from 0.59389 to 0.61135, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2967 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2865 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3022 - acc: 0.8812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3133 - acc: 0.8750
 576/1283 [============>.................] - ETA: 0s - loss: 0.3106 - acc: 0.8715
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3127 - acc: 0.8665
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3074 - acc: 0.8714
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3098 - acc: 0.8708
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3156 - acc: 0.8686
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3175 - acc: 0.8672
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3184 - acc: 0.8676
1283/1283 [==============================] - 1s 886us/step - loss: 0.3191 - acc: 0.8691 - val_loss: 0.8451 - val_acc: 0.5808

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2863 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2827 - acc: 0.8958
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2762 - acc: 0.9031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2875 - acc: 0.8880
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2909 - acc: 0.8817
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2944 - acc: 0.8770
 576/1283 [============>.................] - ETA: 0s - loss: 0.3018 - acc: 0.8733
 640/1283 [=============>................] - ETA: 0s - loss: 0.3010 - acc: 0.8719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3038 - acc: 0.8665
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2976 - acc: 0.8738
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2941 - acc: 0.8792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2928 - acc: 0.8796
1280/1283 [============================>.] - ETA: 0s - loss: 0.2895 - acc: 0.8859
1283/1283 [==============================] - 1s 884us/step - loss: 0.2894 - acc: 0.8862 - val_loss: 1.0398 - val_acc: 0.5197

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2654 - acc: 0.8594
 128/1283 [=>............................] - ETA: 1s - loss: 0.2845 - acc: 0.8672
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2965 - acc: 0.8672
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2799 - acc: 0.8906
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2855 - acc: 0.8945
 576/1283 [============>.................] - ETA: 0s - loss: 0.2777 - acc: 0.8976
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2669 - acc: 0.9048
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2684 - acc: 0.9026
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2706 - acc: 0.8996
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2692 - acc: 0.8990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2686 - acc: 0.8994
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2661 - acc: 0.9002
1283/1283 [==============================] - 1s 867us/step - loss: 0.2693 - acc: 0.8971 - val_loss: 0.8984 - val_acc: 0.5764

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2217 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2254 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2145 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2103 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2099 - acc: 0.9397
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2172 - acc: 0.9336
 640/1283 [=============>................] - ETA: 0s - loss: 0.2106 - acc: 0.9359
 768/1283 [================>.............] - ETA: 0s - loss: 0.2085 - acc: 0.9362
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2124 - acc: 0.9330
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2136 - acc: 0.9313
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2143 - acc: 0.9301
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2159 - acc: 0.9276
1283/1283 [==============================] - 1s 857us/step - loss: 0.2144 - acc: 0.9283 - val_loss: 0.9794 - val_acc: 0.5721

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1511 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1949 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2064 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2066 - acc: 0.9576
 576/1283 [============>.................] - ETA: 0s - loss: 0.2138 - acc: 0.9444
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2101 - acc: 0.9503
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2070 - acc: 0.9495
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2004 - acc: 0.9500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2041 - acc: 0.9467
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2066 - acc: 0.9427
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2043 - acc: 0.9416
1283/1283 [==============================] - 1s 749us/step - loss: 0.2029 - acc: 0.9423 - val_loss: 0.9540 - val_acc: 0.5852

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2395 - acc: 0.9375
 128/1283 [=>............................] - ETA: 1s - loss: 0.1973 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1803 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1766 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1724 - acc: 0.9344
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1596 - acc: 0.9512
 640/1283 [=============>................] - ETA: 0s - loss: 0.1568 - acc: 0.9563
 768/1283 [================>.............] - ETA: 0s - loss: 0.1596 - acc: 0.9557
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1657 - acc: 0.9552
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1644 - acc: 0.9557
1283/1283 [==============================] - 1s 847us/step - loss: 0.1632 - acc: 0.9564 - val_loss: 1.0151 - val_acc: 0.5764

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1491 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1552 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1460 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1525 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1510 - acc: 0.9583
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1497 - acc: 0.9590
 640/1283 [=============>................] - ETA: 0s - loss: 0.1495 - acc: 0.9563
 768/1283 [================>.............] - ETA: 0s - loss: 0.1404 - acc: 0.9635
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1354 - acc: 0.9656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1378 - acc: 0.9619
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1372 - acc: 0.9623
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1350 - acc: 0.9630
1283/1283 [==============================] - 1s 840us/step - loss: 0.1342 - acc: 0.9626 - val_loss: 1.0514 - val_acc: 0.5764

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1214 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1033 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1018 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1048 - acc: 0.9740
 576/1283 [============>.................] - ETA: 0s - loss: 0.1081 - acc: 0.9792
 768/1283 [================>.............] - ETA: 0s - loss: 0.1040 - acc: 0.9805
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1064 - acc: 0.9788
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1090 - acc: 0.9775
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1090 - acc: 0.9783
1280/1283 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9797
1283/1283 [==============================] - 1s 763us/step - loss: 0.1119 - acc: 0.9782 - val_loss: 1.3011 - val_acc: 0.5459

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1606 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.2586 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3008 - acc: 0.8542
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2658 - acc: 0.8750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2294 - acc: 0.9036
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2433 - acc: 0.8945
 640/1283 [=============>................] - ETA: 0s - loss: 0.2456 - acc: 0.8953
 768/1283 [================>.............] - ETA: 0s - loss: 0.2319 - acc: 0.9076
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2277 - acc: 0.9111
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2238 - acc: 0.9129
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2237 - acc: 0.9189
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2240 - acc: 0.9141
1280/1283 [============================>.] - ETA: 0s - loss: 0.2192 - acc: 0.9172
1283/1283 [==============================] - 1s 847us/step - loss: 0.2200 - acc: 0.9166 - val_loss: 1.1524 - val_acc: 0.5677

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1724 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1872 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1777 - acc: 0.9469
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1724 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1767 - acc: 0.9464
 576/1283 [============>.................] - ETA: 0s - loss: 0.1752 - acc: 0.9427
 640/1283 [=============>................] - ETA: 0s - loss: 0.1832 - acc: 0.9375
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1808 - acc: 0.9435
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1822 - acc: 0.9404
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1790 - acc: 0.9424
1283/1283 [==============================] - 1s 663us/step - loss: 0.1772 - acc: 0.9447 - val_loss: 1.1186 - val_acc: 0.5808

Epoch 00019: val_acc did not improve
Epoch 00019: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=15
PCA text=100
accuracy=0.5495626822157434
best_valid_accuracy=0.5189504373177842
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:09:09.807856: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.7341 - acc: 0.5156
 192/1283 [===>..........................] - ETA: 2s - loss: 0.7286 - acc: 0.5156
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7163 - acc: 0.5219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7085 - acc: 0.5491
 576/1283 [============>.................] - ETA: 0s - loss: 0.7177 - acc: 0.5365
 768/1283 [================>.............] - ETA: 0s - loss: 0.7101 - acc: 0.5443
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7108 - acc: 0.5406
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7198 - acc: 0.5312
1280/1283 [============================>.] - ETA: 0s - loss: 0.7182 - acc: 0.5266
1283/1283 [==============================] - 1s 724us/step - loss: 0.7188 - acc: 0.5269 - val_loss: 0.7104 - val_acc: 0.5371

Epoch 00001: val_acc improved from -inf to 0.53712, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6159 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6152 - acc: 0.6302
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6101 - acc: 0.6406
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5985 - acc: 0.6540
 576/1283 [============>.................] - ETA: 0s - loss: 0.5891 - acc: 0.6684
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6029 - acc: 0.6548
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6062 - acc: 0.6514
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6121 - acc: 0.6490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6170 - acc: 0.6445
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6172 - acc: 0.6461
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6188 - acc: 0.6450
1280/1283 [============================>.] - ETA: 0s - loss: 0.6187 - acc: 0.6430
1283/1283 [==============================] - 1s 824us/step - loss: 0.6190 - acc: 0.6430 - val_loss: 0.6868 - val_acc: 0.5808

Epoch 00002: val_acc improved from 0.53712 to 0.58079, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6378 - acc: 0.6719
 128/1283 [=>............................] - ETA: 1s - loss: 0.6286 - acc: 0.6484
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6018 - acc: 0.6680
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6260 - acc: 0.6594
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6227 - acc: 0.6615
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6062 - acc: 0.6738
 640/1283 [=============>................] - ETA: 0s - loss: 0.5969 - acc: 0.6875
 768/1283 [================>.............] - ETA: 0s - loss: 0.5951 - acc: 0.6823
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5953 - acc: 0.6808
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5954 - acc: 0.6813
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5935 - acc: 0.6826
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5942 - acc: 0.6820
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5895 - acc: 0.6834
1280/1283 [============================>.] - ETA: 0s - loss: 0.5877 - acc: 0.6844
1283/1283 [==============================] - 1s 865us/step - loss: 0.5882 - acc: 0.6836 - val_loss: 0.7232 - val_acc: 0.5590

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5726 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5231 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5164 - acc: 0.7734
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5340 - acc: 0.7526
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5426 - acc: 0.7422
 640/1283 [=============>................] - ETA: 0s - loss: 0.5346 - acc: 0.7281
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5189 - acc: 0.7440
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5282 - acc: 0.7354
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5237 - acc: 0.7418
1283/1283 [==============================] - 1s 784us/step - loss: 0.5234 - acc: 0.7405 - val_loss: 0.7193 - val_acc: 0.5764

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4694 - acc: 0.7344
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4605 - acc: 0.7760
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4583 - acc: 0.7781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4523 - acc: 0.7924
 576/1283 [============>.................] - ETA: 0s - loss: 0.4569 - acc: 0.7882
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4615 - acc: 0.7798
 768/1283 [================>.............] - ETA: 0s - loss: 0.4642 - acc: 0.7786
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4616 - acc: 0.7788
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4658 - acc: 0.7812
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4631 - acc: 0.7833
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4678 - acc: 0.7822
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4681 - acc: 0.7821
1283/1283 [==============================] - 1s 734us/step - loss: 0.4673 - acc: 0.7825 - val_loss: 0.8310 - val_acc: 0.5197

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4812 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4481 - acc: 0.8008
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4522 - acc: 0.7943
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4580 - acc: 0.7852
 640/1283 [=============>................] - ETA: 0s - loss: 0.4563 - acc: 0.7922
 768/1283 [================>.............] - ETA: 0s - loss: 0.4561 - acc: 0.7917
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4525 - acc: 0.7924
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4512 - acc: 0.7906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4467 - acc: 0.7950
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4470 - acc: 0.7944
1283/1283 [==============================] - 1s 797us/step - loss: 0.4447 - acc: 0.7973 - val_loss: 0.7771 - val_acc: 0.5590

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3504 - acc: 0.8750
 128/1283 [=>............................] - ETA: 1s - loss: 0.3631 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3550 - acc: 0.8828
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3399 - acc: 0.8938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3433 - acc: 0.8958
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3486 - acc: 0.8750
 640/1283 [=============>................] - ETA: 0s - loss: 0.3615 - acc: 0.8609
 768/1283 [================>.............] - ETA: 0s - loss: 0.3662 - acc: 0.8529
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3674 - acc: 0.8546
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3708 - acc: 0.8521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3778 - acc: 0.8447
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3809 - acc: 0.8429
1283/1283 [==============================] - 1s 857us/step - loss: 0.3795 - acc: 0.8441 - val_loss: 0.7730 - val_acc: 0.5764

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2759 - acc: 0.9375
 128/1283 [=>............................] - ETA: 0s - loss: 0.3377 - acc: 0.8828
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3649 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3636 - acc: 0.8516
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3521 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3475 - acc: 0.8613
 640/1283 [=============>................] - ETA: 0s - loss: 0.3410 - acc: 0.8703
 768/1283 [================>.............] - ETA: 0s - loss: 0.3383 - acc: 0.8711
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3394 - acc: 0.8740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3350 - acc: 0.8787
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3330 - acc: 0.8758
1280/1283 [============================>.] - ETA: 0s - loss: 0.3325 - acc: 0.8750
1283/1283 [==============================] - 1s 760us/step - loss: 0.3324 - acc: 0.8753 - val_loss: 0.8302 - val_acc: 0.5371

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2703 - acc: 0.8750
 128/1283 [=>............................] - ETA: 0s - loss: 0.2635 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2605 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2750 - acc: 0.9000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2751 - acc: 0.9085
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2773 - acc: 0.9023
 576/1283 [============>.................] - ETA: 0s - loss: 0.2797 - acc: 0.8976
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2805 - acc: 0.8991
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2799 - acc: 0.8966
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2831 - acc: 0.8938
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2872 - acc: 0.8906
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2863 - acc: 0.8931
1283/1283 [==============================] - 1s 854us/step - loss: 0.2827 - acc: 0.8956 - val_loss: 0.8837 - val_acc: 0.5721

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2289 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2573 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2684 - acc: 0.8844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2635 - acc: 0.8929
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2585 - acc: 0.9004
 640/1283 [=============>................] - ETA: 0s - loss: 0.2477 - acc: 0.9109
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2470 - acc: 0.9091
 768/1283 [================>.............] - ETA: 0s - loss: 0.2481 - acc: 0.9089
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2486 - acc: 0.9111
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2490 - acc: 0.9085
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2477 - acc: 0.9125
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2459 - acc: 0.9154
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2426 - acc: 0.9169
1283/1283 [==============================] - 1s 851us/step - loss: 0.2444 - acc: 0.9166 - val_loss: 0.8874 - val_acc: 0.5546

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1990 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1863 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1956 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1980 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1986 - acc: 0.9442
 576/1283 [============>.................] - ETA: 0s - loss: 0.1982 - acc: 0.9444
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1963 - acc: 0.9460
 768/1283 [================>.............] - ETA: 0s - loss: 0.1950 - acc: 0.9453
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1939 - acc: 0.9453
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1914 - acc: 0.9453
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1905 - acc: 0.9458
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1948 - acc: 0.9400
1283/1283 [==============================] - 1s 928us/step - loss: 0.1951 - acc: 0.9400 - val_loss: 0.9611 - val_acc: 0.5633

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1551 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1498 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1574 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1555 - acc: 0.9740
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1549 - acc: 0.9707
 640/1283 [=============>................] - ETA: 0s - loss: 0.1625 - acc: 0.9609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1632 - acc: 0.9602
 768/1283 [================>.............] - ETA: 0s - loss: 0.1601 - acc: 0.9635
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1598 - acc: 0.9639
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1663 - acc: 0.9565
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1632 - acc: 0.9583
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1696 - acc: 0.9550
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1692 - acc: 0.9548
1283/1283 [==============================] - 1s 715us/step - loss: 0.1701 - acc: 0.9540 - val_loss: 1.0892 - val_acc: 0.5546

Epoch 00012: val_acc did not improve
Epoch 00012: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=20
PCA text=100
accuracy=0.5349854227405247
best_valid_accuracy=0.478134110787172
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:18:24.772684: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.8299 - acc: 0.4688
 192/1283 [===>..........................] - ETA: 4s - loss: 0.8524 - acc: 0.4948 
 320/1283 [======>.......................] - ETA: 2s - loss: 0.8218 - acc: 0.4781
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7951 - acc: 0.4941
 640/1283 [=============>................] - ETA: 0s - loss: 0.7698 - acc: 0.5047
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7469 - acc: 0.5337
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7327 - acc: 0.5459
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7231 - acc: 0.5564
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7222 - acc: 0.5534 - val_loss: 0.7024 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6200 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6149 - acc: 0.6719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6006 - acc: 0.6830
 640/1283 [=============>................] - ETA: 0s - loss: 0.6118 - acc: 0.6625
 768/1283 [================>.............] - ETA: 0s - loss: 0.6201 - acc: 0.6536
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6097 - acc: 0.6719
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6123 - acc: 0.6682
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6186 - acc: 0.6579
1283/1283 [==============================] - 1s 447us/step - loss: 0.6168 - acc: 0.6594 - val_loss: 0.6965 - val_acc: 0.5284

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5633 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5569 - acc: 0.7148
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5410 - acc: 0.7318
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5487 - acc: 0.7207
 640/1283 [=============>................] - ETA: 0s - loss: 0.5487 - acc: 0.7188
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5566 - acc: 0.7067
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5495 - acc: 0.7169
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5472 - acc: 0.7163
1283/1283 [==============================] - 0s 385us/step - loss: 0.5470 - acc: 0.7155 - val_loss: 0.7327 - val_acc: 0.5197

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4908 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4913 - acc: 0.7734
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4990 - acc: 0.7478
 640/1283 [=============>................] - ETA: 0s - loss: 0.4963 - acc: 0.7578
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5011 - acc: 0.7584
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4990 - acc: 0.7598
1280/1283 [============================>.] - ETA: 0s - loss: 0.4974 - acc: 0.7586
1283/1283 [==============================] - 0s 347us/step - loss: 0.4968 - acc: 0.7592 - val_loss: 0.7305 - val_acc: 0.5633

Epoch 00004: val_acc improved from 0.55022 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4275 - acc: 0.7812
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4117 - acc: 0.8086
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4189 - acc: 0.8147
 640/1283 [=============>................] - ETA: 0s - loss: 0.4288 - acc: 0.7937
 768/1283 [================>.............] - ETA: 0s - loss: 0.4313 - acc: 0.7904
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4371 - acc: 0.7920
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4341 - acc: 0.7960
1280/1283 [============================>.] - ETA: 0s - loss: 0.4339 - acc: 0.7953
1283/1283 [==============================] - 1s 456us/step - loss: 0.4346 - acc: 0.7942 - val_loss: 0.7893 - val_acc: 0.5197

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4085 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4488 - acc: 0.7917
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4282 - acc: 0.8156
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4086 - acc: 0.8359
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4172 - acc: 0.8310
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4145 - acc: 0.8292
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4116 - acc: 0.8301
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4119 - acc: 0.8273
1283/1283 [==============================] - 1s 438us/step - loss: 0.4074 - acc: 0.8324 - val_loss: 0.7378 - val_acc: 0.6332

Epoch 00006: val_acc improved from 0.56332 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3093 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3165 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3340 - acc: 0.8844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3239 - acc: 0.8884
 576/1283 [============>.................] - ETA: 0s - loss: 0.3234 - acc: 0.8837
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3369 - acc: 0.8636
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3354 - acc: 0.8654
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3371 - acc: 0.8662
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3405 - acc: 0.8618
1283/1283 [==============================] - 1s 495us/step - loss: 0.3408 - acc: 0.8620 - val_loss: 0.7464 - val_acc: 0.6070

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3618 - acc: 0.7969
 128/1283 [=>............................] - ETA: 0s - loss: 0.3619 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3398 - acc: 0.8203
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3146 - acc: 0.8542
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3049 - acc: 0.8770
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2997 - acc: 0.8835
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2953 - acc: 0.8862
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2880 - acc: 0.8936
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2875 - acc: 0.8939
1283/1283 [==============================] - 1s 485us/step - loss: 0.2881 - acc: 0.8932 - val_loss: 0.8017 - val_acc: 0.6201

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2391 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3863 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3507 - acc: 0.8094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3367 - acc: 0.8326
 576/1283 [============>.................] - ETA: 0s - loss: 0.3349 - acc: 0.8351
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3271 - acc: 0.8480
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3147 - acc: 0.8571
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3131 - acc: 0.8555
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3097 - acc: 0.8594
1280/1283 [============================>.] - ETA: 0s - loss: 0.3028 - acc: 0.8656
1283/1283 [==============================] - 1s 525us/step - loss: 0.3026 - acc: 0.8659 - val_loss: 0.7831 - val_acc: 0.5939

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2277 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2301 - acc: 0.9479
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2226 - acc: 0.9500
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2193 - acc: 0.9453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2137 - acc: 0.9446
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2147 - acc: 0.9423
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2176 - acc: 0.9396
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2179 - acc: 0.9393
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2170 - acc: 0.9367
1283/1283 [==============================] - 1s 469us/step - loss: 0.2150 - acc: 0.9376 - val_loss: 0.8386 - val_acc: 0.5895

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2111 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1809 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1654 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1576 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.1647 - acc: 0.9705
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1723 - acc: 0.9645
 768/1283 [================>.............] - ETA: 0s - loss: 0.1730 - acc: 0.9609
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1759 - acc: 0.9604
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1746 - acc: 0.9613
1283/1283 [==============================] - 1s 482us/step - loss: 0.1807 - acc: 0.9571 - val_loss: 0.8792 - val_acc: 0.5983

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0992 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1332 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1380 - acc: 0.9750
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1313 - acc: 0.9766
 640/1283 [=============>................] - ETA: 0s - loss: 0.1282 - acc: 0.9797
 768/1283 [================>.............] - ETA: 0s - loss: 0.1331 - acc: 0.9766
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1313 - acc: 0.9777
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1330 - acc: 0.9733
1280/1283 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9703
1283/1283 [==============================] - 1s 426us/step - loss: 0.1357 - acc: 0.9704 - val_loss: 1.0704 - val_acc: 0.5677

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0938 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1206 - acc: 0.9750
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1260 - acc: 0.9766
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1291 - acc: 0.9716
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1293 - acc: 0.9732
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1271 - acc: 0.9743
1280/1283 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9750
1283/1283 [==============================] - 0s 304us/step - loss: 0.1244 - acc: 0.9751 - val_loss: 1.0461 - val_acc: 0.5808

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0805 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0916 - acc: 0.9906
 576/1283 [============>.................] - ETA: 0s - loss: 0.0926 - acc: 0.9913
 768/1283 [================>.............] - ETA: 0s - loss: 0.0908 - acc: 0.9896
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0920 - acc: 0.9885
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0916 - acc: 0.9868
1283/1283 [==============================] - 0s 278us/step - loss: 0.0910 - acc: 0.9867 - val_loss: 1.0161 - val_acc: 0.5852

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0795 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0607 - acc: 0.9938
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0638 - acc: 0.9941
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0659 - acc: 0.9943
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0694 - acc: 0.9911
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0684 - acc: 0.9913
1283/1283 [==============================] - 0s 288us/step - loss: 0.0670 - acc: 0.9922 - val_loss: 1.1126 - val_acc: 0.5808

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0533 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0525 - acc: 0.9974
 576/1283 [============>.................] - ETA: 0s - loss: 0.0525 - acc: 0.9983
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0521 - acc: 0.9976
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0504 - acc: 0.9982
1280/1283 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9977
1283/1283 [==============================] - 0s 255us/step - loss: 0.0500 - acc: 0.9977 - val_loss: 1.1812 - val_acc: 0.5415

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=25
PCA text=100
accuracy=0.5233236151603499
best_valid_accuracy=0.5291545189504373
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:24:32.153846: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.6848 - acc: 0.5312
 192/1283 [===>..........................] - ETA: 1s - loss: 0.8339 - acc: 0.5156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.8171 - acc: 0.5208
 640/1283 [=============>................] - ETA: 0s - loss: 0.7868 - acc: 0.5250
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7588 - acc: 0.5229
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7428 - acc: 0.5288
1283/1283 [==============================] - 1s 472us/step - loss: 0.7378 - acc: 0.5355 - val_loss: 0.7153 - val_acc: 0.5109

Epoch 00001: val_acc improved from -inf to 0.51092, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6296 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6150 - acc: 0.6927
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6138 - acc: 0.6849
 576/1283 [============>.................] - ETA: 0s - loss: 0.6070 - acc: 0.6892
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6011 - acc: 0.6989
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6105 - acc: 0.6786
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6081 - acc: 0.6768
1280/1283 [============================>.] - ETA: 0s - loss: 0.6095 - acc: 0.6664
1283/1283 [==============================] - 1s 435us/step - loss: 0.6095 - acc: 0.6664 - val_loss: 0.7197 - val_acc: 0.5459

Epoch 00002: val_acc improved from 0.51092 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5160 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5247 - acc: 0.7383
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5237 - acc: 0.7526
 576/1283 [============>.................] - ETA: 0s - loss: 0.5308 - acc: 0.7396
 768/1283 [================>.............] - ETA: 0s - loss: 0.5391 - acc: 0.7318
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5407 - acc: 0.7323
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5532 - acc: 0.7188
1283/1283 [==============================] - 0s 376us/step - loss: 0.5540 - acc: 0.7163 - val_loss: 0.7771 - val_acc: 0.5109

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5156 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4818 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4749 - acc: 0.7625
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4837 - acc: 0.7567
 576/1283 [============>.................] - ETA: 0s - loss: 0.4899 - acc: 0.7483
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4991 - acc: 0.7415
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4995 - acc: 0.7500
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5063 - acc: 0.7454
1280/1283 [============================>.] - ETA: 0s - loss: 0.5017 - acc: 0.7492
1283/1283 [==============================] - 1s 428us/step - loss: 0.5026 - acc: 0.7482 - val_loss: 0.7998 - val_acc: 0.5328

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4279 - acc: 0.8281
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4271 - acc: 0.8438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4274 - acc: 0.8281
 576/1283 [============>.................] - ETA: 0s - loss: 0.4272 - acc: 0.8281
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4267 - acc: 0.8338
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4365 - acc: 0.8209
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4352 - acc: 0.8146
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4378 - acc: 0.8079
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4450 - acc: 0.7985
1283/1283 [==============================] - 1s 408us/step - loss: 0.4492 - acc: 0.7919 - val_loss: 0.8581 - val_acc: 0.5502

Epoch 00005: val_acc improved from 0.54585 to 0.55022, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5595 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4472 - acc: 0.7708
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4273 - acc: 0.7995
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4210 - acc: 0.7930
 768/1283 [================>.............] - ETA: 0s - loss: 0.4114 - acc: 0.8086
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4123 - acc: 0.8105
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4106 - acc: 0.8100
1283/1283 [==============================] - 0s 343us/step - loss: 0.4111 - acc: 0.8114 - val_loss: 0.8742 - val_acc: 0.5197

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3191 - acc: 0.9219
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3397 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3520 - acc: 0.8698
 576/1283 [============>.................] - ETA: 0s - loss: 0.3390 - acc: 0.8750
 768/1283 [================>.............] - ETA: 0s - loss: 0.3424 - acc: 0.8750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3393 - acc: 0.8809
1280/1283 [============================>.] - ETA: 0s - loss: 0.3416 - acc: 0.8727
1283/1283 [==============================] - 0s 344us/step - loss: 0.3409 - acc: 0.8730 - val_loss: 0.8857 - val_acc: 0.5197

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2999 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2799 - acc: 0.9167
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2734 - acc: 0.9193
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2692 - acc: 0.9297
 640/1283 [=============>................] - ETA: 0s - loss: 0.2832 - acc: 0.9141
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2846 - acc: 0.9111
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2803 - acc: 0.9102
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2797 - acc: 0.9097
1280/1283 [============================>.] - ETA: 0s - loss: 0.2830 - acc: 0.9047
1283/1283 [==============================] - 1s 426us/step - loss: 0.2834 - acc: 0.9049 - val_loss: 0.8848 - val_acc: 0.5240

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2278 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2110 - acc: 0.9625
 576/1283 [============>.................] - ETA: 0s - loss: 0.2287 - acc: 0.9427
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2347 - acc: 0.9339
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2431 - acc: 0.9210
1283/1283 [==============================] - 0s 263us/step - loss: 0.2396 - acc: 0.9260 - val_loss: 0.9803 - val_acc: 0.5328

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2299 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1989 - acc: 0.9563
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1974 - acc: 0.9512
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1948 - acc: 0.9517
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1914 - acc: 0.9521
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1911 - acc: 0.9515
1283/1283 [==============================] - 0s 295us/step - loss: 0.1885 - acc: 0.9509 - val_loss: 1.0393 - val_acc: 0.5284

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1273 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1416 - acc: 0.9727
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1645 - acc: 0.9598
 640/1283 [=============>................] - ETA: 0s - loss: 0.1617 - acc: 0.9641
 768/1283 [================>.............] - ETA: 0s - loss: 0.1614 - acc: 0.9648
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1630 - acc: 0.9625
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1589 - acc: 0.9630
1283/1283 [==============================] - 0s 340us/step - loss: 0.1590 - acc: 0.9634 - val_loss: 1.0659 - val_acc: 0.5633

Epoch 00011: val_acc improved from 0.55022 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1349 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1293 - acc: 0.9875
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1339 - acc: 0.9805
 640/1283 [=============>................] - ETA: 0s - loss: 0.1291 - acc: 0.9812
 768/1283 [================>.............] - ETA: 0s - loss: 0.1263 - acc: 0.9831
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1306 - acc: 0.9766
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1340 - acc: 0.9752
1280/1283 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9766
1283/1283 [==============================] - 0s 376us/step - loss: 0.1294 - acc: 0.9766 - val_loss: 1.2558 - val_acc: 0.5371

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1266 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1323 - acc: 0.9727
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1283 - acc: 0.9707
 768/1283 [================>.............] - ETA: 0s - loss: 0.1136 - acc: 0.9779
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1100 - acc: 0.9802
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1095 - acc: 0.9800
1283/1283 [==============================] - 0s 310us/step - loss: 0.1122 - acc: 0.9766 - val_loss: 1.3679 - val_acc: 0.5240

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1379 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3467 - acc: 0.8320
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2468 - acc: 0.8862
 640/1283 [=============>................] - ETA: 0s - loss: 0.2576 - acc: 0.8828
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2478 - acc: 0.8942
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2434 - acc: 0.8994
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2358 - acc: 0.9071
1283/1283 [==============================] - 0s 328us/step - loss: 0.2275 - acc: 0.9127 - val_loss: 1.2574 - val_acc: 0.4803

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1672 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1300 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1306 - acc: 0.9688
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1260 - acc: 0.9688
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1208 - acc: 0.9699
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1156 - acc: 0.9733
1280/1283 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9734
1283/1283 [==============================] - 0s 326us/step - loss: 0.1116 - acc: 0.9735 - val_loss: 1.4301 - val_acc: 0.4978

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0403 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0549 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0566 - acc: 0.9978
 640/1283 [=============>................] - ETA: 0s - loss: 0.0568 - acc: 0.9969
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0579 - acc: 0.9964
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0563 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0556 - acc: 0.9974
1283/1283 [==============================] - 0s 364us/step - loss: 0.0586 - acc: 0.9953 - val_loss: 1.5108 - val_acc: 0.5153

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0549 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0686 - acc: 0.9883
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0699 - acc: 0.9866
 640/1283 [=============>................] - ETA: 0s - loss: 0.0694 - acc: 0.9875
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0730 - acc: 0.9844
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0692 - acc: 0.9854
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0662 - acc: 0.9877
1283/1283 [==============================] - 0s 343us/step - loss: 0.0650 - acc: 0.9883 - val_loss: 1.5319 - val_acc: 0.4847

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0511 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0522 - acc: 0.9961
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0494 - acc: 0.9922
 768/1283 [================>.............] - ETA: 0s - loss: 0.0491 - acc: 0.9909
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0454 - acc: 0.9932
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0444 - acc: 0.9942
1283/1283 [==============================] - 0s 295us/step - loss: 0.0437 - acc: 0.9945 - val_loss: 1.5499 - val_acc: 0.5109

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0309 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0324 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0307 - acc: 0.9978
 640/1283 [=============>................] - ETA: 0s - loss: 0.0326 - acc: 0.9984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0322 - acc: 0.9988
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0303 - acc: 0.9991
1280/1283 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9992
1283/1283 [==============================] - 0s 339us/step - loss: 0.0297 - acc: 0.9992 - val_loss: 1.5967 - val_acc: 0.5240

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0196 - acc: 1.0000/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.149895). Check your callbacks.
  % delta_t_median)

 128/1283 [=>............................] - ETA: 1s - loss: 0.0232 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0247 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0265 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0248 - acc: 0.9983
 768/1283 [================>.............] - ETA: 0s - loss: 0.0240 - acc: 0.9987
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0246 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0235 - acc: 0.9991
1283/1283 [==============================] - 1s 504us/step - loss: 0.0234 - acc: 0.9992 - val_loss: 1.6999 - val_acc: 0.5066

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0176 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0162 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0186 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0223 - acc: 0.9965
 768/1283 [================>.............] - ETA: 0s - loss: 0.0241 - acc: 0.9974
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0256 - acc: 0.9958
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0261 - acc: 0.9965
1283/1283 [==============================] - 1s 404us/step - loss: 0.0263 - acc: 0.9969 - val_loss: 1.7381 - val_acc: 0.4934

Epoch 00021: val_acc did not improve
Epoch 00021: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=30
PCA text=100
accuracy=0.5014577259475219
best_valid_accuracy=0.47667638483965014
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:44:15.990580: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.9105 - acc: 0.3906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.7817 - acc: 0.5290
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7408 - acc: 0.5445
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7288 - acc: 0.5486
1283/1283 [==============================] - 1s 436us/step - loss: 0.7318 - acc: 0.5409 - val_loss: 0.7260 - val_acc: 0.5109

Epoch 00001: val_acc improved from -inf to 0.51092, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6607 - acc: 0.6094
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5859 - acc: 0.6969
 576/1283 [============>.................] - ETA: 0s - loss: 0.5680 - acc: 0.7188
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5722 - acc: 0.7043
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5719 - acc: 0.7040
1283/1283 [==============================] - 0s 235us/step - loss: 0.5706 - acc: 0.7062 - val_loss: 0.7502 - val_acc: 0.5066

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5186 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4978 - acc: 0.7604
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5201 - acc: 0.7266
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4975 - acc: 0.7608
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5031 - acc: 0.7491
1283/1283 [==============================] - 0s 251us/step - loss: 0.5020 - acc: 0.7482 - val_loss: 0.7838 - val_acc: 0.5109

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4268 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4848 - acc: 0.7531
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4863 - acc: 0.7539
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4767 - acc: 0.7713
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4812 - acc: 0.7667
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4805 - acc: 0.7647
1283/1283 [==============================] - 0s 290us/step - loss: 0.4774 - acc: 0.7724 - val_loss: 0.8635 - val_acc: 0.5109

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4566 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3696 - acc: 0.8625
 576/1283 [============>.................] - ETA: 0s - loss: 0.3837 - acc: 0.8420
 768/1283 [================>.............] - ETA: 0s - loss: 0.3872 - acc: 0.8424
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3857 - acc: 0.8447
1280/1283 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.8461
1283/1283 [==============================] - 0s 289us/step - loss: 0.3798 - acc: 0.8457 - val_loss: 0.8873 - val_acc: 0.4716

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3104 - acc: 0.9062
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2997 - acc: 0.9258
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2985 - acc: 0.9241
 640/1283 [=============>................] - ETA: 0s - loss: 0.2956 - acc: 0.9094
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3037 - acc: 0.8990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3073 - acc: 0.8945
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3128 - acc: 0.8845
1283/1283 [==============================] - 0s 366us/step - loss: 0.3129 - acc: 0.8831 - val_loss: 0.8335 - val_acc: 0.5240

Epoch 00006: val_acc improved from 0.51092 to 0.52402, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2465 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2892 - acc: 0.8844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2795 - acc: 0.8906
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2683 - acc: 0.9062
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2776 - acc: 0.9007
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2719 - acc: 0.9071
1280/1283 [============================>.] - ETA: 0s - loss: 0.2706 - acc: 0.9094
1283/1283 [==============================] - 0s 327us/step - loss: 0.2704 - acc: 0.9096 - val_loss: 0.9081 - val_acc: 0.5109

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2148 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2031 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2132 - acc: 0.9375
 640/1283 [=============>................] - ETA: 0s - loss: 0.2162 - acc: 0.9344
 768/1283 [================>.............] - ETA: 0s - loss: 0.2136 - acc: 0.9375
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2106 - acc: 0.9427
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2100 - acc: 0.9441
1283/1283 [==============================] - 1s 390us/step - loss: 0.2084 - acc: 0.9454 - val_loss: 1.0013 - val_acc: 0.4978

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1509 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1622 - acc: 0.9648
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1624 - acc: 0.9665
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1627 - acc: 0.9645
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1645 - acc: 0.9615
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1597 - acc: 0.9655
1283/1283 [==============================] - 0s 284us/step - loss: 0.1586 - acc: 0.9673 - val_loss: 1.0295 - val_acc: 0.5153

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1480 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1235 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.1162 - acc: 0.9878
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1129 - acc: 0.9868
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1145 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9805
1283/1283 [==============================] - 0s 265us/step - loss: 0.1150 - acc: 0.9805 - val_loss: 1.0543 - val_acc: 0.5371

Epoch 00010: val_acc improved from 0.52402 to 0.53712, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_30.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0938 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0804 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0875 - acc: 0.9953
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0859 - acc: 0.9944
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0832 - acc: 0.9948
1283/1283 [==============================] - 0s 244us/step - loss: 0.0821 - acc: 0.9945 - val_loss: 1.1956 - val_acc: 0.5197

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0532 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0699 - acc: 0.9938
 576/1283 [============>.................] - ETA: 0s - loss: 0.0663 - acc: 0.9931
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0645 - acc: 0.9928
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0647 - acc: 0.9926
1283/1283 [==============================] - 0s 277us/step - loss: 0.0645 - acc: 0.9938 - val_loss: 1.2740 - val_acc: 0.5371

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0475 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0441 - acc: 0.9969
 576/1283 [============>.................] - ETA: 0s - loss: 0.0455 - acc: 0.9983
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0443 - acc: 0.9988
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0435 - acc: 0.9991
1280/1283 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9992
1283/1283 [==============================] - 0s 265us/step - loss: 0.0438 - acc: 0.9992 - val_loss: 1.2593 - val_acc: 0.5240

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0359 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0336 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0362 - acc: 0.9969
 576/1283 [============>.................] - ETA: 0s - loss: 0.0346 - acc: 0.9983
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0335 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0336 - acc: 0.9990
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0340 - acc: 0.9984
1283/1283 [==============================] - 0s 340us/step - loss: 0.0334 - acc: 0.9984 - val_loss: 1.3772 - val_acc: 0.5197

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0264 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0376 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0349 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0405 - acc: 0.9988
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0411 - acc: 0.9982
1280/1283 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9984
1283/1283 [==============================] - 0s 251us/step - loss: 0.0405 - acc: 0.9984 - val_loss: 1.3647 - val_acc: 0.5109

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0210 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0295 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0284 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0303 - acc: 0.9988
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0312 - acc: 0.9991
1283/1283 [==============================] - 0s 237us/step - loss: 0.0308 - acc: 0.9992 - val_loss: 1.5154 - val_acc: 0.5022

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0247 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0175 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0188 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0197 - acc: 0.9990
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0190 - acc: 0.9992
1283/1283 [==============================] - 0s 208us/step - loss: 0.0190 - acc: 0.9992 - val_loss: 1.5358 - val_acc: 0.5371

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0144 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0183 - acc: 0.9974
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0188 - acc: 0.9986
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0175 - acc: 0.9980
1283/1283 [==============================] - 0s 203us/step - loss: 0.0171 - acc: 0.9984 - val_loss: 1.5864 - val_acc: 0.5197

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0116 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0100 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0121 - acc: 0.9984
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0123 - acc: 0.9990
1280/1283 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9984
1283/1283 [==============================] - 0s 203us/step - loss: 0.0119 - acc: 0.9984 - val_loss: 1.6940 - val_acc: 0.5240

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0104 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0194 - acc: 0.9969
 640/1283 [=============>................] - ETA: 0s - loss: 0.0154 - acc: 0.9984
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0157 - acc: 0.9990
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0150 - acc: 0.9992
1283/1283 [==============================] - 0s 215us/step - loss: 0.0148 - acc: 0.9992 - val_loss: 1.7650 - val_acc: 0.4847

Epoch 00020: val_acc did not improve
Epoch 00020: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=35
PCA text=100
accuracy=0.5189504373177842
best_valid_accuracy=0.4752186588921283
