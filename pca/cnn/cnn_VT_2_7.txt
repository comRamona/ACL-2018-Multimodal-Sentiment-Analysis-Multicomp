/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:47:09.227302: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 16s - loss: 0.7305 - acc: 0.5625
 128/1283 [=>............................] - ETA: 8s - loss: 0.7549 - acc: 0.5156 
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7659 - acc: 0.5104
 256/1283 [====>.........................] - ETA: 4s - loss: 0.7561 - acc: 0.5391
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7516 - acc: 0.5500
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7513 - acc: 0.5521
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7516 - acc: 0.5335
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7567 - acc: 0.5332
 576/1283 [============>.................] - ETA: 1s - loss: 0.7474 - acc: 0.5434
 640/1283 [=============>................] - ETA: 1s - loss: 0.7462 - acc: 0.5359
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7479 - acc: 0.5384
 768/1283 [================>.............] - ETA: 1s - loss: 0.7519 - acc: 0.5312
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7472 - acc: 0.5300
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7426 - acc: 0.5312
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7389 - acc: 0.5344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7367 - acc: 0.5303
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7344 - acc: 0.5322
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7318 - acc: 0.5312
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7321 - acc: 0.5296
1280/1283 [============================>.] - ETA: 0s - loss: 0.7290 - acc: 0.5336
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7286 - acc: 0.5347 - val_loss: 0.6871 - val_acc: 0.5983

Epoch 00001: val_acc improved from -inf to 0.59825, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5937 - acc: 0.6719
 128/1283 [=>............................] - ETA: 0s - loss: 0.5772 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5745 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5840 - acc: 0.7305
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5817 - acc: 0.7344
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5807 - acc: 0.7344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5760 - acc: 0.7411
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5702 - acc: 0.7441
 576/1283 [============>.................] - ETA: 0s - loss: 0.5682 - acc: 0.7431
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5659 - acc: 0.7372
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5602 - acc: 0.7392
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5593 - acc: 0.7377
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5573 - acc: 0.7375
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5555 - acc: 0.7334
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5519 - acc: 0.7335
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5499 - acc: 0.7361
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5512 - acc: 0.7303
1280/1283 [============================>.] - ETA: 0s - loss: 0.5475 - acc: 0.7344
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5471 - acc: 0.7342 - val_loss: 0.7984 - val_acc: 0.6288

Epoch 00002: val_acc improved from 0.59825 to 0.62882, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5244 - acc: 0.7031
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4688 - acc: 0.7812
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4677 - acc: 0.7937
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4653 - acc: 0.7917
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4525 - acc: 0.8058
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4511 - acc: 0.8047
 576/1283 [============>.................] - ETA: 0s - loss: 0.4567 - acc: 0.8003
 640/1283 [=============>................] - ETA: 0s - loss: 0.4519 - acc: 0.8047
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4467 - acc: 0.8054
 768/1283 [================>.............] - ETA: 0s - loss: 0.4461 - acc: 0.8034
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4485 - acc: 0.8005
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4472 - acc: 0.8002
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4439 - acc: 0.8063
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4414 - acc: 0.8076
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4374 - acc: 0.8116
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4362 - acc: 0.8142
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4365 - acc: 0.8150
1280/1283 [============================>.] - ETA: 0s - loss: 0.4311 - acc: 0.8211
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4307 - acc: 0.8207 - val_loss: 0.7386 - val_acc: 0.6026

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2475 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2621 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2947 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2871 - acc: 0.8945
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2875 - acc: 0.9000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2851 - acc: 0.9062
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2878 - acc: 0.9085
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2929 - acc: 0.9102
 576/1283 [============>.................] - ETA: 1s - loss: 0.2949 - acc: 0.9080
 640/1283 [=============>................] - ETA: 1s - loss: 0.2988 - acc: 0.9000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3046 - acc: 0.8935
 768/1283 [================>.............] - ETA: 0s - loss: 0.3033 - acc: 0.8906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3052 - acc: 0.8894
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3035 - acc: 0.8895
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2977 - acc: 0.8927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2986 - acc: 0.8867
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2932 - acc: 0.8888
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2891 - acc: 0.8898
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2892 - acc: 0.8873
1280/1283 [============================>.] - ETA: 0s - loss: 0.2899 - acc: 0.8852
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2905 - acc: 0.8839 - val_loss: 0.9147 - val_acc: 0.5852

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.2056 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.2728 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2651 - acc: 0.8698
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2750 - acc: 0.8711
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2713 - acc: 0.8719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2722 - acc: 0.8802
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2881 - acc: 0.8705
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2881 - acc: 0.8672
 576/1283 [============>.................] - ETA: 0s - loss: 0.2806 - acc: 0.8715
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2619 - acc: 0.8864
 768/1283 [================>.............] - ETA: 0s - loss: 0.2582 - acc: 0.8893
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2576 - acc: 0.8918
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2543 - acc: 0.8951
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2526 - acc: 0.8948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2484 - acc: 0.8975
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2445 - acc: 0.8998
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2453 - acc: 0.8976
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2454 - acc: 0.8997
1280/1283 [============================>.] - ETA: 0s - loss: 0.2437 - acc: 0.9016
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2433 - acc: 0.9018 - val_loss: 0.9166 - val_acc: 0.6201

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1501 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1367 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1594 - acc: 0.9271
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1598 - acc: 0.9297
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1816 - acc: 0.9125
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1882 - acc: 0.9036
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1860 - acc: 0.9085
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1807 - acc: 0.9180
 576/1283 [============>.................] - ETA: 0s - loss: 0.1793 - acc: 0.9201
 640/1283 [=============>................] - ETA: 0s - loss: 0.1750 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1707 - acc: 0.9290
 768/1283 [================>.............] - ETA: 0s - loss: 0.1753 - acc: 0.9258
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1743 - acc: 0.9243
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1749 - acc: 0.9230
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1755 - acc: 0.9219
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1776 - acc: 0.9209
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1758 - acc: 0.9219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1726 - acc: 0.9245
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1721 - acc: 0.9252
1280/1283 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9258
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1718 - acc: 0.9260 - val_loss: 1.0675 - val_acc: 0.6026

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1230 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.1298 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1414 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1462 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1389 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1319 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1274 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1256 - acc: 0.9570
 576/1283 [============>.................] - ETA: 1s - loss: 0.1201 - acc: 0.9601
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1213 - acc: 0.9560
 768/1283 [================>.............] - ETA: 0s - loss: 0.1200 - acc: 0.9557
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1216 - acc: 0.9543
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1229 - acc: 0.9531
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1225 - acc: 0.9531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1241 - acc: 0.9521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1213 - acc: 0.9540
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1217 - acc: 0.9523
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1226 - acc: 0.9523
1280/1283 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9539
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1233 - acc: 0.9532 - val_loss: 1.1754 - val_acc: 0.6288

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1181 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1047 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1031 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0973 - acc: 0.9766
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0972 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1050 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1135 - acc: 0.9629
 576/1283 [============>.................] - ETA: 0s - loss: 0.1103 - acc: 0.9653
 640/1283 [=============>................] - ETA: 0s - loss: 0.1110 - acc: 0.9625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1101 - acc: 0.9602
 768/1283 [================>.............] - ETA: 0s - loss: 0.1116 - acc: 0.9557
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1130 - acc: 0.9543
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1124 - acc: 0.9542
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1132 - acc: 0.9542
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1161 - acc: 0.9531
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1166 - acc: 0.9531
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1152 - acc: 0.9540
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1152 - acc: 0.9531
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1157 - acc: 0.9548 - val_loss: 1.3175 - val_acc: 0.6245

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0803 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0807 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0923 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0900 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0899 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0900 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0924 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0969 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.1029 - acc: 0.9549
 640/1283 [=============>................] - ETA: 0s - loss: 0.1112 - acc: 0.9531
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1110 - acc: 0.9517
 768/1283 [================>.............] - ETA: 0s - loss: 0.1085 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1017 - acc: 0.9587
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1051 - acc: 0.9573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1033 - acc: 0.9590
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1023 - acc: 0.9596
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0999 - acc: 0.9601
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0997 - acc: 0.9605
1280/1283 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9594
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1028 - acc: 0.9595 - val_loss: 1.5373 - val_acc: 0.5590

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.1174 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1042 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1005 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1136 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1011 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1006 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1000 - acc: 0.9576
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0952 - acc: 0.9590
 576/1283 [============>.................] - ETA: 0s - loss: 0.0925 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.0907 - acc: 0.9641
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0890 - acc: 0.9645
 768/1283 [================>.............] - ETA: 0s - loss: 0.0877 - acc: 0.9635
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0957 - acc: 0.9579
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0921 - acc: 0.9598
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0890 - acc: 0.9625
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0895 - acc: 0.9629
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0896 - acc: 0.9627
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0899 - acc: 0.9613
1280/1283 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9617
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0891 - acc: 0.9618 - val_loss: 1.6329 - val_acc: 0.6114

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1056 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.1145 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1057 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0927 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0930 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0796 - acc: 0.9621
 576/1283 [============>.................] - ETA: 0s - loss: 0.0751 - acc: 0.9653
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0711 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0734 - acc: 0.9675
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0707 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0729 - acc: 0.9668
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0719 - acc: 0.9670
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0705 - acc: 0.9679
1280/1283 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9688
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0691 - acc: 0.9688 - val_loss: 1.6116 - val_acc: 0.5939

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0777 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0478 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0445 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0576 - acc: 0.9766
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0542 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0526 - acc: 0.9818
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0493 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0537 - acc: 0.9785
 576/1283 [============>.................] - ETA: 1s - loss: 0.0576 - acc: 0.9757
 640/1283 [=============>................] - ETA: 1s - loss: 0.0582 - acc: 0.9750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0560 - acc: 0.9773
 768/1283 [================>.............] - ETA: 0s - loss: 0.0576 - acc: 0.9753
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0568 - acc: 0.9760
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0619 - acc: 0.9729
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0623 - acc: 0.9733
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0624 - acc: 0.9737
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0625 - acc: 0.9727 - val_loss: 1.7520 - val_acc: 0.6026

Epoch 00012: val_acc did not improve
Epoch 00012: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=VT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.5816326530612245
best_valid_accuracy=0.5918367346938775
