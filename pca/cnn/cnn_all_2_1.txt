/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 07:58:31.640712: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 33s - loss: 1.0986 - acc: 0.4219
 128/1283 [=>............................] - ETA: 17s - loss: 0.8867 - acc: 0.4766
 192/1283 [===>..........................] - ETA: 11s - loss: 1.0341 - acc: 0.4531
 320/1283 [======>.......................] - ETA: 6s - loss: 0.9761 - acc: 0.4656 
 384/1283 [=======>......................] - ETA: 5s - loss: 0.9366 - acc: 0.4740
 448/1283 [=========>....................] - ETA: 4s - loss: 0.8991 - acc: 0.4866
 512/1283 [==========>...................] - ETA: 3s - loss: 0.8729 - acc: 0.4941
 576/1283 [============>.................] - ETA: 3s - loss: 0.8527 - acc: 0.5087
 640/1283 [=============>................] - ETA: 2s - loss: 0.8381 - acc: 0.5188
 768/1283 [================>.............] - ETA: 1s - loss: 0.8221 - acc: 0.5221
 832/1283 [==================>...........] - ETA: 1s - loss: 0.8111 - acc: 0.5276
 896/1283 [===================>..........] - ETA: 1s - loss: 0.8064 - acc: 0.5223
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7888 - acc: 0.5352
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7814 - acc: 0.5395
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7744 - acc: 0.5417
1280/1283 [============================>.] - ETA: 0s - loss: 0.7699 - acc: 0.5414
1283/1283 [==============================] - 4s 3ms/step - loss: 0.7700 - acc: 0.5409 - val_loss: 0.6899 - val_acc: 0.5939

Epoch 00001: val_acc improved from -inf to 0.59389, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6299 - acc: 0.6094
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6032 - acc: 0.7448
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5974 - acc: 0.7578
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5907 - acc: 0.7531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5919 - acc: 0.7318
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5994 - acc: 0.7054
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6106 - acc: 0.6738
 640/1283 [=============>................] - ETA: 0s - loss: 0.6094 - acc: 0.6672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6097 - acc: 0.6634
 768/1283 [================>.............] - ETA: 0s - loss: 0.6062 - acc: 0.6732
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6000 - acc: 0.6851
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5977 - acc: 0.6908
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5916 - acc: 0.6982
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5879 - acc: 0.7022
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5899 - acc: 0.6988
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5850 - acc: 0.7056
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5844 - acc: 0.7054 - val_loss: 0.6643 - val_acc: 0.6245

Epoch 00002: val_acc improved from 0.59389 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4903 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4875 - acc: 0.8021
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4839 - acc: 0.8047
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4730 - acc: 0.8219
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4636 - acc: 0.8333
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4621 - acc: 0.8438
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4539 - acc: 0.8516
 576/1283 [============>.................] - ETA: 1s - loss: 0.4500 - acc: 0.8507
 640/1283 [=============>................] - ETA: 0s - loss: 0.4487 - acc: 0.8453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4492 - acc: 0.8423
 768/1283 [================>.............] - ETA: 0s - loss: 0.4437 - acc: 0.8438
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4409 - acc: 0.8462
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4352 - acc: 0.8448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4316 - acc: 0.8419
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4243 - acc: 0.8413
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4224 - acc: 0.8394 - val_loss: 0.6687 - val_acc: 0.6550

Epoch 00003: val_acc improved from 0.62445 to 0.65502, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2945 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.2746 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2975 - acc: 0.9010
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3082 - acc: 0.8945
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2930 - acc: 0.9094
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2891 - acc: 0.9010
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2877 - acc: 0.8973
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2865 - acc: 0.8965
 576/1283 [============>.................] - ETA: 0s - loss: 0.2838 - acc: 0.8993
 640/1283 [=============>................] - ETA: 0s - loss: 0.2897 - acc: 0.8969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2804 - acc: 0.9006
 768/1283 [================>.............] - ETA: 0s - loss: 0.2761 - acc: 0.9010
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2797 - acc: 0.8984
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2803 - acc: 0.8969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2780 - acc: 0.8984
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2754 - acc: 0.8984
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2761 - acc: 0.8972
1280/1283 [============================>.] - ETA: 0s - loss: 0.2732 - acc: 0.8992
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2736 - acc: 0.8987 - val_loss: 0.7264 - val_acc: 0.6900

Epoch 00004: val_acc improved from 0.65502 to 0.68996, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1164 - acc: 0.9844
 128/1283 [=>............................] - ETA: 0s - loss: 0.1643 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1928 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1935 - acc: 0.9414
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1882 - acc: 0.9453
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1896 - acc: 0.9420
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1867 - acc: 0.9375
 576/1283 [============>.................] - ETA: 0s - loss: 0.1922 - acc: 0.9323
 640/1283 [=============>................] - ETA: 0s - loss: 0.1892 - acc: 0.9359
 768/1283 [================>.............] - ETA: 0s - loss: 0.1865 - acc: 0.9349
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1820 - acc: 0.9375
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1771 - acc: 0.9406
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1789 - acc: 0.9393
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1786 - acc: 0.9410
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1819 - acc: 0.9383
1280/1283 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9383
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1836 - acc: 0.9376 - val_loss: 0.8021 - val_acc: 0.6507

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1169 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.1490 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1402 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1281 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1287 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1312 - acc: 0.9661
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1285 - acc: 0.9643
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1267 - acc: 0.9629
 576/1283 [============>.................] - ETA: 0s - loss: 0.1300 - acc: 0.9583
 640/1283 [=============>................] - ETA: 0s - loss: 0.1311 - acc: 0.9547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1291 - acc: 0.9545
 768/1283 [================>.............] - ETA: 0s - loss: 0.1239 - acc: 0.9557
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1246 - acc: 0.9567
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1293 - acc: 0.9520
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1230 - acc: 0.9561
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1258 - acc: 0.9531
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1259 - acc: 0.9540
1280/1283 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9539
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1272 - acc: 0.9540 - val_loss: 0.9200 - val_acc: 0.6812

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1207 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0824 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0747 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0909 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0976 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0927 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0976 - acc: 0.9792
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0995 - acc: 0.9759
 768/1283 [================>.............] - ETA: 0s - loss: 0.0951 - acc: 0.9779
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0917 - acc: 0.9777
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0898 - acc: 0.9775
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0874 - acc: 0.9779
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0846 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0832 - acc: 0.9794
1283/1283 [==============================] - 1s 947us/step - loss: 0.0826 - acc: 0.9797 - val_loss: 1.0887 - val_acc: 0.6332

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0385 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0433 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0450 - acc: 0.9883
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0551 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0556 - acc: 0.9844
 576/1283 [============>.................] - ETA: 0s - loss: 0.0558 - acc: 0.9861
 640/1283 [=============>................] - ETA: 0s - loss: 0.0530 - acc: 0.9875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0562 - acc: 0.9858
 768/1283 [================>.............] - ETA: 0s - loss: 0.0558 - acc: 0.9870
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0512 - acc: 0.9888
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0496 - acc: 0.9896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0492 - acc: 0.9899
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0478 - acc: 0.9905
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0480 - acc: 0.9901
1280/1283 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9898
1283/1283 [==============================] - 1s 941us/step - loss: 0.0478 - acc: 0.9899 - val_loss: 1.1479 - val_acc: 0.6463

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0196 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0221 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0229 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0233 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0275 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0284 - acc: 0.9943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0268 - acc: 0.9952
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0291 - acc: 0.9938
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0283 - acc: 0.9945
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0276 - acc: 0.9942
1283/1283 [==============================] - 1s 828us/step - loss: 0.0280 - acc: 0.9938 - val_loss: 1.2834 - val_acc: 0.6419

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0058 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0156 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0211 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0221 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0242 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0253 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0253 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0245 - acc: 0.9940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0240 - acc: 0.9927
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0222 - acc: 0.9936
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0224 - acc: 0.9931
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0222 - acc: 0.9934
1280/1283 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9938
1283/1283 [==============================] - 1s 854us/step - loss: 0.0226 - acc: 0.9938 - val_loss: 1.3313 - val_acc: 0.6288

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0135 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0165 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0129 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0123 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0127 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0135 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0142 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0141 - acc: 0.9979
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0148 - acc: 0.9972
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0149 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9961
1283/1283 [==============================] - 1s 836us/step - loss: 0.0153 - acc: 0.9961 - val_loss: 1.4018 - val_acc: 0.6332

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0221 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0132 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0107 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0109 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0107 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0098 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0099 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0097 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0095 - acc: 0.9987
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0094 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0111 - acc: 0.9969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0104 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0104 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0117 - acc: 0.9967
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0124 - acc: 0.9961 - val_loss: 1.4657 - val_acc: 0.6245

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0050 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0056 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0052 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0058 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0079 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0091 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0087 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0096 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0112 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0105 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0106 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0104 - acc: 0.9974
1280/1283 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9969
1283/1283 [==============================] - 1s 884us/step - loss: 0.0111 - acc: 0.9969 - val_loss: 1.5443 - val_acc: 0.6288

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0042 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0035 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0087 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0074 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0065 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0057 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0053 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0080 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0097 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0091 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0105 - acc: 0.9935
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0104 - acc: 0.9940
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0112 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0106 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0104 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0099 - acc: 0.9945
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0095 - acc: 0.9948
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0097 - acc: 0.9951
1280/1283 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9953
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0094 - acc: 0.9953 - val_loss: 1.5775 - val_acc: 0.6245

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=15
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6341107871720116
best_valid_accuracy=0.6297376093294461
