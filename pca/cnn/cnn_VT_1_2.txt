/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:47:26.901745: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 16s - loss: 0.6954 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7387 - acc: 0.5469 
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7725 - acc: 0.5594
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7798 - acc: 0.5625
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7619 - acc: 0.5664
 640/1283 [=============>................] - ETA: 1s - loss: 0.7351 - acc: 0.5906
 768/1283 [================>.............] - ETA: 0s - loss: 0.7360 - acc: 0.5859
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7302 - acc: 0.5815
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7275 - acc: 0.5850
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7169 - acc: 0.5929
1280/1283 [============================>.] - ETA: 0s - loss: 0.7131 - acc: 0.5914
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7137 - acc: 0.5900 - val_loss: 0.7141 - val_acc: 0.6026

Epoch 00001: val_acc improved from -inf to 0.60262, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4840 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5078 - acc: 0.7552
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4963 - acc: 0.7617
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4982 - acc: 0.7688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4834 - acc: 0.7902
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4828 - acc: 0.7891
 640/1283 [=============>................] - ETA: 0s - loss: 0.4738 - acc: 0.8063
 768/1283 [================>.............] - ETA: 0s - loss: 0.4688 - acc: 0.8125
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4649 - acc: 0.8158
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4547 - acc: 0.8242
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4453 - acc: 0.8290
1280/1283 [============================>.] - ETA: 0s - loss: 0.4379 - acc: 0.8297
1283/1283 [==============================] - 1s 678us/step - loss: 0.4381 - acc: 0.8293 - val_loss: 0.7706 - val_acc: 0.6245

Epoch 00002: val_acc improved from 0.60262 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3988 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3971 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3584 - acc: 0.8320
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3557 - acc: 0.8438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3428 - acc: 0.8594
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3455 - acc: 0.8555
 640/1283 [=============>................] - ETA: 0s - loss: 0.3338 - acc: 0.8625
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3271 - acc: 0.8651
 768/1283 [================>.............] - ETA: 0s - loss: 0.3207 - acc: 0.8685
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3215 - acc: 0.8654
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3233 - acc: 0.8627
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3221 - acc: 0.8635
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3186 - acc: 0.8652
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3235 - acc: 0.8631
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3314 - acc: 0.8576
1280/1283 [============================>.] - ETA: 0s - loss: 0.3254 - acc: 0.8641
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3252 - acc: 0.8644 - val_loss: 0.7423 - val_acc: 0.6419

Epoch 00003: val_acc improved from 0.62445 to 0.64192, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1852 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2267 - acc: 0.9271
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2176 - acc: 0.9344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2138 - acc: 0.9401
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2120 - acc: 0.9355
 640/1283 [=============>................] - ETA: 0s - loss: 0.2129 - acc: 0.9328
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2119 - acc: 0.9332
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2084 - acc: 0.9399
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2048 - acc: 0.9420
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2034 - acc: 0.9417
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2018 - acc: 0.9424
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1990 - acc: 0.9436
1280/1283 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9422
1283/1283 [==============================] - 1s 772us/step - loss: 0.1981 - acc: 0.9415 - val_loss: 0.7914 - val_acc: 0.6245

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1010 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1168 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1293 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1330 - acc: 0.9777
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1341 - acc: 0.9785
 640/1283 [=============>................] - ETA: 0s - loss: 0.1319 - acc: 0.9766
 768/1283 [================>.............] - ETA: 0s - loss: 0.1307 - acc: 0.9779
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1265 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1254 - acc: 0.9781
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1224 - acc: 0.9789
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1242 - acc: 0.9770
1283/1283 [==============================] - 1s 739us/step - loss: 0.1222 - acc: 0.9774 - val_loss: 0.9359 - val_acc: 0.6026

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1186 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1211 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0970 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0909 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0881 - acc: 0.9826
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0830 - acc: 0.9858
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0806 - acc: 0.9856
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0796 - acc: 0.9865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0808 - acc: 0.9862
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0799 - acc: 0.9870
1280/1283 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9867
1283/1283 [==============================] - 1s 734us/step - loss: 0.0792 - acc: 0.9867 - val_loss: 0.9487 - val_acc: 0.6463

Epoch 00006: val_acc improved from 0.64192 to 0.64629, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0539 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0505 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0524 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0516 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0510 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0506 - acc: 0.9961
 576/1283 [============>.................] - ETA: 0s - loss: 0.0483 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0460 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0457 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0460 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0462 - acc: 0.9958
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0456 - acc: 0.9961
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0436 - acc: 0.9965
1280/1283 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9953
1283/1283 [==============================] - 1s 854us/step - loss: 0.0436 - acc: 0.9953 - val_loss: 1.0202 - val_acc: 0.6507

Epoch 00007: val_acc improved from 0.64629 to 0.65066, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0205 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0236 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0236 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0250 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0271 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0264 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0264 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0268 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0263 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0273 - acc: 0.9992
1283/1283 [==============================] - 1s 624us/step - loss: 0.0271 - acc: 0.9992 - val_loss: 1.0767 - val_acc: 0.6507

Epoch 00008: val_acc improved from 0.65066 to 0.65066, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0278 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0220 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0226 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0242 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0248 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0233 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0243 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0225 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0221 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0216 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0233 - acc: 0.9984
1283/1283 [==============================] - 1s 686us/step - loss: 0.0229 - acc: 0.9984 - val_loss: 1.1389 - val_acc: 0.6594

Epoch 00009: val_acc improved from 0.65066 to 0.65939, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0184 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0604 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0434 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0394 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0357 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0325 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0285 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0257 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0253 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0248 - acc: 0.9989
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0232 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0224 - acc: 0.9991
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0219 - acc: 0.9991
1280/1283 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9992
1283/1283 [==============================] - 1s 864us/step - loss: 0.0210 - acc: 0.9992 - val_loss: 1.2104 - val_acc: 0.6507

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0144 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0164 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0176 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0174 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0180 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0249 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0221 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0204 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0193 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0197 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0222 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0224 - acc: 0.9989
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0212 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0209 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0197 - acc: 0.9992
1283/1283 [==============================] - 1s 896us/step - loss: 0.0205 - acc: 0.9977 - val_loss: 1.3289 - val_acc: 0.6638

Epoch 00011: val_acc improved from 0.65939 to 0.66376, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0141 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0135 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0120 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0105 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0105 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0117 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0112 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0110 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0107 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0105 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0103 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0106 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 1.0000
1283/1283 [==============================] - 1s 828us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.2985 - val_acc: 0.6638

Epoch 00012: val_acc improved from 0.66376 to 0.66376, saving model to classification_logs//cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_VT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0070 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0071 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0073 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0067 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0064 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0063 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0070 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0066 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0063 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0060 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0060 - acc: 1.0000
1283/1283 [==============================] - 1s 846us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 1.3141 - val_acc: 0.6463

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0057 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0044 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0071 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0072 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0085 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0091 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0089 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0088 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0091 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0090 - acc: 0.9992
1283/1283 [==============================] - 1s 735us/step - loss: 0.0087 - acc: 0.9992 - val_loss: 1.3071 - val_acc: 0.6419

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0051 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0058 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0058 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0058 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0054 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0054 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0051 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0049 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0050 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 1.0000
1283/1283 [==============================] - 1s 713us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 1.3835 - val_acc: 0.6594

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0039 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0040 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0036 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0033 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0034 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0034 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0034 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0034 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 1.0000
1283/1283 [==============================] - 1s 667us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.3998 - val_acc: 0.6376

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0022 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0024 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0024 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0023 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0023 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0023 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0023 - acc: 1.0000
1283/1283 [==============================] - 1s 621us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.4163 - val_acc: 0.6376

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0018 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0016 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0018 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0022 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0021 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0019 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0019 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 1.0000
1283/1283 [==============================] - 1s 461us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.4498 - val_acc: 0.6463

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0011 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0016 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0021 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0022 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0020 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0019 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0020 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0020 - acc: 1.0000
1283/1283 [==============================] - 1s 468us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.4798 - val_acc: 0.6463

Epoch 00019: val_acc did not improve
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0018 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0017 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0016 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0016 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0015 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1283/1283 [==============================] - 1s 450us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.5103 - val_acc: 0.6507

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0014 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0021 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0016 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0016 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0014 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0015 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0015 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0014 - acc: 1.0000
1283/1283 [==============================] - 1s 464us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.5325 - val_acc: 0.6507

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0015 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0014 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0012 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0012 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0012 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0012 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0012 - acc: 1.0000
1283/1283 [==============================] - 1s 393us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.5474 - val_acc: 0.6550

Epoch 00022: val_acc did not improve
Epoch 00022: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
nodes=100
mode=VT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6530612244897959
best_valid_accuracy=0.6676384839650146
