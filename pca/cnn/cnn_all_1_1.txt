/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 07:59:00.570612: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.7230 - acc: 0.4688
 192/1283 [===>..........................] - ETA: 4s - loss: 0.7708 - acc: 0.5000 
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7745 - acc: 0.4906
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7659 - acc: 0.5022
 576/1283 [============>.................] - ETA: 1s - loss: 0.7525 - acc: 0.5017
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7518 - acc: 0.4943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7492 - acc: 0.4916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7503 - acc: 0.4944
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7426 - acc: 0.5029
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7357 - acc: 0.5122
1280/1283 [============================>.] - ETA: 0s - loss: 0.7360 - acc: 0.5117
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7376 - acc: 0.5113 - val_loss: 0.7002 - val_acc: 0.5546

Epoch 00001: val_acc improved from -inf to 0.55459, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5402 - acc: 0.7500
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5219 - acc: 0.7773
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5393 - acc: 0.7370
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5458 - acc: 0.7232
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5445 - acc: 0.7266
 640/1283 [=============>................] - ETA: 0s - loss: 0.5321 - acc: 0.7469
 768/1283 [================>.............] - ETA: 0s - loss: 0.5245 - acc: 0.7513
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5199 - acc: 0.7567
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5218 - acc: 0.7510
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5160 - acc: 0.7561
1280/1283 [============================>.] - ETA: 0s - loss: 0.5134 - acc: 0.7570
1283/1283 [==============================] - 1s 730us/step - loss: 0.5131 - acc: 0.7576 - val_loss: 0.7058 - val_acc: 0.5852

Epoch 00002: val_acc improved from 0.55459 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3812 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3789 - acc: 0.8398
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3710 - acc: 0.8531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3670 - acc: 0.8620
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3714 - acc: 0.8549
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3763 - acc: 0.8535
 640/1283 [=============>................] - ETA: 0s - loss: 0.3837 - acc: 0.8484
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3860 - acc: 0.8466
 768/1283 [================>.............] - ETA: 0s - loss: 0.3802 - acc: 0.8516
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3732 - acc: 0.8605
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3794 - acc: 0.8521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3821 - acc: 0.8465
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3795 - acc: 0.8481
1280/1283 [============================>.] - ETA: 0s - loss: 0.3762 - acc: 0.8500
1283/1283 [==============================] - 1s 747us/step - loss: 0.3761 - acc: 0.8504 - val_loss: 0.7300 - val_acc: 0.6026

Epoch 00003: val_acc improved from 0.58515 to 0.60262, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3564 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3332 - acc: 0.8854
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3182 - acc: 0.8938
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3060 - acc: 0.9089
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3109 - acc: 0.8945
 640/1283 [=============>................] - ETA: 0s - loss: 0.3055 - acc: 0.8938
 768/1283 [================>.............] - ETA: 0s - loss: 0.2937 - acc: 0.8984
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2939 - acc: 0.8940
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2922 - acc: 0.8955
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2870 - acc: 0.8993
1280/1283 [============================>.] - ETA: 0s - loss: 0.2834 - acc: 0.9016
1283/1283 [==============================] - 1s 645us/step - loss: 0.2829 - acc: 0.9018 - val_loss: 0.7295 - val_acc: 0.6245

Epoch 00004: val_acc improved from 0.60262 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2008 - acc: 0.9531
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2074 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1956 - acc: 0.9375
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1842 - acc: 0.9512
 640/1283 [=============>................] - ETA: 0s - loss: 0.1786 - acc: 0.9578
 768/1283 [================>.............] - ETA: 0s - loss: 0.1813 - acc: 0.9557
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1808 - acc: 0.9565
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1790 - acc: 0.9551
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1782 - acc: 0.9566
1283/1283 [==============================] - 1s 563us/step - loss: 0.1743 - acc: 0.9587 - val_loss: 0.7039 - val_acc: 0.6812

Epoch 00005: val_acc improved from 0.62445 to 0.68122, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1538 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1335 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1325 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1215 - acc: 0.9665
 576/1283 [============>.................] - ETA: 0s - loss: 0.1190 - acc: 0.9670
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1194 - acc: 0.9673
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1163 - acc: 0.9700
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1152 - acc: 0.9708
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1133 - acc: 0.9722
1280/1283 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9727
1283/1283 [==============================] - 1s 587us/step - loss: 0.1116 - acc: 0.9727 - val_loss: 0.7709 - val_acc: 0.6856

Epoch 00006: val_acc improved from 0.68122 to 0.68559, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0914 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0864 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0738 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0730 - acc: 0.9896
 576/1283 [============>.................] - ETA: 0s - loss: 0.0705 - acc: 0.9878
 768/1283 [================>.............] - ETA: 0s - loss: 0.0704 - acc: 0.9883
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0702 - acc: 0.9855
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0714 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0712 - acc: 0.9852
1280/1283 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9859
1283/1283 [==============================] - 1s 598us/step - loss: 0.0700 - acc: 0.9860 - val_loss: 0.8267 - val_acc: 0.6681

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0391 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0421 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0533 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0532 - acc: 0.9969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0518 - acc: 0.9961
 640/1283 [=============>................] - ETA: 0s - loss: 0.0503 - acc: 0.9953
 768/1283 [================>.............] - ETA: 0s - loss: 0.0501 - acc: 0.9935
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0515 - acc: 0.9922
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0515 - acc: 0.9912
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0503 - acc: 0.9917
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0502 - acc: 0.9910
1283/1283 [==============================] - 1s 569us/step - loss: 0.0489 - acc: 0.9914 - val_loss: 0.9070 - val_acc: 0.6638

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0286 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0338 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0366 - acc: 0.9922
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0355 - acc: 0.9922
 576/1283 [============>.................] - ETA: 0s - loss: 0.0366 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0356 - acc: 0.9915
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0352 - acc: 0.9922
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0348 - acc: 0.9922
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0335 - acc: 0.9931
1280/1283 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9938
1283/1283 [==============================] - 1s 565us/step - loss: 0.0330 - acc: 0.9938 - val_loss: 0.9556 - val_acc: 0.6943

Epoch 00009: val_acc improved from 0.68559 to 0.69432, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0188 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0289 - acc: 0.9896
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0285 - acc: 0.9922
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0270 - acc: 0.9922
 640/1283 [=============>................] - ETA: 0s - loss: 0.0247 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0252 - acc: 0.9935
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0257 - acc: 0.9933
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0251 - acc: 0.9941
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0276 - acc: 0.9922
1280/1283 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9922
1283/1283 [==============================] - 1s 507us/step - loss: 0.0281 - acc: 0.9922 - val_loss: 1.0445 - val_acc: 0.6943

Epoch 00010: val_acc improved from 0.69432 to 0.69432, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0185 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0177 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0177 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0190 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0176 - acc: 0.9983
 768/1283 [================>.............] - ETA: 0s - loss: 0.0184 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0188 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0187 - acc: 0.9971
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0189 - acc: 0.9967
1283/1283 [==============================] - 1s 499us/step - loss: 0.0188 - acc: 0.9961 - val_loss: 1.0670 - val_acc: 0.6856

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0189 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0154 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0152 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0136 - acc: 0.9983
 768/1283 [================>.............] - ETA: 0s - loss: 0.0131 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0143 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0154 - acc: 0.9961
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0152 - acc: 0.9965
1280/1283 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9961
1283/1283 [==============================] - 1s 479us/step - loss: 0.0151 - acc: 0.9961 - val_loss: 1.0985 - val_acc: 0.6900

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0090 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0110 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0111 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0140 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0129 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0120 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0112 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0120 - acc: 0.9969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0125 - acc: 0.9963
1280/1283 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9969
1283/1283 [==============================] - 1s 475us/step - loss: 0.0119 - acc: 0.9969 - val_loss: 1.1362 - val_acc: 0.6856

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0059 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0149 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0144 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0137 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0123 - acc: 0.9957
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0125 - acc: 0.9952
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0123 - acc: 0.9951
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0116 - acc: 0.9957
1283/1283 [==============================] - 1s 454us/step - loss: 0.0111 - acc: 0.9961 - val_loss: 1.2160 - val_acc: 0.6900

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0201 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0136 - acc: 0.9948
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0141 - acc: 0.9948
 576/1283 [============>.................] - ETA: 0s - loss: 0.0118 - acc: 0.9965
 768/1283 [================>.............] - ETA: 0s - loss: 0.0102 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0102 - acc: 0.9967
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0099 - acc: 0.9972
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0097 - acc: 0.9975
1283/1283 [==============================] - 1s 441us/step - loss: 0.0098 - acc: 0.9977 - val_loss: 1.2421 - val_acc: 0.6987

Epoch 00015: val_acc improved from 0.69432 to 0.69869, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0080 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0144 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0136 - acc: 0.9955
 640/1283 [=============>................] - ETA: 0s - loss: 0.0142 - acc: 0.9953
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0133 - acc: 0.9964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0123 - acc: 0.9969
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0115 - acc: 0.9974
1283/1283 [==============================] - 0s 382us/step - loss: 0.0111 - acc: 0.9977 - val_loss: 1.2724 - val_acc: 0.6900

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0301 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0115 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0117 - acc: 0.9955
 640/1283 [=============>................] - ETA: 0s - loss: 0.0097 - acc: 0.9969
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0097 - acc: 0.9964
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0099 - acc: 0.9972
1280/1283 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9977
1283/1283 [==============================] - 0s 333us/step - loss: 0.0090 - acc: 0.9977 - val_loss: 1.2756 - val_acc: 0.6987

Epoch 00017: val_acc did not improve
Epoch 18/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0180 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0106 - acc: 0.9969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0215 - acc: 0.9941
 768/1283 [================>.............] - ETA: 0s - loss: 0.0181 - acc: 0.9961
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0165 - acc: 0.9969
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0166 - acc: 0.9965
1283/1283 [==============================] - 0s 294us/step - loss: 0.0155 - acc: 0.9969 - val_loss: 1.2815 - val_acc: 0.6594

Epoch 00018: val_acc did not improve
Epoch 19/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0155 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0107 - acc: 0.9978
 640/1283 [=============>................] - ETA: 0s - loss: 0.0103 - acc: 0.9984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0099 - acc: 0.9988
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0114 - acc: 0.9980
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0107 - acc: 0.9984
1283/1283 [==============================] - 0s 329us/step - loss: 0.0104 - acc: 0.9984 - val_loss: 1.2278 - val_acc: 0.7074

Epoch 00019: val_acc improved from 0.69869 to 0.70742, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 20/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0150 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0105 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0108 - acc: 0.9969
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0088 - acc: 0.9978
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0079 - acc: 0.9982
1280/1283 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9984
1283/1283 [==============================] - 0s 260us/step - loss: 0.0073 - acc: 0.9984 - val_loss: 1.3008 - val_acc: 0.7031

Epoch 00020: val_acc did not improve
Epoch 21/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0045 - acc: 0.9980
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0054 - acc: 0.9986
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0065 - acc: 0.9967
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0069 - acc: 0.9972
1280/1283 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9977
1283/1283 [==============================] - 0s 300us/step - loss: 0.0062 - acc: 0.9977 - val_loss: 1.3841 - val_acc: 0.6856

Epoch 00021: val_acc did not improve
Epoch 22/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0021 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0046 - acc: 0.9987
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0042 - acc: 0.9990
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0059 - acc: 0.9975
1283/1283 [==============================] - 0s 261us/step - loss: 0.0063 - acc: 0.9969 - val_loss: 1.3866 - val_acc: 0.6987

Epoch 00022: val_acc did not improve
Epoch 23/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0030 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0047 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0128 - acc: 0.9965
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0100 - acc: 0.9976
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0114 - acc: 0.9972
1283/1283 [==============================] - 0s 245us/step - loss: 0.0111 - acc: 0.9969 - val_loss: 1.5547 - val_acc: 0.6812

Epoch 00023: val_acc did not improve
Epoch 24/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0043 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0162 - acc: 0.9938
 576/1283 [============>.................] - ETA: 0s - loss: 0.0119 - acc: 0.9965
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0105 - acc: 0.9976
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0104 - acc: 0.9974
1283/1283 [==============================] - 0s 237us/step - loss: 0.0110 - acc: 0.9969 - val_loss: 1.4858 - val_acc: 0.6943

Epoch 00024: val_acc did not improve
Epoch 25/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0256 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0094 - acc: 0.9969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0066 - acc: 0.9980
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0061 - acc: 0.9986
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0053 - acc: 0.9989
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0070 - acc: 0.9972
1280/1283 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9969
1283/1283 [==============================] - 0s 299us/step - loss: 0.0077 - acc: 0.9969 - val_loss: 1.4460 - val_acc: 0.6681

Epoch 00025: val_acc did not improve
Epoch 26/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0163 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0205 - acc: 0.9875
 576/1283 [============>.................] - ETA: 0s - loss: 0.0130 - acc: 0.9931
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0114 - acc: 0.9940
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0115 - acc: 0.9936
1280/1283 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9945
1283/1283 [==============================] - 0s 271us/step - loss: 0.0107 - acc: 0.9945 - val_loss: 1.4570 - val_acc: 0.6987

Epoch 00026: val_acc did not improve
Epoch 27/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0022 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0071 - acc: 0.9974
 640/1283 [=============>................] - ETA: 0s - loss: 0.0079 - acc: 0.9969
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0083 - acc: 0.9967
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0080 - acc: 0.9965
1283/1283 [==============================] - 0s 238us/step - loss: 0.0074 - acc: 0.9969 - val_loss: 1.5411 - val_acc: 0.6681

Epoch 00027: val_acc did not improve
Epoch 28/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0227 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0069 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0055 - acc: 0.9986
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0050 - acc: 0.9990
1280/1283 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9977
1283/1283 [==============================] - 0s 210us/step - loss: 0.0058 - acc: 0.9977 - val_loss: 1.5849 - val_acc: 0.6638

Epoch 00028: val_acc did not improve
Epoch 29/100

  64/1283 [>.............................] - ETA: 0s - loss: 6.9735e-04 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0079 - acc: 0.9922    
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0075 - acc: 0.9929
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0060 - acc: 0.9951
1283/1283 [==============================] - 0s 197us/step - loss: 0.0054 - acc: 0.9961 - val_loss: 1.6168 - val_acc: 0.6638

Epoch 00029: val_acc did not improve
Epoch 00029: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6166180758017493
best_valid_accuracy=0.6151603498542274
