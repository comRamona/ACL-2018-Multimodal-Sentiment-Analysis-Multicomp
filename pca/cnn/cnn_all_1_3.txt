/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 07:59:24.052850: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 0s - loss: 1.0446 - acc: 0.5625
 384/1283 [=======>......................] - ETA: 0s - loss: 0.8546 - acc: 0.5078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.8067 - acc: 0.5284
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7935 - acc: 0.5322
1283/1283 [==============================] - 0s 232us/step - loss: 0.7739 - acc: 0.5331 - val_loss: 0.7236 - val_acc: 0.5590

Epoch 00001: val_acc improved from -inf to 0.55895, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5743 - acc: 0.6719
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5521 - acc: 0.7406
 576/1283 [============>.................] - ETA: 0s - loss: 0.5403 - acc: 0.7587
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5272 - acc: 0.7764
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5148 - acc: 0.7769
1283/1283 [==============================] - 0s 220us/step - loss: 0.5125 - acc: 0.7747 - val_loss: 0.6812 - val_acc: 0.6638

Epoch 00002: val_acc improved from 0.55895 to 0.66376, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3987 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3883 - acc: 0.8464
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3816 - acc: 0.8438
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3811 - acc: 0.8369
1283/1283 [==============================] - 0s 193us/step - loss: 0.3747 - acc: 0.8449 - val_loss: 0.6734 - val_acc: 0.6900

Epoch 00003: val_acc improved from 0.66376 to 0.68996, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2322 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2449 - acc: 0.9141
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2644 - acc: 0.8949
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2622 - acc: 0.8975
1283/1283 [==============================] - 0s 191us/step - loss: 0.2526 - acc: 0.9034 - val_loss: 0.7299 - val_acc: 0.6943

Epoch 00004: val_acc improved from 0.68996 to 0.69432, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_25.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1093 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1980 - acc: 0.9297
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1949 - acc: 0.9347
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1982 - acc: 0.9316
1283/1283 [==============================] - 0s 189us/step - loss: 0.1903 - acc: 0.9361 - val_loss: 0.7383 - val_acc: 0.6638

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1180 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1367 - acc: 0.9557
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1281 - acc: 0.9588
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1310 - acc: 0.9600
1283/1283 [==============================] - 0s 193us/step - loss: 0.1309 - acc: 0.9602 - val_loss: 0.8121 - val_acc: 0.6550

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1017 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0784 - acc: 0.9870
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0784 - acc: 0.9886
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0807 - acc: 0.9854
1283/1283 [==============================] - 0s 192us/step - loss: 0.0812 - acc: 0.9844 - val_loss: 0.9081 - val_acc: 0.6638

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0782 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0529 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0507 - acc: 0.9901
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0536 - acc: 0.9902
1283/1283 [==============================] - 0s 190us/step - loss: 0.0568 - acc: 0.9891 - val_loss: 0.9274 - val_acc: 0.6594

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0447 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0431 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0472 - acc: 0.9901
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0444 - acc: 0.9912
1283/1283 [==============================] - 0s 193us/step - loss: 0.0442 - acc: 0.9914 - val_loss: 0.9910 - val_acc: 0.6463

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0160 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0456 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0534 - acc: 0.9858
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0536 - acc: 0.9873
1283/1283 [==============================] - 0s 195us/step - loss: 0.0610 - acc: 0.9805 - val_loss: 1.1611 - val_acc: 0.6594

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0720 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0413 - acc: 0.9922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0341 - acc: 0.9929
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0347 - acc: 0.9932
1283/1283 [==============================] - 0s 194us/step - loss: 0.0345 - acc: 0.9930 - val_loss: 1.1744 - val_acc: 0.6638

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0217 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0193 - acc: 0.9974
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0194 - acc: 0.9972
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0201 - acc: 0.9980
1283/1283 [==============================] - 0s 190us/step - loss: 0.0207 - acc: 0.9984 - val_loss: 1.2202 - val_acc: 0.6419

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0117 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0160 - acc: 0.9974
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0146 - acc: 0.9986
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0159 - acc: 0.9971
1283/1283 [==============================] - 0s 192us/step - loss: 0.0169 - acc: 0.9969 - val_loss: 1.2639 - val_acc: 0.6463

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0169 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0162 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0169 - acc: 0.9957
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0156 - acc: 0.9961
1283/1283 [==============================] - 0s 193us/step - loss: 0.0148 - acc: 0.9961 - val_loss: 1.3235 - val_acc: 0.6332

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=25
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6151603498542274
best_valid_accuracy=0.6239067055393586
