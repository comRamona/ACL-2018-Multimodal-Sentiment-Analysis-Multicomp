/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:34:00.087009: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 8s - loss: 0.8303 - acc: 0.4375
 192/1283 [===>..........................] - ETA: 3s - loss: 0.7856 - acc: 0.5104
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7641 - acc: 0.5391
 384/1283 [=======>......................] - ETA: 1s - loss: 0.7726 - acc: 0.5469
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7814 - acc: 0.5379
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7796 - acc: 0.5410
 640/1283 [=============>................] - ETA: 1s - loss: 0.7499 - acc: 0.5609
 768/1283 [================>.............] - ETA: 0s - loss: 0.7405 - acc: 0.5586
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7410 - acc: 0.5513
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7382 - acc: 0.5490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7356 - acc: 0.5537
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7266 - acc: 0.5668
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7244 - acc: 0.5683
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7293 - acc: 0.5627 - val_loss: 0.6708 - val_acc: 0.6114

Epoch 00001: val_acc improved from -inf to 0.61135, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4826 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.4827 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4810 - acc: 0.8086
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4742 - acc: 0.8187
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4670 - acc: 0.8151
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4668 - acc: 0.8214
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4680 - acc: 0.8203
 576/1283 [============>.................] - ETA: 0s - loss: 0.4681 - acc: 0.8229
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4656 - acc: 0.8196
 768/1283 [================>.............] - ETA: 0s - loss: 0.4638 - acc: 0.8229
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4632 - acc: 0.8233
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4595 - acc: 0.8270
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4552 - acc: 0.8320
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4498 - acc: 0.8351
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4439 - acc: 0.8372
1283/1283 [==============================] - 1s 983us/step - loss: 0.4408 - acc: 0.8379 - val_loss: 0.7331 - val_acc: 0.6026

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4491 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4570 - acc: 0.7135
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4044 - acc: 0.7844
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3829 - acc: 0.8103
 576/1283 [============>.................] - ETA: 0s - loss: 0.3824 - acc: 0.8177
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3640 - acc: 0.8366
 768/1283 [================>.............] - ETA: 0s - loss: 0.3555 - acc: 0.8424
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3539 - acc: 0.8426
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3515 - acc: 0.8448
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3485 - acc: 0.8474
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3474 - acc: 0.8470
1283/1283 [==============================] - 1s 713us/step - loss: 0.3438 - acc: 0.8504 - val_loss: 0.6569 - val_acc: 0.6550

Epoch 00003: val_acc improved from 0.61135 to 0.65502, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1870 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2522 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2332 - acc: 0.9250
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2348 - acc: 0.9193
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2314 - acc: 0.9196
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2298 - acc: 0.9219
 576/1283 [============>.................] - ETA: 0s - loss: 0.2310 - acc: 0.9219
 640/1283 [=============>................] - ETA: 0s - loss: 0.2299 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2283 - acc: 0.9261
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2243 - acc: 0.9291
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2201 - acc: 0.9319
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2171 - acc: 0.9316
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2174 - acc: 0.9288
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2154 - acc: 0.9317
1283/1283 [==============================] - 1s 965us/step - loss: 0.2131 - acc: 0.9345 - val_loss: 0.6618 - val_acc: 0.6681

Epoch 00004: val_acc improved from 0.65502 to 0.66812, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1337 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1376 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1357 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1375 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1400 - acc: 0.9792
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1389 - acc: 0.9785
 640/1283 [=============>................] - ETA: 0s - loss: 0.1368 - acc: 0.9750
 768/1283 [================>.............] - ETA: 0s - loss: 0.1385 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1399 - acc: 0.9700
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1361 - acc: 0.9719
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1341 - acc: 0.9733
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1347 - acc: 0.9729
1280/1283 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9727
1283/1283 [==============================] - 1s 765us/step - loss: 0.1330 - acc: 0.9727 - val_loss: 0.7299 - val_acc: 0.6769

Epoch 00005: val_acc improved from 0.66812 to 0.67686, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1336 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1148 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1046 - acc: 0.9844
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0922 - acc: 0.9896
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0908 - acc: 0.9883
 640/1283 [=============>................] - ETA: 0s - loss: 0.0884 - acc: 0.9875
 768/1283 [================>.............] - ETA: 0s - loss: 0.0851 - acc: 0.9883
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0838 - acc: 0.9888
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0823 - acc: 0.9883
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0818 - acc: 0.9878
1280/1283 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9875
1283/1283 [==============================] - 1s 629us/step - loss: 0.0810 - acc: 0.9875 - val_loss: 0.7962 - val_acc: 0.7074

Epoch 00006: val_acc improved from 0.67686 to 0.70742, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_20.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0583 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0536 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0545 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0524 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0503 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0500 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0490 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0505 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0477 - acc: 0.9963
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0468 - acc: 0.9967
1283/1283 [==============================] - 1s 617us/step - loss: 0.0468 - acc: 0.9961 - val_loss: 0.8080 - val_acc: 0.6856

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0258 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0252 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0238 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0260 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0285 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0275 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0276 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0278 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0292 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0289 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0289 - acc: 0.9992
1283/1283 [==============================] - 1s 675us/step - loss: 0.0291 - acc: 0.9992 - val_loss: 0.8701 - val_acc: 0.6900

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0291 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0229 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0220 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0225 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0214 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0222 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0208 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0200 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0195 - acc: 0.9991
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0192 - acc: 0.9991
1280/1283 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9992
1283/1283 [==============================] - 1s 719us/step - loss: 0.0189 - acc: 0.9992 - val_loss: 0.9269 - val_acc: 0.6943

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0153 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0155 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0139 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0140 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0135 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0130 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0122 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0119 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0127 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0123 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0120 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 1.0000
1283/1283 [==============================] - 1s 824us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.9721 - val_acc: 0.6943

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0077 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0101 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0100 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0095 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0092 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0087 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0085 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0086 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0088 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0089 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0087 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 1.0000
1283/1283 [==============================] - 1s 794us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.0213 - val_acc: 0.6943

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0067 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0066 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0064 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0064 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0061 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0061 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0063 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0063 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0063 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 1.0000
1283/1283 [==============================] - 1s 901us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0559 - val_acc: 0.6900

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0033 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0048 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0043 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0056 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0052 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0052 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0051 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0053 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0051 - acc: 1.0000
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0050 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 1.0000
1283/1283 [==============================] - 1s 899us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 1.1862 - val_acc: 0.6681

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0064 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0152 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0258 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0252 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0207 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0200 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0226 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0220 - acc: 0.9969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0213 - acc: 0.9972
 768/1283 [================>.............] - ETA: 0s - loss: 0.0205 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0191 - acc: 0.9978
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0189 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0188 - acc: 0.9980
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0189 - acc: 0.9982
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0197 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0196 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9977
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0210 - acc: 0.9969 - val_loss: 1.1365 - val_acc: 0.6812

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0117 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0853 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1031 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1230 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1094 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0959 - acc: 0.9714
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1100 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.1094 - acc: 0.9672
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1075 - acc: 0.9673
 768/1283 [================>.............] - ETA: 0s - loss: 0.1049 - acc: 0.9688
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1083 - acc: 0.9651
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1054 - acc: 0.9646
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0993 - acc: 0.9669
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1005 - acc: 0.9653
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0972 - acc: 0.9671
1280/1283 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9688
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0944 - acc: 0.9688 - val_loss: 1.0425 - val_acc: 0.6987

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0361 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0352 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0265 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0397 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0690 - acc: 0.9888
 576/1283 [============>.................] - ETA: 0s - loss: 0.0590 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0563 - acc: 0.9915
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0505 - acc: 0.9928
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0484 - acc: 0.9933
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0452 - acc: 0.9941
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0417 - acc: 0.9948
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0402 - acc: 0.9951
1280/1283 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9953
1283/1283 [==============================] - 1s 893us/step - loss: 0.0394 - acc: 0.9953 - val_loss: 0.9753 - val_acc: 0.6987

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=20
nodes=100
mode=AT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6384839650145773
best_valid_accuracy=0.6282798833819242
