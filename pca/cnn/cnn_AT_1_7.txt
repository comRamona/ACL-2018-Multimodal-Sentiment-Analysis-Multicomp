/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 08:35:02.172680: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.9548 - acc: 0.5625
 192/1283 [===>..........................] - ETA: 1s - loss: 0.8644 - acc: 0.5729
 320/1283 [======>.......................] - ETA: 1s - loss: 0.8410 - acc: 0.5563
 448/1283 [=========>....................] - ETA: 0s - loss: 0.8279 - acc: 0.5603
 576/1283 [============>.................] - ETA: 0s - loss: 0.8057 - acc: 0.5694
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7925 - acc: 0.5724
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7959 - acc: 0.5613
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7889 - acc: 0.5677
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7773 - acc: 0.5717
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7750 - acc: 0.5650
1280/1283 [============================>.] - ETA: 0s - loss: 0.7687 - acc: 0.5664
1283/1283 [==============================] - 1s 861us/step - loss: 0.7685 - acc: 0.5666 - val_loss: 0.6985 - val_acc: 0.6114

Epoch 00001: val_acc improved from -inf to 0.61135, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5011 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5029 - acc: 0.8229
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5144 - acc: 0.7750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5175 - acc: 0.7634
 576/1283 [============>.................] - ETA: 0s - loss: 0.5048 - acc: 0.7847
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4995 - acc: 0.7940
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4951 - acc: 0.7993
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4880 - acc: 0.8042
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4849 - acc: 0.8079
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4823 - acc: 0.8108
1280/1283 [============================>.] - ETA: 0s - loss: 0.4777 - acc: 0.8141
1283/1283 [==============================] - 1s 646us/step - loss: 0.4776 - acc: 0.8145 - val_loss: 0.6950 - val_acc: 0.5983

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3258 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3498 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3541 - acc: 0.8344
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3477 - acc: 0.8549
 576/1283 [============>.................] - ETA: 0s - loss: 0.3535 - acc: 0.8507
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3490 - acc: 0.8537
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3619 - acc: 0.8413
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3578 - acc: 0.8469
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3566 - acc: 0.8474
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3542 - acc: 0.8479
1283/1283 [==============================] - 1s 627us/step - loss: 0.3532 - acc: 0.8488 - val_loss: 0.6900 - val_acc: 0.6943

Epoch 00003: val_acc improved from 0.61135 to 0.69432, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2492 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2514 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2444 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2377 - acc: 0.9286
 576/1283 [============>.................] - ETA: 0s - loss: 0.2431 - acc: 0.9271
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2551 - acc: 0.9162
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2543 - acc: 0.9159
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2532 - acc: 0.9156
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2503 - acc: 0.9164
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2475 - acc: 0.9161
1283/1283 [==============================] - 1s 549us/step - loss: 0.2445 - acc: 0.9182 - val_loss: 0.7139 - val_acc: 0.6812

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1528 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1692 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2049 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2079 - acc: 0.9241
 576/1283 [============>.................] - ETA: 0s - loss: 0.2054 - acc: 0.9288
 768/1283 [================>.............] - ETA: 0s - loss: 0.2022 - acc: 0.9310
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2009 - acc: 0.9319
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1987 - acc: 0.9316
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1954 - acc: 0.9358
1280/1283 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9375
1283/1283 [==============================] - 1s 540us/step - loss: 0.1923 - acc: 0.9376 - val_loss: 0.7218 - val_acc: 0.6987

Epoch 00005: val_acc improved from 0.69432 to 0.69869, saving model to classification_logs//cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25/saved_models/best_validation_cnn_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.2_nl_1_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1011 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1276 - acc: 0.9609
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1312 - acc: 0.9609
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1254 - acc: 0.9668
 640/1283 [=============>................] - ETA: 0s - loss: 0.1271 - acc: 0.9625
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1312 - acc: 0.9603
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1326 - acc: 0.9615
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1332 - acc: 0.9605
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1314 - acc: 0.9613
1283/1283 [==============================] - 1s 524us/step - loss: 0.1304 - acc: 0.9618 - val_loss: 0.7755 - val_acc: 0.6769

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1155 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1096 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0931 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0864 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.0866 - acc: 0.9774
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0875 - acc: 0.9801
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0849 - acc: 0.9808
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0874 - acc: 0.9792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0880 - acc: 0.9789
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0881 - acc: 0.9786
1283/1283 [==============================] - 1s 510us/step - loss: 0.0884 - acc: 0.9782 - val_loss: 0.8298 - val_acc: 0.6725

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0843 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0846 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0722 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0632 - acc: 0.9866
 576/1283 [============>.................] - ETA: 0s - loss: 0.0665 - acc: 0.9844
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0614 - acc: 0.9872
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0618 - acc: 0.9868
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0628 - acc: 0.9875
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0627 - acc: 0.9871
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0642 - acc: 0.9860
1283/1283 [==============================] - 1s 518us/step - loss: 0.0655 - acc: 0.9860 - val_loss: 0.8864 - val_acc: 0.6725

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0444 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0566 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0516 - acc: 0.9938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0485 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0467 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0514 - acc: 0.9901
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0511 - acc: 0.9904
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0497 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0486 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0488 - acc: 0.9910
1283/1283 [==============================] - 1s 526us/step - loss: 0.0482 - acc: 0.9914 - val_loss: 0.9943 - val_acc: 0.6725

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0222 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0281 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0360 - acc: 0.9969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0373 - acc: 0.9941
 640/1283 [=============>................] - ETA: 0s - loss: 0.0371 - acc: 0.9953
 768/1283 [================>.............] - ETA: 0s - loss: 0.0365 - acc: 0.9948
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0351 - acc: 0.9948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0378 - acc: 0.9945
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0375 - acc: 0.9942
1283/1283 [==============================] - 1s 464us/step - loss: 0.0372 - acc: 0.9938 - val_loss: 1.0260 - val_acc: 0.6812

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0322 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0373 - acc: 0.9922
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0311 - acc: 0.9948
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0281 - acc: 0.9941
 640/1283 [=============>................] - ETA: 0s - loss: 0.0291 - acc: 0.9938
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0291 - acc: 0.9940
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0307 - acc: 0.9927
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0297 - acc: 0.9922
1283/1283 [==============================] - 1s 418us/step - loss: 0.0298 - acc: 0.9914 - val_loss: 1.0774 - val_acc: 0.6681

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0222 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0226 - acc: 0.9883
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0222 - acc: 0.9888
 640/1283 [=============>................] - ETA: 0s - loss: 0.0221 - acc: 0.9906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0199 - acc: 0.9928
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0206 - acc: 0.9941
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0222 - acc: 0.9942
1283/1283 [==============================] - 0s 324us/step - loss: 0.0216 - acc: 0.9945 - val_loss: 1.1173 - val_acc: 0.6725

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0195 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0143 - acc: 0.9961
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0162 - acc: 0.9955
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0159 - acc: 0.9957
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0181 - acc: 0.9944
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0177 - acc: 0.9954
1280/1283 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9953
1283/1283 [==============================] - 0s 308us/step - loss: 0.0184 - acc: 0.9953 - val_loss: 1.1436 - val_acc: 0.6594

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0166 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0140 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0183 - acc: 0.9941
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0177 - acc: 0.9943
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0172 - acc: 0.9938
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0162 - acc: 0.9951
1283/1283 [==============================] - 0s 278us/step - loss: 0.0158 - acc: 0.9953 - val_loss: 1.2005 - val_acc: 0.6681

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0380 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0194 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0155 - acc: 0.9980
 768/1283 [================>.............] - ETA: 0s - loss: 0.0160 - acc: 0.9961
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0162 - acc: 0.9948
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0146 - acc: 0.9957
1283/1283 [==============================] - 0s 277us/step - loss: 0.0139 - acc: 0.9961 - val_loss: 1.2453 - val_acc: 0.6900

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=1
max_len=25
nodes=100
mode=AT
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6137026239067055
best_valid_accuracy=0.6209912536443148
