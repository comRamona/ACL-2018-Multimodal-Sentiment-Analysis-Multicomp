/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 07:58:41.901955: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 21s - loss: 1.0986 - acc: 0.4219
 128/1283 [=>............................] - ETA: 11s - loss: 0.8866 - acc: 0.4766
 192/1283 [===>..........................] - ETA: 7s - loss: 1.0269 - acc: 0.4531 
 256/1283 [====>.........................] - ETA: 5s - loss: 1.0032 - acc: 0.4688
 320/1283 [======>.......................] - ETA: 4s - loss: 0.9722 - acc: 0.4656
 384/1283 [=======>......................] - ETA: 3s - loss: 0.9352 - acc: 0.4714
 448/1283 [=========>....................] - ETA: 3s - loss: 0.8980 - acc: 0.4911
 512/1283 [==========>...................] - ETA: 2s - loss: 0.8702 - acc: 0.5000
 576/1283 [============>.................] - ETA: 2s - loss: 0.8481 - acc: 0.5139
 640/1283 [=============>................] - ETA: 1s - loss: 0.8333 - acc: 0.5234
 704/1283 [===============>..............] - ETA: 1s - loss: 0.8263 - acc: 0.5241
 768/1283 [================>.............] - ETA: 1s - loss: 0.8177 - acc: 0.5260
 896/1283 [===================>..........] - ETA: 0s - loss: 0.8039 - acc: 0.5246
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7863 - acc: 0.5312
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7717 - acc: 0.5347
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7684 - acc: 0.5337
1280/1283 [============================>.] - ETA: 0s - loss: 0.7668 - acc: 0.5336
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7670 - acc: 0.5331 - val_loss: 0.7010 - val_acc: 0.5677

Epoch 00001: val_acc improved from -inf to 0.56769, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6477 - acc: 0.5938
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6142 - acc: 0.6875
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6071 - acc: 0.7148
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6018 - acc: 0.7219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5982 - acc: 0.7266
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6021 - acc: 0.7054
 576/1283 [============>.................] - ETA: 0s - loss: 0.6113 - acc: 0.6684
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6115 - acc: 0.6605
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6026 - acc: 0.6743
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5977 - acc: 0.6875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5938 - acc: 0.6953
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5904 - acc: 0.6985
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5866 - acc: 0.7039
1280/1283 [============================>.] - ETA: 0s - loss: 0.5859 - acc: 0.7070
1283/1283 [==============================] - 1s 937us/step - loss: 0.5855 - acc: 0.7069 - val_loss: 0.6673 - val_acc: 0.6332

Epoch 00002: val_acc improved from 0.56769 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4906 - acc: 0.8125
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4921 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4868 - acc: 0.7969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4671 - acc: 0.8307
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4661 - acc: 0.8348
 576/1283 [============>.................] - ETA: 0s - loss: 0.4533 - acc: 0.8403
 640/1283 [=============>................] - ETA: 0s - loss: 0.4533 - acc: 0.8313
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4527 - acc: 0.8324
 768/1283 [================>.............] - ETA: 0s - loss: 0.4467 - acc: 0.8333
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4445 - acc: 0.8353
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4391 - acc: 0.8365
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4359 - acc: 0.8355
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4297 - acc: 0.8372
1283/1283 [==============================] - 1s 910us/step - loss: 0.4273 - acc: 0.8371 - val_loss: 0.6796 - val_acc: 0.6550

Epoch 00003: val_acc improved from 0.63319 to 0.65502, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3016 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2986 - acc: 0.9271
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3079 - acc: 0.9219
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2871 - acc: 0.9245
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2873 - acc: 0.9219
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2878 - acc: 0.9141
 640/1283 [=============>................] - ETA: 0s - loss: 0.2873 - acc: 0.9094
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2784 - acc: 0.9105
 768/1283 [================>.............] - ETA: 0s - loss: 0.2728 - acc: 0.9128
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2737 - acc: 0.9111
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2762 - acc: 0.9074
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2729 - acc: 0.9092
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2740 - acc: 0.9081
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2708 - acc: 0.9104
1280/1283 [============================>.] - ETA: 0s - loss: 0.2681 - acc: 0.9109
1283/1283 [==============================] - 1s 995us/step - loss: 0.2683 - acc: 0.9104 - val_loss: 0.7593 - val_acc: 0.6681

Epoch 00004: val_acc improved from 0.65502 to 0.66812, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1099 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1862 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1834 - acc: 0.9414
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1765 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1754 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1742 - acc: 0.9434
 576/1283 [============>.................] - ETA: 0s - loss: 0.1804 - acc: 0.9358
 640/1283 [=============>................] - ETA: 0s - loss: 0.1781 - acc: 0.9406
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1765 - acc: 0.9403
 768/1283 [================>.............] - ETA: 0s - loss: 0.1751 - acc: 0.9401
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1721 - acc: 0.9411
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1716 - acc: 0.9420
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1675 - acc: 0.9448
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1640 - acc: 0.9463
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1644 - acc: 0.9479
1280/1283 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9445
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1710 - acc: 0.9447 - val_loss: 0.8587 - val_acc: 0.6376

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1111 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1447 - acc: 0.9609
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1234 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1207 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1167 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1155 - acc: 0.9648
 640/1283 [=============>................] - ETA: 0s - loss: 0.1166 - acc: 0.9609
 768/1283 [================>.............] - ETA: 0s - loss: 0.1072 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1093 - acc: 0.9675
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1128 - acc: 0.9632
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1093 - acc: 0.9656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1065 - acc: 0.9668
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1100 - acc: 0.9642
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1076 - acc: 0.9655
1280/1283 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9633
1283/1283 [==============================] - 1s 977us/step - loss: 0.1131 - acc: 0.9626 - val_loss: 0.9544 - val_acc: 0.6419

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0845 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0743 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1037 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1091 - acc: 0.9661
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1048 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.1211 - acc: 0.9635
 640/1283 [=============>................] - ETA: 0s - loss: 0.1318 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1232 - acc: 0.9570
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1162 - acc: 0.9587
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1174 - acc: 0.9563
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1193 - acc: 0.9561
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1168 - acc: 0.9577
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1126 - acc: 0.9601
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1098 - acc: 0.9622
1280/1283 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9625
1283/1283 [==============================] - 1s 1ms/step - loss: 0.1081 - acc: 0.9626 - val_loss: 1.1709 - val_acc: 0.6419

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0520 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0700 - acc: 0.9766
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0590 - acc: 0.9805
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0693 - acc: 0.9766
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0673 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0637 - acc: 0.9824
 576/1283 [============>.................] - ETA: 0s - loss: 0.0676 - acc: 0.9792
 640/1283 [=============>................] - ETA: 0s - loss: 0.0648 - acc: 0.9812
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0678 - acc: 0.9773
 768/1283 [================>.............] - ETA: 0s - loss: 0.0675 - acc: 0.9792
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0619 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0601 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0592 - acc: 0.9834
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0586 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0569 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9844
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0563 - acc: 0.9844 - val_loss: 1.1991 - val_acc: 0.6245

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0236 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0232 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0222 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0240 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0261 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0266 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0310 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0307 - acc: 0.9948
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0305 - acc: 0.9944
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0318 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0311 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0309 - acc: 0.9945
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0303 - acc: 0.9942
1280/1283 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9938
1283/1283 [==============================] - 1s 881us/step - loss: 0.0302 - acc: 0.9938 - val_loss: 1.3322 - val_acc: 0.6376

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0088 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0133 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0216 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0232 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0227 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0226 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0234 - acc: 0.9980
 576/1283 [============>.................] - ETA: 0s - loss: 0.0247 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0257 - acc: 0.9957
 768/1283 [================>.............] - ETA: 0s - loss: 0.0261 - acc: 0.9948
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0252 - acc: 0.9944
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0232 - acc: 0.9951
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0223 - acc: 0.9954
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0222 - acc: 0.9948
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0220 - acc: 0.9951
1283/1283 [==============================] - 1s 999us/step - loss: 0.0225 - acc: 0.9953 - val_loss: 1.3903 - val_acc: 0.6288

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0054 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0154 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0153 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0126 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0129 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0131 - acc: 0.9983
 640/1283 [=============>................] - ETA: 0s - loss: 0.0137 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0152 - acc: 0.9974
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0145 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0143 - acc: 0.9978
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0150 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0156 - acc: 0.9965
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0151 - acc: 0.9967
1283/1283 [==============================] - 1s 733us/step - loss: 0.0154 - acc: 0.9961 - val_loss: 1.4595 - val_acc: 0.6288

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0217 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0106 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0120 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0110 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0104 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0107 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0105 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0103 - acc: 0.9987
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0102 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0118 - acc: 0.9969
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0110 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0110 - acc: 0.9974
1280/1283 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9961
1283/1283 [==============================] - 1s 857us/step - loss: 0.0130 - acc: 0.9961 - val_loss: 1.5220 - val_acc: 0.6157

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0089 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0094 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0092 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0086 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0105 - acc: 0.9964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0112 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0109 - acc: 0.9963
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0105 - acc: 0.9967
1283/1283 [==============================] - 1s 754us/step - loss: 0.0115 - acc: 0.9961 - val_loss: 1.5819 - val_acc: 0.5983

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0045 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0042 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0081 - acc: 0.9961
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0066 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0058 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0099 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0107 - acc: 0.9961
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0114 - acc: 0.9955
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0108 - acc: 0.9958
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0102 - acc: 0.9963
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0101 - acc: 0.9967
1283/1283 [==============================] - 1s 709us/step - loss: 0.0097 - acc: 0.9969 - val_loss: 1.6166 - val_acc: 0.6201

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=15
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6370262390670554
best_valid_accuracy=0.6224489795918368
