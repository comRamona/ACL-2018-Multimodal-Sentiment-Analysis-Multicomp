/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 07:58:28.599342: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 19s - loss: 0.6787 - acc: 0.5156
 128/1283 [=>............................] - ETA: 10s - loss: 0.7458 - acc: 0.5078
 192/1283 [===>..........................] - ETA: 7s - loss: 0.7378 - acc: 0.5104 
 256/1283 [====>.........................] - ETA: 5s - loss: 0.7555 - acc: 0.5273
 320/1283 [======>.......................] - ETA: 4s - loss: 0.7636 - acc: 0.5437
 384/1283 [=======>......................] - ETA: 3s - loss: 0.7585 - acc: 0.5391
 448/1283 [=========>....................] - ETA: 3s - loss: 0.7482 - acc: 0.5446
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7685 - acc: 0.5352
 576/1283 [============>.................] - ETA: 2s - loss: 0.7597 - acc: 0.5503
 640/1283 [=============>................] - ETA: 1s - loss: 0.7555 - acc: 0.5500
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7592 - acc: 0.5483
 768/1283 [================>.............] - ETA: 1s - loss: 0.7581 - acc: 0.5404
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7516 - acc: 0.5433
 896/1283 [===================>..........] - ETA: 1s - loss: 0.7495 - acc: 0.5391
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7493 - acc: 0.5385
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7463 - acc: 0.5410
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7435 - acc: 0.5441
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7402 - acc: 0.5417
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7403 - acc: 0.5395
1280/1283 [============================>.] - ETA: 0s - loss: 0.7375 - acc: 0.5422
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7382 - acc: 0.5417 - val_loss: 0.6990 - val_acc: 0.5502

Epoch 00001: val_acc improved from -inf to 0.55022, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5465 - acc: 0.7656
 128/1283 [=>............................] - ETA: 1s - loss: 0.5472 - acc: 0.7891
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5458 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5639 - acc: 0.7578
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5631 - acc: 0.7562
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5661 - acc: 0.7422
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5674 - acc: 0.7388
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5681 - acc: 0.7363
 576/1283 [============>.................] - ETA: 1s - loss: 0.5675 - acc: 0.7361
 640/1283 [=============>................] - ETA: 1s - loss: 0.5639 - acc: 0.7406
 704/1283 [===============>..............] - ETA: 1s - loss: 0.5637 - acc: 0.7401
 768/1283 [================>.............] - ETA: 1s - loss: 0.5626 - acc: 0.7422
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5597 - acc: 0.7464
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5572 - acc: 0.7455
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5569 - acc: 0.7427
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5588 - acc: 0.7363
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5578 - acc: 0.7353
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5570 - acc: 0.7326
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5564 - acc: 0.7311
1280/1283 [============================>.] - ETA: 0s - loss: 0.5548 - acc: 0.7297
1283/1283 [==============================] - 3s 3ms/step - loss: 0.5550 - acc: 0.7295 - val_loss: 0.8035 - val_acc: 0.5764

Epoch 00002: val_acc improved from 0.55022 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5463 - acc: 0.7031
 128/1283 [=>............................] - ETA: 1s - loss: 0.5147 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4961 - acc: 0.7552
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4721 - acc: 0.7734
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4756 - acc: 0.7812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4717 - acc: 0.7786
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4688 - acc: 0.7768
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4665 - acc: 0.7793
 576/1283 [============>.................] - ETA: 0s - loss: 0.4624 - acc: 0.7865
 640/1283 [=============>................] - ETA: 0s - loss: 0.4610 - acc: 0.7875
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4558 - acc: 0.7912
 768/1283 [================>.............] - ETA: 0s - loss: 0.4545 - acc: 0.7943
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4573 - acc: 0.7921
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4542 - acc: 0.7958
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4494 - acc: 0.8031
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4478 - acc: 0.8047
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4429 - acc: 0.8070
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4413 - acc: 0.8064
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4409 - acc: 0.8051
1280/1283 [============================>.] - ETA: 0s - loss: 0.4379 - acc: 0.8086
1283/1283 [==============================] - 3s 2ms/step - loss: 0.4378 - acc: 0.8083 - val_loss: 0.7751 - val_acc: 0.5939

Epoch 00003: val_acc improved from 0.57642 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2852 - acc: 0.9219
 128/1283 [=>............................] - ETA: 2s - loss: 0.3090 - acc: 0.8750
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3220 - acc: 0.8854
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3109 - acc: 0.8906
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3083 - acc: 0.8969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3090 - acc: 0.8880
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3076 - acc: 0.8929
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3092 - acc: 0.8906
 576/1283 [============>.................] - ETA: 1s - loss: 0.3173 - acc: 0.8819
 640/1283 [=============>................] - ETA: 1s - loss: 0.3235 - acc: 0.8719
 704/1283 [===============>..............] - ETA: 1s - loss: 0.3296 - acc: 0.8636
 768/1283 [================>.............] - ETA: 0s - loss: 0.3392 - acc: 0.8555
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3408 - acc: 0.8582
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3383 - acc: 0.8594
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3387 - acc: 0.8583
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3460 - acc: 0.8496
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3424 - acc: 0.8511
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3368 - acc: 0.8542
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3380 - acc: 0.8520
1280/1283 [============================>.] - ETA: 0s - loss: 0.3411 - acc: 0.8516
1283/1283 [==============================] - 3s 2ms/step - loss: 0.3419 - acc: 0.8511 - val_loss: 0.8416 - val_acc: 0.5371

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.2507 - acc: 0.8750
 128/1283 [=>............................] - ETA: 2s - loss: 0.3379 - acc: 0.7969
 192/1283 [===>..........................] - ETA: 2s - loss: 0.3348 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 2s - loss: 0.3859 - acc: 0.7773
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3745 - acc: 0.7875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3540 - acc: 0.8125
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3494 - acc: 0.8281
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3466 - acc: 0.8340
 576/1283 [============>.................] - ETA: 1s - loss: 0.3381 - acc: 0.8403
 640/1283 [=============>................] - ETA: 1s - loss: 0.3353 - acc: 0.8438
 704/1283 [===============>..............] - ETA: 1s - loss: 0.3259 - acc: 0.8494
 768/1283 [================>.............] - ETA: 1s - loss: 0.3206 - acc: 0.8516
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3144 - acc: 0.8570
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3112 - acc: 0.8583
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3116 - acc: 0.8573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3134 - acc: 0.8564
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3099 - acc: 0.8621
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3083 - acc: 0.8628
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3057 - acc: 0.8668
1280/1283 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.8672
1283/1283 [==============================] - 3s 2ms/step - loss: 0.3027 - acc: 0.8675 - val_loss: 0.8852 - val_acc: 0.6288

Epoch 00005: val_acc improved from 0.59389 to 0.62882, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1911 - acc: 0.9531
 128/1283 [=>............................] - ETA: 2s - loss: 0.1899 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1933 - acc: 0.9323
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1949 - acc: 0.9375
 320/1283 [======>.......................] - ETA: 2s - loss: 0.2087 - acc: 0.9219
 384/1283 [=======>......................] - ETA: 2s - loss: 0.2165 - acc: 0.9089
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2129 - acc: 0.9107
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2125 - acc: 0.9121
 576/1283 [============>.................] - ETA: 1s - loss: 0.2100 - acc: 0.9115
 640/1283 [=============>................] - ETA: 1s - loss: 0.2045 - acc: 0.9156
 704/1283 [===============>..............] - ETA: 1s - loss: 0.2025 - acc: 0.9190
 768/1283 [================>.............] - ETA: 1s - loss: 0.2009 - acc: 0.9193
 832/1283 [==================>...........] - ETA: 1s - loss: 0.2005 - acc: 0.9207
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2005 - acc: 0.9196
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2012 - acc: 0.9208
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2016 - acc: 0.9209
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2001 - acc: 0.9219
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1997 - acc: 0.9219
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2007 - acc: 0.9211
1280/1283 [============================>.] - ETA: 0s - loss: 0.2025 - acc: 0.9195
1283/1283 [==============================] - 3s 2ms/step - loss: 0.2022 - acc: 0.9197 - val_loss: 0.8945 - val_acc: 0.6332

Epoch 00006: val_acc improved from 0.62882 to 0.63319, saving model to classification_logs//cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25/saved_models/best_validation_cnn_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.2_nl_2_ml_25.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1512 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.1525 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1563 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1668 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1640 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1546 - acc: 0.9479
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1504 - acc: 0.9487
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1493 - acc: 0.9434
 576/1283 [============>.................] - ETA: 1s - loss: 0.1436 - acc: 0.9462
 640/1283 [=============>................] - ETA: 1s - loss: 0.1440 - acc: 0.9469
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1447 - acc: 0.9460
 768/1283 [================>.............] - ETA: 0s - loss: 0.1445 - acc: 0.9479
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1475 - acc: 0.9447
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1493 - acc: 0.9442
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1496 - acc: 0.9437
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1509 - acc: 0.9424
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1484 - acc: 0.9449
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1486 - acc: 0.9436
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1491 - acc: 0.9433
1280/1283 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9422
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1510 - acc: 0.9415 - val_loss: 1.0911 - val_acc: 0.6070

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1350 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.1198 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1181 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1159 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1154 - acc: 0.9688
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1159 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1213 - acc: 0.9665
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1251 - acc: 0.9609
 576/1283 [============>.................] - ETA: 1s - loss: 0.1228 - acc: 0.9601
 640/1283 [=============>................] - ETA: 1s - loss: 0.1235 - acc: 0.9547
 704/1283 [===============>..............] - ETA: 1s - loss: 0.1248 - acc: 0.9517
 768/1283 [================>.............] - ETA: 1s - loss: 0.1251 - acc: 0.9505
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1261 - acc: 0.9495
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1250 - acc: 0.9498
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1245 - acc: 0.9490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1292 - acc: 0.9453
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1282 - acc: 0.9467
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1271 - acc: 0.9479
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1286 - acc: 0.9457
1280/1283 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9461
1283/1283 [==============================] - 3s 2ms/step - loss: 0.1301 - acc: 0.9454 - val_loss: 1.1024 - val_acc: 0.6070

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0718 - acc: 0.9688
 128/1283 [=>............................] - ETA: 2s - loss: 0.0780 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1036 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1020 - acc: 0.9453
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1041 - acc: 0.9437
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0991 - acc: 0.9505
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0997 - acc: 0.9509
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1040 - acc: 0.9492
 576/1283 [============>.................] - ETA: 1s - loss: 0.1062 - acc: 0.9497
 640/1283 [=============>................] - ETA: 1s - loss: 0.1140 - acc: 0.9484
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1135 - acc: 0.9489
 768/1283 [================>.............] - ETA: 0s - loss: 0.1122 - acc: 0.9492
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1082 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1075 - acc: 0.9542
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1070 - acc: 0.9552
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1043 - acc: 0.9570
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1031 - acc: 0.9577
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1013 - acc: 0.9583
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1029 - acc: 0.9581
1280/1283 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9555
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1060 - acc: 0.9556 - val_loss: 1.1919 - val_acc: 0.5721

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1150 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0972 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0960 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1004 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0936 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0987 - acc: 0.9583
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0990 - acc: 0.9554
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0939 - acc: 0.9570
 576/1283 [============>.................] - ETA: 0s - loss: 0.0924 - acc: 0.9601
 640/1283 [=============>................] - ETA: 0s - loss: 0.0889 - acc: 0.9609
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0863 - acc: 0.9631
 768/1283 [================>.............] - ETA: 0s - loss: 0.0834 - acc: 0.9661
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0881 - acc: 0.9615
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0865 - acc: 0.9632
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0845 - acc: 0.9656
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0845 - acc: 0.9668
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0863 - acc: 0.9660
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0857 - acc: 0.9661
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0863 - acc: 0.9646
1280/1283 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9641
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0861 - acc: 0.9641 - val_loss: 1.3696 - val_acc: 0.5677

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1250 - acc: 0.9219
 128/1283 [=>............................] - ETA: 1s - loss: 0.1149 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1077 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0927 - acc: 0.9531
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0957 - acc: 0.9531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0931 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0826 - acc: 0.9621
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0805 - acc: 0.9609
 576/1283 [============>.................] - ETA: 0s - loss: 0.0761 - acc: 0.9635
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0715 - acc: 0.9673
 768/1283 [================>.............] - ETA: 0s - loss: 0.0741 - acc: 0.9674
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0741 - acc: 0.9688
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0758 - acc: 0.9665
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0729 - acc: 0.9688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0754 - acc: 0.9668
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0760 - acc: 0.9660
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0740 - acc: 0.9670
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0726 - acc: 0.9679
1280/1283 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9688
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0714 - acc: 0.9688 - val_loss: 1.4271 - val_acc: 0.5764

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0678 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0443 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0488 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0609 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0556 - acc: 0.9781
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0545 - acc: 0.9792
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0515 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0561 - acc: 0.9766
 576/1283 [============>.................] - ETA: 0s - loss: 0.0588 - acc: 0.9740
 640/1283 [=============>................] - ETA: 0s - loss: 0.0593 - acc: 0.9734
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0578 - acc: 0.9744
 768/1283 [================>.............] - ETA: 0s - loss: 0.0591 - acc: 0.9727
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0571 - acc: 0.9748
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0591 - acc: 0.9721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0604 - acc: 0.9719
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0595 - acc: 0.9736
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0604 - acc: 0.9724
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0608 - acc: 0.9729
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0608 - acc: 0.9719 - val_loss: 1.5988 - val_acc: 0.6201

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0460 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0548 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0636 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0705 - acc: 0.9727
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0695 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0727 - acc: 0.9714
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0734 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0730 - acc: 0.9707
 576/1283 [============>.................] - ETA: 0s - loss: 0.0715 - acc: 0.9705
 640/1283 [=============>................] - ETA: 0s - loss: 0.0696 - acc: 0.9719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0693 - acc: 0.9702
 768/1283 [================>.............] - ETA: 0s - loss: 0.0682 - acc: 0.9701
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0675 - acc: 0.9700
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0676 - acc: 0.9688
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0665 - acc: 0.9698
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0678 - acc: 0.9678
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0709 - acc: 0.9678
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0702 - acc: 0.9679
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0678 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9703
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0683 - acc: 0.9704 - val_loss: 1.7666 - val_acc: 0.5808

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0363 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0528 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0514 - acc: 0.9740
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0507 - acc: 0.9805
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0551 - acc: 0.9781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0514 - acc: 0.9821
 576/1283 [============>.................] - ETA: 0s - loss: 0.0543 - acc: 0.9774
 640/1283 [=============>................] - ETA: 0s - loss: 0.0525 - acc: 0.9797
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0543 - acc: 0.9773
 768/1283 [================>.............] - ETA: 0s - loss: 0.0524 - acc: 0.9792
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0499 - acc: 0.9796
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0507 - acc: 0.9788
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0549 - acc: 0.9750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0556 - acc: 0.9746
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0565 - acc: 0.9733
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0579 - acc: 0.9722
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0573 - acc: 0.9729
1280/1283 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9727
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0573 - acc: 0.9727 - val_loss: 1.6729 - val_acc: 0.5939

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0497 - acc: 0.9688
 128/1283 [=>............................] - ETA: 1s - loss: 0.0607 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0658 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0682 - acc: 0.9570
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0651 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0577 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0570 - acc: 0.9710
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0562 - acc: 0.9727
 576/1283 [============>.................] - ETA: 0s - loss: 0.0570 - acc: 0.9722
 640/1283 [=============>................] - ETA: 0s - loss: 0.0574 - acc: 0.9719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0536 - acc: 0.9744
 768/1283 [================>.............] - ETA: 0s - loss: 0.0542 - acc: 0.9740
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0528 - acc: 0.9748
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0545 - acc: 0.9732
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0530 - acc: 0.9750
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0507 - acc: 0.9770
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0501 - acc: 0.9774
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0509 - acc: 0.9762
1280/1283 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9766
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0503 - acc: 0.9766 - val_loss: 1.7219 - val_acc: 0.5502

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0705 - acc: 0.9531
 128/1283 [=>............................] - ETA: 1s - loss: 0.0541 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0588 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0512 - acc: 0.9750
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0560 - acc: 0.9714
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0558 - acc: 0.9688
 576/1283 [============>.................] - ETA: 0s - loss: 0.0537 - acc: 0.9705
 640/1283 [=============>................] - ETA: 0s - loss: 0.0532 - acc: 0.9703
 768/1283 [================>.............] - ETA: 0s - loss: 0.0477 - acc: 0.9753
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0489 - acc: 0.9748
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0477 - acc: 0.9766
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0466 - acc: 0.9771
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0462 - acc: 0.9785
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0475 - acc: 0.9779
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0483 - acc: 0.9792
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0502 - acc: 0.9770
1280/1283 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9781
1283/1283 [==============================] - 2s 1ms/step - loss: 0.0483 - acc: 0.9782 - val_loss: 1.7762 - val_acc: 0.5721

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.2
n_layers=2
max_len=25
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.543731778425656
best_valid_accuracy=0.5553935860058309
