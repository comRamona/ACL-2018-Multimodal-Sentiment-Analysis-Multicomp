/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_lstm.py:173: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_lstm.py:175: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-29 00:41:47.699050: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 16s - loss: 0.7114 - acc: 0.4844
 128/1283 [=>............................] - ETA: 8s - loss: 0.7101 - acc: 0.4766 
 192/1283 [===>..........................] - ETA: 5s - loss: 0.7069 - acc: 0.4844
 256/1283 [====>.........................] - ETA: 4s - loss: 0.7018 - acc: 0.4922
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7018 - acc: 0.4875
 384/1283 [=======>......................] - ETA: 2s - loss: 0.7002 - acc: 0.4922
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7000 - acc: 0.4888
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6986 - acc: 0.4902
 576/1283 [============>.................] - ETA: 1s - loss: 0.6979 - acc: 0.4896
 640/1283 [=============>................] - ETA: 1s - loss: 0.6977 - acc: 0.4938
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6981 - acc: 0.4858
 768/1283 [================>.............] - ETA: 1s - loss: 0.6957 - acc: 0.4922
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6931 - acc: 0.5024
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6918 - acc: 0.5145
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6928 - acc: 0.5104
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6902 - acc: 0.5254
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6890 - acc: 0.5312
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6894 - acc: 0.5286
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6887 - acc: 0.5296
1280/1283 [============================>.] - ETA: 0s - loss: 0.6886 - acc: 0.5305
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6887 - acc: 0.5300 - val_loss: 0.6529 - val_acc: 0.6594

Epoch 00001: val_acc improved from -inf to 0.65939, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6557 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6426 - acc: 0.7344
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6383 - acc: 0.7305
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6402 - acc: 0.7214
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6455 - acc: 0.6942
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6411 - acc: 0.7051
 576/1283 [============>.................] - ETA: 0s - loss: 0.6409 - acc: 0.6979
 640/1283 [=============>................] - ETA: 0s - loss: 0.6426 - acc: 0.6891
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6417 - acc: 0.6861
 768/1283 [================>.............] - ETA: 0s - loss: 0.6415 - acc: 0.6862
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6415 - acc: 0.6827
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6388 - acc: 0.6875
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6373 - acc: 0.6896
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6358 - acc: 0.6904
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6354 - acc: 0.6912
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6341 - acc: 0.6908
1280/1283 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.6891
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6336 - acc: 0.6882 - val_loss: 0.6207 - val_acc: 0.6900

Epoch 00002: val_acc improved from 0.65939 to 0.68996, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6153 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6064 - acc: 0.7135
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6076 - acc: 0.7031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6073 - acc: 0.7005
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6015 - acc: 0.7121
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5976 - acc: 0.7207
 640/1283 [=============>................] - ETA: 0s - loss: 0.5908 - acc: 0.7312
 768/1283 [================>.............] - ETA: 0s - loss: 0.5846 - acc: 0.7435
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5798 - acc: 0.7464
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5785 - acc: 0.7489
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5781 - acc: 0.7458
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5759 - acc: 0.7520
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5753 - acc: 0.7500
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5719 - acc: 0.7549
1280/1283 [============================>.] - ETA: 0s - loss: 0.5707 - acc: 0.7547
1283/1283 [==============================] - 1s 947us/step - loss: 0.5712 - acc: 0.7537 - val_loss: 0.5779 - val_acc: 0.7031

Epoch 00003: val_acc improved from 0.68996 to 0.70306, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5089 - acc: 0.7812
 128/1283 [=>............................] - ETA: 1s - loss: 0.5234 - acc: 0.7812
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5263 - acc: 0.7865
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5353 - acc: 0.7734
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5279 - acc: 0.7839
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5173 - acc: 0.7930
 576/1283 [============>.................] - ETA: 0s - loss: 0.5173 - acc: 0.7917
 640/1283 [=============>................] - ETA: 0s - loss: 0.5156 - acc: 0.7984
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5175 - acc: 0.7955
 768/1283 [================>.............] - ETA: 0s - loss: 0.5143 - acc: 0.7969
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5115 - acc: 0.8017
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5061 - acc: 0.8058
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5021 - acc: 0.8104
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4962 - acc: 0.8107
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4908 - acc: 0.8158
1283/1283 [==============================] - 1s 878us/step - loss: 0.4922 - acc: 0.8137 - val_loss: 0.5363 - val_acc: 0.7293

Epoch 00004: val_acc improved from 0.70306 to 0.72926, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4623 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4007 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4174 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4194 - acc: 0.8719
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4119 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4137 - acc: 0.8638
 576/1283 [============>.................] - ETA: 0s - loss: 0.4079 - acc: 0.8611
 640/1283 [=============>................] - ETA: 0s - loss: 0.4099 - acc: 0.8625
 768/1283 [================>.............] - ETA: 0s - loss: 0.4072 - acc: 0.8581
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4000 - acc: 0.8583
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3983 - acc: 0.8583
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4032 - acc: 0.8525
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3996 - acc: 0.8548
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4045 - acc: 0.8481
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4032 - acc: 0.8446
1280/1283 [============================>.] - ETA: 0s - loss: 0.4006 - acc: 0.8469
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4009 - acc: 0.8465 - val_loss: 0.5150 - val_acc: 0.7249

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3929 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3414 - acc: 0.8958
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3397 - acc: 0.9023
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3256 - acc: 0.9031
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3218 - acc: 0.8958
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3181 - acc: 0.8951
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3191 - acc: 0.8926
 640/1283 [=============>................] - ETA: 0s - loss: 0.3247 - acc: 0.8812
 768/1283 [================>.............] - ETA: 0s - loss: 0.3263 - acc: 0.8802
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3224 - acc: 0.8810
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3278 - acc: 0.8772
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3289 - acc: 0.8750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3282 - acc: 0.8740
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3249 - acc: 0.8724
1280/1283 [============================>.] - ETA: 0s - loss: 0.3300 - acc: 0.8680
1283/1283 [==============================] - 1s 892us/step - loss: 0.3307 - acc: 0.8675 - val_loss: 0.5163 - val_acc: 0.7467

Epoch 00006: val_acc improved from 0.72926 to 0.74672, saving model to classification_logs//lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_lstm_early_fusion_m_AT_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3394 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2930 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2999 - acc: 0.8867
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2928 - acc: 0.8938
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3006 - acc: 0.8862
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2968 - acc: 0.8887
 576/1283 [============>.................] - ETA: 0s - loss: 0.2876 - acc: 0.8958
 640/1283 [=============>................] - ETA: 0s - loss: 0.2810 - acc: 0.9000
 768/1283 [================>.............] - ETA: 0s - loss: 0.2757 - acc: 0.9076
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2720 - acc: 0.9075
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2676 - acc: 0.9094
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2634 - acc: 0.9131
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2630 - acc: 0.9145
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2634 - acc: 0.9123
1280/1283 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.9141
1283/1283 [==============================] - 1s 886us/step - loss: 0.2607 - acc: 0.9135 - val_loss: 0.5294 - val_acc: 0.7162

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1620 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1678 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1889 - acc: 0.9594
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1914 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.1983 - acc: 0.9549
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1983 - acc: 0.9517
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1991 - acc: 0.9483
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1987 - acc: 0.9448
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1967 - acc: 0.9453
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1993 - acc: 0.9449
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1990 - acc: 0.9433
1283/1283 [==============================] - 1s 760us/step - loss: 0.1982 - acc: 0.9447 - val_loss: 0.5604 - val_acc: 0.7162

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1400 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.1742 - acc: 0.9453
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1516 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1439 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1358 - acc: 0.9656
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1366 - acc: 0.9635
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1378 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1367 - acc: 0.9609
 640/1283 [=============>................] - ETA: 0s - loss: 0.1345 - acc: 0.9609
 768/1283 [================>.............] - ETA: 0s - loss: 0.1348 - acc: 0.9609
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1420 - acc: 0.9565
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1407 - acc: 0.9573
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1455 - acc: 0.9561
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1460 - acc: 0.9550
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1438 - acc: 0.9572
1283/1283 [==============================] - 1s 876us/step - loss: 0.1411 - acc: 0.9579 - val_loss: 0.5864 - val_acc: 0.7380

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1596 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1139 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1128 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1118 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.1121 - acc: 0.9740
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1085 - acc: 0.9759
 768/1283 [================>.............] - ETA: 0s - loss: 0.1071 - acc: 0.9766
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1042 - acc: 0.9766
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0982 - acc: 0.9795
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0979 - acc: 0.9783
1280/1283 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9797
1283/1283 [==============================] - 1s 733us/step - loss: 0.0965 - acc: 0.9790 - val_loss: 0.6660 - val_acc: 0.7336

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0878 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0876 - acc: 0.9635
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0800 - acc: 0.9648
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0899 - acc: 0.9563
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1070 - acc: 0.9505
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0975 - acc: 0.9609
 640/1283 [=============>................] - ETA: 0s - loss: 0.0919 - acc: 0.9672
 768/1283 [================>.............] - ETA: 0s - loss: 0.0887 - acc: 0.9701
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0860 - acc: 0.9721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0844 - acc: 0.9729
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0862 - acc: 0.9717
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0869 - acc: 0.9714
1280/1283 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9719
1283/1283 [==============================] - 1s 803us/step - loss: 0.0877 - acc: 0.9719 - val_loss: 0.6985 - val_acc: 0.7074

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0582 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0912 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0834 - acc: 0.9719
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0731 - acc: 0.9777
 576/1283 [============>.................] - ETA: 0s - loss: 0.0720 - acc: 0.9809
 640/1283 [=============>................] - ETA: 0s - loss: 0.0727 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0721 - acc: 0.9787
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0671 - acc: 0.9820
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0664 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0655 - acc: 0.9823
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0668 - acc: 0.9816
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0645 - acc: 0.9836
1283/1283 [==============================] - 1s 704us/step - loss: 0.0646 - acc: 0.9836 - val_loss: 0.7731 - val_acc: 0.7249

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0343 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0463 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0493 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0460 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0511 - acc: 0.9878
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0495 - acc: 0.9901
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0472 - acc: 0.9916
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0501 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0485 - acc: 0.9917
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0508 - acc: 0.9905
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0505 - acc: 0.9910
1280/1283 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9914
1283/1283 [==============================] - 1s 684us/step - loss: 0.0491 - acc: 0.9914 - val_loss: 0.8369 - val_acc: 0.7162

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0524 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0351 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0323 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0305 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0327 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0315 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0298 - acc: 0.9987
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0287 - acc: 0.9989
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0294 - acc: 0.9980
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0298 - acc: 0.9974
1280/1283 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9969
1283/1283 [==============================] - 1s 664us/step - loss: 0.0330 - acc: 0.9961 - val_loss: 0.8744 - val_acc: 0.7031

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0208 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0232 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0287 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0385 - acc: 0.9955
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0394 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0384 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0403 - acc: 0.9929
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0445 - acc: 0.9892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0431 - acc: 0.9906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0435 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0415 - acc: 0.9918
1283/1283 [==============================] - 1s 672us/step - loss: 0.0406 - acc: 0.9922 - val_loss: 0.9257 - val_acc: 0.7074

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0425 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0419 - acc: 0.9896
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0389 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0337 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0318 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0305 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0334 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0321 - acc: 0.9943
 768/1283 [================>.............] - ETA: 0s - loss: 0.0313 - acc: 0.9948
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0369 - acc: 0.9933
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0359 - acc: 0.9938
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0351 - acc: 0.9941
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0341 - acc: 0.9945
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0331 - acc: 0.9942
1283/1283 [==============================] - 1s 784us/step - loss: 0.0323 - acc: 0.9945 - val_loss: 0.9304 - val_acc: 0.7031

Epoch 00016: val_acc did not improve
Epoch 00016: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=AT
PCA audio=10
PCA visual=25
PCA text=110
accuracy=0.6807580174927114
best_valid_accuracy=0.685131195335277
