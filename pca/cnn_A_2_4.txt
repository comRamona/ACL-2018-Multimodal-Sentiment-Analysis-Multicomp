/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:48:30.765248: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 12s - loss: 0.7007 - acc: 0.5469
 128/1283 [=>............................] - ETA: 7s - loss: 0.7002 - acc: 0.5547 
 192/1283 [===>..........................] - ETA: 4s - loss: 0.7064 - acc: 0.5417
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6983 - acc: 0.5547
 320/1283 [======>.......................] - ETA: 3s - loss: 0.6882 - acc: 0.5750
 384/1283 [=======>......................] - ETA: 3s - loss: 0.6996 - acc: 0.5599
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7120 - acc: 0.5580
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7228 - acc: 0.5508
 576/1283 [============>.................] - ETA: 1s - loss: 0.7194 - acc: 0.5503
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7188 - acc: 0.5497
 768/1283 [================>.............] - ETA: 1s - loss: 0.7192 - acc: 0.5495
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7160 - acc: 0.5541
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7140 - acc: 0.5525
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7125 - acc: 0.5500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7140 - acc: 0.5439
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7086 - acc: 0.5503
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7108 - acc: 0.5436
1280/1283 [============================>.] - ETA: 0s - loss: 0.7111 - acc: 0.5414
1283/1283 [==============================] - 2s 2ms/step - loss: 0.7111 - acc: 0.5409 - val_loss: 0.6886 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6610 - acc: 0.6094
 128/1283 [=>............................] - ETA: 3s - loss: 0.6560 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 2s - loss: 0.6550 - acc: 0.6354
 256/1283 [====>.........................] - ETA: 3s - loss: 0.6475 - acc: 0.6523
 320/1283 [======>.......................] - ETA: 2s - loss: 0.6535 - acc: 0.6281
 384/1283 [=======>......................] - ETA: 2s - loss: 0.6534 - acc: 0.6198
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6517 - acc: 0.6228
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6558 - acc: 0.6074
 576/1283 [============>.................] - ETA: 1s - loss: 0.6593 - acc: 0.5990
 640/1283 [=============>................] - ETA: 1s - loss: 0.6565 - acc: 0.6062
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6571 - acc: 0.6065
 768/1283 [================>.............] - ETA: 0s - loss: 0.6563 - acc: 0.6068
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6590 - acc: 0.5998
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6596 - acc: 0.5993
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6586 - acc: 0.6021
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6577 - acc: 0.6048
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6573 - acc: 0.6076
1280/1283 [============================>.] - ETA: 0s - loss: 0.6592 - acc: 0.6094
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6592 - acc: 0.6095 - val_loss: 0.6832 - val_acc: 0.5852

Epoch 00002: val_acc improved from 0.52838 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6229 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.6487 - acc: 0.6250
 192/1283 [===>..........................] - ETA: 1s - loss: 0.6501 - acc: 0.6302
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6364 - acc: 0.6562
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6348 - acc: 0.6531
 384/1283 [=======>......................] - ETA: 0s - loss: 0.6294 - acc: 0.6641
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6275 - acc: 0.6652
 512/1283 [==========>...................] - ETA: 0s - loss: 0.6338 - acc: 0.6484
 576/1283 [============>.................] - ETA: 0s - loss: 0.6361 - acc: 0.6424
 640/1283 [=============>................] - ETA: 0s - loss: 0.6367 - acc: 0.6406
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6340 - acc: 0.6435
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6329 - acc: 0.6418
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6340 - acc: 0.6384
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6357 - acc: 0.6365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6358 - acc: 0.6348
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6364 - acc: 0.6360
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6348 - acc: 0.6398
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6330 - acc: 0.6447
1280/1283 [============================>.] - ETA: 0s - loss: 0.6333 - acc: 0.6430
1283/1283 [==============================] - 2s 2ms/step - loss: 0.6332 - acc: 0.6430 - val_loss: 0.6829 - val_acc: 0.5590

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.5676 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 2s - loss: 0.5721 - acc: 0.7083
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5833 - acc: 0.6937
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5896 - acc: 0.7005
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5863 - acc: 0.7031
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5907 - acc: 0.7012
 576/1283 [============>.................] - ETA: 1s - loss: 0.5924 - acc: 0.6944
 640/1283 [=============>................] - ETA: 1s - loss: 0.5914 - acc: 0.6922
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5950 - acc: 0.6903
 768/1283 [================>.............] - ETA: 0s - loss: 0.5922 - acc: 0.6940
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5959 - acc: 0.6875
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5957 - acc: 0.6864
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5917 - acc: 0.6948
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5938 - acc: 0.6914
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5916 - acc: 0.6949
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5952 - acc: 0.6883
1280/1283 [============================>.] - ETA: 0s - loss: 0.5973 - acc: 0.6875
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5971 - acc: 0.6882 - val_loss: 0.6661 - val_acc: 0.6245

Epoch 00004: val_acc improved from 0.58515 to 0.62445, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5475 - acc: 0.7031
 128/1283 [=>............................] - ETA: 4s - loss: 0.5295 - acc: 0.7422
 192/1283 [===>..........................] - ETA: 2s - loss: 0.5228 - acc: 0.7604
 256/1283 [====>.........................] - ETA: 2s - loss: 0.5284 - acc: 0.7578
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5433 - acc: 0.7438
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5370 - acc: 0.7578
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5360 - acc: 0.7567
 576/1283 [============>.................] - ETA: 1s - loss: 0.5325 - acc: 0.7622
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5314 - acc: 0.7514
 768/1283 [================>.............] - ETA: 0s - loss: 0.5355 - acc: 0.7448
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5353 - acc: 0.7416
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5364 - acc: 0.7388
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5375 - acc: 0.7365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5362 - acc: 0.7373
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5357 - acc: 0.7390
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5412 - acc: 0.7318
1280/1283 [============================>.] - ETA: 0s - loss: 0.5433 - acc: 0.7312
1283/1283 [==============================] - 2s 2ms/step - loss: 0.5432 - acc: 0.7311 - val_loss: 0.6965 - val_acc: 0.6245

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4273 - acc: 0.8281
 128/1283 [=>............................] - ETA: 1s - loss: 0.4457 - acc: 0.8281
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4590 - acc: 0.8125
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4684 - acc: 0.8086
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4803 - acc: 0.7906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4774 - acc: 0.7969
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4865 - acc: 0.7835
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4953 - acc: 0.7773
 640/1283 [=============>................] - ETA: 1s - loss: 0.4903 - acc: 0.7828
 768/1283 [================>.............] - ETA: 0s - loss: 0.4979 - acc: 0.7747
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4933 - acc: 0.7788
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4940 - acc: 0.7712
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4896 - acc: 0.7734
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4883 - acc: 0.7739
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4832 - acc: 0.7786
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4808 - acc: 0.7796
1283/1283 [==============================] - 2s 2ms/step - loss: 0.4838 - acc: 0.7747 - val_loss: 0.7328 - val_acc: 0.5895

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4535 - acc: 0.7500
 128/1283 [=>............................] - ETA: 1s - loss: 0.3988 - acc: 0.8203
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4018 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4239 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4244 - acc: 0.8187
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4331 - acc: 0.8047
 448/1283 [=========>....................] - ETA: 1s - loss: 0.4378 - acc: 0.7946
 512/1283 [==========>...................] - ETA: 1s - loss: 0.4382 - acc: 0.8008
 576/1283 [============>.................] - ETA: 0s - loss: 0.4348 - acc: 0.7986
 640/1283 [=============>................] - ETA: 0s - loss: 0.4380 - acc: 0.7984
 704/1283 [===============>..............] - ETA: 1s - loss: 0.4340 - acc: 0.8026
 768/1283 [================>.............] - ETA: 1s - loss: 0.4285 - acc: 0.8073
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4243 - acc: 0.8103
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4310 - acc: 0.8052
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4318 - acc: 0.8015
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4292 - acc: 0.8035
1283/1283 [==============================] - 2s 2ms/step - loss: 0.4292 - acc: 0.8020 - val_loss: 0.7329 - val_acc: 0.5895

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.3484 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3514 - acc: 0.8698
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3501 - acc: 0.8711
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3586 - acc: 0.8688
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3575 - acc: 0.8750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3635 - acc: 0.8705
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3661 - acc: 0.8633
 640/1283 [=============>................] - ETA: 0s - loss: 0.3574 - acc: 0.8719
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3558 - acc: 0.8722
 768/1283 [================>.............] - ETA: 0s - loss: 0.3562 - acc: 0.8698
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3492 - acc: 0.8683
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3480 - acc: 0.8688
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3502 - acc: 0.8682
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3516 - acc: 0.8672
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3495 - acc: 0.8684
1280/1283 [============================>.] - ETA: 0s - loss: 0.3489 - acc: 0.8703
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3486 - acc: 0.8706 - val_loss: 0.8053 - val_acc: 0.6070

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.3081 - acc: 0.9062
 128/1283 [=>............................] - ETA: 3s - loss: 0.3171 - acc: 0.8906
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3132 - acc: 0.8828
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3218 - acc: 0.8802
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3166 - acc: 0.8730
 576/1283 [============>.................] - ETA: 0s - loss: 0.3071 - acc: 0.8785
 640/1283 [=============>................] - ETA: 0s - loss: 0.3110 - acc: 0.8750
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3115 - acc: 0.8750
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2998 - acc: 0.8786
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2992 - acc: 0.8806
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3089 - acc: 0.8750
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3084 - acc: 0.8760
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3056 - acc: 0.8787
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3108 - acc: 0.8750
1280/1283 [============================>.] - ETA: 0s - loss: 0.3108 - acc: 0.8742
1283/1283 [==============================] - 2s 1ms/step - loss: 0.3113 - acc: 0.8737 - val_loss: 0.8363 - val_acc: 0.5939

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2710 - acc: 0.9062
 128/1283 [=>............................] - ETA: 0s - loss: 0.2702 - acc: 0.9141
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2524 - acc: 0.9323
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2421 - acc: 0.9344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2468 - acc: 0.9271
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2534 - acc: 0.9174
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2536 - acc: 0.9141
 576/1283 [============>.................] - ETA: 0s - loss: 0.2643 - acc: 0.9045
 640/1283 [=============>................] - ETA: 0s - loss: 0.2585 - acc: 0.9078
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2598 - acc: 0.9077
 768/1283 [================>.............] - ETA: 0s - loss: 0.2587 - acc: 0.9115
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2567 - acc: 0.9123
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2521 - acc: 0.9152
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2551 - acc: 0.9115
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2502 - acc: 0.9141
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2465 - acc: 0.9164
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2457 - acc: 0.9175
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2439 - acc: 0.9186
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2440 - acc: 0.9182 - val_loss: 0.9939 - val_acc: 0.5983

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 7s - loss: 0.1712 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1878 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2258 - acc: 0.9125
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2451 - acc: 0.9062
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2457 - acc: 0.9082
 576/1283 [============>.................] - ETA: 0s - loss: 0.2410 - acc: 0.9097
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2406 - acc: 0.9077
 768/1283 [================>.............] - ETA: 0s - loss: 0.2424 - acc: 0.9049
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2445 - acc: 0.9002
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2523 - acc: 0.8929
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2473 - acc: 0.8969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2458 - acc: 0.8984
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2438 - acc: 0.8989
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2440 - acc: 0.8993
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2473 - acc: 0.8997
1280/1283 [============================>.] - ETA: 0s - loss: 0.2437 - acc: 0.9008
1283/1283 [==============================] - 2s 1ms/step - loss: 0.2437 - acc: 0.9010 - val_loss: 0.9904 - val_acc: 0.5328

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2186 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2171 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2340 - acc: 0.9156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2229 - acc: 0.9219
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2272 - acc: 0.9152
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2266 - acc: 0.9180
 576/1283 [============>.................] - ETA: 0s - loss: 0.2161 - acc: 0.9236
 640/1283 [=============>................] - ETA: 0s - loss: 0.2157 - acc: 0.9234
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2205 - acc: 0.9162
 768/1283 [================>.............] - ETA: 0s - loss: 0.2270 - acc: 0.9141
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2225 - acc: 0.9159
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2176 - acc: 0.9196
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2216 - acc: 0.9177
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2224 - acc: 0.9136
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2219 - acc: 0.9123
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2226 - acc: 0.9128
1283/1283 [==============================] - 1s 1ms/step - loss: 0.2296 - acc: 0.9057 - val_loss: 1.0249 - val_acc: 0.5852

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 3s - loss: 0.2054 - acc: 0.9219
 128/1283 [=>............................] - ETA: 2s - loss: 0.1583 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 2s - loss: 0.1724 - acc: 0.9427
 256/1283 [====>.........................] - ETA: 2s - loss: 0.1608 - acc: 0.9453
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1680 - acc: 0.9427
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1664 - acc: 0.9420
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1658 - acc: 0.9414
 640/1283 [=============>................] - ETA: 0s - loss: 0.1628 - acc: 0.9484
 768/1283 [================>.............] - ETA: 0s - loss: 0.1581 - acc: 0.9505
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1576 - acc: 0.9509
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1593 - acc: 0.9510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1582 - acc: 0.9512
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1563 - acc: 0.9497
1280/1283 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9484
1283/1283 [==============================] - 2s 1ms/step - loss: 0.1607 - acc: 0.9470 - val_loss: 1.2223 - val_acc: 0.5546

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1115 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1755 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 1s - loss: 0.2193 - acc: 0.9115
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2111 - acc: 0.9102
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2114 - acc: 0.9156
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2100 - acc: 0.9141
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2322 - acc: 0.8945
 576/1283 [============>.................] - ETA: 0s - loss: 0.2517 - acc: 0.8837
 640/1283 [=============>................] - ETA: 0s - loss: 0.2545 - acc: 0.8828
 768/1283 [================>.............] - ETA: 0s - loss: 0.2518 - acc: 0.8815
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2490 - acc: 0.8846
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2434 - acc: 0.8927
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2395 - acc: 0.8980
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2368 - acc: 0.9021
1283/1283 [==============================] - 1s 985us/step - loss: 0.2331 - acc: 0.9049 - val_loss: 1.2714 - val_acc: 0.5590

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.49416909620991256
best_valid_accuracy=0.543731778425656
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 21:55:00.256700: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 20s - loss: 0.7133 - acc: 0.4531
 192/1283 [===>..........................] - ETA: 6s - loss: 0.7486 - acc: 0.5260 
 320/1283 [======>.......................] - ETA: 3s - loss: 0.7424 - acc: 0.4938
 448/1283 [=========>....................] - ETA: 2s - loss: 0.7275 - acc: 0.4911
 640/1283 [=============>................] - ETA: 1s - loss: 0.7177 - acc: 0.5156
 768/1283 [================>.............] - ETA: 0s - loss: 0.7137 - acc: 0.5286
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7103 - acc: 0.5346
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7055 - acc: 0.5430
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7049 - acc: 0.5495
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7026 - acc: 0.5511 - val_loss: 0.6909 - val_acc: 0.5328

Epoch 00001: val_acc improved from -inf to 0.53275, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6563 - acc: 0.5625
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6449 - acc: 0.6328
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6501 - acc: 0.6161
 576/1283 [============>.................] - ETA: 0s - loss: 0.6516 - acc: 0.6111
 768/1283 [================>.............] - ETA: 0s - loss: 0.6475 - acc: 0.6146
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6444 - acc: 0.6281
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6486 - acc: 0.6250
1283/1283 [==============================] - 0s 372us/step - loss: 0.6434 - acc: 0.6368 - val_loss: 0.7039 - val_acc: 0.5284

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5835 - acc: 0.7344
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5889 - acc: 0.6813
 576/1283 [============>.................] - ETA: 0s - loss: 0.5970 - acc: 0.6823
 768/1283 [================>.............] - ETA: 0s - loss: 0.5972 - acc: 0.6875
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6072 - acc: 0.6771
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6090 - acc: 0.6661
1283/1283 [==============================] - 0s 279us/step - loss: 0.6080 - acc: 0.6687 - val_loss: 0.6873 - val_acc: 0.5633

Epoch 00003: val_acc improved from 0.53275 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5454 - acc: 0.7188
 256/1283 [====>.........................] - ETA: 0s - loss: 0.5484 - acc: 0.7227
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5740 - acc: 0.6897
 640/1283 [=============>................] - ETA: 0s - loss: 0.5735 - acc: 0.6937
 768/1283 [================>.............] - ETA: 0s - loss: 0.5676 - acc: 0.7044
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5575 - acc: 0.7207
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5647 - acc: 0.7039
1283/1283 [==============================] - 0s 344us/step - loss: 0.5655 - acc: 0.7023 - val_loss: 0.7039 - val_acc: 0.5415

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5005 - acc: 0.8125
 320/1283 [======>.......................] - ETA: 0s - loss: 0.4909 - acc: 0.7875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4957 - acc: 0.7812
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4985 - acc: 0.7812
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5078 - acc: 0.7604
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5070 - acc: 0.7604
1283/1283 [==============================] - 0s 327us/step - loss: 0.5036 - acc: 0.7638 - val_loss: 0.7045 - val_acc: 0.5939

Epoch 00005: val_acc improved from 0.56332 to 0.59389, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4543 - acc: 0.7656
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4472 - acc: 0.7969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4263 - acc: 0.8203
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4209 - acc: 0.8164
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4256 - acc: 0.8153
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4281 - acc: 0.8113
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4268 - acc: 0.8094
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4270 - acc: 0.8134
1283/1283 [==============================] - 1s 434us/step - loss: 0.4282 - acc: 0.8114 - val_loss: 0.7760 - val_acc: 0.5502

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3699 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3932 - acc: 0.8187
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4153 - acc: 0.8008
 768/1283 [================>.............] - ETA: 0s - loss: 0.4229 - acc: 0.7956
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4140 - acc: 0.8086
1280/1283 [============================>.] - ETA: 0s - loss: 0.4043 - acc: 0.8172
1283/1283 [==============================] - 0s 307us/step - loss: 0.4037 - acc: 0.8176 - val_loss: 0.8048 - val_acc: 0.5721

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3630 - acc: 0.8594
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3084 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3028 - acc: 0.9018
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3028 - acc: 0.8892
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2992 - acc: 0.8865
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3021 - acc: 0.8828
1280/1283 [============================>.] - ETA: 0s - loss: 0.3027 - acc: 0.8820
1283/1283 [==============================] - 0s 334us/step - loss: 0.3031 - acc: 0.8815 - val_loss: 0.8524 - val_acc: 0.5721

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2023 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2219 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2425 - acc: 0.9167
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2382 - acc: 0.9238
 640/1283 [=============>................] - ETA: 0s - loss: 0.2535 - acc: 0.9141
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2557 - acc: 0.9123
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2492 - acc: 0.9160
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2518 - acc: 0.9149
1283/1283 [==============================] - 1s 462us/step - loss: 0.2493 - acc: 0.9174 - val_loss: 0.9320 - val_acc: 0.5633

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1998 - acc: 0.9375
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2563 - acc: 0.8906
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2570 - acc: 0.8958
 640/1283 [=============>................] - ETA: 0s - loss: 0.2509 - acc: 0.9062
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2476 - acc: 0.9042
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2572 - acc: 0.8967
1283/1283 [==============================] - 0s 311us/step - loss: 0.2551 - acc: 0.9010 - val_loss: 0.9297 - val_acc: 0.5677

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2148 - acc: 0.9688
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2845 - acc: 0.8781
 576/1283 [============>.................] - ETA: 0s - loss: 0.2946 - acc: 0.8611
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2744 - acc: 0.8798
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2690 - acc: 0.8879
1280/1283 [============================>.] - ETA: 0s - loss: 0.2689 - acc: 0.8922
1283/1283 [==============================] - 0s 303us/step - loss: 0.2686 - acc: 0.8924 - val_loss: 1.0337 - val_acc: 0.5284

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1777 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1844 - acc: 0.9479
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2020 - acc: 0.9336
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1835 - acc: 0.9479
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1802 - acc: 0.9473
 640/1283 [=============>................] - ETA: 0s - loss: 0.1718 - acc: 0.9516
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1681 - acc: 0.9519
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1629 - acc: 0.9504
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1575 - acc: 0.9548
1283/1283 [==============================] - 1s 421us/step - loss: 0.1575 - acc: 0.9548 - val_loss: 1.1175 - val_acc: 0.5677

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1160 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1429 - acc: 0.9531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1340 - acc: 0.9598
 576/1283 [============>.................] - ETA: 0s - loss: 0.1367 - acc: 0.9566
 768/1283 [================>.............] - ETA: 0s - loss: 0.1265 - acc: 0.9622
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1267 - acc: 0.9615
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1268 - acc: 0.9609
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1264 - acc: 0.9613
1283/1283 [==============================] - 1s 521us/step - loss: 0.1246 - acc: 0.9626 - val_loss: 1.1574 - val_acc: 0.5721

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0488 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0839 - acc: 0.9688
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0901 - acc: 0.9732
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0906 - acc: 0.9759
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0842 - acc: 0.9792
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0827 - acc: 0.9789
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0820 - acc: 0.9786
1283/1283 [==============================] - 0s 355us/step - loss: 0.0803 - acc: 0.9790 - val_loss: 1.2682 - val_acc: 0.5502

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0926 - acc: 0.9844
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0663 - acc: 0.9922
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0620 - acc: 0.9933
 640/1283 [=============>................] - ETA: 0s - loss: 0.0587 - acc: 0.9938
 768/1283 [================>.............] - ETA: 0s - loss: 0.0597 - acc: 0.9935
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0606 - acc: 0.9927
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0586 - acc: 0.9931
1283/1283 [==============================] - 0s 384us/step - loss: 0.0594 - acc: 0.9930 - val_loss: 1.3524 - val_acc: 0.5808

Epoch 00015: val_acc did not improve
Epoch 00015: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=15
PCA text=100
accuracy=0.5510204081632653
best_valid_accuracy=0.5145772594752187
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:08:48.420917: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 22s - loss: 0.7706 - acc: 0.5156
 128/1283 [=>............................] - ETA: 11s - loss: 0.7492 - acc: 0.4922
 192/1283 [===>..........................] - ETA: 7s - loss: 0.7533 - acc: 0.4948 
 256/1283 [====>.........................] - ETA: 5s - loss: 0.7473 - acc: 0.4922
 384/1283 [=======>......................] - ETA: 3s - loss: 0.7316 - acc: 0.5078
 512/1283 [==========>...................] - ETA: 2s - loss: 0.7277 - acc: 0.5156
 576/1283 [============>.................] - ETA: 2s - loss: 0.7244 - acc: 0.5278
 640/1283 [=============>................] - ETA: 1s - loss: 0.7210 - acc: 0.5281
 704/1283 [===============>..............] - ETA: 1s - loss: 0.7193 - acc: 0.5312
 768/1283 [================>.............] - ETA: 1s - loss: 0.7207 - acc: 0.5339
 832/1283 [==================>...........] - ETA: 1s - loss: 0.7186 - acc: 0.5373
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7174 - acc: 0.5379
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7170 - acc: 0.5365
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7149 - acc: 0.5352
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7128 - acc: 0.5395
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7115 - acc: 0.5403
1280/1283 [============================>.] - ETA: 0s - loss: 0.7102 - acc: 0.5406
1283/1283 [==============================] - 3s 2ms/step - loss: 0.7102 - acc: 0.5401 - val_loss: 0.6898 - val_acc: 0.5284

Epoch 00001: val_acc improved from -inf to 0.52838, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6155 - acc: 0.7031
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6236 - acc: 0.7188
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6201 - acc: 0.7121
 640/1283 [=============>................] - ETA: 0s - loss: 0.6240 - acc: 0.6984
 768/1283 [================>.............] - ETA: 0s - loss: 0.6298 - acc: 0.6810
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6332 - acc: 0.6674
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6343 - acc: 0.6604
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6368 - acc: 0.6562
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6365 - acc: 0.6553
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6391 - acc: 0.6502
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6391 - acc: 0.6505
1280/1283 [============================>.] - ETA: 0s - loss: 0.6376 - acc: 0.6508
1283/1283 [==============================] - 1s 1ms/step - loss: 0.6379 - acc: 0.6500 - val_loss: 0.6878 - val_acc: 0.5633

Epoch 00002: val_acc improved from 0.52838 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.6418 - acc: 0.6406
 128/1283 [=>............................] - ETA: 1s - loss: 0.6088 - acc: 0.6484
 256/1283 [====>.........................] - ETA: 1s - loss: 0.6048 - acc: 0.6445
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6278 - acc: 0.6156
 384/1283 [=======>......................] - ETA: 1s - loss: 0.6241 - acc: 0.6146
 448/1283 [=========>....................] - ETA: 1s - loss: 0.6166 - acc: 0.6250
 512/1283 [==========>...................] - ETA: 1s - loss: 0.6085 - acc: 0.6348
 576/1283 [============>.................] - ETA: 0s - loss: 0.6105 - acc: 0.6319
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6043 - acc: 0.6477
 768/1283 [================>.............] - ETA: 0s - loss: 0.6059 - acc: 0.6458
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6063 - acc: 0.6490
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6056 - acc: 0.6521
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6100 - acc: 0.6461
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6086 - acc: 0.6484
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6066 - acc: 0.6521
1280/1283 [============================>.] - ETA: 0s - loss: 0.6042 - acc: 0.6555
1283/1283 [==============================] - 2s 1ms/step - loss: 0.6046 - acc: 0.6547 - val_loss: 0.7152 - val_acc: 0.5590

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5897 - acc: 0.6406
 128/1283 [=>............................] - ETA: 0s - loss: 0.5625 - acc: 0.6641
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5588 - acc: 0.6771
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5445 - acc: 0.7188
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5390 - acc: 0.7312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5453 - acc: 0.7277
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5492 - acc: 0.7246
 640/1283 [=============>................] - ETA: 0s - loss: 0.5483 - acc: 0.7266
 768/1283 [================>.............] - ETA: 0s - loss: 0.5399 - acc: 0.7344
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5403 - acc: 0.7356
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5439 - acc: 0.7323
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5431 - acc: 0.7324
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5444 - acc: 0.7335
1280/1283 [============================>.] - ETA: 0s - loss: 0.5424 - acc: 0.7359
1283/1283 [==============================] - 1s 947us/step - loss: 0.5422 - acc: 0.7366 - val_loss: 0.7051 - val_acc: 0.5852

Epoch 00004: val_acc improved from 0.56332 to 0.58515, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 5s - loss: 0.4602 - acc: 0.7969
 128/1283 [=>............................] - ETA: 3s - loss: 0.4804 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 2s - loss: 0.4524 - acc: 0.7917
 256/1283 [====>.........................] - ETA: 2s - loss: 0.4578 - acc: 0.7969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4537 - acc: 0.7943
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4568 - acc: 0.7988
 640/1283 [=============>................] - ETA: 0s - loss: 0.4559 - acc: 0.7969
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4598 - acc: 0.7940
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4606 - acc: 0.7885
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4571 - acc: 0.7948
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4652 - acc: 0.7877
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4693 - acc: 0.7812
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4676 - acc: 0.7825 - val_loss: 0.8111 - val_acc: 0.5328

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 4s - loss: 0.4526 - acc: 0.8125
 128/1283 [=>............................] - ETA: 2s - loss: 0.3980 - acc: 0.8672
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4122 - acc: 0.8438
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4177 - acc: 0.8242
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4288 - acc: 0.8151
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4334 - acc: 0.8164
 640/1283 [=============>................] - ETA: 0s - loss: 0.4414 - acc: 0.8094
 768/1283 [================>.............] - ETA: 0s - loss: 0.4460 - acc: 0.8034
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4388 - acc: 0.8092
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4372 - acc: 0.8063
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4331 - acc: 0.8105
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4307 - acc: 0.8134
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4283 - acc: 0.8160
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4292 - acc: 0.8150
1280/1283 [============================>.] - ETA: 0s - loss: 0.4252 - acc: 0.8187
1283/1283 [==============================] - 1s 1ms/step - loss: 0.4254 - acc: 0.8184 - val_loss: 0.8053 - val_acc: 0.5633

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3110 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3550 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3549 - acc: 0.8359
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3355 - acc: 0.8646
 576/1283 [============>.................] - ETA: 0s - loss: 0.3398 - acc: 0.8628
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3477 - acc: 0.8594
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3463 - acc: 0.8570
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3445 - acc: 0.8594
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3441 - acc: 0.8594
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3472 - acc: 0.8574
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3436 - acc: 0.8611
1280/1283 [============================>.] - ETA: 0s - loss: 0.3412 - acc: 0.8633
1283/1283 [==============================] - 1s 1ms/step - loss: 0.3413 - acc: 0.8636 - val_loss: 0.8541 - val_acc: 0.5852

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2292 - acc: 0.9688
 128/1283 [=>............................] - ETA: 0s - loss: 0.3155 - acc: 0.8750
 256/1283 [====>.........................] - ETA: 0s - loss: 0.3573 - acc: 0.8438
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3448 - acc: 0.8438
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3355 - acc: 0.8527
 576/1283 [============>.................] - ETA: 0s - loss: 0.3339 - acc: 0.8542
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3154 - acc: 0.8693
 768/1283 [================>.............] - ETA: 0s - loss: 0.3071 - acc: 0.8763
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3072 - acc: 0.8783
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3020 - acc: 0.8823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2993 - acc: 0.8877
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2941 - acc: 0.8925
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2936 - acc: 0.8932
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2916 - acc: 0.8923
1280/1283 [============================>.] - ETA: 0s - loss: 0.2897 - acc: 0.8938
1283/1283 [==============================] - 1s 904us/step - loss: 0.2893 - acc: 0.8940 - val_loss: 0.8668 - val_acc: 0.5721

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1690 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1707 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1731 - acc: 0.9896
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1921 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1866 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1843 - acc: 0.9583
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1918 - acc: 0.9512
 576/1283 [============>.................] - ETA: 0s - loss: 0.1971 - acc: 0.9462
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1981 - acc: 0.9446
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1949 - acc: 0.9483
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1972 - acc: 0.9437
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1970 - acc: 0.9439
1280/1283 [============================>.] - ETA: 0s - loss: 0.1889 - acc: 0.9461
1283/1283 [==============================] - 1s 776us/step - loss: 0.1885 - acc: 0.9462 - val_loss: 0.9755 - val_acc: 0.5546

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1237 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1253 - acc: 0.9740
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1357 - acc: 0.9688
 512/1283 [==========>...................] - ETA: 0s - loss: 0.1285 - acc: 0.9727
 640/1283 [=============>................] - ETA: 0s - loss: 0.1235 - acc: 0.9750
 768/1283 [================>.............] - ETA: 0s - loss: 0.1251 - acc: 0.9766
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1259 - acc: 0.9740
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1232 - acc: 0.9761
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1199 - acc: 0.9770
1283/1283 [==============================] - 1s 469us/step - loss: 0.1203 - acc: 0.9766 - val_loss: 1.0609 - val_acc: 0.5633

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0982 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0953 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0922 - acc: 0.9781
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0887 - acc: 0.9824
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0866 - acc: 0.9787
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0879 - acc: 0.9784
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0836 - acc: 0.9814
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0880 - acc: 0.9811
1283/1283 [==============================] - 1s 399us/step - loss: 0.0870 - acc: 0.9813 - val_loss: 1.1941 - val_acc: 0.5590

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0749 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0520 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0612 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0606 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0596 - acc: 0.9931
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0599 - acc: 0.9929
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0613 - acc: 0.9911
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0593 - acc: 0.9917
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0594 - acc: 0.9901
1283/1283 [==============================] - 1s 504us/step - loss: 0.0588 - acc: 0.9899 - val_loss: 1.3932 - val_acc: 0.5852

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0737 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0551 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0446 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0445 - acc: 0.9955
 576/1283 [============>.................] - ETA: 0s - loss: 0.0431 - acc: 0.9965
 640/1283 [=============>................] - ETA: 0s - loss: 0.0436 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0446 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0433 - acc: 0.9978
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0430 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0408 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0407 - acc: 0.9967
1280/1283 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9961
1283/1283 [==============================] - 1s 727us/step - loss: 0.0407 - acc: 0.9961 - val_loss: 1.4195 - val_acc: 0.5808

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0243 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0238 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0234 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0240 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0232 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0221 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0217 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0212 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0213 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0215 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0215 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0220 - acc: 0.9980
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0247 - acc: 0.9974
1280/1283 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9977
1283/1283 [==============================] - 1s 1ms/step - loss: 0.0243 - acc: 0.9977 - val_loss: 1.5149 - val_acc: 0.5852

Epoch 00014: val_acc did not improve
Epoch 00014: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=20
PCA text=100
accuracy=0.5539358600583091
best_valid_accuracy=0.5233236151603499
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:18:56.428547: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 9s - loss: 0.7723 - acc: 0.3906
 192/1283 [===>..........................] - ETA: 3s - loss: 0.7438 - acc: 0.4844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.7356 - acc: 0.4719
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7386 - acc: 0.4665
 512/1283 [==========>...................] - ETA: 1s - loss: 0.7308 - acc: 0.4863
 640/1283 [=============>................] - ETA: 0s - loss: 0.7213 - acc: 0.5047
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7141 - acc: 0.5312
 960/1283 [=====================>........] - ETA: 0s - loss: 0.7078 - acc: 0.5354
1088/1283 [========================>.....] - ETA: 0s - loss: 0.7027 - acc: 0.5441
1280/1283 [============================>.] - ETA: 0s - loss: 0.7026 - acc: 0.5383
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7022 - acc: 0.5394 - val_loss: 0.7129 - val_acc: 0.5066

Epoch 00001: val_acc improved from -inf to 0.50655, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6223 - acc: 0.6719
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6009 - acc: 0.7083
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5942 - acc: 0.7156
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5917 - acc: 0.7109
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5923 - acc: 0.6934
 640/1283 [=============>................] - ETA: 0s - loss: 0.6022 - acc: 0.6750
 768/1283 [================>.............] - ETA: 0s - loss: 0.6016 - acc: 0.6771
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6030 - acc: 0.6685
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6032 - acc: 0.6689
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6053 - acc: 0.6667
1280/1283 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.6711
1283/1283 [==============================] - 1s 679us/step - loss: 0.6022 - acc: 0.6711 - val_loss: 0.7131 - val_acc: 0.4978

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5542 - acc: 0.7188
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5474 - acc: 0.7292
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5393 - acc: 0.7344
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5283 - acc: 0.7474
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5309 - acc: 0.7402
 640/1283 [=============>................] - ETA: 0s - loss: 0.5302 - acc: 0.7281
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5378 - acc: 0.7248
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5308 - acc: 0.7292
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5302 - acc: 0.7307
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5291 - acc: 0.7319
1283/1283 [==============================] - 1s 611us/step - loss: 0.5279 - acc: 0.7319 - val_loss: 0.7747 - val_acc: 0.5240

Epoch 00003: val_acc improved from 0.50655 to 0.52402, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.4955 - acc: 0.7031
 128/1283 [=>............................] - ETA: 0s - loss: 0.4624 - acc: 0.7891
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4532 - acc: 0.8047
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4572 - acc: 0.7969
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4588 - acc: 0.7969
 640/1283 [=============>................] - ETA: 0s - loss: 0.4554 - acc: 0.7937
 768/1283 [================>.............] - ETA: 0s - loss: 0.4647 - acc: 0.7826
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4571 - acc: 0.7891
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4588 - acc: 0.7906
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4561 - acc: 0.7858
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4528 - acc: 0.7911
1283/1283 [==============================] - 1s 774us/step - loss: 0.4496 - acc: 0.7942 - val_loss: 0.7915 - val_acc: 0.5459

Epoch 00004: val_acc improved from 0.52402 to 0.54585, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3511 - acc: 0.8906
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3333 - acc: 0.9062
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3271 - acc: 0.8906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3373 - acc: 0.8906
 576/1283 [============>.................] - ETA: 0s - loss: 0.3458 - acc: 0.8802
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3464 - acc: 0.8722
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3536 - acc: 0.8606
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3556 - acc: 0.8594
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3566 - acc: 0.8612
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3548 - acc: 0.8594
1280/1283 [============================>.] - ETA: 0s - loss: 0.3543 - acc: 0.8578
1283/1283 [==============================] - 1s 600us/step - loss: 0.3549 - acc: 0.8574 - val_loss: 0.8474 - val_acc: 0.5153

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2592 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2990 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3007 - acc: 0.8781
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2901 - acc: 0.8906
 576/1283 [============>.................] - ETA: 0s - loss: 0.2895 - acc: 0.8924
 640/1283 [=============>................] - ETA: 0s - loss: 0.2866 - acc: 0.8938
 768/1283 [================>.............] - ETA: 0s - loss: 0.2980 - acc: 0.8841
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3013 - acc: 0.8850
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2956 - acc: 0.8896
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2941 - acc: 0.8915
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2971 - acc: 0.8872
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3007 - acc: 0.8865
1283/1283 [==============================] - 1s 724us/step - loss: 0.3011 - acc: 0.8870 - val_loss: 1.4146 - val_acc: 0.5633

Epoch 00006: val_acc improved from 0.54585 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4674 - acc: 0.7656
 192/1283 [===>..........................] - ETA: 0s - loss: 0.4542 - acc: 0.7656
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3957 - acc: 0.8125
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3685 - acc: 0.8304
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3479 - acc: 0.8438
 640/1283 [=============>................] - ETA: 0s - loss: 0.3284 - acc: 0.8547
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3461 - acc: 0.8409
 768/1283 [================>.............] - ETA: 0s - loss: 0.3462 - acc: 0.8411
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3375 - acc: 0.8474
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3277 - acc: 0.8542
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3266 - acc: 0.8557
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3229 - acc: 0.8594
1280/1283 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8648
1283/1283 [==============================] - 1s 831us/step - loss: 0.3152 - acc: 0.8652 - val_loss: 1.0198 - val_acc: 0.5983

Epoch 00007: val_acc improved from 0.56332 to 0.59825, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3097 - acc: 0.8438
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3034 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2497 - acc: 0.8812
 384/1283 [=======>......................] - ETA: 0s - loss: 0.2339 - acc: 0.8984
 512/1283 [==========>...................] - ETA: 0s - loss: 0.2261 - acc: 0.9121
 640/1283 [=============>................] - ETA: 0s - loss: 0.2216 - acc: 0.9172
 768/1283 [================>.............] - ETA: 0s - loss: 0.2231 - acc: 0.9193
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2205 - acc: 0.9243
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2169 - acc: 0.9263
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2114 - acc: 0.9302
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2084 - acc: 0.9316
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2105 - acc: 0.9301
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2066 - acc: 0.9314
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2056 - acc: 0.9317
1283/1283 [==============================] - 1s 863us/step - loss: 0.2029 - acc: 0.9330 - val_loss: 1.0108 - val_acc: 0.5371

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1299 - acc: 0.9531
 128/1283 [=>............................] - ETA: 0s - loss: 0.1570 - acc: 0.9297
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1705 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1816 - acc: 0.9187
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1737 - acc: 0.9308
 576/1283 [============>.................] - ETA: 0s - loss: 0.1818 - acc: 0.9271
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1838 - acc: 0.9318
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1757 - acc: 0.9351
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1787 - acc: 0.9344
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1792 - acc: 0.9346
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1787 - acc: 0.9329
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1778 - acc: 0.9301
1283/1283 [==============================] - 1s 875us/step - loss: 0.1759 - acc: 0.9314 - val_loss: 1.0747 - val_acc: 0.5590

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0884 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.1108 - acc: 0.9766
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1095 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1283 - acc: 0.9727
 384/1283 [=======>......................] - ETA: 0s - loss: 0.1436 - acc: 0.9609
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1428 - acc: 0.9576
 640/1283 [=============>................] - ETA: 0s - loss: 0.1521 - acc: 0.9484
 768/1283 [================>.............] - ETA: 0s - loss: 0.1535 - acc: 0.9427
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1521 - acc: 0.9431
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1536 - acc: 0.9406
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1506 - acc: 0.9424
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1494 - acc: 0.9427
1280/1283 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9445
1283/1283 [==============================] - 1s 761us/step - loss: 0.1486 - acc: 0.9447 - val_loss: 1.1529 - val_acc: 0.5895

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1156 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1072 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0943 - acc: 0.9906
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0865 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0860 - acc: 0.9878
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0885 - acc: 0.9872
 768/1283 [================>.............] - ETA: 0s - loss: 0.0870 - acc: 0.9870
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0864 - acc: 0.9855
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0879 - acc: 0.9844
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0859 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9844
1283/1283 [==============================] - 1s 703us/step - loss: 0.0858 - acc: 0.9844 - val_loss: 1.3366 - val_acc: 0.5546

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0402 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0567 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0475 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0470 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0457 - acc: 0.9933
 576/1283 [============>.................] - ETA: 0s - loss: 0.0476 - acc: 0.9948
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0500 - acc: 0.9929
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0487 - acc: 0.9928
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0491 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0487 - acc: 0.9932
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0485 - acc: 0.9931
1280/1283 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9922
1283/1283 [==============================] - 1s 873us/step - loss: 0.0491 - acc: 0.9922 - val_loss: 1.3654 - val_acc: 0.5590

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0250 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0374 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0349 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0397 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0381 - acc: 0.9965
 768/1283 [================>.............] - ETA: 0s - loss: 0.0376 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0365 - acc: 0.9978
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0354 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0338 - acc: 0.9974
1280/1283 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9969
1283/1283 [==============================] - 1s 589us/step - loss: 0.0330 - acc: 0.9969 - val_loss: 1.4455 - val_acc: 0.5240

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0149 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0296 - acc: 0.9922
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0232 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0226 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0258 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0246 - acc: 0.9941
 576/1283 [============>.................] - ETA: 0s - loss: 0.0235 - acc: 0.9948
 640/1283 [=============>................] - ETA: 0s - loss: 0.0237 - acc: 0.9953
 768/1283 [================>.............] - ETA: 0s - loss: 0.0226 - acc: 0.9961
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0221 - acc: 0.9967
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0220 - acc: 0.9971
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0223 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0220 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9977
1283/1283 [==============================] - 1s 802us/step - loss: 0.0217 - acc: 0.9977 - val_loss: 1.5439 - val_acc: 0.5284

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0117 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0101 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0150 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0185 - acc: 0.9974
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0179 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0169 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0176 - acc: 0.9987
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0180 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0175 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0170 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0170 - acc: 0.9992
1283/1283 [==============================] - 1s 739us/step - loss: 0.0167 - acc: 0.9992 - val_loss: 1.6791 - val_acc: 0.5459

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0172 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0143 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0120 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0111 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0118 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0126 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0135 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0131 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0127 - acc: 1.0000
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0127 - acc: 1.0000
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0123 - acc: 1.0000
1280/1283 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 1.0000
1283/1283 [==============================] - 1s 630us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.7022 - val_acc: 0.5371

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0045 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0103 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0104 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0115 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0106 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0095 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0094 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0096 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0099 - acc: 0.9989
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0101 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0095 - acc: 0.9991
1280/1283 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9992
1283/1283 [==============================] - 1s 738us/step - loss: 0.0090 - acc: 0.9992 - val_loss: 1.7332 - val_acc: 0.5328

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=25
PCA text=100
accuracy=0.5306122448979592
best_valid_accuracy=0.48250728862973763
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:23:58.408121: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.7776 - acc: 0.4219
 128/1283 [=>............................] - ETA: 6s - loss: 0.7613 - acc: 0.4766 
 256/1283 [====>.........................] - ETA: 3s - loss: 0.7498 - acc: 0.4766
 320/1283 [======>.......................] - ETA: 2s - loss: 0.7299 - acc: 0.5000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7524 - acc: 0.4710
 576/1283 [============>.................] - ETA: 1s - loss: 0.7371 - acc: 0.5017
 704/1283 [===============>..............] - ETA: 0s - loss: 0.7285 - acc: 0.5085
 832/1283 [==================>...........] - ETA: 0s - loss: 0.7296 - acc: 0.5072
 896/1283 [===================>..........] - ETA: 0s - loss: 0.7286 - acc: 0.5089
1024/1283 [======================>.......] - ETA: 0s - loss: 0.7231 - acc: 0.5166
1152/1283 [=========================>....] - ETA: 0s - loss: 0.7185 - acc: 0.5182
1216/1283 [===========================>..] - ETA: 0s - loss: 0.7149 - acc: 0.5288
1283/1283 [==============================] - 2s 1ms/step - loss: 0.7119 - acc: 0.5316 - val_loss: 0.7115 - val_acc: 0.4978

Epoch 00001: val_acc improved from -inf to 0.49782, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6717 - acc: 0.6562
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6723 - acc: 0.6198
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6673 - acc: 0.6312
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6499 - acc: 0.6585
 576/1283 [============>.................] - ETA: 0s - loss: 0.6493 - acc: 0.6476
 704/1283 [===============>..............] - ETA: 0s - loss: 0.6471 - acc: 0.6449
 832/1283 [==================>...........] - ETA: 0s - loss: 0.6421 - acc: 0.6490
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6303 - acc: 0.6631
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6288 - acc: 0.6632
1283/1283 [==============================] - 1s 560us/step - loss: 0.6234 - acc: 0.6656 - val_loss: 0.7145 - val_acc: 0.5328

Epoch 00002: val_acc improved from 0.49782 to 0.53275, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5475 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5632 - acc: 0.6771
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5533 - acc: 0.7188
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5508 - acc: 0.7277
 576/1283 [============>.................] - ETA: 0s - loss: 0.5510 - acc: 0.7309
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5599 - acc: 0.7216
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5549 - acc: 0.7200
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5528 - acc: 0.7208
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5488 - acc: 0.7289
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5514 - acc: 0.7294
1283/1283 [==============================] - 1s 540us/step - loss: 0.5498 - acc: 0.7295 - val_loss: 0.8391 - val_acc: 0.5284

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5012 - acc: 0.7500
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5131 - acc: 0.7448
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5044 - acc: 0.7531
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4994 - acc: 0.7567
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5011 - acc: 0.7520
 640/1283 [=============>................] - ETA: 0s - loss: 0.4890 - acc: 0.7703
 768/1283 [================>.............] - ETA: 0s - loss: 0.4863 - acc: 0.7721
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4765 - acc: 0.7865
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4767 - acc: 0.7868
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4730 - acc: 0.7887
1283/1283 [==============================] - 1s 591us/step - loss: 0.4712 - acc: 0.7896 - val_loss: 0.7668 - val_acc: 0.5633

Epoch 00004: val_acc improved from 0.53275 to 0.56332, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3728 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3859 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3943 - acc: 0.8250
 448/1283 [=========>....................] - ETA: 0s - loss: 0.4066 - acc: 0.8147
 576/1283 [============>.................] - ETA: 0s - loss: 0.4040 - acc: 0.8194
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4110 - acc: 0.8168
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4000 - acc: 0.8257
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3967 - acc: 0.8281
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3964 - acc: 0.8262
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4001 - acc: 0.8212
1280/1283 [============================>.] - ETA: 0s - loss: 0.3978 - acc: 0.8242
1283/1283 [==============================] - 1s 592us/step - loss: 0.3973 - acc: 0.8246 - val_loss: 0.7980 - val_acc: 0.5415

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3410 - acc: 0.9062
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3219 - acc: 0.9010
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3129 - acc: 0.9031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.3030 - acc: 0.8996
 576/1283 [============>.................] - ETA: 0s - loss: 0.2991 - acc: 0.9028
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3003 - acc: 0.8920
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3029 - acc: 0.8930
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3036 - acc: 0.8929
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3045 - acc: 0.8896
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3006 - acc: 0.8915
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2999 - acc: 0.8906
1283/1283 [==============================] - 1s 705us/step - loss: 0.2996 - acc: 0.8893 - val_loss: 0.8305 - val_acc: 0.5677

Epoch 00006: val_acc improved from 0.56332 to 0.56769, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2052 - acc: 0.9375
 192/1283 [===>..........................] - ETA: 0s - loss: 0.2288 - acc: 0.9427
 320/1283 [======>.......................] - ETA: 0s - loss: 0.2233 - acc: 0.9375
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2164 - acc: 0.9420
 576/1283 [============>.................] - ETA: 0s - loss: 0.2182 - acc: 0.9410
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2186 - acc: 0.9418
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2094 - acc: 0.9459
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2045 - acc: 0.9490
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2055 - acc: 0.9458
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2111 - acc: 0.9400
1280/1283 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9422
1283/1283 [==============================] - 1s 589us/step - loss: 0.2086 - acc: 0.9423 - val_loss: 1.0003 - val_acc: 0.5764

Epoch 00007: val_acc improved from 0.56769 to 0.57642, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1342 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1528 - acc: 0.9583
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1441 - acc: 0.9656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1363 - acc: 0.9710
 576/1283 [============>.................] - ETA: 0s - loss: 0.1339 - acc: 0.9757
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1362 - acc: 0.9744
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1340 - acc: 0.9732
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1387 - acc: 0.9688
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1361 - acc: 0.9696
1280/1283 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9680
1283/1283 [==============================] - 1s 511us/step - loss: 0.1378 - acc: 0.9680 - val_loss: 1.1230 - val_acc: 0.5197

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1160 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1056 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0979 - acc: 0.9875
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0912 - acc: 0.9888
 576/1283 [============>.................] - ETA: 0s - loss: 0.0844 - acc: 0.9913
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0873 - acc: 0.9886
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0885 - acc: 0.9844
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0870 - acc: 0.9855
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0858 - acc: 0.9854
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0849 - acc: 0.9853
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0848 - acc: 0.9844
1283/1283 [==============================] - 1s 646us/step - loss: 0.0822 - acc: 0.9852 - val_loss: 1.2662 - val_acc: 0.4891

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0731 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0942 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0780 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0781 - acc: 0.9799
 576/1283 [============>.................] - ETA: 0s - loss: 0.0802 - acc: 0.9809
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0731 - acc: 0.9844
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0710 - acc: 0.9868
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0674 - acc: 0.9893
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0694 - acc: 0.9887
1280/1283 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9875
1283/1283 [==============================] - 1s 579us/step - loss: 0.0681 - acc: 0.9875 - val_loss: 1.3258 - val_acc: 0.5022

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0748 - acc: 0.9531
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0555 - acc: 0.9792
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0491 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0500 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0490 - acc: 0.9863
 640/1283 [=============>................] - ETA: 0s - loss: 0.0474 - acc: 0.9875
 768/1283 [================>.............] - ETA: 0s - loss: 0.0454 - acc: 0.9896
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0447 - acc: 0.9900
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0428 - acc: 0.9912
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0414 - acc: 0.9913
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0403 - acc: 0.9918
1280/1283 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9914
1283/1283 [==============================] - 1s 785us/step - loss: 0.0403 - acc: 0.9914 - val_loss: 1.4612 - val_acc: 0.5546

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0177 - acc: 1.0000
 128/1283 [=>............................] - ETA: 1s - loss: 0.0181 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0227 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0222 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0236 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0256 - acc: 0.9980
 640/1283 [=============>................] - ETA: 0s - loss: 0.0233 - acc: 0.9984
 768/1283 [================>.............] - ETA: 0s - loss: 0.0220 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0215 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0216 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0220 - acc: 0.9980
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0218 - acc: 0.9983
1280/1283 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9984
1283/1283 [==============================] - 1s 909us/step - loss: 0.0210 - acc: 0.9984 - val_loss: 1.5116 - val_acc: 0.4978

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0185 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0201 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0191 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0180 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0171 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0168 - acc: 1.0000
 768/1283 [================>.............] - ETA: 0s - loss: 0.0162 - acc: 1.0000
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0164 - acc: 0.9989
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0156 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0156 - acc: 0.9991
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0152 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0149 - acc: 0.9992
1280/1283 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9992
1283/1283 [==============================] - 1s 925us/step - loss: 0.0147 - acc: 0.9992 - val_loss: 1.5981 - val_acc: 0.5546

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0216 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0114 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0097 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0111 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0110 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0102 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0098 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0096 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0094 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0086 - acc: 0.9991
1280/1283 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9984
1283/1283 [==============================] - 1s 688us/step - loss: 0.0093 - acc: 0.9984 - val_loss: 1.6565 - val_acc: 0.5502

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0117 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0086 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0074 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0083 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0091 - acc: 0.9965
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0085 - acc: 0.9972
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0082 - acc: 0.9976
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0079 - acc: 0.9978
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0075 - acc: 0.9980
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0071 - acc: 0.9983
1280/1283 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9984
1283/1283 [==============================] - 1s 680us/step - loss: 0.0069 - acc: 0.9984 - val_loss: 1.7229 - val_acc: 0.5502

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0064 - acc: 1.0000
 128/1283 [=>............................] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0073 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0073 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0065 - acc: 1.0000
 576/1283 [============>.................] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0057 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0055 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0053 - acc: 1.0000
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0051 - acc: 1.0000
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0060 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0061 - acc: 0.9992
1283/1283 [==============================] - 1s 830us/step - loss: 0.0060 - acc: 0.9992 - val_loss: 1.7537 - val_acc: 0.5197

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0054 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0038 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0065 - acc: 0.9969
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0065 - acc: 0.9978
 576/1283 [============>.................] - ETA: 0s - loss: 0.0058 - acc: 0.9983
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0054 - acc: 0.9986
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0060 - acc: 0.9976
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0057 - acc: 0.9979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0055 - acc: 0.9980
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0053 - acc: 0.9983
1280/1283 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9984
1283/1283 [==============================] - 1s 697us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 1.8506 - val_acc: 0.5109

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=30
PCA text=100
accuracy=0.5233236151603499
best_valid_accuracy=0.5174927113702624
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_cnn.py:146: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_cnn.py:148: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 22:44:43.087651: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 13s - loss: 0.7689 - acc: 0.4062
 256/1283 [====>.........................] - ETA: 2s - loss: 0.7551 - acc: 0.4805 
 448/1283 [=========>....................] - ETA: 1s - loss: 0.7273 - acc: 0.5089
 576/1283 [============>.................] - ETA: 1s - loss: 0.7108 - acc: 0.5365
 640/1283 [=============>................] - ETA: 0s - loss: 0.7094 - acc: 0.5391
 768/1283 [================>.............] - ETA: 0s - loss: 0.7039 - acc: 0.5482
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6974 - acc: 0.5647
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6981 - acc: 0.5576
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6970 - acc: 0.5590
1280/1283 [============================>.] - ETA: 0s - loss: 0.6997 - acc: 0.5570
1283/1283 [==============================] - 1s 1ms/step - loss: 0.7000 - acc: 0.5557 - val_loss: 0.7145 - val_acc: 0.5459

Epoch 00001: val_acc improved from -inf to 0.54585, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6062 - acc: 0.6719
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6499 - acc: 0.5859
 320/1283 [======>.......................] - ETA: 0s - loss: 0.6462 - acc: 0.6031
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6439 - acc: 0.6138
 640/1283 [=============>................] - ETA: 0s - loss: 0.6325 - acc: 0.6391
 768/1283 [================>.............] - ETA: 0s - loss: 0.6447 - acc: 0.6237
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6314 - acc: 0.6396
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6283 - acc: 0.6445
1152/1283 [=========================>....] - ETA: 0s - loss: 0.6282 - acc: 0.6467
1280/1283 [============================>.] - ETA: 0s - loss: 0.6246 - acc: 0.6508
1283/1283 [==============================] - 1s 546us/step - loss: 0.6245 - acc: 0.6508 - val_loss: 0.7325 - val_acc: 0.5153

Epoch 00002: val_acc did not improve
Epoch 3/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.5627 - acc: 0.6875
 192/1283 [===>..........................] - ETA: 0s - loss: 0.5598 - acc: 0.7031
 320/1283 [======>.......................] - ETA: 0s - loss: 0.5563 - acc: 0.7094
 448/1283 [=========>....................] - ETA: 0s - loss: 0.5490 - acc: 0.7210
 576/1283 [============>.................] - ETA: 0s - loss: 0.5376 - acc: 0.7378
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5380 - acc: 0.7315
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5326 - acc: 0.7380
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5366 - acc: 0.7266
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5351 - acc: 0.7257
1283/1283 [==============================] - 1s 548us/step - loss: 0.5304 - acc: 0.7288 - val_loss: 0.7374 - val_acc: 0.5240

Epoch 00003: val_acc did not improve
Epoch 4/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3944 - acc: 0.8594
 256/1283 [====>.........................] - ETA: 0s - loss: 0.4372 - acc: 0.8242
 384/1283 [=======>......................] - ETA: 0s - loss: 0.4415 - acc: 0.8151
 512/1283 [==========>...................] - ETA: 0s - loss: 0.4540 - acc: 0.7949
 640/1283 [=============>................] - ETA: 0s - loss: 0.4433 - acc: 0.8016
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4396 - acc: 0.8041
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4400 - acc: 0.8010
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4357 - acc: 0.8057
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4344 - acc: 0.8082
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4362 - acc: 0.8067
1283/1283 [==============================] - 1s 602us/step - loss: 0.4418 - acc: 0.8012 - val_loss: 0.7472 - val_acc: 0.5328

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3082 - acc: 0.9688
 192/1283 [===>..........................] - ETA: 0s - loss: 0.3658 - acc: 0.8385
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3751 - acc: 0.8406
 384/1283 [=======>......................] - ETA: 0s - loss: 0.3621 - acc: 0.8568
 576/1283 [============>.................] - ETA: 0s - loss: 0.3676 - acc: 0.8594
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3598 - acc: 0.8636
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3570 - acc: 0.8666
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3493 - acc: 0.8701
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3452 - acc: 0.8709
1283/1283 [==============================] - 1s 493us/step - loss: 0.3437 - acc: 0.8714 - val_loss: 0.8321 - val_acc: 0.5328

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.2735 - acc: 0.9219
 320/1283 [======>.......................] - ETA: 0s - loss: 0.3236 - acc: 0.8562
 512/1283 [==========>...................] - ETA: 0s - loss: 0.3279 - acc: 0.8574
 768/1283 [================>.............] - ETA: 0s - loss: 0.3092 - acc: 0.8698
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2973 - acc: 0.8802
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2949 - acc: 0.8857
1283/1283 [==============================] - 0s 298us/step - loss: 0.2940 - acc: 0.8862 - val_loss: 0.9715 - val_acc: 0.5459

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.3287 - acc: 0.7969
 256/1283 [====>.........................] - ETA: 0s - loss: 0.2940 - acc: 0.8672
 448/1283 [=========>....................] - ETA: 0s - loss: 0.2675 - acc: 0.8973
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2565 - acc: 0.9048
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2542 - acc: 0.9094
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2455 - acc: 0.9161
1283/1283 [==============================] - 0s 297us/step - loss: 0.2452 - acc: 0.9166 - val_loss: 0.9150 - val_acc: 0.5546

Epoch 00007: val_acc improved from 0.54585 to 0.55459, saving model to classification_logs//cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30/saved_models/best_validation_cnn_early_fusion_m_A_ep_100_bs_64_bn_False_dr_0.1_nl_2_ml_30.ckpt
Epoch 8/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1203 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.1572 - acc: 0.9635
 320/1283 [======>.......................] - ETA: 0s - loss: 0.1508 - acc: 0.9656
 448/1283 [=========>....................] - ETA: 0s - loss: 0.1536 - acc: 0.9643
 640/1283 [=============>................] - ETA: 0s - loss: 0.1463 - acc: 0.9734
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1383 - acc: 0.9748
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1365 - acc: 0.9736
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1335 - acc: 0.9748
1283/1283 [==============================] - 1s 406us/step - loss: 0.1351 - acc: 0.9735 - val_loss: 1.0692 - val_acc: 0.5197

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.1130 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.1026 - acc: 0.9805
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0887 - acc: 0.9866
 640/1283 [=============>................] - ETA: 0s - loss: 0.0828 - acc: 0.9906
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0794 - acc: 0.9904
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0792 - acc: 0.9893
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0756 - acc: 0.9901
1283/1283 [==============================] - 1s 411us/step - loss: 0.0752 - acc: 0.9906 - val_loss: 1.2373 - val_acc: 0.5109

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0629 - acc: 0.9688
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0441 - acc: 0.9883
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0469 - acc: 0.9911
 576/1283 [============>.................] - ETA: 0s - loss: 0.0453 - acc: 0.9931
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0454 - acc: 0.9929
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0482 - acc: 0.9933
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0446 - acc: 0.9948
1280/1283 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9945
1283/1283 [==============================] - 1s 442us/step - loss: 0.0461 - acc: 0.9945 - val_loss: 1.2896 - val_acc: 0.5109

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0285 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0315 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0269 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0258 - acc: 1.0000
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0285 - acc: 0.9986
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0271 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0271 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0276 - acc: 0.9982
1280/1283 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9977
1283/1283 [==============================] - 1s 435us/step - loss: 0.0288 - acc: 0.9977 - val_loss: 1.3829 - val_acc: 0.5240

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0126 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0341 - acc: 0.9948
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0743 - acc: 0.9750
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0823 - acc: 0.9710
 640/1283 [=============>................] - ETA: 0s - loss: 0.0954 - acc: 0.9594
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1111 - acc: 0.9507
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1123 - acc: 0.9510
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1076 - acc: 0.9550
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1049 - acc: 0.9581
1283/1283 [==============================] - 1s 469us/step - loss: 0.1022 - acc: 0.9602 - val_loss: 1.4703 - val_acc: 0.5066

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0419 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0917 - acc: 0.9740
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0777 - acc: 0.9812
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0843 - acc: 0.9754
 576/1283 [============>.................] - ETA: 0s - loss: 0.0796 - acc: 0.9774
 768/1283 [================>.............] - ETA: 0s - loss: 0.0747 - acc: 0.9805
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0699 - acc: 0.9823
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0663 - acc: 0.9844
1280/1283 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9844
1283/1283 [==============================] - 1s 549us/step - loss: 0.0669 - acc: 0.9836 - val_loss: 1.4238 - val_acc: 0.5240

Epoch 00013: val_acc did not improve
Epoch 14/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0216 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0523 - acc: 0.9844
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0426 - acc: 0.9902
 704/1283 [===============>..............] - ETA: 0s - loss: 0.0446 - acc: 0.9901
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0434 - acc: 0.9900
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0421 - acc: 0.9908
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0417 - acc: 0.9910
1283/1283 [==============================] - 0s 363us/step - loss: 0.0407 - acc: 0.9914 - val_loss: 1.4590 - val_acc: 0.5109

Epoch 00014: val_acc did not improve
Epoch 15/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0127 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0145 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 0s - loss: 0.0143 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0147 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0179 - acc: 0.9984
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0171 - acc: 0.9988
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0177 - acc: 0.9979
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0165 - acc: 0.9983
1280/1283 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9984
1283/1283 [==============================] - 1s 502us/step - loss: 0.0160 - acc: 0.9984 - val_loss: 1.5625 - val_acc: 0.5284

Epoch 00015: val_acc did not improve
Epoch 16/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 0s - loss: 0.0069 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0081 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 0s - loss: 0.0133 - acc: 0.9961
 640/1283 [=============>................] - ETA: 0s - loss: 0.0123 - acc: 0.9969
 768/1283 [================>.............] - ETA: 0s - loss: 0.0116 - acc: 0.9974
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0106 - acc: 0.9978
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0108 - acc: 0.9982
1280/1283 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9984
1283/1283 [==============================] - 1s 515us/step - loss: 0.0103 - acc: 0.9984 - val_loss: 1.7478 - val_acc: 0.5502

Epoch 00016: val_acc did not improve
Epoch 17/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.0057 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 0s - loss: 0.0065 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 0s - loss: 0.0067 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 0s - loss: 0.0062 - acc: 1.0000
 640/1283 [=============>................] - ETA: 0s - loss: 0.0060 - acc: 1.0000
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0083 - acc: 0.9988
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0076 - acc: 0.9990
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0072 - acc: 0.9991
1283/1283 [==============================] - 1s 414us/step - loss: 0.0068 - acc: 0.9992 - val_loss: 1.7588 - val_acc: 0.5371

Epoch 00017: val_acc did not improve
Epoch 00017: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=2
max_len=30
nodes=100
mode=A
PCA audio=30
PCA visual=35
PCA text=100
accuracy=0.5043731778425656
best_valid_accuracy=0.4970845481049563
