/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/pandas/core/nanops.py:39: UserWarning: The installed version of bottleneck 0.7.0 is not supported in pandas and will be not be used
The minimum supported version is 1.0.0

  ver=ver, min_ver=_MIN_BOTTLENECK_VERSION), UserWarning)
/afs/inf.ed.ac.uk/user/s17/s1738075/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
pca_early_fusion_blstm.py:147: RuntimeWarning: invalid value encountered in divide
  train_set_audio = train_set_audio / audio_max
pca_early_fusion_blstm.py:149: RuntimeWarning: invalid value encountered in divide
  test_set_audio = test_set_audio / audio_max
2018-03-28 06:54:47.882633: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
This API will be deprecated in the future versions. Please check the Github page for the current API

Modality facet for video 8qrpnFRGt2A segment 13 is (partially) missing and is thus being replaced by zeros!

Train on 1283 samples, validate on 229 samples
Epoch 1/100

  64/1283 [>.............................] - ETA: 24s - loss: 0.6709 - acc: 0.6406
 192/1283 [===>..........................] - ETA: 7s - loss: 0.6818 - acc: 0.5729 
 320/1283 [======>.......................] - ETA: 4s - loss: 0.6765 - acc: 0.5938
 448/1283 [=========>....................] - ETA: 2s - loss: 0.6802 - acc: 0.5737
 512/1283 [==========>...................] - ETA: 2s - loss: 0.6852 - acc: 0.5664
 640/1283 [=============>................] - ETA: 1s - loss: 0.6835 - acc: 0.5563
 704/1283 [===============>..............] - ETA: 1s - loss: 0.6863 - acc: 0.5483
 768/1283 [================>.............] - ETA: 1s - loss: 0.6849 - acc: 0.5547
 896/1283 [===================>..........] - ETA: 0s - loss: 0.6836 - acc: 0.5569
 960/1283 [=====================>........] - ETA: 0s - loss: 0.6833 - acc: 0.5510
1024/1283 [======================>.......] - ETA: 0s - loss: 0.6837 - acc: 0.5459
1088/1283 [========================>.....] - ETA: 0s - loss: 0.6821 - acc: 0.5496
1216/1283 [===========================>..] - ETA: 0s - loss: 0.6824 - acc: 0.5493
1280/1283 [============================>.] - ETA: 0s - loss: 0.6810 - acc: 0.5523
1283/1283 [==============================] - 3s 2ms/step - loss: 0.6807 - acc: 0.5534 - val_loss: 0.6677 - val_acc: 0.5546

Epoch 00001: val_acc improved from -inf to 0.55459, saving model to classification_logs//blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 2/100

  64/1283 [>.............................] - ETA: 0s - loss: 0.6252 - acc: 0.6250
 128/1283 [=>............................] - ETA: 0s - loss: 0.6217 - acc: 0.6484
 192/1283 [===>..........................] - ETA: 0s - loss: 0.6201 - acc: 0.6667
 256/1283 [====>.........................] - ETA: 0s - loss: 0.6099 - acc: 0.6992
 384/1283 [=======>......................] - ETA: 0s - loss: 0.5987 - acc: 0.7161
 448/1283 [=========>....................] - ETA: 0s - loss: 0.6027 - acc: 0.6964
 512/1283 [==========>...................] - ETA: 0s - loss: 0.5994 - acc: 0.7012
 576/1283 [============>.................] - ETA: 0s - loss: 0.6032 - acc: 0.6892
 640/1283 [=============>................] - ETA: 0s - loss: 0.5997 - acc: 0.6937
 704/1283 [===============>..............] - ETA: 0s - loss: 0.5981 - acc: 0.6960
 768/1283 [================>.............] - ETA: 0s - loss: 0.5968 - acc: 0.6927
 832/1283 [==================>...........] - ETA: 0s - loss: 0.5965 - acc: 0.6947
 896/1283 [===================>..........] - ETA: 0s - loss: 0.5973 - acc: 0.6964
 960/1283 [=====================>........] - ETA: 0s - loss: 0.5958 - acc: 0.6979
1024/1283 [======================>.......] - ETA: 0s - loss: 0.5961 - acc: 0.6982
1088/1283 [========================>.....] - ETA: 0s - loss: 0.5973 - acc: 0.6958
1152/1283 [=========================>....] - ETA: 0s - loss: 0.5971 - acc: 0.6979
1216/1283 [===========================>..] - ETA: 0s - loss: 0.5981 - acc: 0.6982
1280/1283 [============================>.] - ETA: 0s - loss: 0.5958 - acc: 0.7000
1283/1283 [==============================] - 2s 1ms/step - loss: 0.5958 - acc: 0.6999 - val_loss: 0.6343 - val_acc: 0.6245

Epoch 00002: val_acc improved from 0.55459 to 0.62445, saving model to classification_logs//blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 3/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.5199 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.5110 - acc: 0.8359
 192/1283 [===>..........................] - ETA: 1s - loss: 0.5141 - acc: 0.8333
 256/1283 [====>.........................] - ETA: 1s - loss: 0.5115 - acc: 0.8281
 320/1283 [======>.......................] - ETA: 1s - loss: 0.5046 - acc: 0.8281
 384/1283 [=======>......................] - ETA: 1s - loss: 0.5079 - acc: 0.8203
 448/1283 [=========>....................] - ETA: 1s - loss: 0.5021 - acc: 0.8281
 512/1283 [==========>...................] - ETA: 1s - loss: 0.5008 - acc: 0.8262
 576/1283 [============>.................] - ETA: 0s - loss: 0.4989 - acc: 0.8229
 640/1283 [=============>................] - ETA: 0s - loss: 0.4996 - acc: 0.8172
 704/1283 [===============>..............] - ETA: 0s - loss: 0.4989 - acc: 0.8210
 768/1283 [================>.............] - ETA: 0s - loss: 0.4927 - acc: 0.8242
 832/1283 [==================>...........] - ETA: 0s - loss: 0.4914 - acc: 0.8233
 896/1283 [===================>..........] - ETA: 0s - loss: 0.4942 - acc: 0.8170
 960/1283 [=====================>........] - ETA: 0s - loss: 0.4914 - acc: 0.8156
1024/1283 [======================>.......] - ETA: 0s - loss: 0.4906 - acc: 0.8145
1088/1283 [========================>.....] - ETA: 0s - loss: 0.4916 - acc: 0.8107
1152/1283 [=========================>....] - ETA: 0s - loss: 0.4922 - acc: 0.8082
1216/1283 [===========================>..] - ETA: 0s - loss: 0.4896 - acc: 0.8100
1280/1283 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8070
1283/1283 [==============================] - 2s 1ms/step - loss: 0.4902 - acc: 0.8067 - val_loss: 0.6139 - val_acc: 0.6681

Epoch 00003: val_acc improved from 0.62445 to 0.66812, saving model to classification_logs//blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15/saved_models/best_validation_blstm_early_fusion_m_all_ep_100_bs_64_bn_False_dr_0.1_nl_1_ml_15.ckpt
Epoch 4/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.4583 - acc: 0.7969
 128/1283 [=>............................] - ETA: 1s - loss: 0.4223 - acc: 0.8516
 192/1283 [===>..........................] - ETA: 1s - loss: 0.4264 - acc: 0.8385
 256/1283 [====>.........................] - ETA: 1s - loss: 0.4159 - acc: 0.8359
 320/1283 [======>.......................] - ETA: 1s - loss: 0.4095 - acc: 0.8406
 384/1283 [=======>......................] - ETA: 1s - loss: 0.4022 - acc: 0.8411
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3937 - acc: 0.8504
 512/1283 [==========>...................] - ETA: 1s - loss: 0.3930 - acc: 0.8535
 576/1283 [============>.................] - ETA: 1s - loss: 0.3955 - acc: 0.8455
 640/1283 [=============>................] - ETA: 0s - loss: 0.3934 - acc: 0.8453
 704/1283 [===============>..............] - ETA: 0s - loss: 0.3886 - acc: 0.8509
 768/1283 [================>.............] - ETA: 0s - loss: 0.3952 - acc: 0.8438
 832/1283 [==================>...........] - ETA: 0s - loss: 0.3978 - acc: 0.8413
 896/1283 [===================>..........] - ETA: 0s - loss: 0.3932 - acc: 0.8449
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3909 - acc: 0.8500
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3892 - acc: 0.8525
1088/1283 [========================>.....] - ETA: 0s - loss: 0.3838 - acc: 0.8557
1152/1283 [=========================>....] - ETA: 0s - loss: 0.3861 - acc: 0.8533
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3861 - acc: 0.8536
1280/1283 [============================>.] - ETA: 0s - loss: 0.3856 - acc: 0.8555
1283/1283 [==============================] - 2s 2ms/step - loss: 0.3853 - acc: 0.8558 - val_loss: 0.6268 - val_acc: 0.6507

Epoch 00004: val_acc did not improve
Epoch 5/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.3885 - acc: 0.8438
 128/1283 [=>............................] - ETA: 2s - loss: 0.3469 - acc: 0.8594
 192/1283 [===>..........................] - ETA: 1s - loss: 0.3263 - acc: 0.8802
 256/1283 [====>.........................] - ETA: 1s - loss: 0.3330 - acc: 0.8750
 320/1283 [======>.......................] - ETA: 1s - loss: 0.3150 - acc: 0.8844
 384/1283 [=======>......................] - ETA: 1s - loss: 0.3157 - acc: 0.8854
 448/1283 [=========>....................] - ETA: 1s - loss: 0.3014 - acc: 0.8996
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2964 - acc: 0.9062
 576/1283 [============>.................] - ETA: 1s - loss: 0.2973 - acc: 0.9028
 640/1283 [=============>................] - ETA: 1s - loss: 0.2925 - acc: 0.9062
 704/1283 [===============>..............] - ETA: 1s - loss: 0.2953 - acc: 0.9020
 768/1283 [================>.............] - ETA: 0s - loss: 0.2912 - acc: 0.9036
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2860 - acc: 0.9038
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2991 - acc: 0.8951
 960/1283 [=====================>........] - ETA: 0s - loss: 0.3055 - acc: 0.8875
1024/1283 [======================>.......] - ETA: 0s - loss: 0.3017 - acc: 0.8916
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2987 - acc: 0.8915
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2991 - acc: 0.8889
1216/1283 [===========================>..] - ETA: 0s - loss: 0.3050 - acc: 0.8865
1280/1283 [============================>.] - ETA: 0s - loss: 0.3027 - acc: 0.8883
1283/1283 [==============================] - 2s 2ms/step - loss: 0.3022 - acc: 0.8885 - val_loss: 0.6680 - val_acc: 0.6507

Epoch 00005: val_acc did not improve
Epoch 6/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.2140 - acc: 0.9219
 128/1283 [=>............................] - ETA: 2s - loss: 0.2231 - acc: 0.9219
 192/1283 [===>..........................] - ETA: 2s - loss: 0.2322 - acc: 0.9167
 256/1283 [====>.........................] - ETA: 1s - loss: 0.2137 - acc: 0.9297
 320/1283 [======>.......................] - ETA: 1s - loss: 0.2097 - acc: 0.9375
 384/1283 [=======>......................] - ETA: 1s - loss: 0.2059 - acc: 0.9401
 448/1283 [=========>....................] - ETA: 1s - loss: 0.2098 - acc: 0.9375
 512/1283 [==========>...................] - ETA: 1s - loss: 0.2128 - acc: 0.9336
 576/1283 [============>.................] - ETA: 1s - loss: 0.2159 - acc: 0.9358
 640/1283 [=============>................] - ETA: 1s - loss: 0.2155 - acc: 0.9359
 704/1283 [===============>..............] - ETA: 0s - loss: 0.2147 - acc: 0.9332
 768/1283 [================>.............] - ETA: 0s - loss: 0.2173 - acc: 0.9349
 832/1283 [==================>...........] - ETA: 0s - loss: 0.2135 - acc: 0.9363
 896/1283 [===================>..........] - ETA: 0s - loss: 0.2137 - acc: 0.9353
 960/1283 [=====================>........] - ETA: 0s - loss: 0.2256 - acc: 0.9260
1024/1283 [======================>.......] - ETA: 0s - loss: 0.2209 - acc: 0.9287
1088/1283 [========================>.....] - ETA: 0s - loss: 0.2169 - acc: 0.9292
1152/1283 [=========================>....] - ETA: 0s - loss: 0.2232 - acc: 0.9262
1216/1283 [===========================>..] - ETA: 0s - loss: 0.2206 - acc: 0.9252
1280/1283 [============================>.] - ETA: 0s - loss: 0.2193 - acc: 0.9266
1283/1283 [==============================] - 2s 2ms/step - loss: 0.2201 - acc: 0.9260 - val_loss: 0.7160 - val_acc: 0.6681

Epoch 00006: val_acc did not improve
Epoch 7/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.1310 - acc: 0.9531
 128/1283 [=>............................] - ETA: 2s - loss: 0.1317 - acc: 0.9609
 192/1283 [===>..........................] - ETA: 1s - loss: 0.1441 - acc: 0.9583
 256/1283 [====>.........................] - ETA: 1s - loss: 0.1499 - acc: 0.9609
 320/1283 [======>.......................] - ETA: 1s - loss: 0.1461 - acc: 0.9625
 384/1283 [=======>......................] - ETA: 1s - loss: 0.1576 - acc: 0.9557
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1560 - acc: 0.9598
 512/1283 [==========>...................] - ETA: 1s - loss: 0.1550 - acc: 0.9590
 576/1283 [============>.................] - ETA: 1s - loss: 0.1578 - acc: 0.9549
 640/1283 [=============>................] - ETA: 1s - loss: 0.1543 - acc: 0.9563
 704/1283 [===============>..............] - ETA: 0s - loss: 0.1598 - acc: 0.9531
 768/1283 [================>.............] - ETA: 0s - loss: 0.1595 - acc: 0.9518
 832/1283 [==================>...........] - ETA: 0s - loss: 0.1557 - acc: 0.9531
 896/1283 [===================>..........] - ETA: 0s - loss: 0.1549 - acc: 0.9531
 960/1283 [=====================>........] - ETA: 0s - loss: 0.1538 - acc: 0.9531
1024/1283 [======================>.......] - ETA: 0s - loss: 0.1608 - acc: 0.9502
1088/1283 [========================>.....] - ETA: 0s - loss: 0.1659 - acc: 0.9476
1152/1283 [=========================>....] - ETA: 0s - loss: 0.1614 - acc: 0.9497
1216/1283 [===========================>..] - ETA: 0s - loss: 0.1576 - acc: 0.9515
1280/1283 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9516
1283/1283 [==============================] - 2s 2ms/step - loss: 0.1570 - acc: 0.9517 - val_loss: 0.7998 - val_acc: 0.6507

Epoch 00007: val_acc did not improve
Epoch 8/100

  64/1283 [>.............................] - ETA: 1s - loss: 0.0742 - acc: 0.9844
 128/1283 [=>............................] - ETA: 1s - loss: 0.0811 - acc: 0.9844
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0908 - acc: 0.9792
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0884 - acc: 0.9844
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0980 - acc: 0.9812
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0958 - acc: 0.9844
 448/1283 [=========>....................] - ETA: 1s - loss: 0.1024 - acc: 0.9799
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0989 - acc: 0.9824
 576/1283 [============>.................] - ETA: 1s - loss: 0.0967 - acc: 0.9826
 640/1283 [=============>................] - ETA: 1s - loss: 0.0973 - acc: 0.9797
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0970 - acc: 0.9801
 768/1283 [================>.............] - ETA: 0s - loss: 0.0937 - acc: 0.9818
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0956 - acc: 0.9808
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0933 - acc: 0.9821
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0925 - acc: 0.9823
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0908 - acc: 0.9834
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0922 - acc: 0.9835
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0912 - acc: 0.9835
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0910 - acc: 0.9836
1280/1283 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9812
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0957 - acc: 0.9813 - val_loss: 0.8942 - val_acc: 0.6594

Epoch 00008: val_acc did not improve
Epoch 9/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0543 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0492 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0532 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0516 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 2s - loss: 0.0544 - acc: 0.9938
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0518 - acc: 0.9948
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0516 - acc: 0.9933
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0505 - acc: 0.9941
 576/1283 [============>.................] - ETA: 1s - loss: 0.0494 - acc: 0.9931
 640/1283 [=============>................] - ETA: 1s - loss: 0.0488 - acc: 0.9938
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0543 - acc: 0.9901
 768/1283 [================>.............] - ETA: 1s - loss: 0.0563 - acc: 0.9883
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0588 - acc: 0.9868
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0588 - acc: 0.9877
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0573 - acc: 0.9885
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0586 - acc: 0.9873
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0614 - acc: 0.9853
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0623 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0626 - acc: 0.9836
1280/1283 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9844
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0642 - acc: 0.9836 - val_loss: 1.0263 - val_acc: 0.6288

Epoch 00009: val_acc did not improve
Epoch 10/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0316 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0401 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0376 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0383 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0457 - acc: 0.9906
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0526 - acc: 0.9870
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0604 - acc: 0.9821
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0587 - acc: 0.9844
 576/1283 [============>.................] - ETA: 1s - loss: 0.0694 - acc: 0.9792
 640/1283 [=============>................] - ETA: 1s - loss: 0.0745 - acc: 0.9781
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0715 - acc: 0.9801
 768/1283 [================>.............] - ETA: 1s - loss: 0.0681 - acc: 0.9818
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0656 - acc: 0.9832
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0631 - acc: 0.9844
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0651 - acc: 0.9833
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0646 - acc: 0.9834
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0642 - acc: 0.9835
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0638 - acc: 0.9844
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0658 - acc: 0.9836
1280/1283 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9844
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0642 - acc: 0.9844 - val_loss: 1.0241 - val_acc: 0.6419

Epoch 00010: val_acc did not improve
Epoch 11/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0647 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0438 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 1s - loss: 0.0361 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 2s - loss: 0.0416 - acc: 0.9922
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0481 - acc: 0.9875
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0439 - acc: 0.9896
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0444 - acc: 0.9888
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0442 - acc: 0.9902
 576/1283 [============>.................] - ETA: 1s - loss: 0.0459 - acc: 0.9878
 640/1283 [=============>................] - ETA: 1s - loss: 0.0453 - acc: 0.9891
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0432 - acc: 0.9901
 768/1283 [================>.............] - ETA: 0s - loss: 0.0417 - acc: 0.9909
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0408 - acc: 0.9916
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0395 - acc: 0.9922
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0388 - acc: 0.9927
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0389 - acc: 0.9932
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0386 - acc: 0.9926
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0380 - acc: 0.9931
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0373 - acc: 0.9934
1280/1283 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9938
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0364 - acc: 0.9938 - val_loss: 1.1537 - val_acc: 0.6288

Epoch 00011: val_acc did not improve
Epoch 12/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0302 - acc: 0.9844
 128/1283 [=>............................] - ETA: 2s - loss: 0.0335 - acc: 0.9922
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0265 - acc: 0.9948
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0241 - acc: 0.9961
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0238 - acc: 0.9969
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0221 - acc: 0.9974
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0206 - acc: 0.9978
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0201 - acc: 0.9980
 576/1283 [============>.................] - ETA: 1s - loss: 0.0217 - acc: 0.9983
 640/1283 [=============>................] - ETA: 1s - loss: 0.0214 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0204 - acc: 0.9986
 768/1283 [================>.............] - ETA: 0s - loss: 0.0200 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0202 - acc: 0.9988
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0199 - acc: 0.9989
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0192 - acc: 0.9990
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0187 - acc: 0.9990
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0188 - acc: 0.9991
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0187 - acc: 0.9991
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0189 - acc: 0.9992
1280/1283 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9992
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0195 - acc: 0.9992 - val_loss: 1.2653 - val_acc: 0.6201

Epoch 00012: val_acc did not improve
Epoch 13/100

  64/1283 [>.............................] - ETA: 2s - loss: 0.0135 - acc: 1.0000
 128/1283 [=>............................] - ETA: 2s - loss: 0.0114 - acc: 1.0000
 192/1283 [===>..........................] - ETA: 2s - loss: 0.0131 - acc: 1.0000
 256/1283 [====>.........................] - ETA: 1s - loss: 0.0124 - acc: 1.0000
 320/1283 [======>.......................] - ETA: 1s - loss: 0.0134 - acc: 1.0000
 384/1283 [=======>......................] - ETA: 1s - loss: 0.0126 - acc: 1.0000
 448/1283 [=========>....................] - ETA: 1s - loss: 0.0129 - acc: 1.0000
 512/1283 [==========>...................] - ETA: 1s - loss: 0.0129 - acc: 1.0000
 576/1283 [============>.................] - ETA: 1s - loss: 0.0131 - acc: 1.0000
 640/1283 [=============>................] - ETA: 1s - loss: 0.0148 - acc: 0.9984
 704/1283 [===============>..............] - ETA: 1s - loss: 0.0150 - acc: 0.9986
 768/1283 [================>.............] - ETA: 1s - loss: 0.0161 - acc: 0.9987
 832/1283 [==================>...........] - ETA: 0s - loss: 0.0196 - acc: 0.9964
 896/1283 [===================>..........] - ETA: 0s - loss: 0.0198 - acc: 0.9967
 960/1283 [=====================>........] - ETA: 0s - loss: 0.0205 - acc: 0.9969
1024/1283 [======================>.......] - ETA: 0s - loss: 0.0204 - acc: 0.9971
1088/1283 [========================>.....] - ETA: 0s - loss: 0.0197 - acc: 0.9972
1152/1283 [=========================>....] - ETA: 0s - loss: 0.0193 - acc: 0.9974
1216/1283 [===========================>..] - ETA: 0s - loss: 0.0192 - acc: 0.9975
1280/1283 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9969
1283/1283 [==============================] - 3s 2ms/step - loss: 0.0197 - acc: 0.9969 - val_loss: 1.3017 - val_acc: 0.6332

Epoch 00013: val_acc did not improve
Epoch 00013: early stopping
batch_size=64
batch_norm=False
dropout_rate=0.1
n_layers=1
max_len=15
nodes=100
mode=all
PCA audio=30
PCA visual=10
PCA text=100
accuracy=0.6559766763848397
best_valid_accuracy=0.7128279883381924
